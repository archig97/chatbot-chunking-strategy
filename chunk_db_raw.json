[
  {
    "id": "sec_0000",
    "title": "(preamble)",
    "pages": [
      1,
      2,
      3,
      4,
      5
    ],
    "text_blocks": [
      "Engineering Software as a Service: An Agile Approach Using Cloud Computing Second Edition, 2.0b7 Armando Fox and David Patterson July 8, 2021 Copyright 2021 by Armando Fox and David Patterson. You are free to make digital or printed copies of this material for your own personal use. You may not redistribute this material in either digital or printed form, whether or not for \ufb01nancial gain, without the express permission of the copyright holders. Book version: 2.0b7 The cover background is a photo of the Aqueduct of Segovia, Spain. We chose it as an example of a beautiful, long-lasting design. The full aqueduct is about 20 miles (32 km) long and was built by the Romans in the 1st or 2nd century CE. This photo is of the half- mile long, 92 foot high segment (0.8 km long, 28 m high) built using unmortared granite blocks. The Roman designers followed the architectural principles in the ten-volume series De Architectura (\u201cOn Architecture\u201d), written in 15 BCE by Marcus Vitruvius Pollio. It was untouched until the 1500s CE, when King Ferdinand and Queen Isabella performed the \ufb01rst reconstruction of these arches. The aqueduct was in use and delivering water until recently. Cover photo derived from an original photo by Bernard Gagnon, licensed un- https://commons.wikimedia.org/wiki/Aqueduct#/media/ der CC-BY-SA 3.0, File:Aqueduct_of_Segovia_02.jpg Both the print book and ebook were prepared with LATEX and a series of Ruby packages, all freely available at http://github.com/armandofox/latex2ebook. Arthur Klepchukov designed the covers and graphics for all versions. Publisher\u2019s Cataloging-in-Publication Fox, Armando. Engineering software as a service : an agile approach using cloud computing / Armando Fox and David Patterson. -- Second edition. Includes bibliographical references. ISBN 978-1-7352338-0-2 1. Software engineering. 2. Cloud computing. I. Patterson, David A. II. Title. QA76.758.F684 2020 005.1 QBI14-600139 About the Authors Armando Fox (pronouns: he, him, \u00e9l) is a Professor of Computer Science, Diversity and Eq- uity Of\ufb01cer at both the EECS Department level and Campus level, and Faculty Advisor for Digital Learning Strategy at UC Berkeley. He is an ACM Distinguished Scientist and in 2015 received the ACM Karl V. Karlstrom Outstanding Educator Award for his work on software engineering education. During his previous time at Stanford, he received teaching and men- toring awards from the Associated Students of Stanford University, the Society of Women Engineers, and Tau Beta Pi Engineering Honor Society. In 2016 he and co-author David Pat- terson received the Most Promising New Textbook award (\u201cTexty\u201d) from the Textbook and Academic Authors Association for the First Edition of this book. In previous lives he helped design the Intel Pentium Pro microprocessor, founded a successful startup to commercialize his UC Berkeley dissertation research on mobile computing including the world\u2019s \ufb01rst mo- bile graphical web browser (Top Gun Wingman on Palm Pilot), and co-founded a couple of startups that were artistic successes. He received his BS in electrical engineering and com- puter science from MIT and his MS from the University of Illinois at Urbana-Champaign. He is also a classically-trained musician, freelance Music Director, and bilingual/bicultural (Cuban-American) New Yorker transplanted to San Francisco. David Patterson (pronouns: he, him) recently retired from a 40-year career as a Professor of Computer Science at UC Berkeley. In the past, he served as Chair of Berkeley\u2019s Computer Science Division, Chair of the Computing Research Association, and President of the Asso- ciation for Computing Machinery. His best-known research projects are Reduced Instruction Set Computers (RISC), Redundant Arrays of Inexpensive Disks (RAID), and Networks of Workstations (NOW). This research led to many papers, 6 books, and more than 35 hon- ors, including election to the National Academy of Engineering, the National Academy of Sciences, and the Silicon Valley Engineering Hall of Fame; being named a Fellow of the Computer History Museum, ACM, IEEE, and both AAAS organizations; and most recently, the ACM A.M. Turing Award, shared with Prof. John Hennessy of Stanford University for their work on RISC and their quantitative approach to computer architecture and design. His teaching awards include the UC Berkeley Distinguished Teaching Award, the ACM Karl V. Karlstrom Outstanding Educator Award, the IEEE Mulligan Education Medal, and the IEEE Undergraduate Teaching Award. Prior to winning the Textbook Excellence Award (\u201cTexty\u201d) for this book, he received one for his pioneering textbook on computer architec- ture. He received all his degrees from UCLA, which awarded him an Outstanding Engineer- ing Academic Alumni Award. He grew up in California, and for fun he enters sporting events with his two adult sons, including weekly soccer games and charity bike rides. i ii This is beta version 2.0b7. There are three \u201cplaceholders\u201d for new programming assign- ments (CHIPS\u2014see below) that are still being developed. Associations (CHIPS 5.7) and Caching and Indices (CHIPS 12.8) will provide hands-on practice for those concepts in the corresponding chapters. We are also working on a JavaScript/AJAX CHIPS (6.9). JavaScript frameworks continue to proliferate, including many that barely existed when the First Edition was released, while JavaScript continues to bring unique debugging and programming challenges that are not as well supported by tools as Ruby and Rails. As a result of all this churn, the material in Chapter 6 is still evolving. Quick Contents Preface to the Second Edition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii 1 Introduction to Software as a Service, Agile Development, and Cloud Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Part I: Software as a Service: Frameworks and Languages 2 3 4 5 6 How to Learn a New Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . SaaS Application Architecture: Microservices, APIs, and REST . . . SaaS Framework: Rails as a Model\u2013View\u2013Controller Framework . SaaS Framework: Advanced Programming Abstractions for SaaS . Mobile and Desktop SaaS Clients: JavaScript Introduction . . . . . . . . Part II: Agile Software Development 7 8 9 10 11 12 Requirements: BDD and User Stories . . . . . . . . . . . . . . . . . . . . . . . . . . . . Testing: Test-Driven Development . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Software Maintenance: Enhancing Legacy Software Using Refac- toring and Agile Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Agile Teams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Design Patterns for SaaS Apps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Dev/Ops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 72 96 124 152 204 236 268 302 336 370"
    ]
  },
  {
    "id": "sec_0001",
    "title": "Afterword",
    "pages": [
      5
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410"
    ]
  },
  {
    "id": "sec_0002",
    "title": "Contents",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0003",
    "title": "Preface",
    "pages": [
      6
    ],
    "text_blocks": [
      "viii . . . . . Introduction ."
    ]
  },
  {
    "id": "sec_0004",
    "title": "1 Introduction to Software as a Service, Agile Development, and Cloud Computing",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 5 1.1"
    ]
  },
  {
    "id": "sec_0005",
    "title": "1.2 Software Development Processes: Plan-and-Document",
    "pages": [
      6
    ],
    "text_blocks": [
      "6"
    ]
  },
  {
    "id": "sec_0006",
    "title": "1.3 Software Development Processes: The Agile Manifesto . . . . . . . . . . . . 12",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0007",
    "title": "1.4 Software Quality Assurance: Testing . . . . . . . . . . . . . . . . . . . . . . 17",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0008",
    "title": "1.5 Productivity: Conciseness, Synthesis, Reuse, and Tools . . . . . . . . . . . . 19",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0009",
    "title": "1.6 SaaS and Service Oriented Architecture . . . . . . . . . . . . . . . . . . . . 22",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0010",
    "title": "1.7 Deploying SaaS: Cloud Computing . . . . . . . . . . . . . . . . . . . . . . . 25",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0011",
    "title": "1.8 Deploying SaaS: Browsers and Mobile . . . . . . . . . . . . . . . . . . . . . 27",
    "pages": [
      6
    ],
    "text_blocks": [
      "1.9 Beautiful vs. Legacy Code . . . . . . . . . . . . . . . . . . . . . . . . . . . 31"
    ]
  },
  {
    "id": "sec_0012",
    "title": "1.10 Guided Tour and How To Use This Book . . . . . . . . . . . . . . . . . . . 33",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0013",
    "title": "1.11 Fallacies and Pitfalls",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 36"
    ]
  },
  {
    "id": "sec_0014",
    "title": "1.12 Concluding Remarks: Software Engineering Is More Than Programming . . 37",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . I Software as a Service: Frameworks and Languages 43"
    ]
  },
  {
    "id": "sec_0015",
    "title": "2 How to Learn a New Language",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . 44"
    ]
  },
  {
    "id": "sec_0016",
    "title": "2.1 Prelude: Learning to Learn Languages and Frameworks . . . . . . . . . . . . 46",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0017",
    "title": "2.2 Pair Programming .",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 2.3 Introducing Ruby, an Object-Oriented Language . . . . . . . . . . . . . . . . 51"
    ]
  },
  {
    "id": "sec_0018",
    "title": "2.4 Ruby Idioms: Poetry Mode, Blocks, Duck Typing . . . . . . . . . . . . . . . 59",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 64"
    ]
  },
  {
    "id": "sec_0019",
    "title": "2.5 CHIPS: Ruby Intro .",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0020",
    "title": "2.6 Gems and Bundler: Library Management in Ruby . . . . . . . . . . . . . . . 64",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0021",
    "title": "2.7 Fallacies and Pitfalls",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 67"
    ]
  },
  {
    "id": "sec_0022",
    "title": "2.8 Concluding Remarks: How (Not) To Learn a Language By Googling . . . . . 69",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0023",
    "title": "3 SaaS Application Architecture: Microservices, APIs, and REST",
    "pages": [
      6
    ],
    "text_blocks": [
      "72"
    ]
  },
  {
    "id": "sec_0024",
    "title": "3.1 The Web\u2019s Client\u2013Server Architecture . . . . . . . . . . . . . . . . . . . . . 74",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0025",
    "title": "3.2 SaaS Communication Uses HTTP Routes",
    "pages": [
      6
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . 76 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80"
    ]
  },
  {
    "id": "sec_0026",
    "title": "3.3 CHIPS: HTTP and URIs",
    "pages": [
      6
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0027",
    "title": "3.4 From Web Sites to Microservices: Service-Oriented Architecture . . . . . . . 80",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0028",
    "title": "3.5 RESTful APIs: Everything is a Resource . . . . . . . . . . . . . . . . . . . . 84",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0029",
    "title": "3.6 RESTful URIs, API Calls, and JSON . . . . . . . . . . . . . . . . . . . . . . 89",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0030",
    "title": "3.7 CHIPS: Create and Deploy a Simple SaaS App . . . . . . . . . . . . . . . . 92",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 92"
    ]
  },
  {
    "id": "sec_0031",
    "title": "3.8 Fallacies and Pitfalls",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0032",
    "title": "3.9 Concluding Remarks: Continuity From CGI to SOA . . . . . . . . . . . . . 94",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . ."
    ]
  },
  {
    "id": "sec_0033",
    "title": "4 SaaS Framework: Rails as a Model\u2013View\u2013Controller Framework",
    "pages": [
      7
    ],
    "text_blocks": [
      "96"
    ]
  },
  {
    "id": "sec_0034",
    "title": "4.1 The Model\u2013View\u2013Controller (MVC) Architecture . . . . . . . . . . . . . . . 98",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0035",
    "title": "4.2 Rails Models: Databases and Active Record . . . . . . . . . . . . . . . . . . 100",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 105"
    ]
  },
  {
    "id": "sec_0036",
    "title": "4.3 CHIPS: ActiveRecord Basics .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . 105"
    ]
  },
  {
    "id": "sec_0037",
    "title": "4.4 Routes, Controllers, and Views .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . 110 ."
    ]
  },
  {
    "id": "sec_0038",
    "title": "4.5 CHIPS: Rails Routes .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 111 ."
    ]
  },
  {
    "id": "sec_0039",
    "title": "4.6 Forms .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0040",
    "title": "4.7 CHIPS: Hangperson on Rails .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 116 ."
    ]
  },
  {
    "id": "sec_0041",
    "title": "4.8 Debugging: When Things Go Wrong . . . . . . . . . . . . . . . . . . . . . . 116",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0042",
    "title": "4.9 CHIPS: Hello Rails .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 120 . . . . . . . . . . . . . . . . . . . . . . 120"
    ]
  },
  {
    "id": "sec_0043",
    "title": "4.10 Fallacies and Pitfalls",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0044",
    "title": "4.11 Concluding Remarks: Rails as a Service Framework . . . . . . . . . . . . . 121",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0045",
    "title": "5 SaaS Framework: Advanced Programming Abstractions for SaaS",
    "pages": [
      7
    ],
    "text_blocks": [
      "124"
    ]
  },
  {
    "id": "sec_0046",
    "title": "5.1 DRYing Out MVC: Partials, Validations and Filters . . . . . . . . . . . . . . 126",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0047",
    "title": "5.2 Single Sign-On and Third-Party Authentication . . . . . . . . . . . . . . . . 131",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . 136"
    ]
  },
  {
    "id": "sec_0048",
    "title": "5.3 CHIPS: Rails Intro .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . 136 ."
    ]
  },
  {
    "id": "sec_0049",
    "title": "5.4 Associations and Foreign Keys .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 140 . ."
    ]
  },
  {
    "id": "sec_0050",
    "title": "5.5 Through-Associations .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 143"
    ]
  },
  {
    "id": "sec_0051",
    "title": "5.6 RESTful Routes for Associations .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 146 ."
    ]
  },
  {
    "id": "sec_0052",
    "title": "5.7 CHIPS: Associations .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 147 ."
    ]
  },
  {
    "id": "sec_0053",
    "title": "5.8 Other Types of Code .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 149 . ."
    ]
  },
  {
    "id": "sec_0054",
    "title": "5.9 Fallacies and Pitfalls",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0055",
    "title": "5.10 Concluding Remarks: Languages, Productivity, and Beauty . . . . . . . . . . 149",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0056",
    "title": "6 Mobile and Desktop SaaS Clients: JavaScript Introduction",
    "pages": [
      7
    ],
    "text_blocks": [
      "JavaScript: The Big Picture . . Introducing ECMAScript . 152 6.1 . . . . . . . . . . . . . . . . . . . . . . 154 . . . . . . . . . . . . . . . . . . . . . . 157 6.2"
    ]
  },
  {
    "id": "sec_0057",
    "title": "6.3 Classes, Functions and Constructors . . . . . . . . . . . . . . . . . . . . . . 163",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0058",
    "title": "6.4 The Document Object Model (DOM) and jQuery . . . . . . . . . . . . . . . 166",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0059",
    "title": "6.5 The DOM and Accessibility .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 169 . . . . . . . . . . . . . . . . . . . . . . 173 ."
    ]
  },
  {
    "id": "sec_0060",
    "title": "6.6 Events and Callbacks .",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0061",
    "title": "6.7 AJAX: Asynchronous JavaScript And XML . . . . . . . . . . . . . . . . . . 178",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0062",
    "title": "6.8 Testing JavaScript and AJAX .",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 183"
    ]
  },
  {
    "id": "sec_0063",
    "title": "6.9 CHIPS: AJAX Enhancements to RottenPotatoes . . . . . . . . . . . . . . . . 190",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 190"
    ]
  },
  {
    "id": "sec_0064",
    "title": "6.10 Single-Page Apps and JSON APIs .",
    "pages": [
      7
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0065",
    "title": "6.11 Fallacies and Pitfalls",
    "pages": [
      7
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 195 ."
    ]
  },
  {
    "id": "sec_0066",
    "title": "6.12 Concluding Remarks: JavaScript Past, Present and Future . . . . . . . . . . . 199",
    "pages": [
      7,
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . v II Agile Software Development 203"
    ]
  },
  {
    "id": "sec_0067",
    "title": "7 Requirements: BDD and User Stories",
    "pages": [
      8
    ],
    "text_blocks": [
      ". 204 . . . . . . . . . . . . . . . . . . . 206"
    ]
  },
  {
    "id": "sec_0068",
    "title": "7.1 Behavior-Driven Design and User Stories",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 209"
    ]
  },
  {
    "id": "sec_0069",
    "title": "7.2 SMART User Stories .",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . 211"
    ]
  },
  {
    "id": "sec_0070",
    "title": "7.3 Lo-Fi User Interface Sketches and Storyboards",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213"
    ]
  },
  {
    "id": "sec_0071",
    "title": "7.4 Points and Velocity .",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216 ."
    ]
  },
  {
    "id": "sec_0072",
    "title": "7.5 Agile Cost Estimation .",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . 217"
    ]
  },
  {
    "id": "sec_0073",
    "title": "7.6 Cucumber: From User Stories to Acceptance Tests",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0074",
    "title": "7.7 CHIPS: Intro to BDD and Cucumber . . . . . . . . . . . . . . . . . . . . . . 220",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0075",
    "title": "7.8 Explicit vs. Implicit and Imperative vs. Declarative Scenarios . . . . . . . . . 220",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0076",
    "title": "7.9 The Plan-And-Document Perspective on Documentation . . . . . . . . . . . 223",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 230"
    ]
  },
  {
    "id": "sec_0077",
    "title": "7.10 Fallacies and Pitfalls",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0078",
    "title": "7.11 Concluding Remarks: Pros and Cons of BDD . . . . . . . . . . . . . . . . . 233",
    "pages": [
      8
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0079",
    "title": "8 Testing: Test-Driven Development",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . Isolating Code: Doubles and Seams 236"
    ]
  },
  {
    "id": "sec_0080",
    "title": "8.1 FIRST, TDD, and Red\u2013Green\u2013Refactor",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . 238"
    ]
  },
  {
    "id": "sec_0081",
    "title": "8.2 Anatomy of a Test Case: Arrange, Act, Assert . . . . . . . . . . . . . . . . . 240",
    "pages": [
      8
    ],
    "text_blocks": [
      "8.3 . . . . . . . . . . . . . . . . . . . . . . 243 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248"
    ]
  },
  {
    "id": "sec_0082",
    "title": "8.4 Stubbing the Internet",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . 249"
    ]
  },
  {
    "id": "sec_0083",
    "title": "8.5 CHIPS: Intro to RSpec on Rails",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 249"
    ]
  },
  {
    "id": "sec_0084",
    "title": "8.6 Fixtures and Factories .",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0085",
    "title": "8.7 Coverage Concepts and Types of Tests . . . . . . . . . . . . . . . . . . . . . 255",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0086",
    "title": "8.8 Other Testing Approaches and Terminology . . . . . . . . . . . . . . . . . . 258",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0087",
    "title": "8.9 CHIPS: The Acceptance Test/Unit Test Cycle . . . . . . . . . . . . . . . . . 260",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0088",
    "title": "8.10 The Plan-And-Document Perspective on Testing . . . . . . . . . . . . . . . . 260",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0089",
    "title": "8.11 Fallacies and Pitfalls",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 264"
    ]
  },
  {
    "id": "sec_0090",
    "title": "8.12 Concluding Remarks: TDD vs. Conventional Debugging . . . . . . . . . . . 266",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0091",
    "title": "9 Software Maintenance: Enhancing Legacy Software Using Refactoring and Ag-",
    "pages": [
      8
    ],
    "text_blocks": [
      "ile Methods 268"
    ]
  },
  {
    "id": "sec_0092",
    "title": "9.1 What Makes Code \u201cLegacy\u201d and How Can Agile Help? . . . . . . . . . . . . 270",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0093",
    "title": "9.2 Exploring a Legacy Codebase",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . 273"
    ]
  },
  {
    "id": "sec_0094",
    "title": "9.3 Establishing Ground Truth With Characterization Tests . . . . . . . . . . . . 277",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0095",
    "title": "9.4 Comments and Commits: Documenting Code . . . . . . . . . . . . . . . . . 279",
    "pages": [
      8
    ],
    "text_blocks": [
      "9.5 Metrics, Code Smells, and SOFA . . . . . . . . . . . . . . . . . . . . . . . . 281"
    ]
  },
  {
    "id": "sec_0096",
    "title": "9.6 Method-Level Refactoring: Replacing Dependencies With Seams",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . 286"
    ]
  },
  {
    "id": "sec_0097",
    "title": "9.7 The Plan-And-Document Perspective on Working With Legacy Code . . . . . 292",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 297"
    ]
  },
  {
    "id": "sec_0098",
    "title": "9.8 Fallacies and Pitfalls",
    "pages": [
      8
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0099",
    "title": "9.9 Concluding Remarks: Continuous Refactoring . . . . . . . . . . . . . . . . . 298",
    "pages": [
      8
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0100",
    "title": "10 Agile Teams",
    "pages": [
      8
    ],
    "text_blocks": [
      "302"
    ]
  },
  {
    "id": "sec_0101",
    "title": "10.1 It Takes a Team: Two-Pizza and Scrum . . . . . . . . . . . . . . . . . . . . . 304",
    "pages": [
      8
    ],
    "text_blocks": [
      "10.2 Using Branches Effectively . . . . . . . . . . . . . . . . . . . . . . . . . . . 306 10.3 Pull Requests and Code Reviews . . . . . . . . . . . . . . . . . . . . . . . . 311"
    ]
  },
  {
    "id": "sec_0102",
    "title": "10.4 Delivering the Backlog Using Continuous Integration . . . . . . . . . . . . . 315",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 320"
    ]
  },
  {
    "id": "sec_0103",
    "title": "10.5 CHIPS: Agile Iterations .",
    "pages": [
      8
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . 320"
    ]
  },
  {
    "id": "sec_0104",
    "title": "10.6 Reporting and Fixing Bugs: The Five R\u2019s",
    "pages": [
      8
    ],
    "text_blocks": [
      "vi"
    ]
  },
  {
    "id": "sec_0105",
    "title": "10.7 The Plan-And-Document Perspective on Managing Teams",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0106",
    "title": "10.8 Fallacies and Pitfalls",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0107",
    "title": "10.9 Concluding Remarks: From Solo Developer to Teams of Teams",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . 322 . . . . . . . . . . . . . . . . . . . . . . 330 . . . . . . . 332 . . . . . vii"
    ]
  },
  {
    "id": "sec_0108",
    "title": "11 Design Patterns for SaaS Apps",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . 336"
    ]
  },
  {
    "id": "sec_0109",
    "title": "11.1 Patterns, Antipatterns, and SOLID Class Architecture . . . . . . . . . . . . . 338",
    "pages": [
      9
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0110",
    "title": "11.2 Just Enough UML .",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . 342 . . . . . . . . . . . . . . . . . . . . . . 345 ."
    ]
  },
  {
    "id": "sec_0111",
    "title": "11.3 Single Responsibility Principle .",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . 347 . . . ."
    ]
  },
  {
    "id": "sec_0112",
    "title": "11.4 Open/Closed Principle .",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 351"
    ]
  },
  {
    "id": "sec_0113",
    "title": "11.5 Liskov Substitution Principle .",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . 354"
    ]
  },
  {
    "id": "sec_0114",
    "title": "11.6 Dependency Injection Principle .",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0115",
    "title": "11.7 Demeter Principle .",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 358 ."
    ]
  },
  {
    "id": "sec_0116",
    "title": "11.8 The Plan-And-Document Perspective on Design Patterns . . . . . . . . . . . 362",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 363"
    ]
  },
  {
    "id": "sec_0117",
    "title": "11.9 6S: A Clean Code Checklist",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . 365 11.10Fallacies and Pitfalls . . . . . . . . . . 366 11.11Concluding Remarks: Frameworks Capture Design Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0118",
    "title": "12 Dev/Ops",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . 370 . . . . . . . . . . . . . . . . . . . . . . 373"
    ]
  },
  {
    "id": "sec_0119",
    "title": "12.1 From Development to Deployment .",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0120",
    "title": "12.2 Three-Tier Architecture .",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . 375 . ."
    ]
  },
  {
    "id": "sec_0121",
    "title": "12.3 Responsiveness, Service Level Objectives, and Apdex . . . . . . . . . . . . . 378",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . 382 ."
    ]
  },
  {
    "id": "sec_0122",
    "title": "12.4 Releases and Feature Flags .",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0123",
    "title": "12.5 Monitoring and Finding Bottlenecks . . . . . . . . . . . . . . . . . . . . . . 385",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0124",
    "title": "12.6 Improving Rendering and Database Performance With Caching . . . . . . . . 387",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0125",
    "title": "12.7 Avoiding Abusive Database Queries . . . . . . . . . . . . . . . . . . . . . . 391",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0126",
    "title": "12.8 CHIPS: Exploiting Caching and Indices . . . . . . . . . . . . . . . . . . . . 394",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0127",
    "title": "12.9 Security: Defending Customer Data in Your App . . . . . . . . . . . . . . . 394",
    "pages": [
      9
    ],
    "text_blocks": [
      "12.10The Plan-And-Document Perspective on Operations . . . . . . . . . . . . . . 400 . . . . . . . . . . . . . . . . . . . . . . 402 12.11Fallacies and Pitfalls . . . . . . . . . . . . . . . . . . 406 12.12Concluding Remarks: Beyond PaaS Basics . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0128",
    "title": "13 Afterword",
    "pages": [
      9
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0129",
    "title": "13.1 Looking Backwards .",
    "pages": [
      9
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0130",
    "title": "13.2 Looking Forwards .",
    "pages": [
      9
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0131",
    "title": "13.3 Essential Readings",
    "pages": [
      9
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0132",
    "title": "13.4 Last Words",
    "pages": [
      9
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410 . . . . . . . . . . . . . . . . . . . . 412 . . . . . . . . . . . . . . . . . . . . . . 413 . . . . . . . . . . . . . . . . . . . . . . 415 . . . . . . . . . . . . . . . . . . . . . . 416"
    ]
  },
  {
    "id": "sec_0133",
    "title": "Preface to the Second Edition",
    "pages": [
      10,
      11
    ],
    "text_blocks": [
      "Why so many quotes? We think quotes make the book more fun to read, but they are also an ef\ufb01cient mechanism to pass along wisdom from the elders, and to help set cultural standards for good software engineering. We also want readers to pick up a bit of history of the \ufb01eld, which is why we feature quotes from Turing Award winners to open each chapter and throughout the text. If you want to build a ship, don\u2019t drum up the men to gather wood, divide the work and give orders. Instead, teach them to yearn for the vast and endless sea. \u2014Antoine de Saint-Exup\u00e9ry, Citadelle, 1948 If you\u2019re nostalgic for the Welcome from the First Edition, you can read it at http://www.saasbook.info/welcome-1st-edition1. We created the First Edition of ESaaS in 2014 to help other instructors and students of software engineering practice what we had discovered: Agile+SaaS is not just a great way to develop and deploy software, it\u2019s also a great \ufb01t for teaching software engineering. We have been humbled by the success of the book, the accompanying instructor materials (for which visit saasbook.info2), and the Massive Open Online Courses on edX as a way of \u201cspreading the word!\u201d What\u2019s New: COD, CHIPS, and Codio This Second Edition has an improved structure (in our opinion) as well as substantial revi- sions to nearly half of the material. COD and CHIPS. Most of the book\u2019s sections are Content-Oriented Didactics (COD): the conceptual vocabulary that shows the learner how to think about an important idea. In- terspersed after every few COD sections are Coding/Hands-on Integrated Programming ac- tivities (CHIPS), where students learn by doing, applying the ideas of the COD sections in hands-on exercises. Each CHIPS has a rating from one to three \u201caqueducts\u201d re\ufb02ecting the relative time and effort required to complete it. All-in-one course using Codio. We have worked closely with Codio to integrate COD, CHIPS, and autograding into their education-focused IDE. We strongly urge instructors or students to use Codio to get started as quickly as possible, including built-in autograding for most of the CHIPS and a precon\ufb01gured curated environment with the correct versions of all tools needed. Visit codio.com/esaas3 to get started. If you\u2019re not using Codio, the starter code and student-facing documentation for each CHIPS are available in a public GitHub repository whose name is given as part of each CHIPS, and instructors can visit saasbook.info to gain access to reference solutions and Gradescope-compatible autograders. ix What\u2019s New: Major Content Changes Mobile-\ufb01rst, API-\ufb01rst exposition of SaaS. Since the First Edition, \u201ccloud + client\u201d has remained the dominant way that software is developed, but SaaS has transitioned from deliv- ering primarily HTML views to delivering data to mobile clients over APIs. As well, much greater attention is being paid to designing for persons with disabilities. We therefore imme- diately motivate the use of a resource-based, API-centric approach to thinking about server design, and the use of mobile-\ufb01rst and mobile-friendly frameworks based on open standards, such as Bootstrap, for the client side. The new \u201cAPI \ufb01rst\u201d exposition should empower learn- ers to think about resource-centric design of their apps and how a RESTful API exposes those resources to a client, and then transfer this thinking to the development of mobile apps. From \u201clearning Ruby and Rails\u201d to \u201clearning a language and framework.\u201d Recog- nizing that languages and frameworks continue to evolve, our expositions of Ruby, Rails, and JavaScript now suggest a more general strategy for learning new languages and frame- works rapidly, and on understanding the relationship between a framework and the language features that make it work well. What Has Not Changed? Our students at Berkeley still ask \u201cWill this course teach me X?\u201d where popular values of X in 2019 include React, AWS Lambda, MongoDB, and Node. Our answer has not changed since the First Edition. The software ecosystem evolves so rapidly that at any given time you will have many frameworks and tools from which to choose. Since our choices won\u2019t please everyone and will probably be outdated in a few years anyway, we still choose the tools that best support our pedagogical goal of teaching a particular methodology for developing great software. Our hope is that learners can use our suggested approaches and principles to help learn new languages and frameworks rapidly. Acknowledgments Some acknowledgments are in order, as it truly takes a village to create and maintain a good set of course materials. Beyond the people we thanked in the First Edition, the following colleagues were particularly helpful in reviewing the technical accuracy of the Second Edi- tion changes: Prof. Kristin Stephens-Martinez, Duke University (Chapter 1); Prof. Mark Smucker, University of Waterloo (Chapter 2); Blagovesta Kostova, EPFL (Chapter 3); Prof. Michael Verdicchio, The Citadel Military College of South Carolina (Chapter 4); Lic. Mat\u00edas Mascazzini, independent Rails developer (Chapter 5); Prof. Tom Hastings, University of Col- orado at Colorado Springs (Chapter 6); Prof. Hank Walker, Texas A&M University (Chapters"
    ]
  },
  {
    "id": "sec_0134",
    "title": "7 and 8); Prof. Prabhat Vaish, New Jersey Institute of Technology (Chapter 9); Prof. Anastasia",
    "pages": [
      11,
      12,
      13,
      14
    ],
    "text_blocks": [
      "Kurdia, Tulane University (Chapter 10); Prof. Ed Gehringer, North Carolina State University (Chapter 11); Prof. Daniel Cordeiro, Universidade de S\u00e3o Paulo (Chapter 12). Finally, many thanks to Peter Zhang, legal technologist, Melbourne, Australia, for an exceedingly thorough and precise proofreading of the entire 2nd Edition. As always, the core members of the \u201cBeta Gold\u201d group, formed way back in the days of the First Edition, have stuck with us and proactively helped improve the course in ways too numerous to mention that bene\ufb01t everyone who uses the materials: Michael and Hank x NOTES from the list above, plus Rose Williams, Binghamton University, and Kristen Walcott-Justice, University of Colorado at Colorado Springs. Our colleagues at GitHub, and particularly Director of Developer Education Vanessa Gennarelli (@mozzadrella), continue to be more generous and supportive of our education efforts than we have any right to expect. The Codio team, especially Elise Deitrick, Max Kraev, and CEO Phillip Snalune, have done phenomenal work in beautifully integrating both the book and exercises into the Co- dio platform, providing a one-stop shop for instructors and students wanting to get started quickly. We hope the seamlessness of that experience encourages many more learners to try ESaaS. Finally, as always, we thank the thousands of UC Berkeley students and teaching assis- tants, and the hundreds of thousands of MOOC students, for their debugging help and their continuing interest in this material! Armando Fox January 2021 San Francisco, California Notes 1http://www.saasbook.info/welcome-1st-edition 2http://www.saasbook.info 3https://codio.com/esaas NOTES 1 1 Introduction to Software as a Service, Agile Development, and Cloud Computing Donald Knuth (1938\u2013 ), one of the most illustrious computer scientists, received the Turing Award in"
    ]
  },
  {
    "id": "sec_0135",
    "title": "1974 for major contributions",
    "pages": [
      14
    ],
    "text_blocks": [
      "to the analysis of algorithms and the design of programming languages, and in particular for his contributions to his multi-volume The Art of Computer Programming, arguably the de\ufb01nitive reference on analysis of algorithms. Knuth also invented the widely-used TEX typesetting system, with which this book was prepared. Let us change our traditional attitude to the construction of programs: Instead of imag- ining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do. \u2014Donald Knuth, Literate Programming, 1984 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Introduction . . . . 1.1 ."
    ]
  },
  {
    "id": "sec_0136",
    "title": "1.2 Software Development Processes: Plan-and-Document",
    "pages": [
      14
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0137",
    "title": "1.3 Software Development Processes: The Agile Manifesto .",
    "pages": [
      14
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0138",
    "title": "1.4 Software Quality Assurance: Testing .",
    "pages": [
      14
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0139",
    "title": "1.5 Productivity: Conciseness, Synthesis, Reuse, and Tools .",
    "pages": [
      14
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0140",
    "title": "1.6 SaaS and Service Oriented Architecture .",
    "pages": [
      14
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0141",
    "title": "1.7 Deploying SaaS: Cloud Computing .",
    "pages": [
      14
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0142",
    "title": "1.8 Deploying SaaS: Browsers and Mobile .",
    "pages": [
      14
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0143",
    "title": "1.9 Beautiful vs. Legacy Code .",
    "pages": [
      14
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0144",
    "title": "1.10 Guided Tour and How To Use This Book .",
    "pages": [
      14
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0145",
    "title": "1.11 Fallacies and Pitfalls .",
    "pages": [
      14
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0146",
    "title": "1.12 Concluding Remarks: Software Engineering Is More Than Program-",
    "pages": [
      14,
      15,
      16,
      17
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 6 12 17 19 22 25 27 31 33 36 37 3 Prerequisites and Concepts Each chapter opening starts with a brief summary of the chapter\u2019s prerequisites and big concepts. Prerequisites are skills or knowledge you should already have in order to get the most out of the material in the chapter. Big concepts are the main ideas we want you to take away after nishing the chapter when you step back from the details. Prerequisites: The rst prerequisite is to determine whether this book is right for you! This book is a good t if you want to. . . Allow software design principles to inform your eval- uation and creation of new technologies Learn how to learn new frameworks and languages, and put them to use quickly Learn by doing But not if you want to. . . Just learn framework X, without understanding its design principles Follow a step-by-step recipe tutorial for a specic framework or language Learn by only reading and watching videos For this chapter, the technical prerequisite is basic knowledge of HTML, the Hyper- Text Markup Language that is the lingua franca of the web. We recommend the free Introduction to HTML1 module from the Mozilla Developer Network. We suggest working through all the sections under Guides and the two Assessments. Concepts: The big concepts of this chapter are the contrasts between Plan-and-Document soft- ware development and Agile software development, and the synergy among Agile de- velopment, Software as a Service, and cloud computing. \u2022 Plan-and-Document software development processes or lifecycles rely on careful, up-front planning, whereas Agile software development relies on incrementally rening a prototype with continuous feedback from the customer over the course of many 14 week iterations. Of the two, Agile has the superior track record for managing change, running compact projects with small teams, and delivering quality software on time and within budget. \u2022 Software quality is dened as providing business value to both customers and developers and involves many kinds of testing. In Agile, the developers themselves, rather than a separate QA team, bear primary responsibility for software quality. \u2022 Clarity via conciseness, synthesis, reuse, and automation via tools are four paths to improving developer productivity . Ruby on Rails employs all of them. \u2022 Software as a Service (SaaS) is software deployed on Internet servers accessible to millions of users. Compared with Software as a Product (SaaP) that users install on their devices, SaaS is easier to upgrade and evolve because there is only a single copy deployed in the eld. Cloud Computing supplies the dependable and scalable computation and storage for SaaS by utilizing Warehouse Scale 4 CHAPTER 1. INTRODUCTION TO AGILE & SAAS Computers containing as many as 100,000 servers. Economies of scale allow Cloud Computing to be offered as a utility, where you pay only for actual use. \u2022 Mobile devices now account for the majority of visits to web sites. Mobile-rst apps can be developed, tested, and deployed using the same tools as SaaS for desktop browsers, using responsive web design to automatically adapt to a variety of screen sizes while accommodating for users with disabilities. \u2022 Legacy Code evolution is vital in the real world, yet often ignored in software engineering books and courses. Agile practices enhancing code each iteration, so the skills gained also apply to legacy code. 1.1. INTRODUCTION 5 Topic Customers/Day (Goal) Customers/Day (Actual) Average Response time (seconds) Downtime/Month (hours) Availability (% up) Error Rate Secure Amazon.com ACA Oct ACA Nov ACA Dec \u2013 >10,000,000 0.2 0.07 99.99% \u2013 Yes 50,000 800 8 446 40% 10% No 50,000 3,700 1 107 85% 10% No 30,000 34,300 1 36 95% \u2013 No Figure 1.1: Comparing Amazon.com and HealthCare.gov during its \ufb01rst three months. (Thorp 2013) After its stumbling start, the deadline was extended from December 15, 2013 to March 31, 2014, which explains the lower goal in customers per day in December. Note that availability for ACA does not include time for \u201cscheduled maintenance,\u201d which Amazon does include (Zients 2013). The error rate was for signi\ufb01cant errors on the forms sent to insurance companies (Horsley 2013). The site was widely labeled by security experts as insecure, as the developers were under tremendous pressure to get proper functionality, and little attention was paid to security (Harrington 2013)."
    ]
  },
  {
    "id": "sec_0147",
    "title": "1.1 Introduction",
    "pages": [
      17,
      18
    ],
    "text_blocks": [
      "Now, this is real simple. It\u2019s a website where you can compare and purchase affordable health insurance plans, side-by-side, the same way you shop for a plane ticket on Kayak or the same way you shop for a TV on Amazon. . . Starting on Tuesday, every American can visit HealthCare.gov to \ufb01nd out what\u2019s called the insurance marketplace. . . So tell your friends, tell your family. . . Make sure they sign up. Let\u2019s help our fellow Americans get covered. (Applause.) \u2014President Barack Obama, Remarks on the Affordable Care Act, Prince George\u2019s Community College, Maryland, September 26, 2013 . . . it has now been six weeks since the Affordable Care Act\u2019s new marketplaces opened for business. I think it\u2019s fair to say that the rollout has been rough so far, and I think everybody understands that I\u2019m not happy about the fact that the rollout has been, you know, fraught with a whole range of problems that I\u2019ve been deeply concerned about. \u2014President Barack Obama, Statement on the Affordable Care Act, The White House Press Brie\ufb01ng Room, November 14, 2013 When the Affordable Care Act (ACA) was passed in 2010, it was seen as the most am- bitious US social program in decades, and it was perhaps the crowning achievement of the Obama administration. Just as millions shop for items on Amazon.com, HealthCare.gov\u2014 also known as the Affordable Care Act website\u2014was supposed to let millions of uninsured Americans shop for insurance policies. Despite taking three years to build, it fell \ufb02at on its face when it debuted on October 1, 2013. Figure 1.1 compares Amazon.com to Health- Care.gov in the \ufb01rst three months of operation, demonstrating that not only was it slow, error prone, and insecure, it was also down much of the time. Why is it that companies like Amazon.com can build software that serves a much large customer base so much better? While the media uncovered many questionable decisions, a surprising amount of the blame was placed on the methodology used to develop the software (Johnson and Reed 2013). Given their approach, as one commentator said, \u201cThe real news would have been if it actually did work.\u201d (Johnson 2013a) We\u2019re honored to have the chance to explain how Internet companies and others build successful software services and extend the reach of those services to the billions of mobile devices out there. As this introduction illustrates, this \ufb01eld is not some dreary academic discipline where few care what happens: failed software projects can become infamous, and 6 CHAPTER 1. INTRODUCTION TO AGILE & SAAS can even derail Presidents. On the other hand, successful software projects can create services that billions of people use every day whose creators become household names. All involved with such services are proud to be associated with them, unlike the ACA. The rest of this chapter explains why disasters like ACA can happen and how to avoid repeating this unfortunate history. We start our journey with the origins of software engi- neering itself, which began with software development methodologies that placed a heavy emphasis on planning and documenting, since that approach had worked well in other \u201cbig\u201d engineering projects such as civil engineering. We next review the statistics on how well the Plan-and-Document methodologies worked, alas documenting that project outcomes like ACA are all too common, if not as well known. The frequently disappointing results of fol- lowing conventional wisdom in software engineering inspired a few software developers to stage a revolt. While the Agile Manifesto was quite controversial when it was announced, over time Agile software development has overcome its critics. Agile allows small teams to outperform the industrial giants, especially for small projects. Our next step in the journey demonstrates how service-oriented architecture allows the successful composition of large software services like Amazon.com from many smaller software services developed and op- erated by small Agile teams. As a \ufb01nal but critical point, it\u2019s rare in practice for software developers to do \u201cgreen \ufb01eld\u201d development, in which they start from a blank slate. It\u2019s much more common to enhance large existing code bases. The next step in our journey observes that unlike Plan-and-Document, which aims at a perfect design up front and then implements it, the Agile process spends almost all of its time enhancing working code. Thus, by getting good at Agile, you are also practicing the skills you need to evolve existing code bases. To start us on our journey, we introduce the software methodology used to develop HealthCare.gov."
    ]
  },
  {
    "id": "sec_0148",
    "title": "1.2 Software Development Processes: Plan-and-Document",
    "pages": [
      18,
      19,
      20
    ],
    "text_blocks": [
      "If builders built buildings the way programmers wrote programs, then the \ufb01rst wood- pecker that came along would destroy civilization. \u2014Weinberg\u2019s Second Law, 1978, attributed to Gerald Weinberg, University of Nebraska computer scientist The general unpredictability of software development in the late 1960s, along with the software disasters similar to ACA, led to the study of how high-quality software could be developed on a predictable schedule and budget. Drawing the analogy to other engineering \ufb01elds, the term software engineering was coined (Naur and Randell 1969). The goal was to discover methods to build software that were as predictable in quality, cost, and time as those used to build bridges in civil engineering. One thrust of software engineering was to bring an engineering discipline to what was often unplanned software development. Before starting to code, come up with a plan for the project, including extensive, detailed documentation of all phases of that plan. Progress is then measured against the plan. Changes to the project must be re\ufb02ected in the documentation and possibly to the plan. The goal of all these \u201cPlan-and-Document\u201d software development processes is to im- prove predictability via extensive documentation, which must be changed whenever the goals change. Here is how textbook authors put it (Lethbridge and Laganiere 2002; Braude 2001): 1.2. PROCESSES: PLAN & DOCUMENT 7 Documentation should be written at all stages of development, and includes requirements, designs, user manuals, instructions for testers and project plans. \u2014Timothy Lethbridge and Robert Laganiere, 2002 Documentation is the lifeblood of software engineering. \u2014Eric Braude, 2001 This process is even embraced with an of\ufb01cial standard of documentation: IEEE/ANSI stan- dard 830/1993. Governments like that of the US have elaborate regulations to prevent corruption when acquiring new equipment, which lead to lengthy speci\ufb01cations and contracts. Since the goal of software engineering was to make software development as predictable as building bridges, including elaborate speci\ufb01cations, government contracts were a natural match to Plan-and- Document software development. Thus, like many countries, US acquisition regulations left the ACA developers little choice but to follow a Plan-and-Document lifecycle. Of course, like other engineering \ufb01elds, the government has escape clauses in the con- tracts that let it still acquire the product even if it is late. Ironically, the contractor makes more money the longer it takes to develop the software. Thus, the art is in negotiating the contract and the penalty clauses. As one commentator on ACA noted (Howard 2013), \u201cThe \ufb01rms that typically get contracts are the \ufb01rms that are good at getting contracts, not typically good at executing on them.\u201d Another noted that the Plan-and-Document approach is not well suited to modern practices, especially when government contractors focus on maximizing pro\ufb01ts (Chung 2013). An early version of this Plan-and-Document software development process was devel- oped in 1970 (Royce 1970). It follows this sequence of phases: 1. Requirements analysis and speci\ufb01cation 2. Architectural design 3. Implementation and Integration 4. Veri\ufb01cation 5. Operation and Maintenance (Sidebars like this one provide historical context or perspective. They are optional, but as George Santayana famously said, \u201cThose who do not know history are condemned to repeat it.\u201d) CGI Group won the contract for the back end of the ACA website. The initial estimate ballooned from US$94M to $292M (Begley 2013). This same company was involved in a Canadian \ufb01rearms registry whose costs skyrocketed, from an initial estimate of US$2M to $2B (2 \u00d7 109). When MITRE investigated the problems with Massachusetts\u2019 ACA website, it said CGI Group lacked expertise to build the site, lost data, failed to adequately test, and managed the project poorly (Bidgood 2014). Given that the earlier you \ufb01nd an error the cheaper it is to \ufb01x, the philosophy of this process is to complete a phase before going on to the next one, thereby removing as many errors as early as possible. Getting the early phases right could also prevent unnecessary work downstream. As this process could take years, the extensive documentation helps to ensure that important information is not lost if a person leaves the project and that new people can get up to speed quickly when they join the project. Because it \ufb02ows from the top down to completion, this process is called the Waterfall software development process or Waterfall software development lifecycle. Understandably, given the complexity of each stage in the Waterfall lifecycle, product releases are major events toward which engineers worked feverishly and which are accompanied by much fanfare. In the Waterfall lifecycle, the long life of software is acknowledged by a maintenance phase that repairs errors as they are discovered. New versions of software developed in the Waterfall model go through the same several phases, and take typically between 6 and 18 months. Windows 95 was heralded by a US$300 million party2 for which Microsoft hired comedian Jay Leno, lit up New York\u2019s Empire State Building using the Microsoft Windows logo colors, and licensed \u201cStart Me Up\u201d by the Rolling Stones as the celebration\u2019s theme song. 8 CHAPTER 1. INTRODUCTION TO AGILE & SAAS The Waterfall model can work well with well-speci\ufb01ed tasks like NASA space \ufb02ights, but it runs into trouble when customers change their minds about what they want. A Turing Award winner captures this observation: Plan to throw one [implementation] away; you will, anyhow. \u2014Fred Brooks, Jr. That is, it\u2019s easier for customers to understand what they want once they see a prototype and for engineers to understand how to build it better once they\u2019ve done it the \ufb01rst time. This observation led to a software development lifecycle developed in the 1980s that combines prototypes with the Waterfall model (Boehm 1986). The idea is to iterate through a sequence of four phases, with each iteration resulting in a prototype that is a re\ufb01nement of the previous version. Figure 1.2 illustrates this model of development across the four phases, which gives this lifecycle its name: the Spiral model . The phases are: 1. Determine objectives and constraints of this iteration 2. Evaluate alternatives and identify and resolve risks 3. Develop and verify the prototype for this iteration 4. Plan the next iteration Big Design Up Front, abbreviated BDUF , is a name some use for software processes like Waterfall, Spiral, and RUP that depend on extensive planning and documentation. They are also known variously as heavyweight, plan-driven, disciplined, or structured processes. Rather than document all the requirements at the beginning, as in the Waterfall model, the requirement documents are developed across the iteration as they are needed and evolve with the project. Iterations involve the customer before the product is completed, which reduces chances of misunderstandings. However, as originally envisioned, these iterations were 6 to"
    ]
  },
  {
    "id": "sec_0149",
    "title": "24 months long, so there is plenty of time for customers to change their minds during an",
    "pages": [
      20,
      21,
      22,
      23,
      24
    ],
    "text_blocks": [
      "iteration! Thus, Spiral still relies on planning and extensive documentation, but the plan is expected to evolve on each iteration. Given the importance of software development, many variations of Plan-and-Document methodologies were proposed beyond these two. A recent one is called the Rational Uni\ufb01ed Process (RUP) (Kruchten 2003), developed during the 1990s, which combines features of both Waterfall and Spiral lifecycles as well standards for diagrams and documentation. We\u2019ll use RUP as a representative of the latest thinking in Plan-and-Document lifecycles. Unlike Waterfall and Spiral, it is more closely allied to business issues than to technical issues. Like Waterfall and Spiral, RUP has phases: 1. Inception: makes the business case for the software and scopes the project to set the schedule and budget, which is used to judge progress and justify expenditures, and initial assessment of risks to schedule and budget. 2. Elaboration: works with stakeholders to identify use cases, designs a software archi- tecture, sets the development plan, and builds an initial prototype. 3. Construction: codes and tests the product, resulting in the \ufb01rst external release. 4. Transition: moves the product from development to production in the real environment, including customer acceptance testing and user training. 1.2. PROCESSES: PLAN & DOCUMENT 9 Figure 1.2: The Spiral lifecycle combines Waterfall with prototyping. It starts at the center, with each iteration around the spiral going through the four phases and resulting in a revised prototype until the product is ready for release. 10 CHAPTER 1. INTRODUCTION TO AGILE & SAAS Figure 1.3: The Rational Uni\ufb01ed Process lifecycle allows the project to have multiple iterations in each phase and identi\ufb01es the skills needed by the project team, which vary in effort over time. RUP also has three \u201csupporting disciplines\u201d not shown in this \ufb01gure: Con\ufb01guration and Change Management, Project Management, and Environment. (Image from Wikimedia Commons by Dutchgilder.) 1.2. PROCESSES: PLAN & DOCUMENT 11 Unlike Waterfall, each phase involves iteration. For example, a project might have one inception phase iteration, two elaboration phase iterations, four construction phase iterations, and two transition phase iterations. Like Spiral, a project could also iterate across all four phases repeatedly. In addition to the dynamically changing phases of the project, RUP identi\ufb01es six \u201cengi- neering disciplines\u201d (also known as work\ufb02ows) that people working on the project should collectively cover: 1. Business Modeling 2. Requirements 3. Analysis and Design 4. Implementation 5. Test 6. Deployment These disciplines are more static than the phases, in that they nominally exist over the whole lifetime of the project. However, some disciplines get used more in earlier phases (like business modeling), some periodically throughout the process (like test), and some more towards the end (deployment). Figure 1.3 shows the relationship of the phases and the disci- plines, with the area indicating the amount of effort in each discipline over time. An unfortunate downside to teaching a Plan-and-Document approach is that students may \ufb01nd software development tedious (Nawrocki et al. 2002; Estler et al. 2012). Of course, this is hardly a strong enough reason not to teach it; the good news is that there are alternatives that work just as well for many projects that are a better \ufb01t to the classroom, as we describe in the next section. Summary: The basic activities of software engineering are the same in all the software development processes or lifecycles, but their interaction over time relative to product re- leases differs among the models. The Waterfall lifecycle is characterized by much of the design being done in advance of coding, completing each phase before going on to the next one. The Spiral lifecycle iterates through all the development phases to produce pro- totypes, but like Waterfall, the customers may only get involved every 6 to 24 months. The more recent Rational Uni\ufb01ed Process lifecycle includes phases, iterations, and prototypes, while identifying the people skills needed for the project. All rely on careful planning and thorough documentation, and all measure progress against a plan. 12 CHAPTER 1. INTRODUCTION TO AGILE & SAAS Elaboration: SEI Capability Maturity Model (CMM) (Elaborations are included for curious readers who want to know more about what is going on behind the curtain. Beginning readers can safely skip them the \ufb01rst time, but we hope as you become more experienced you\u2019ll \ufb01nd them more intriguing!) The Software Engineering Institute at Carnegie Mellon University proposed the Capa- bility Maturity Model (CMM) (Paulk et al. 1995) to evaluate organizations\u2019 software- development processes based on Plan-and-Document methodologies. The idea is that by modeling the software development process, an organization can improve them. SEI studies observed \ufb01ve levels of software practice: 1. Initial or Chaotic: undocumented/ad hoc/unstable software development. 2. Repeatable: not following rigorous discipline, but some processes repeatable with consistent results. 3. De\ufb01ned: De\ufb01ned and documented standard processes that improve over time. 4. Managed: Management can control software development using process metrics, adapting the process to different projects successfully. 5. Optimizing: Part of the management process is deliberate quantitative optimization of the development process. CMM implicitly encourages an organization to move up the CMM levels. While not proposed as a software development methodology, many consider it one. For example, (Nawrocki et al. 2002) compares CMM Level 2 to the Agile software methodology (see next section). Self-Check 1.2.1. What are a major similarity and a major difference between processes like Spiral and RUP versus Waterfall? All rely on planning and documentation, but Spiral and RUP use iteration and prototypes to improve them over time versus a single long path to the product. Self-Check 1.2.2. What are the differences between the phases of these Plan-and-Document processes? Waterfall phases separate planning (requirements and architectural design) from implemen- tation. Testing the product before release is next, followed by a separate operations phase. The Spiral phases are aimed at an iteration: set the goals for an iteration; explore alternatives; develop and verify the prototype for this iteration; and plan the next iteration. RUP phases are tied more closely to business objectives: the inception phase makes the business case and sets schedule and budget; the elaboration phase works with customers to build an initial prototype; the construction phase builds and tests the \ufb01rst version; and the transition phase deploys the product."
    ]
  },
  {
    "id": "sec_0150",
    "title": "1.3 Software Development Processes: The Agile Manifesto",
    "pages": [
      24,
      25,
      26
    ],
    "text_blocks": [
      "If a problem has no solution, it may not be a problem, but a fact\u2014not to be solved, but to be coped with over time. \u2014Shimon Peres While Plan-and-Document processes brought discipline to software development, there were still software projects that failed so disastrously that they live in infamy. Programmers have heard these sorry stories of the Ariane 5 rocket explosion, the Therac-25 lethal Each section includes one or more questions to self-check whether you understood the material. It\u2019s okay to \ufb01nd that you sometimes need to reread a section in order to get the self-check correct. 1.3. PROCESSES: THE AGILE MANIFESTO 13 radiation overdose, Mars Climate Orbiter disintegration, and the FBI Virtual Case File project abandonment so frequently that they are clich\u00e9s. No software engineer would want these projects on their r\u00e9sum\u00e9s. One article even listed a \u201cSoftware Wall of Shame\u201d with dozens of highly-visible software projects that collectively were responsible for losses of $17B, with the majority of these projects abandoned (Charette 2005). Figure 1.4 summarizes four surveys of software projects. With just 10% to 16% on time and on budget, more projects were cancelled or abandoned than met their mark. A closer look at the 13% of projects in survey (b) that were successful is even more sobering, as fewer than 1% of new development projects met their schedules and budgets. Although the \ufb01rst three surveys are 10 to 25 years old, survey d) is from 2013. Nearly 40% of these large projects were cancelled or abandoned, and 50% were late, over budget, and missing functionality. Using history as our guide, poor President Obama had only a one in ten chance that HealthCare.gov would have a successful debut. Perhaps the \u201cReformation moment\u201d for software engineering was the Agile Manifesto in February 2001. A group of software developers met to develop a lighter-weight software lifecycle. Here is exactly what the Agile Alliance nailed to the door of the \u201cChurch of Plan-and-Document\u201d: \u201cWe are uncovering better ways of developing software by doing it and helping others do it. Through this work we have come to value: Ariane 5 \ufb02ight 501. On June 4, 1996, 37 seconds after liftoff, the rocket\u2019s guidance system experienced a math over\ufb02ow error: a \ufb02oating point number was converted to a shorter integer, leading to an explosion at liftoff3. This exception could not have occurred on the slower Ariane 4 rocket for which the software was originally developed. As this incident shows, reusing software components without thorough system testing can be expensive: satellites worth $370M were lost. Agile is also known variously as a lightweight or undisciplined process. \u2022 Individuals and interactions over processes and tools \u2022 Working software over comprehensive documentation \u2022 Customer collaboration over contract negotiation \u2022 Responding to change over following a plan That is, while there is value in the items on the right, we value the items on the left more.\u201d This alternative development model is based on embracing change as a fact of life: de- velopers should continuously re\ufb01ne a working but incomplete prototype until the customer is happy with the result, with the customer offering feedback on each iteration. Agile em- phasizes test-driven development (TDD) to reduce mistakes by writing the tests before writing the code, user stories to reach agreement and validate customer requirements, and velocity to measure project progress. We\u2019ll cover these topics in detail in later chapters. Regarding software lifetimes, the Agile software lifecycle is so quick that new versions are available every week or two\u2014with some even releasing every day\u2014so they are not even special events as in the Plan-and-Document models. The assumption is one of basically continuous improvement over its lifetime. We mentioned in the prior section that newcomers can \ufb01nd Plan-and-Document processes tedious, but this is not the case for Agile. This perspective is captured by a software engi- neering instructor\u2019s early review of Agile: Remember when programming was fun? Is this how you got interested in computers in the \ufb01rst place and later in computer science? Is this why many of our majors enter the discipline\u2014because they like to program computers? Well, there may be promising and respectable software development methodologies that are perfectly suited to these kinds of folks. . . . [Agile] is fun and effective, because not only do we not bog down the process in Variants of Agile There are many variants of Agile software development (Fowler 2005). The one we use in this book is Extreme Programming , which is abbreviated XP, and credited to Kent Beck. 14 CHAPTER 1. INTRODUCTION TO AGILE & SAAS Figure 1.4: (a) A 1995 study of software projects found that 53% of projects exceeded their budgets and schedules by factors of 3, and another 31% were cancelled before completion (Johnson 1995). The estimated annual cost in the United States for such software projects was $100B. (b) A 2000 survey of members of the British Computer Society found that only 130 of"
    ]
  },
  {
    "id": "sec_0151",
    "title": "1027 projects met their schedule and budget. Half of all projects were maintenance or data conversion projects and half new",
    "pages": [
      26,
      27,
      28
    ],
    "text_blocks": [
      "development projects, but the successful projects divided into 127 of the former and just 3 of the latter (Taylor 2000). (c) Survey of 250 large projects, each with the equivalent of more than a million lines of C code, found similarly disappointing results (Jones 2004). (d) The dismal outcomes for \u201clarge\u201d (at least $10M) projects in this survey of 50,000 projects (Johnson 2013b) suggest that HealthCare.gov had just a 10% chance of success. (e) Some good news: the \u201csmall\u201d (under $1M) projects in the same survey were largely completed on time and within budget, motivating the use of Agile. 1.3. PROCESSES: THE AGILE MANIFESTO 15 mountains of documentation, but also because developers work face-to-face with clients throughout the development process and produce working software early on. \u2014Renee McCauley, \u201cAgile Development Methods Poised to Upset Status Quo,\u201d SIGCSE Bulletin, 2001 By de-emphasizing planning, documentation, and contractually binding speci\ufb01cations, the Agile Manifesto ran counter to conventional wisdom of the software engineering intelli- gentsia, so it was not universally welcomed with open arms (Cormick 2001): [The Agile Manifesto] is yet another attempt to undermine the discipline of software en- gineering. . . In the software engineering profession, there are engineers and there are hackers. . . It seems to me that this is nothing more than an attempt to legitimize hacker behavior. . . The software engineering profession will change for the better only when cus- tomers refuse to pay for software that doesn\u2019t do what they contracted for. . . Changing the culture from one that encourages the hacker mentality to one that is based on predictable software engineering practices will only help transform software engineering into a re- spected engineering discipline. \u2014Steven Ratkin, \u201cManifesto Elicits Cynicism,\u201d IEEE Computer, 2001 One pair of critics even published the case against Agile as a 432-page book! (Stephens and Rosenberg 2003) \u201cThe battle lines are drawn. Hostilities have broken out between armed camps of the software development community. This time the rallying cry is, \"XP!\" ... What XP un- covered (again) is an ancient, sociological San Andreas fault that runs under the software community\u2013programming versus software engineering (a.k.a. the scruffy hackers versus the tweedy computer scientists).\u201d The software engineering research community went on to compare Plan-and-Document lifecycles to the Agile lifecycle in the \ufb01eld and found\u2014to the surprise of some cynics\u2014 that Agile could indeed work well, depending on the circumstances. Figure 1.5 shows 10 questions from a popular software engineering textbook (Sommerville 2010) whose answers suggest when to use Agile and when to use Plan-and-Document methods. While Figure 1.4(d) shows the disappointing results for large software projects, which do not use Agile, Figure 1.4(e) shows the success of small software projects\u2014de\ufb01ned as costing less than $1M\u2014that typically do use Agile. With three-fourths of these projects on time, on budget, and with full functionality, the results are in stark contrast to the other charts in the \ufb01gure. Success has fanned Agile\u2019s popularity, and recent surveys peg Agile as the primary development method for 60% to 80% of all programming teams in 2013 (ET Bureau 2012, Project Management Institute 2012). One paper even found Agile was used by the majority of programming teams that are geographically distributed, which is much more dif\ufb01cult to pull off (Estler et al. 2012). Thus, we concentrate on Agile in the six software development chapters in Part II of the book, but each chapter also gives the perspective of the Plan-and-Document methodologies on topics like requirements, testing, project management, and maintenance. This contrast allows readers to decide for themselves when each methodology is appropriate. Part I intro- duces SaaS and SaaS programming environments, including Ruby, Rails, and Javascript. Agile is a family of methodologies, not a single methodology. We follow Extreme Pro- gramming (XP), which includes one- to two-week iterations, behavior driven design (see Chapter 7), test-driven development (see Chapter 8), and pair programming (Section 2.2). Another popular variant is Scrum (Section 10.1), where self-organizing teams use two- to 16 CHAPTER 1. INTRODUCTION TO AGILE & SAAS Question: A no answer suggests Agile; a yes suggests Plan-and-Document Is speci\ufb01cation required? Are customers unavailable? Is the system to be built large? Is the system to be built complex (e.g., real time)? 1 2 3 4"
    ]
  },
  {
    "id": "sec_0152",
    "title": "5 Will it have a long product lifetime?",
    "pages": [
      28,
      29
    ],
    "text_blocks": [
      "Are you using poor software tools? 6 Is the project team geographically distributed? 7 Is team part of a documentation-oriented culture? 8 Does the team have poor programming skills? 9 Is the system to be built subject to regulation? 10 Figure 1.5: Ten questions to help decide whether to use an Agile lifecycle (the answer is no) or a Plan-and-Document lifecycle (the answer is yes) (Sommerville 2010). We \ufb01nd it striking that when asking these questions for projects done by student teams in a class, virtually all answers point to Agile. As this book attests, open source software tools are excellent, thus available to students (question 6). Our survey of industry (see Preface) found that graduating students do indeed have good programming skills (question 9). The other eight answers are clearly no for student projects. four-week iterations called sprints, and then regroup to plan the next sprint. A key feature of many Agile methodologies is a daily standup meeting to identify and overcome obstacles. While there are multiple roles in the scrum team, the norm is to rotate the roles over time. The Kanban approach is derived from Toyota\u2019s just-in-time manufacturing process, which in this case treats software development as a pipeline. Here the team members have \ufb01xed roles, and the goal is to balance the number of team members so that there are no bottlenecks with tasks stacking up waiting for processing. One common feature is a wall of cards to illustrate the state of all tasks in the pipeline. There are also hybrid lifecycles that try to combine the best of two worlds. For example, ScrumBan uses the daily meetings and sprints of Scrum but replaces the planning phase with the more dynamic pipeline control of the wall of cards from Kanban. While we now see how to build some software successfully, not all projects are small. We next show how to design software to enable composing smaller pieces into large services like Amazon.com. Summary: In contrast to the Plan-and-Document lifecycles, the Agile lifecycle works with customers to continuously add features to working prototypes until the customer is satis\ufb01ed, allowing customers to change what they want as the project develops. Documen- tation is primarily through user stories and test cases, and it does not measure progress against a prede\ufb01ned plan. Progress is gauged instead by recording velocity , which essen- tially is the rate that a project completes features. 1.4. SOFTWARE QUALITY ASSURANCE: TESTING 17 Elaboration: Reforming Government Acquisition Regulations President Obama belatedly recognized the dif\ufb01culties of software acquisition. On November 14, 2013, he said in a speech: \u201c. . . when I do some Monday morning quarterbacking on myself, one of the things that I do recognize is since I know how we purchase technology in the federal government is cumbersome, complicated and outdated . . . it\u2019s part of the reason why, chronically, federal IT programs are over budget, behind schedule. . . since I [now] know that the federal government has not been good at this stuff in the past, two years ago as we were thinking about this. . . we might have done more to make sure that we were breaking the mold on how we were going to be setting this up.\u201d Indeed, long before the ACA website, there were calls to reform software acquisition, as in this US National Academies study of the Department of Defense (DOD): \u201cThe DOD is hampered by a culture and acquisition-related practices that favor large pro- grams, high-level oversight, and a very deliberate, serial approach to development and test- ing (the waterfall model). Programs that are expected to deliver complete, nearly perfect solutions and that take years to develop are the norm in the DOD. . . These approaches run counter to Agile acquisition practices in which the product is the primary focus, end users are engaged early and often, the oversight of incremental product development is delegated to the lowest practical level, and the program management team has the \ufb02exibility to adjust the content of the increments in order to meet delivery schedules. . . Agile approaches have allowed their adopters to outstrip established industrial giants that were beset with ponder- ous, process-bound, industrial-age management structures. Agile approaches have succeeded because their adopters recognized the issues that contribute to risks in an IT program and changed their management structures and processes to mitigate the risks.\u201d (National Research Council 2010) Self-Check 1.3.1. True or False: A big difference between Spiral and Agile development is building prototypes and interacting with customers during the process. False: Both build working but incomplete prototypes that the customer helps evaluate. The difference is that customers are involved at least every two weeks in Agile, versus up to every two years in Spiral. Self-Check 1.3.2. True or False: A big difference between Waterfall and Agile development is that Agile does not use requirements. False: While Agile does not develop extensive requirements documents as does Waterfall, the interactions with customers lead to the creation of requirements as user stories, as we shall see in Chapter 7."
    ]
  },
  {
    "id": "sec_0153",
    "title": "1.4 Software Quality Assurance: Testing",
    "pages": [
      29,
      30
    ],
    "text_blocks": [
      "And the users exclaimed with a laugh and a taunt: \u201cIt\u2019s just what we asked for, but not what we want.\u201d A standard de\ufb01nition of quality for any product is \u201c\ufb01tness for use,\u201d which must provide business value for both the customer and the manufacturer (Juran and Gryna 1998). For soft- ware, quality means both satisfying the customer\u2019s needs\u2014easy to use, gets correct answers, does not crash, and so on\u2014and being easy for the developer to debug and enhance. Qual- ity Assurance (QA) also comes from manufacturing, and refers to processes and standards \u2014Anonymous Infeasibility of exhaustive testing Suppose it took just"
    ]
  },
  {
    "id": "sec_0154",
    "title": "1 nanosecond to test a",
    "pages": [
      30,
      31
    ],
    "text_blocks": [
      "program and it had just one 64-bit input that we wanted to test exhaustively. (Obviously, most programs take longer to run and have more inputs.) Just this simple case would take 264 nanoseconds, or 500 years! 18 CHAPTER 1. INTRODUCTION TO AGILE & SAAS that lead to manufacture of high-quality products and to the introduction of manufacturing processes that improve quality. Software QA, then, means both ensuring that products under development have high quality and creating processes and standards in an organization that lead to high quality software. As we shall see, some Plan-and-Document software processes even use a separate QA team that tests software quality (Section 8.10). Determining software quality involves two terms that are commonly interchanged but have subtle distinctions (Boehm 1979): \u2022 Veri\ufb01cation: Did you build the thing right? (Did you meet the speci\ufb01cation?) \u2022 Validation: Did you build the right thing? (Is this what the customer wants? That is, is the speci\ufb01cation correct?) Software prototypes that are the lifeblood of Agile typically help with validation rather than veri\ufb01cation, since customers often change their minds on what they want once they begin to see the product work. The main approach to veri\ufb01cation and validation is testing ; the motivation for testing is that the earlier developers \ufb01nd mistakes, the cheaper it is to repair them. Given the vast number of different combinations of inputs, testing cannot be exhaustive. One way to reduce the space is to perform different tests at different phases of software development. Starting bottom up, unit testing makes sure that a single procedure or method does what was ex- pected. The next level up is module testing, which tests across individual units. For example, unit testing works within a single class whereas module testing works across classes. Above this level is integration testing , which ensures that the interfaces between the units have consistent assumptions and communicate correctly. This level does not test the functionality of the units. At the top level is system testing or acceptance testing , which tests to see if the integrated program meets its speci\ufb01cations. In Chapter 8, we\u2019ll describe an alternative to testing, called formal methods. As mentioned brie\ufb02y in Section 1.3, the approach to testing for the XP version of Agile is to write the tests before you write the code. You then write the minimum code you need to pass the test, which ensures that your code is always tested and reduces the chances of writing code that will be later discarded. XP splits this test-\ufb01rst philosophy into two parts, depending on the level of the testing. For system, acceptance, and integration tests, XP uses Behavior-Driven Design (BDD), which is the topic of Chapter 7. For unit and module tests, XP uses Test-Driven Development (TDD), which is the topic of Chapter 8. Summary: Testing reduces the risks of errors in designs. \u2022 In its many forms, testing helps verify that software meets the speci\ufb01cation and validates that the design does what the customer wants. \u2022 To attack the infeasibility of exhaustive testing, we divide in order to conquer by focusing on unit testing , module testing, integration testing , and full system testing or acceptance testing . Each higher-level test delegates more detailed testing to lower levels. \u2022 Agile attacks testing by writing the tests before writing the code, using either Behavior-Driven Design or Test-Driven Development, depending on the level of the test. 1.5. PRODUCTIVITY: CONCISENESS, SYNTHESIS, REUSE, AND TOOLS 19 Elaboration: Testing: Plan-and-Document vs. Agile lifecycles For the Waterfall development process, testing happens after each phase is complete and in a \ufb01nal veri\ufb01cation phase that includes acceptance tests. For Spiral, it happens on each iteration, which can last one or two years. Assurance for the XP version of Agile comes from test-driven development, in that the tests are written before the code when coding from scratch. When enhancing existing code, test-driven development means writing the tests be- fore writing the enhancements. The amount of testing depends on whether you are enhancing beautiful code or legacy code, with the latter needing a lot more. Self-Check 1.4.1. While all of the following help with veri\ufb01cation, which form of testing is most likely to help with validation: Unit, Module, Integration, or Acceptance? Validation is concerned with doing what the customer really wants versus whether code met the speci\ufb01cation, so acceptance testing is most likely to point out the difference between doing the thing right and doing the right thing."
    ]
  },
  {
    "id": "sec_0155",
    "title": "1.5 Productivity: Conciseness, Synthesis, Reuse, and Tools",
    "pages": [
      31,
      32,
      33,
      34
    ],
    "text_blocks": [
      "Moore\u2019s Law meant hardware resources have doubled every 18 months for nearly 50 years. These faster computers with much larger memories could run much larger programs. To build bigger applications that could take advantage of the more powerful computers, software engineers needed to improve their productivity. Engineers developed four fundamental mechanisms to improve their productivity: 1. Clarity via conciseness 2. Synthesis 3. Reuse 4. Automation via Tools Clarity via conciseness re\ufb02ects one of the driving assumptions of improving programmer productivity: if programs are easier to understand, they will have fewer bugs and will be easier to maintain. A closely related corollary is that if the program is smaller, it\u2019s generally easier to understand. We capture this notion with our motto of \u201cclarity via conciseness.\u201d Programming languages do this in two ways. The \ufb01rst is simply offering a syntax that lets programmers express ideas naturally and in fewer characters. For example, below are two ways to express a simple assertion: \u2022 assert_greater_than_or_equal_to(a, b) \u2022 expect(a).to be >= b It\u2019s easy to imagine momentary confusion about the order of arguments in the \ufb01rst version in addition to the higher cognitive load of reading twice as many characters. The second version (which happens to be legal Ruby) is shorter and easier to read and understand, and will likely be easier to maintain. The other way to improve clarity is to raise the level of abstraction. That initially meant the invention of higher-level programming languages such as Fortran and COBOL. This 20 CHAPTER 1. INTRODUCTION TO AGILE & SAAS step raised the engineering of software from assembly language for a particular computer to higher-level languages that could target multiple computers simply by changing the com- piler. As computer hardware performance continued to increase, more programmers were will- ing to delegate tasks to the compiler and runtime system that they formerly performed them- selves. For example, Java and similar languages took over memory management from the earlier C and C++ languages. Scripting languages like Python and Ruby have raised the level of abstraction even higher. Examples are re\ufb02ection, which allows programs to observe themselves, and higher order functions, which allows higher-level behaviors to be reused by passing functions as arguments to other functions. This higher level of abstraction made programs more concise and therefore (usually) easier to read, understand, and maintain. To highlight examples that improve productivity via conciseness, we use the \u201cConcise\u201d icon. Synthesis refers to code that is generated automatically rather than created manually. Logic synthesis for hardware engineers meant that they could describe hardware as Boolean functions and receive highly optimized transistors that implemented those functions. The classic software synthesis example is Bit blit. This graphics primitive combines two bitmaps under control of a mask. The straightforward approach would include a conditional statement in the innermost loop to choose the type of mask, but it was slow. The solution was to write a program that could synthesize the appropriate special-purpose code without the conditional statement in the loop. We\u2019ll highlight examples that improve productivity by generating code with this \u201cCodeGen\u201d gears icon. The Rails framework makes extensive use of the Ruby language\u2019s facilities for metaprogramming , which allows Ruby programs to automatically synthesize code at runtime. Reuse of portions from past designs, rather than writing everything from scratch, is a third way to improve productivity. As it is easier to make small changes in software than in hardware, software is even more likely than hardware to reuse a component that is almost but not quite a correct \ufb01t. We highlight examples that improve productivity via reuse with this \u201cReuse\u201d recycling icon. Procedures and functions were invented in the earliest days of software so that different parts of the program could reuse the same code with different parameter values. Standardized libraries for input/output and for mathematical functions soon followed, so that programmers could reuse code developed by others. Procedures in libraries let you reuse implementations of individual tasks. But more com- monly, programmers want to reuse and manage collections of tasks. The next step in soft- ware reuse was therefore object-oriented programming (OOP), where you could reuse the same tasks with different objects via the use of inheritance in languages like C++ and Java. While inheritance supported reuse of implementations, another opportunity for reuse is a general strategy for doing something even if the implementation varies. Design patterns, inspired by work in civil architecture (Alexander et al. 1977), arose to address this need. Language support for reuse of design patterns includes dynamic typing , which facilitates composition of abstractions, and mix-ins, which offer ways to collect functionality from multiple methods without some of the pathologies of multiple inheritance found in some OOP languages. Python and Ruby are examples of languages with features that help with reuse of design patterns. Note that reuse does not mean copying and pasting code so that you have very similar code in many places. The problem with copying and pasting code is that you may not change all the copies when \ufb01xing a bug or adding a feature. Here is a software engineering guideline 1.5. PRODUCTIVITY: CONCISENESS, SYNTHESIS, REUSE, AND TOOLS 21 that guards against repetition: Every piece of knowledge must have a single, unambiguous, authoritative representation within a system. \u2014Andy Hunt and Dave Thomas, 1999 This guideline has been captured in the motto and acronym: Don\u2019t Repeat Yourself (DRY). We\u2019ll use a towel as the \u201cDRY\u201d icon to show examples of DRY in the following chapters. Ruby and JavaScript, which we use in this book, are typical of modern scripting languages in including automatic memory management, dynamic typing, support for higher-order func- tions, and various mechanisms for code reuse. By including important advances in program- ming languages, Ruby goes beyond languages like Perl in supporting multiple programming paradigms such as object-oriented and functional programming . Automation, our fourth and \ufb01nal productivity-enhancing mechanism, re\ufb02ects another core value of software engineering: replacing tedious manual tasks with tools to save time, improve accuracy, or both. For software development, obvious tools include compilers and interpreters that raise the level of abstraction and generate code as mentioned above, but there are also more subtle productivity tools like Make\ufb01les and version control systems (Sec- tion 10.2) that automate tedious tasks. We highlight tool examples with the hammer icon. The trade-off is always the time it takes to learn a new tool versus the time saved in apply- ing it. Other concerns are the dependability of the tool, the quality of the user experience, and how to decide which one to use if there are many choices. Nevertheless, one of the software engineering tenets of faith is that a new tool can make our lives better. Your authors embrace the value of automation and tools. That is why we show you several tools in this book to make you more productive. The good news is that any tool we show you will have been vetted to ensure its dependability and that time to learn will be paid back many times over in reduced development time and in the improved quality of the \ufb01nal result. For example, Chapter 7 shows how Cucumber helps automate turning user stories into acceptance tests and how Pivotal Tracker automatically measures Velocity , which is a measure of the rate of adding features to an application. Chapter 8 introduces RSpec, which helps automate the unit testing process. The bad news is that you\u2019ll need to learn several new tools. However, we think the ability to quickly learn and apply new tools is a requirement for success in engineering software, so it\u2019s a good skill to cultivate. Thus, our fourth productivity enhancer is automation via tools. We highlight examples that use automation with the robot icon, although they are often also associated with tools. Learning new tools Proverbs 14:4 in the King James Bible discusses improving productivity by taking the time to learn and use tools: Where there are no oxen, the manger is clean; but abundant crops come by the strength of oxen. 22 CHAPTER 1. INTRODUCTION TO AGILE & SAAS Summary: Moore\u2019s Law inspired software engineers to improve their productivity by: \u2022 Coveting conciseness, in using compact syntax and by raising the level of abstrac- tion by using higher-level languages. Examples include re\ufb02ection, which allows programs to observe themselves at runtime, and higher-order functions, which allow higher-level behaviors to be reused by passing functions as arguments to other functions. \u2022 Synthesizing implementations. \u2022 Reusing designs by following the principle of Don\u2019t Repeat Yourself (DRY) and by relying upon innovations that help reuse, such as procedures, libraries, object- oriented programming, and design patterns. \u2022 Using (and inventing) tools to automate tedious tasks. Elaboration: Productivity: Plan-and-Document vs. Agile lifecycles Productivity is measured in the engineer-hours to implement new functionality. The differ- ence is the cycles are much longer in Waterfall and Spiral vs. Agile\u2014on the order of 6 to"
    ]
  },
  {
    "id": "sec_0156",
    "title": "24 months vs. 1/2 month. Therefore, much more work is done between customer-visible",
    "pages": [
      34
    ],
    "text_blocks": [
      "releases in Plan-and-Document methodologies, and hence the chances are greater that more work will ultimately be rejected by the customer. Self-Check 1.5.1. Which mechanism is the weakest argument for productivity bene\ufb01ts of compilers for high-level programming languages: Clarity via conciseness, Synthesis, Reuse, or Automation and Tools? Compilers make high-level programming languages practical, enabling programmers to improve productivity via writing the more concise code in a HLL. Compilers do synthesize lower-level code based on the HLL input. Compilers are de\ufb01nitely tools. While you can argue that HLL makes reuse easier, reuse is the weakest of the four for explaining the bene\ufb01ts of compilers."
    ]
  },
  {
    "id": "sec_0157",
    "title": "1.6 SaaS and Service Oriented Architecture",
    "pages": [
      34,
      35,
      36,
      37
    ],
    "text_blocks": [
      "As the Web started to reach large audiences in the mid 1990s, a new idea started to emerge: rather than relying on users to install software on their computers, why not run the software centrally on Internet-based servers, and allow users to access it via a Web browser? Salesforce was arguably the \ufb01rst large company to fully embrace this new model, which was dubbed Software as a Service (SaaS). Examples of SaaS that many of us now use every day include searching, social networking, and watching videos. But even apps such as word processing, contact management, and calendars, for which the previously dominant software delivery model was for users to install the software on their devices, have largely migrated to SaaS. The advantages of SaaS for both users and developers explain the popularity of SaaS: 1. Since customers do not need to install the application, they don\u2019t have to worry whether their hardware is the right brand or fast enough, nor whether they have the correct version of the operating system. SaaP (Software as a Product) is a retronym that appeared around 2015 to describe software that must be installed on each device when it\u2019s released or updated, in contrast to SaaS, in which the user is always using the latest version of a Web-based app. 1.6. SAAS AND SERVICE ORIENTED ARCHITECTURE 23 SaaS Programming Framework Active Server Pages (ASP.NET) Enterprise Java Beans (EJB) JavaServer Pages (JSP) Spring Rails Django Zend Sinatra Programming Language C#, VB.NET Java Java Java Ruby Python PHP Ruby Introduced 1996 1997 1999 2002 2004 2005 2006 2007 Figure 1.6: Examples of SaaS programming frameworks and the programming languages they are written in. 2. The data associated with the service is generally kept with the service, so customers need not worry about backing it up, losing it due to a local hardware malfunction, or even losing the whole device, such as a phone or tablet. 3. When a group of users wants to collectively interact with the same data, SaaS is a natural vehicle. 4. When data is large and/or updated frequently, it may make more sense to centralize data and offer remote access via SaaS. 5. Only a single copy of the server software runs in a uniform, tightly-controlled hardware and operating system environment selected by the developer. Although different Web browsers still have some incompatible behaviors (a topic we address in Chapter 6), developers overwhelmingly avoid the compatibility hassles of distributing binaries that must run on different users\u2019 computers. 6. Since the only copy of the server software is under the developers\u2019 control, they can upgrade the software and even the hardware as long as they don\u2019t violate the external application program interfaces (API), and they can pre-test new versions of the ap- plication on a small fraction of the real customers \ufb01rst, all without pestering users to upgrade their installed applications. 7. SaaS companies compete regularly on bringing out new features to help ensure that their customers do not abandon them for a competitor who offers a better service. Given the popularity of SaaS, Figure 1.6 lists just a few of the many programming frame- works that claim to help create SaaS applications. In this book, we use the Rails framework written in the Ruby language (\u201cRuby on Rails\u201d), although the ideas we cover will work with other programming frameworks as well. We chose Rails because it came from a community that had already embraced the Agile lifecycle, so the tools support Agile particularly well. If you are not already familiar with Ruby or Rails, this gives you a chance to practice an important software engineering skill: use the right tool for the job, even if it means learning a new tool or new language! Indeed, an attractive feature of the Rails community is that its contributors routinely improve productivity by inventing new tools to automate tasks that were formerly done manually. Note that frequent upgrades of SaaS\u2014due to only having a single copy of the software\u2014 perfectly align with the Agile software lifecycle. Hence, Amazon, eBay, Facebook, Google, 24 CHAPTER 1. INTRODUCTION TO AGILE & SAAS and other SaaS providers all rely on the Agile lifecycle, and traditional software companies like Microsoft are increasingly using Agile in their product development. The Agile process is an excellent match to the fast-changing nature of SaaS applications. Despite all the advantages of SaaS, it was still missing one critical advantage in the area of software reuse. When creating SaaP, developers could make extensive use of software libraries containing code to perform tasks common to many different applications. Because these libraries were often written by others (so-called third-party libraries), they embodied the advantage of software reuse. By the mid 2000s, a similar phenomenon began to take shape in SaaS: the rise of service-oriented architecture (SOA), in which a SaaS service could call upon other services built and maintained by other developers for common tasks. Services that were highly specialized to a narrow range of tasks came to be called microservices; today\u2019s common examples include credit card processing, search, driving directions, and more. As standards solidi\ufb01ed for representing and interacting with such external services, the important bene\ufb01t of reuse \ufb01nally arrived for SaaS. Chapter 3 delves into more detail about SOA and microservices. Of course, we have yet to address one major difference between SaaS and SaaP: the underlying hardware on which the apps will run. With SaaP, that hardware consists of the PCs of millions of individual users. In the next section we explore the underlying hardware that makes SaaS possible. Summary: Software as a Service (SaaS) is attractive to both customers and providers because the universal client (the Web browser) makes it easier for customers to use the service and the single version of the software at a centralized site makes it easier for the provider to deliver and improve the service. Given the ability and desire to frequently upgrade SaaS, the Agile software development process is popular for SaaS, and so there are many frameworks to support Agile and SaaS. This book uses Ruby on Rails. Self-Check 1.6.1. Some of Google\u2019s most popular SaaS apps are Search, Maps, Gmail, Calendar, and Documents. For each of these apps, give one advantage of delivering the app as SaaS rather than SaaP. Many answers are correct, but here are ours: 1. No user installation: Documents 2. Can\u2019t lose data: Gmail, Calendar. 3. Users cooperating: Documents. 4. Large/changing datasets: Search, Maps, YouTube. 5. Software centralized in single environment: Search. 6. No \ufb01eld upgrades when improve app: Documents. Self-Check 1.6.2. True or False: If you are using the Agile development process to develop SaaS apps, you could use Python and Django or languages based on the Microsoft\u2019s .NET framework and ASP.NET instead of Ruby and Rails. True. Programming frameworks for Agile and SaaS include Django and ASP.NET. John McCarthy (1927\u20132011) received the Turing Award in 1971 and was the inventor of Lisp and a pioneer of timesharing large computers. Clusters of commodity hardware and the spread of fast networking have helped make his vision of timeshared \u201cutility computing\u201d a reality. 1.7. DEPLOYING SAAS: CLOUD COMPUTING 25"
    ]
  },
  {
    "id": "sec_0158",
    "title": "1.7 Deploying SaaS: Cloud Computing",
    "pages": [
      37,
      38
    ],
    "text_blocks": [
      "If computers of the kind I have advocated become the computers of the future, then com- puting may someday be organized as a public utility just as the telephone system is a public utility . . . The computer utility could become the basis of a new and important industry. \u2014John McCarthy, at MIT centennial celebration in 1961 SaaS places three demands on our information technology (IT) infrastructure: 1. Communication, to allow any customer to interact with the service. 2. Scalability, in that the central facility running the service must deal with the \ufb02uctuations in demand during the day and during popular times of the year for that service as well as a way for new services to add users rapidly. 3. Availability, in that both the service and the communication vehicle must be continu- ously available: every day, 24 hours a day (\u201c24\u00d77\u201d). The gold standard for availability, set by the US public phone system, is 99.999% (\u201c\ufb01ve nines\u201d), or about 5 minutes of downtime per year. Amazon.com aims for four nines, which is dif\ufb01cult to achieve even for well-run SaaS. The Internet and broadband to the home easily resolve the communication demand of SaaS. Although some early web services were deployed on expensive large-scale computers\u2014in part because such computers were more reliable and in part because it was easier to operate a few large computers\u2014a contrarian approach soon overtook the indus- try. Collections of commodity small-scale computers connected by commodity Ethernet switches, which became known as clusters, offered several advantages over the \u201cbig iron\u201d hardware approach: \u2022 Because of their reliance on Ethernet switches to interconnect, clusters are much more scalable than conventional servers. Early clusters offered 1000 computers, and today\u2019s datacenters contain 100,000 or more. \u2022 Careful selection of the type of hardware to place in the datacenter and careful control of software state made it possible for a very small number of operators to successfully run thousands of servers. In particular, some datacenters rely on virtual machines to simplify operation. A virtual machine monitor is software that imitates a real computer so successfully that you can even run an operating system correctly on top of the virtual machine abstraction that it provides (Popek and Goldberg 1974). The goal is to imitate with low overhead, and one popular use is to simplify software distribution within a cluster. In this way, multiple apps can share hardware with each app even believing it has its own copy of the operating system. If the apps are also able to share the operating system, an even more ef\ufb01cient way to share hardware is to use OS-level virtualiza- tion; the popular tool Docker, which allows each app to run in its own container on a shared OS, is one example. \u2022 Two senior architects at Google showed that the cost of the equivalent amount of pro- cessors, memory, and storage is much less for clusters than for \u201cbig iron,\u201d perhaps by a factor of 20 (Barroso and Hoelzle 2009). Luiz Barroso, VP of Engineering at Google and winner of the 2020 ACM/IEEE Eckert-Mauchly Award, gives an excellent brief history of warehouse-scale computing at the beginning of his award acceptance speech4. FarmVille had 1 million players within 4 days after it was announced, 10 million after 2 months, and 75 million after 9 months. (The prior record for number of users of a social networking game was 5 million.) Fortunately, FarmVille used the Elastic Compute Cloud (EC2) from Amazon Web Services, and kept up with its popularity by simply paying to use larger clusters. 26 CHAPTER 1. INTRODUCTION TO AGILE & SAAS \u2022 Although the cluster components are less reliable than conventional servers and storage systems, the cluster software infrastructure makes the whole system dependable via extensive use of redundancy in both hardware and software. The low hardware cost makes the redundancy at the software level affordable. Modern service providers also use multiple datacenters that are distributed geographically so that a natural disaster cannot knock a service of\ufb02ine. As Internet datacenters grew, some service providers realized that their per capita costs were substantially below what it cost others to run their own smaller datacenters, in large part due to economies of scale when purchasing and operating 100,000 computers at a time. They also bene\ufb01t from higher utilization given that many companies could share these giant datacenters, which (Barroso and Hoelzle 2009) call Warehouse Scale Computers, whereas smaller datacenters often run at only 10% to 20% utilization. Thus, these companies realized they could pro\ufb01t from making their datacenter hardware available on a pay-as-you-go basis. The result is called public cloud services, utility computing , or often simply cloud computing , which offers computing, storage, and communication at pennies per hour (Arm- brust et al. 2010). Moreover, there is no additional cost for scale: Using 1000 computers for"
    ]
  },
  {
    "id": "sec_0159",
    "title": "1 hour costs no more than using 1 computer for 1000 hours. Leading examples of \u201cin\ufb01nitely",
    "pages": [
      38,
      39
    ],
    "text_blocks": [
      "scalable\u201d pay-as-you-go computing are Amazon Web Services, Google AppEngine, and Mi- crosoft Azure. The public cloud means that today anyone with a credit card and a good idea can start a SaaS company that can grow to millions of customers without \ufb01rst having to build and operate a datacenter. From 2010\u20132020, Cloud Computing and SaaS began a major transformation of the com- puter industry. The full impact of this revolution will take the rest of this decade to determine. What is clear is that engineering SaaS for Cloud Computing is radically different from engi- neering shrink-wrap software (SaaP) for PCs and servers, which is why you\u2019re reading this book. Summary \u2022 The Internet supplies the communication for SaaS. \u2022 Cloud Computing provides the scalable and dependable hardware computation and storage for SaaS. \u2022 Cloud computing consists of clusters of commodity servers that are connected by local area network switches, with a software layer providing suf\ufb01cient redundancy to make this cost-effective hardware dependable. \u2022 These large clusters or Warehouse Scale Computers offer economies of scale. \u2022 Taking advantage of economies of scale, some Cloud Computing providers offer this hardware infrastructure as low-cost utility computing that anyone can use on a pay-as-you-go basis, acquiring resources immediately as your customer demand grows and releasing them immediately when it drops. Self-Check 1.7.1. True or False: Internal datacenters could get the same cost savings as Warehouse Scale Computers (WSCs) if they embraced SOA and purchased the same type of 1.8. DEPLOYING SAAS: BROWSERS AND MOBILE 27 hardware. False. While imitating best practices of WSC could lower costs, the major cost advantage of WSCs comes from the economies of scale, which today means 100,000 servers, thereby dwar\ufb01ng most internal datacenters."
    ]
  },
  {
    "id": "sec_0160",
    "title": "1.8 Deploying SaaS: Browsers and Mobile",
    "pages": [
      39,
      40,
      41,
      42,
      43
    ],
    "text_blocks": [
      "Beginning around 1994, the stunning success of the Web quickly led to the phasing-out of many SaaP desktop apps. The proprietary client UIs of fee-based services such as AOL and CompuServe were replaced by free Web-based portals such as Yahoo!. Specialized SaaP apps for accessing Internet-based services, such as Eudora for email, were replaced by browser- based email such as Hotmail. Even productivity apps such as Microsoft Word began to feel pressure from browser-based competitors such as Google Docs. The browser thus became a universal client: any site the browser visited could deliver all the information necessary to render that site\u2019s user interface using HTML, the Hypertext Markup Language. As we\u2019ll see, JavaScript entered the picture later as a way to enrich the interactive experience of Web pages, but the actual visible page content always consists of HTML. As its name implies, HTML is an example of a markup language: it combines text with markup (annotations about the text\u2019s structure) in a way that makes it easy to syntactically distinguish the two. Technically, HTML 5 (the current widely-used version) is really just one type of document that can be expressed in XML, an eXtensible Markup Language that can be used both to represent data and to describe other markup languages. Separating an HTML document\u2019s logical structure from its appearance confers many bene\ufb01ts. Structure refers to the kind of content each logical component of a page represents, such as a major or minor heading, a bulleted list, a paragraph of text, and so on. Some components are simple, such as a page title or a dropdown menu of choices, and correspond to an HTML element with no children. More often, a component consists of an HTML div element with other elements nested inside it. divs often group together logically-related elements, and may be nested. Appearance refers not only to basic typography such as fonts and colors, but to the layout of elements on a page. For example, a navigation menu that is best displayed as a set of horizontal tabs on a full-size screen may work better if displayed as a drop-down menu on a mobile phone screen, even though the menu choices and their meanings are the same. The key to separating structure and appearance is the use of Cascading Style Sheets (CSS), introduced in 1996 as a way to associate visual rendering information with HTML elements. The key concept of CSS is that of a selector \u2014an expression that matches one or more HTML elements in a document. Even if you\u2019re not the developer who will be in charge of visual appearance, understanding CSS selectors is important because, as we will see in Chapter 6, selectors are a key mechanism used by JavaScript frameworks such as jQuery that allow you to create rich interactive Web pages. While there are multiple ways a selector can match an element, by far the most widely used is to associate the selector with an element\u2019s class attribute, since multiple elements of the same or different types on a page can share the same class attribute(s). Figure 1.7 shows a very simple HTML page. The basic mechanism of using CSS to \u201cstyle\u201d HTML is as follows: 1. When the browser loads the page, it looks for one or more link elements, which should As a reminder, the Concepts & Prerequisites page suggests self-study materials for basic HTML and CSS. 28 CHAPTER 1. INTRODUCTION TO AGILE & SAAS <! DOCTYPE html > < html > https://gist.github.com/edb6a189f7892a17b0bc06f0ec2e6d34 1 2 3 4 < head > bootstrap . min . css \" > < link rel = \" stylesheet \" href = \" https :// getbootstrap . com / docs /4.0/ dist / css / 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 < title > Dietary Preferences of Penguins </ title > </ head > < body > < div class = \" container \" > <h1 > Introduction </ h1 > <p class = \" lead \" > This article is a review of the book <i > Dietary Preferences of Penguins </ i > , by Alice Jones and Bill Smith . Jones and Smith 's controversial work makes three hard - to - swallow claims about penguins : </p > < ul class =\" list - group \" > < li class =\" list - group - item \" > First , that penguins actually prefer eating tropical foods to fish </ li > < li class =\" list - group - item \" > Second , that eating tropical foods makes them smell unattractive to predators </ li > </ ul > </ div > </ body > </ html > Figure 1.7: At its simplest, an HTML 5 document is a \ufb01le of text beginning with the XML document type declaration, followed by a single html element whose child elements represent the components on the page. The use of angle brackets for HTML tags comes from SGML (Standard Generalized Markup Language), a codi\ufb01ed standardization of IBM\u2019s Generalized Markup Language, developed in the 1960s for encoding computer-readable project documents. 1.8. DEPLOYING SAAS: BROWSERS AND MOBILE 29 be children of the HTML document\u2019s head element, that specify stylesheets to be used in conjunction with this document. In this case, the link\u2019s href (target) refers to the main stylesheet of Bootstrap CSS, which we discuss next. 2. The browser loads each referenced CSS stylesheet. A stylesheet contains a set of se- lectors and, for each selector, a set of rules for how to display elements matching that selector. These rules can specify typography, layout on the page, colors, and more. 3. When displaying the page, the browser matches up the CSS rules with the matching elements on each displayed page. In this example, Bootstrap provides basic style rules for each element type (h1, p, ul, and so on), and the class attributes on various elements are there to match particular CSS selectors in Bootstrap that further \u201ctweak\u201d the formatting of speci\ufb01c page elements. While CSS syntax is simple, creating visually appealing stylesheets requires graphic de- sign and typography skills. Those of us who lack those skills are better served by using ex- isting stylesheets designed by professionals, collections of which are sometimes referred to as CSS frameworks, or more commonly, front-end frameworks if they also include JavaScript code to further enhance visual effects by adding animations, fades, and so on that are impos- sible using CSS alone. A widely-used front-end framework to which we\u2019ll refer throughout the book is Bootstrap, an open source project contributed by Twitter. A good CSS framework provides at least four main bene\ufb01ts: The CSS Zen Garden shows how dramatically different the same HTML content can be made to look with different CSS stylesheets. 1. A set of high-level components that combine multiple HTML elements into a logical unit. For example, a navigation menu with dropdowns can be managed as a single component, even though it includes many HTML elements. 2. A grid metaphor for specifying the layout of components on a page. In the case of Bootstrap, the page is divided into 12 columns, and any component can be speci\ufb01ed to span any number of columns, with the same component having different layout instructions for smaller vs. larger screens. 3. Responsive behavior on a variety of display sizes. gation menu that normally displays as a set of horizontal tomatically rendered as vertically-stacked choices when the display is small, even if you haven\u2019t explicitly provided such instructions. https://getbootstrap.com/docs/4.0/examples/navbars/5 navigation bars in Bootstrap behave as the screen is resized. examples shows For example, a navi- tabs will be au- too The page how of 4. Support for accessibility for users with disabilities, such as by providing styles for content that should be visually hidden but remain accessible to assistive technologies such as screen readers. HTML/CSS frameworks have become particularly important with the takeover of mobile devices. Although Apple\u2019s introduction of the iPhone in 2007 was de\ufb01nitely not the \ufb01rst smartphone to feature installable apps or Web browsing, it was the \ufb01rst to become wildly successful and widely copied. By 2017, just ten years later, about a third of the world\u2019s population had smartphones, and these accounted for more visits to Web sites than desktops or laptops (Enge 2018). Up to a point, carefully-designed CSS styles can make the same HTML content usable on a wide range of screen sizes. For this reason, while Figure 1.8 30 CHAPTER 1. INTRODUCTION TO AGILE & SAAS Advantages Mobile-\ufb01rst/responsive Web site (HTML, CSS, JavaScript) Use same languages, tools, and framework as desktop SaaS Portable across devices, so no need to develop/main- tain multiple versions User never needs to install updates Can be made to work even when disconnected from the Internet7 Icon placement on user\u2019s home screen (via Web book- mark) Disadvantages Not listed in app stores May lack access to advanced platform hardware fea- tures Depending on app complexity, performance may be noticeably lower than platform-speci\ufb01c app \u201cWrapped\u201d app Same bene\ufb01ts as mobile website approach except for zero-install updates Can be listed in app stores Must rely on users to download and install updates Additional software framework such as PhoneGap re- quired to \u201cpackage\u201d app for distribution Platform app for Android (Java) or iOS (Objective-C) Best performance Can be listed in app stores Guaranteed access to all platform hardware features Must install and learn new platform, development environment, testing framework, and deployment pipeline Must rely on users to download and install updates in a timely way, and commit to supporting old versions until they do Supporting multiple platforms requires maintaining multiple codebases Back to SaaP? The proliferation of installable platform apps has rolled back a major bene\ufb01t of SaaS\u2014users must once again manually update their apps when security bugs are found or when they upgrade their devices. And updates for mobile apps are far more frequent than they ever were for SWS\u2014in 2014, the Twitter mobile app was updated about every 20 days on average.6 Figure 1.8: Three approaches to implementing mobile clients. Today, the vast majority of mobile platform features, including disconnected operation and \ufb01ngerprint-based authentication, are now available via open Web standards as well as via the platform-speci\ufb01c programming environment. shows that there are many approaches to developing client apps, in this book we recommend creating \u201cmobile-\ufb01rst\u201d apps using HTML5, CSS, and JavaScript, thus taking advantage of the extensive existing tooling available in that ecosystem, especially the Bootstrap presentation framework and the jQuery DOM library, which we discuss in Chapter 6. Despite the differences among the ways of building mobile or desktop SaaS, all such apps are structurally similar: they provide a local user interface, possibly including local storage, and they use open SaaS standards and protocols to communicate with one or more remote servers. 1.9. BEAUTIFUL VS. LEGACY CODE 31 Summary \u2022 An HTML (HyperText Markup Language) document consists of a hierarchically nested collection of elements. Each element begins with a tag in <angle brackets> that may have optional attributes. Some elements enclose content. In general, the elements describe the logical structure of the parts of the document, but not how the document should appear when rendered on a screen. \u2022 Cascading Style Sheets (CSS) is a stylesheet language describing visual attributes of elements on a Web page. A stylesheet associates sets of visual properties with selectors that match one or more page elements. There are many ways to express selectors that match different elements, but the most common is to associate one or more CSS classes with the element and write selectors that match elements based on class. \u2022 CSS stylesheets are separate from HTML documents, and link element(s) inside the head element of an HTML document associate one or more stylesheets with that document. \u2022 Mobile devices now account for the majority of visits to SaaS apps. One way to build \u201cmobile-\ufb01rst\u201d client apps that work well on smartphones is to use CSS frameworks such as Bootstrap. These frameworks provide different sets of CSS formatting rules for the same HTML elements depending on the kind of device on which the HTML is being viewed. \u2022 Another way to build \u201cmobile-\ufb01rst\u201d client apps is to create platform-speci\ufb01c instal- lable smartphone apps. Platform apps may allow access to some device features unavailable from HTML, but they also negate important SaaS advantages such as eliminating the need to install updates and maintain multiple codebases. Self-Check 1.8.1. How would you ensure the same CSS stylesheet(s) are used for all pages in your site or your app? Each individual HTML document must include its own stylesheet links, so you\u2019d ensure that the same <link> element appears within the <head> of each page of your site or app."
    ]
  },
  {
    "id": "sec_0161",
    "title": "1.9 Beautiful vs. Legacy Code",
    "pages": [
      43,
      44
    ],
    "text_blocks": [
      "To me programming is more than an important practical art. undertaking in the foundations of knowledge. It is also a gigantic \u2014Grace Murray Hopper Unlike hardware, software is expected to grow and evolve over time. Whereas hard- ware designs must be declared \ufb01nished before they can be manufactured and shipped, initial software designs can easily be shipped and later upgraded over time. Basically, the cost of upgrade in the \ufb01eld is astronomical for hardware and affordable for software. Hence, software can achieve a high-tech version of immortality, potentially getting better over time while generations of computer hardware decay into obsolescence. The drivers of Grace Murray Hopper (1906\u20131992) was one of the \ufb01rst programmers and developed the \ufb01rst compiler. \u201cAmazing Grace\u201d became a Rear Admiral in the US Navy, and in 1997, a warship was named for her, the USS Hopper. The Oldest Living Program might be MOCAS8 (\u201cMechanization of Contract Administration Services\u201d), which was originally purchased by the US Department of Defense in"
    ]
  },
  {
    "id": "sec_0162",
    "title": "1958 and was still in use as",
    "pages": [
      44,
      45
    ],
    "text_blocks": [
      "of 2005. Abacuses are still in use today in many parts of the world despite being thousands of years old. 32 CHAPTER 1. INTRODUCTION TO AGILE & SAAS software evolution are not only \ufb01xing faults, but also adding new features that customers re- quest, adjusting to changing business requirements, improving performance, and adapting to a changed environment. Software customers expect to get notices about and install improved versions of the software over the lifetime that they use it, perhaps even submitting bug reports to help developers \ufb01x their code. They may even have to pay an annual maintenance fee for this privilege! Just as novelists fondly hope that their brainchild will be read long enough to be labeled a classic\u2014which for books is 100 years!\u2014software engineers should hope their creations would also be long lasting. Of course, software has the advantage over books of being able to be improved over time. In fact, a long software life often means that others maintain and enhance it, letting the creators of the original code off the hook. This brings us to a few terms we\u2019ll use throughout the book. The term legacy code refers to software that, despite its old age, continues to be used because it meets customers\u2019 needs. Sixty percent of software maintenance costs are for adding new functionality to legacy software, vs. only 17% for \ufb01xing bugs, so legacy software is successful software. The term \u201clegacy\u201d has a negative connotation, however, in that it indicates that the code is dif\ufb01cult to evolve because it has an inelegant design or uses antiquated technology. In contrast to legacy code, we use the term beautiful code to indicate long-lasting code that is easy to evolve. The worst case is not legacy code, however, but unexpectedly short-lived code that is soon discarded because it doesn\u2019t meet customers\u2019 needs. We\u2019ll highlight examples that lead to beautiful code with the Mona Lisa icon. Similarly, we\u2019ll highlight text that deals with legacy code using an abacus icon, which is certainly a long-lasting but little changed calculating device. In the following chapters, we show examples of both beautiful code and legacy code that we hope will inspire you to make your designs simpler to evolve. Surprisingly, despite the widely accepted importance of enhancing legacy software, this topic is traditionally ignored in college courses and textbooks. We feature such software in this book for three reasons. First, you can reduce the effort to build a program by \ufb01nding existing code that you can reuse. One supplier is open source software. Second, it\u2019s advantageous to learn how to build code that makes it easier for successors to enhance, since such code is more likely to enjoy a long life. Finally, unlike Plan-and-Document, in Agile you revise code continuously to improve the design and to add functionality starting with the second iteration. Thus, the skills you practice in Agile are exactly the ones you need to evolve legacy code\u2014no matter how it was created\u2014and the dual use of Agile techniques makes it much easier for us to cover legacy code within a single book. Summary: Successful software can live decades and is expected to evolve and improve, unlike computer hardware that is \ufb01nalized at time of manufacture and can be considered obsolete within just a few years. One goal of this book is to teach you how to increase the chances of producing beautiful code so that your software lives a long and useful life. Self-Check 1.9.1. Programmers rarely set out to write bad code. Given the ideas of Sec- tion 1.5 about productivity, explain brie\ufb02y how software written a long time ago that was considered high quality at the time might be viewed as dif\ufb01cult-to-maintain legacy software today. Because of the continuously increasing level of abstraction of software tools, developers today can often create the same functionality in far fewer (and more beautiful) lines of code 1.10. GUIDED TOUR AND HOW TO USE THIS BOOK 33 Figure 1.9: An iteration of the Agile software lifecycle and its relationship to the chapters in Part II of this book. The dashed arrows indicate a more tangential relationship between the steps of an iteration, while the solid arrows indicate the typical \ufb02ow. As mentioned earlier, the Agile process applies equally well to legacy applications and new applications. than would have been possible a few decades ago, so by comparison the old code is harder to maintain, even though at the time it was written it may have represented the state of the art. Doubtless the code we write today will be viewed as archaic in another few decades!"
    ]
  },
  {
    "id": "sec_0163",
    "title": "1.10 Guided Tour and How To Use This Book",
    "pages": [
      45,
      46,
      47,
      48
    ],
    "text_blocks": [
      "As this chapter\u2019s Concepts and Prerequisites described, becoming a skilled software engineer requires both conceptual understanding and plenty of hands-on practice. Therefore, our goal in each chapter is to give you the necessary conceptual foundations to work on the exercises, where the real learning happens. The rest of the book is divided into two parts. Part I explains Software as a Service, and Part II explains modern software development, with a heavy emphasis on Agile. Chapter 3 starts Part I with an explanation of the architecture of a SaaS application, and how the Web went from a collection of static pages to an ecosystem of services characterized by RESTful APIs\u2014that is, Application Programming Interfaces based on the design stance of Representational State Transfer. Since languages and frameworks evolve rapidly, we believe learning how to learn new languages and frameworks is a more valuable skill than knowing a speci\ufb01c language or frame- work. Thus, Chapter 2 introduces our methodology for doing so, using Ruby as an example, for programmers already familiar with another modern language such as Java or Python. Similarly, today the main reason for learning a new language is often the desire to use a framework that relies on that language. A good framework both rei\ufb01es a particular ap- plication architecture and takes advantage of the features of a particular language to make 34 CHAPTER 1. INTRODUCTION TO AGILE & SAAS development easy when it conforms to that architecture. Chapter 4 introduces the basics of Rails and its central metaphor of the Model\u2013View\u2013Controller architecture. Chapter 5 covers more advanced Rails features and shows in more depth how Rails takes advantage of Ruby\u2019s language features. Splitting the material this way supports readers who want to get started writing an app as soon as they can, which just requires Chapter 4. Readers already familiar with Ruby and Rails may want to skim or skip these chapters. Using the same strategy for learning new languages and frameworks, Chapter 6 introduces JavaScript, the jQuery framework, and the Jasmine testing tool. The Jasmine discussion assumes knowledge of testing, so readers may prefer to read that material after Chapter 8. Just as Rails ampli\ufb01es the power and productivity of Ruby for SaaS servers, jQuery ampli\ufb01es the power and productivity of JavaScript for the client. Given this background, the next six chapters of Part II illustrate important software en- gineering principles using Rails tools to build and deploy a SaaS app. Figure 1.9 shows one iteration of the Agile lifecycle, which we use as a framework on which to hang the next chapters of the book. Chapter 7 discusses how to work with the customer. Behavior-Driven Design (BDD) advocates writing user stories describing application use cases in terms that nontechnical customers can understand, and Chapter 7 shows how to turn user stories into integration and acceptance tests using the Cucumber tool. The chapter also explains how velocity can be used to measure progress in delivering features, and introduces the Pivotal Tracker tool to track and calculate velocity. Chapter 8 covers Test-Driven Development (TDD). The chapter demonstrates how to write good, testable code and introduces the RSpec testing tool for writing unit tests, the Guard tool for automating test running, and the SimpleCov tool to measure test coverage. Chapter 9 describes how to deal with existing code, including how to enhance legacy code. Helpfully, it shows how to use BDD and TDD to both understand and refactor code and how to use the Cucumber and RSpec tools to make this task easier. Chapter 10 gives advice on how to organize and work as part of an effective team using the Scrum principles mentioned above. It also describes how the version control system Git and the corresponding service GitHub can let team members work on different features without interfering with each other or causing chaos in the release process. To help you practice Don\u2019t Repeat Yourself, Chapter 11 introduces design patterns, which are proven structural solutions to common problems in designing how classes work together, and shows how to exploit Ruby\u2019s language features to adopt and reuse the patterns. The chapter also offers guidelines on how to write good classes. It introduces just enough UML (Uni\ufb01ed Modeling Language) notation to help you notate design patterns and to help you make diagrams that show how the classes should work. Note that Chapter 11 is about software architecture whereas prior chapters in Part II are about the Agile development process. We believe in a college course setting that this order will let you start an Agile iteration sooner, and we think the more iterations you do, the better you will understand the Agile lifecycle. However, as Figure 1.9 suggests, knowing design patterns will be useful when writing or refactoring code, since it is fundamental to the BDD/TDD process. Chapter 12 offers practical advice on how to \ufb01rst deploy and then improve performance and scalability in the cloud, and brie\ufb02y introduces some reliability and security techniques that are uniquely relevant to deploying SaaS. We conclude with an Afterword that re\ufb02ects on the material in the book and projects what 1.10. GUIDED TOUR AND HOW TO USE THIS BOOK 35 might be next. CHIPS. As Confucius said: \u201cI hear and I forget, I see and I remember, I do and I under- stand.\u201d The goal of the book is to give you just enough content to get a conceptual handle on the Coding/Hands-On Integrated Projects (CHIPS) interspersed with the text. Each CHIPS exercise contains signi\ufb01cant guidance and hints for the self-learning you\u2019ll have to do to complete it. If you\u2019re using this book in conjunction with online course materials from Co- dio (either in a classroom setting, in self-learning, or in the edX course sequence), switching between the content-oriented didactic material (COD) and the coding/hands-on integrated projects (CHIPS) is especially easy, and your assignments will be automatically graded for you. Instructors and self-learners, please see www.saasbook.info for more information on all of these options. Terminology. You will encounter many new technical terms (and buzzwords) as you dive into this rich ecosystem. To help you identify important terms, text formatted like this refers to terms with corresponding Wikipedia entries. (In the Kindle book, PDF document, and Codio book, the terms link to the appropriate Wikipedia page.) Depending on your background, we suspect you\u2019ll need to read some chapters more than once before you get the hang of it. Each chapter concludes with a section called Fallacies and Pitfalls, which explains com- mon misconceptions or problems that are easy to experience if you\u2019re not vigilant, and Con- cluding Remarks to provide resources for those who want to dig more deeply into some of the chapter\u2019s concepts. Summary: \u2022 Software engineering can only be learned by doing, and learning by doing is not about following a recipe or cutting and pasting code. The text in this book (COD, or content-oriented didactics) gives you the conceptual foundation to work on the CHIPS (coding/hands-on integrated projects). Both are essential to learning the material. \u2022 If you\u2019re using the book in conjunction with the Codio IDE (either in your class- room, on your own, or in the edX courses), the programming assignments are auto- matically graded for you and all necessary software is preinstalled. \u2022 Each chapter begins with a list of the big ideas of that chapter and the prerequisite knowledge for the chapter. \u2022 Don\u2019t skip the Fallacies & Pitfalls! Even experts run into them, which is why they get a section to themselves in each chapter. Self-Check 1.10.1. Which is most important for rapidly learning SaaS development: under- standing the conceptual foundations, reading code, or writing code? All are important. You won\u2019t learn much by copying-and-pasting code if you don\u2019t un- derstand why it works (or doesn\u2019t). On the other hand, just reading about code doesn\u2019t get anything working. Inspecting others\u2019 high-quality code, which we hope your instructors will emphasize, not only shows you good examples but also helps cement your understanding of the conceptual foundations. 36 CHAPTER 1. INTRODUCTION TO AGILE & SAAS"
    ]
  },
  {
    "id": "sec_0164",
    "title": "1.11 Fallacies and Pitfalls",
    "pages": [
      48,
      49
    ],
    "text_blocks": [
      "Lord, give us the wisdom to utter words that are gentle and tender, for tomorrow we may have to eat them. \u2014Sen. Morris Udall As mentioned above, this section near the end of a chapter explains ideas of a chapter from another perspective, and gives readers a chance to learn from the mistakes of others. Fallacies are statements that seem plausible (or are actually widely held views) based on the ideas in the chapter, but they are not true. Pitfalls, on the other hand, are common dangers associated with the topics in the chapter that are dif\ufb01cult to avoid even when you are warned. Fallacy: The Agile lifecycle is best for all software development. Agile is a nice match to many types of software, particularly SaaS, which is why we use it in this book. However, Agile is not best for everything. Agile may be ineffective for safety-critical apps, for example. Our experience is that once you learn the classic steps of software development and have a positive experience in using them via Agile, you will use these important software engi- neering principles in other projects no matter which methodology is used. Each chapter in Part II concludes with a contrasting Plan-and-Document perspective to help you understand these principles and to help you use other lifecycles should the need arise. Nor will Agile be the last software lifecycle you will ever see. We believe that new development methodologies develop and become popular in response to new opportunities, so expect to learn new methodologies and frameworks in your future. Pitfall: Ignoring the cost of software design. Since there is essentially no cost to distribute software, the temptation is to believe there is almost no cost to changing it so that it can be \u201cremanufactured\u201d the way the customer wants. However, this perspective ignores the cost of design and test, which can be a substantial part of the overall costs for software projects. Zero manufacturing cost is also one rationalization used to justify pirating copies of software and other electronic data, since pirates apparently believe no one should pay for the cost of development, just for manufacturing. Pitfall: Ignoring the historical context of software technology. Those who cannot remember the past are condemned to repeat it. \u2014George Santayana Software engineering is a relatively young engineering \ufb01eld, but a fast-moving one. If you try to learn software technologies while ignoring the historical context in which they arose, you risk making underinformed choices about what tools to use, or worse, \u201creinventing the wheel\u201d without learning from the experiences of others. For example, if you\u2019re debating 1.12. CONCLUDING REMARKS: SOFTWARE ENGINEERING IS MORE THAN PROGRAMMING37 with colleagues about the advisability of using Node.js as your application server, but you are unfamiliar with the long-running \u201cthreads vs. events\u201d debates in the systems software community, at best you will be having an under-informed discussion, and at worst you will be quickly beset by woe. Similarly, the feature creep of \u201cNoSQL\u201d databases mirrors the progression of events that led to the invention of the relational model and its eventual dom- inance over the older hierarchical database model , which \u201cbaseline\u201d NoSQL databases strongly resemble. Reinventing the wheel isn\u2019t always necessarily a bad thing. Sometimes the existing wheel really isn\u2019t a great \ufb01t for your needs\u2014as Douglas Crockford is said to have remarked, \u201cThe good thing about reinventing the wheel is that you can get a round one.\u201d Our hope is that learners of this material will choose to take a few extra minutes to gain a broader perspective on why various things are the way they are (or not). We believe this will not only help you decide whether a particular wheel reinvention is a good one, but also help you avoid techno-fetishism\u2014the belief that a new \u201crockstar\u201d technology is important and worth learning simply because it\u2019s new (or fast, or lean, or whatever), without a well-grounded per- spective of its strengths and weaknesses or of how it builds on ideas that have been explored previously. Pitfall: Being overly focused on learning framework X as rapidly as possible. Possible values of X change so quickly that in any given leap year, the \u201cnew hot tech\u201d for building software is probably different from what it was during the previous leap year. Indeed, since the \ufb01rst edition of this book in 2013, \u201chot tech\u201d for building front-end apps has changed from Prototype.js to jQuery to Angular to Ember to Backbone to React, with Vue now another contender. Therefore, your authors believe that it\u2019s more valuable to learn how to learn new languages and frameworks, by understanding the fundamental principles of software architecture and design on which they\u2019re built, by continuously acquiring \ufb02uency in multiple frameworks and tools, and by adopting an ecumenical approach to the question of \u201cwhich language or framework is best\u201d for a given project."
    ]
  },
  {
    "id": "sec_0165",
    "title": "1.12 Concluding Remarks: Software Engineering Is More Than Program-",
    "pages": [
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56
    ],
    "text_blocks": [
      "ming The Concluding Remarks at the end of each chapter give the learner some perspective on what the chapter has covered: Where did the technical ideas or innovations come from? What, if anything, can we say about where they are going, given that history? Where can an interested reader learn more about these topics? These sections never contain speci\ufb01c technical skill content, so if you\u2019re in a rush, you can skip them; but if you want to become a seasoned practitioner and a good designer of software and tools, you probably shouldn\u2019t. But if Extreme Programming is just a new selection of old practices, what\u2019s so extreme about it? Kent\u2019s answer is that it takes obvious, common sense principles and practices to extreme levels. For example: \u2014 If short iterations are good, make them as short as possible\u2014hours or minutes or seconds rather than days or weeks or years. \u2014 If simplicity is good, always do the simplest thing that could possibly work. \u2014 If testing is good, test all the time. Write the test code before you write the code to test. \u2014 If code reviews are good, review code continuously, by programming in pairs, two programmers to a computer, taking turns looking over each other\u2019s shoulders. 38 CHAPTER 1. INTRODUCTION TO AGILE & SAAS Figure 1.10: The Virtuous Triangle of Engineering SaaS is formed from the three software engineering crown jewels of (1) SaaS on Cloud Computing, (2) Agile Development, and (3) Highly Productive Framework and Tools. \u2014Michael Swaine, interview with Kent Beck, (Swaine 2001) This single quote gives a good deal of the rationale behind the extreme programming (XP) version of Agile that we cover in this book. We keep iterations short, so that the customer sees the next version of the incomplete but working prototype every week or two. You write the tests before you write the code, and then you write the least amount of code it takes to make it pass the test. Pair programming means the code is under continuous review, rather than just on special occasions. Agile went from software methodology heresy to the dominant form of development in just a dozen years, and when combined with service oriented architecture, allows complex services to be built reliably. While there is no inherent dependency among SaaS, Agile, and highly productive frame- works like Rails, Figure 1.10 suggests there is a synergistic relationship among them. Agile development means continuous progress while working closely with the customer, and SaaS on Cloud Computing enables the customer to use the latest version immediately, thereby clos- ing the feedback loop (see Chapters 7 and Chapter 12). SaaS on Cloud Computing matches the Model\u2013View\u2013Controller design pattern (see Chapter 11), which Highly-Productive SaaS Frameworks expose (see Chapters 3, 4, and 5). Highly Productive Frameworks and Tools designed to support Agile development remove obstacles to practicing Agile (see Chapters 7, 8, and 10). We believe these three \u201ccrown jewels\u201d form a \u201cvirtuous triangle\u201d that leads to on-time and on-budget engineering of beautiful Software as a Service, and they form the foundation of this book. 1.12. SOFTWARE ENGINEERING IS MORE THAN PROGRAMMING 39 This virtuous triangle also helps explain the innovative nature of the Rails community, where new important tools are frequently developed that further improve productivity, simply because it\u2019s so easy to do. We fully expect that future editions of this book will include tools not yet invented that are so helpful that we can\u2019t imagine how we got our work done without them! As teachers, since many students \ufb01nd the Plan-and-Document methods tedious, we are pleased that the answers to the 10 questions in Figure 1.5 strongly recommend using Agile for student team projects. Nevertheless, we believe it is worthwhile for readers to be familiar with the Plan-and-Document methodology, as there are some tasks where it may be a better match, some customers require it, and it helps explain parts of the Agile methodology. Thus, we include sections near the end of all chapters in Part II that offer the Plan-and-Document perspective. As researchers, we are convinced that software of the future will increasingly be built and rely on services in the Cloud, and thus Agile methodology will continue to increase in popularity in part given the strong synergy between them. Hence, we are at a happy point in technology where the future of software development is more fun both to learn and to teach. Highly productive frameworks like Rails let you understand this valuable technology by doing in a remarkably short time. The main reason we wrote this book is to help more people become aware of and take advantage of this extraordinary opportunity. Cloud computing had existed for only a few years prior to the First Edition of this book, and has evolved spectacularly since then. Clusters of commodity computers had long been the basis of SaaS, but cloud computing changed how those clusters are used. Until the late 1990s, it was common for a particular computer to be dedicated to a particular SaaS app and have preinstalled all of the software components needed to run it. In contrast, starting in the mid 2000s, virtual machine technology made it possible for a single physical computer to emulate many computers, such that the software running in each virtual computer believed it was running on the real hardware. Like many other SaaS-relevant technologies, virtual machines had been around for decades\u2014in this case, since at least the 1960s\u2014but falling hardware costs and the dominance of the Intel architecture in server computers made high- performance virtual machines a practical tool for hosting many different SaaS apps on a single computer, even those requiring different operating systems and software packages. A typical SaaS app only cares about the type of virtual machine it\u2019s running in, and can remain largely ignorant of the details of the hardware and OS on which that virtual machine is hosted. Since the mid 2000s, further evolution of virtual machine technology led to lightweight container frameworks such as Docker, which isolate software packages from each other while sharing a single operating system kernel image. The most recent phase of virtualization is Function as a Service (FaaS), since the developer now speci\ufb01es only the code of one or more functions and pays per function invocation. An early example is Amazon Lambda9. Although FaaS is also referred to as \u201cserverless computing\u201d, it is of course not truly serverless, as the functions have to run somewhere. The key distinction from SaaS is that developers do not deal with a software stack consisting of an app server, HTTP server, and so on; they write only the functions. Serverless computing is still evolving and has both pros and cons depending on the type of app to be deployed (Castro et al. 2019). We believe if you learn the contents of this book in conjunction with doing the suggested assignments and activities (CHIPS), you can build your own (simpli\ufb01ed) version of a popular software service like FarmVille or Twitter while learning and following sound software engi- neering practices. While being able to imitate currently successful services and deploy them In the venerable LISP language, functions were called lambda-expressions, since the language was heavily inspired by the lambda calculus formalism. 40 REFERENCES in the cloud in a few months is impressive, we are even more excited to see what you will in- vent given this new skill set. We look forward to your beautiful code becoming long-lasting, and to becoming some of its passionate fans! C. Alexander, S. Ishikawa, and M. Silverstein. A Pattern Language: Towns, Buildings, Construction (Cess Center for Environmental). Oxford University Press, 1977. ISBN 0195019199. M. Armbrust, A. Fox, R. Grif\ufb01th, A. D. Joseph, R. Katz, A. Konwinski, G. Lee, D. Patterson, A. Rabkin, I. Stoica, and M. Zaharia. A view of cloud computing. Communications of the ACM (CACM), 53(4):50\u201358, Apr. 2010. L. A. Barroso and U. Hoelzle. The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines (Synthesis Lectures on Computer Architecture). Morgan and Claypool Publishers, 2009. ISBN 159829556X. URL http://www.morganclaypool. com/doi/pdf/10.2200/S00193ED1V01Y200905CAC006. S. Begley. As Obamacare tech woes mounted, contractor payments soared. Reuters, Oc- tober 17, 2013. URL http://www.nbcnews.com/politics/politics-news/stress- tests-show-healthcare-gov-was-overloaded-v21337298. J. Bidgood. Massachusetts appoints of\ufb01cial and hires \ufb01rm to \ufb01x exchange problems. New York Times, February 7, 2014. URL http://www.nytimes.com/news/affordable- care-act/. B. W. Boehm. Software engineering: R & D trends and defense needs. In P. Wegner, editor, Research Directions in Software Technology, Cambridge, MA, 1979. MIT Press. B. W. Boehm. A spiral model of software development and enhancement. In ACM SIGSOFT Software Engineering Notes, 1986. E. Braude. Software Engineering: An Object-Oriented Perspective. John Wiley and Sons, 2001. ISBN 0471692085. P. Castro, V. Ishakian, V. Muthusamy, and A. Slominski. The rise of serverless computing. Communications of the ACM (CACM), 62(12), Dec 2019. R. Charette. Why software fails. IEEE Spectrum, 42(9):42\u201349, September 2005. L. Chung. Too big to \ufb01re: How government contractors on HealthCare.gov maximize prof- its. FMS Software Development Team Blog, December 7, 2013. URL http://blog. fmsinc.com/too-big-to-fire-healthcare-gov-government-contractors. M. Cormick. Programming extremism. Communications of the ACM, 44(6):109\u2013110, June 2001. E. Enge. Mobile vs desktop usage in 2018: Mobile takes the lead. Stone Temple Consult- ing, Apr 2018. URL https://www.stonetemple.com/mobile-vs-desktop-usage- study. H.-C. Estler, M. Nordio, C. A. Furia, B. Meyer, and J. Schneider. Agile vs. structured distributed software development: A case study. In Proceedings of the 7th International Conference on Global Software Engineering (ICGSE\u201912)), pages 11\u201320, 2012. REFERENCES 41 ET Bureau. Need for speed: More it companies switch to agile code development. The Eco- nomic Times, August 6, 2012. URL http://articles.economictimes.indiatimes. com/2012-08-06/news/33065621_1_thoughtworks-software-development- iterative. M. Fowler. The New Methodology. martinfowler.com, 2005. URL http://www. martinfowler.com/articles/newMethodology.html. E. Harrington. Hearing: Security \ufb02aws in Obamacare website endanger AmericansHealth- Care.gov. Washington Free Beacon, 2013. URL http://freebeacon.com/hearing- security-flaws-in-obamacare-website-endanger-americans/. S. Horsley. Enrollment jumps at HealthCare.gov, though totals still lag. NPR.org, Decem- ber 12, 2013. URL http://www.npr.org/blogs/health/2013/12/11/250023704/ enrollment-jumps-at-healthcare-gov-though-totals-still-lag. A. Howard. Why Obama\u2019s HealthCare.gov launch was doomed to fail. The Verge, Octo- ber 8, 2013. URL http://www.theverge.com/2013/10/8/4814098/why-did-the- tech-savvy-obama-administration-launch-a-busted-healthcare-website. C. Johnson and H. Reed. Why the government never gets tech right. New York Times, Octo- ber 24, 2013. URL http://www.pmi.org/en/Professional-Development/Career- Central/Must_Have_Skill_Agile.aspx. J. Johnson. The CHAOS report. Technical report, The Standish Group, Boston, Mas- sachusetts, 1995. URL http://blog.standishgroup.com/. J. Johnson. HealthCare.gov chaos. Technical report, The Standish Group, Boston, Massachusetts, October 22, 2013a. URL http://blog.standishgroup.com/images/ audio/HealthcareGov_Chaos_Tuesday.mp3. J. Johnson. The CHAOS manifesto 2013: Think big, act small. Technical report, The Standish Group, Boston, Massachusetts, 2013b. URL http://www.standishgroup.com. Software project management practices: success. C. Jones. CrossTalk: Journal of Defense Software Engineering, pages 5\u20139, Oct. 2004. URL http://cross5talk2.squarespace.com/storage/issue-archives/ 2004/200410/200410-Jones.pdf. Failure versus The J. M. Juran and F. M. Gryna. Juran\u2019s quality control handbook. New York: McGraw-Hill, 1998. P. Kruchten. The Rational Uni\ufb01ed Process: An Introduction, Third Edition. Addison-Wesley Professional, 2003. ISBN 0321197704. T. Lethbridge and R. Laganiere. Object-Oriented Software Engineering: Practical Software Development using UML and Java. McGraw-Hill, 2002. ISBN 0072834951. National Research Council. Achieving Effective Acquisition of Information Technology in the Department of Defense. The National Academies Press, 2010. ISBN 9780309148283. URL http://www.nap.edu/openbook.php?record_id=12823. 42 NOTES P. Naur and B. Randell. Software engineering. Scienti\ufb01c Affairs Div., NATO, 1969. J. R. Nawrocki, B. Walter, and A. Wojciechowski. Comparison of CMM level 2 and extreme programming. In 7th European Conference on Software Quality, Helsinki, Finland, 2002. M. Paulk, C. Weber, B. Curtis, and M. B. Chrissis. The Capability Maturity Model: Guide- lines for Improving the Software Process. Addison-Wesley, 1995. ISBN 0201546647. G. J. Popek and R. P. Goldberg. Formal requirements for virtualizable third generation architectures. Communications of the ACM, 17(7):412\u2013421, 1974. Project Management Institute. Must-have skill: Agile. Professional Development, Febru- ary 28, 2012. URL http://www.pmi.org/en/Professional-Development/Career- Central/Must_Have_Skill_Agile.aspx. W. W. Royce. Managing the development of large software systems: concepts and tech- niques. In Proceedings of WESCON, pages 1\u20139, Los Angeles, California, August 1970. I. Sommerville. Software Engineering, Ninth Edition. Addison-Wesley, 2010. 0137035152. ISBN M. Stephens and D. Rosenberg. Extreme Programming Refactored: The Case Against XP. Apress, 2003. M. Swaine. Back to the future: Was Bill Gates a good programmer? What does Prolog have to do with the semantic web? And what did Kent Beck have for lunch? Dr. Dobb\u2019s The World of Software Development, 2001. URL http://www.drdobbs.com/back-to-the- future/184404733. A. Taylor. IT projects sink or swim. BCS Review, Jan. 2000. URL http://archive.bcs. org/bulletin/jan00/article1.htm. F. Thorp. \u2018Stress tests\u2019 show HealthCare.gov was overloaded. NBC News, November 18, 2013. URL http://www.nbcnews.com/politics/politics-news/stress-tests- show-healthcare-gov-was-overloaded-v21337298. J. Zients. HealthCare.gov progress and performance report. Technical report, Health and Human Services, December 1, 2013. URL http://www.hhs.gov/digitalstrategy/ sites/digitalstrategy/files/pdf/healthcare.gov-progress-report.pdf. Notes 1https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML#Guides 2http://www.youtube.com/watch?v=DeBi2ZxUZiM 3https://www.bbc.com/future/article/20150505-the-numbers-that-lead-to-disaster 4https://youtu.be/AP7lVJphbSk 5https://getbootstrap.com/docs/4.0/examples/navbars/ 6https://sensortower.com/blog/25-top-ios-apps-and-their-version-update-frequencies 7https://www.w3.org/TR/2011/WD-html5-20110525/offline.html 8http://developers.slashdot.org/story/08/05/11/1759213/ 9https://aws.amazon.com/lambda Part I Software as a Service: Frameworks and Languages 2 How to Learn a New Language Barbara Liskov (1939\u2013) was one of the \ufb01rst women in the USA to receive a Ph.D. in computer science (in 1968) and received the"
    ]
  },
  {
    "id": "sec_0166",
    "title": "2008 Turing Award for",
    "pages": [
      56
    ],
    "text_blocks": [
      "foundational innovations in programming language design. Her inventions include abstract data types and iterators, both of which are central to Ruby. You never need optimal performance, . . . Programmers are far too hung up with performance. you need good-enough performance \u2014Barbara Liskov, 2011 . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0167",
    "title": "2.1 Prelude: Learning to Learn Languages and Frameworks .",
    "pages": [
      56
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0168",
    "title": "2.2 Pair Programming .",
    "pages": [
      56
    ],
    "text_blocks": [
      ". . . . . Introducing Ruby, an Object-Oriented Language . 2.3 . . ."
    ]
  },
  {
    "id": "sec_0169",
    "title": "2.4 Ruby Idioms: Poetry Mode, Blocks, Duck Typing .",
    "pages": [
      56
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0170",
    "title": "2.5 CHIPS: Ruby Intro",
    "pages": [
      56
    ],
    "text_blocks": [
      ". . . . . ."
    ]
  },
  {
    "id": "sec_0171",
    "title": "2.6 Gems and Bundler: Library Management in Ruby .",
    "pages": [
      56
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0172",
    "title": "2.7 Fallacies and Pitfalls .",
    "pages": [
      56
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0173",
    "title": "2.8 Concluding Remarks: How (Not) To Learn a Language By Googling",
    "pages": [
      56,
      57,
      58
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 48 51 59 64 64 67 69 45 Prerequisites and Concepts Software engineers who are unable to quickly learn and use new languages and frame- works risk nding themselves obsolete or out of a job every few years. This chapter focuses on building those skills, starting with a developer\u2019s-eye inhalation of the Ruby language. In Chapter 6 we will repeat the process for JavaScript. Prerequisites: \u2022 You should be comfortable programming in some modern object-oriented (OO) language, such as Java or Python, including OO concepts such as class vs. instance variables and methods, public vs. private methods, and so on. \u2022 Helpful, but not strictly required, is familiarity with basic operations on collections such as those seen in functional programming languages and borrowed by the Python language. For example, map takes a function (or lambda expression) and a collection, and returns a new collection resulting from the application of the function to each element of the original collection. filter takes a Boolean-valued function and a collection, and returns a new collection consisting of those elements from the original collection for which the function returns true. \u2022 Regular expressions, sometimes abbreviated regexps or regexes, are sequences of characters that dene a search pattern. All modern programming languages use them. Rubular1 is a web app that lets you practice regexes in Ruby. Concepts: \u2022 Learning a language and learning a framework often go together: you learn Ruby so that you can use Rails. the new language, the structure or architectural model the framework prescribes for applications (how the moving parts of an application work together), and how the language\u2019s features are used to expose that structure. This means you must understand three things: \u2022 Learning a new language requires understanding its basic object-orientation and encapsulation mechanisms (classes, inheritance, composition), its basic imperative mechanics (variables, naming conventions, control ow), and how it manages complexity (namespacing, libraries, library and package management). \u2022 At the core of Ruby is the idea that everything is an object, and even basic operations like addition are dened in terms of sending a message to an object asking the object to do something. \u2022 Learning the idioms that make a language unique is a key aspect of mastering the language. Idioms pervasive in Ruby but less common in other modern languages include mix-ins (duck typing) and blocks (anonymous lambdas). \u2022 Learning a language is largely about learning its libraries and how they are man- aged. Ruby libraries (gems) and the Bundler tool allow an app to specify ne- grained dependencies on many interrelated libraries. Previously, platform-based mobile apps, or simply \u201cplatform apps,\u201d were sometimes referred to as \u201cnative apps.\u201d While many of these include elements of other language families such as functional languages, the primary way they are used is imperatively. 46 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE"
    ]
  },
  {
    "id": "sec_0174",
    "title": "2.1 Prelude: Learning to Learn Languages and Frameworks",
    "pages": [
      58,
      59,
      60
    ],
    "text_blocks": [
      "We will use the term stack to refer loosely to any set of technologies\u2014typically languages, frameworks, and subsystems\u2014used in the development of a particular type of application. A major part of most stacks is a framework for building a particular type of app using a particular language and relying on other elements in the stack. Today, most developers learn new programming languages not to use them standalone, but because they want to use a particular framework or stack: Platform-based mobile apps for iOS are written in Objective C; React.js apps are written in JavaScript; and the Ruby language had existed for 10 years before the highly productive Rails framework made it popular. As Figure 1.6 showed, though, stacks and frameworks come and go. Thus, our approach is inspired by a Chinese proverb: Give a man a \ufb01sh and you feed him for a day. Teach a man to \ufb01sh and you feed him for a lifetime. \u2014Chinese proverb Following this advice, our goal is not so much to give you a \ufb01sh (introduce you as quickly as possible to a particular framework or stack) but rather to help you learn to \ufb01sh\u2014by giving you guidance on how to develop the conceptual vocabulary to rapidly learn new ones. In this chapter and the next, we will also give you a starter \ufb01sh, in the form of the Ruby language and Rails framework. In Chapter 6, we will do the same for JavaScript and jQuery. For concreteness, we will limit our discussion of learning a new language to imperative, object-oriented (OO) languages. Besides Ruby and JavaScript, which we introduce in this book, other languages in this family include Java, Python, C++, C#, Scala, Perl, PHP, Lua, Tcl, and dozens more. As you will see, from the point of view of learning new languages, all of these languages are far more alike than they are different, because they all foster an imperative (linear, step-by-step) approach to solving programming problems and they all provide comparable facilities for managing complexity by encapsulating data along with the operations on that data. Pro\ufb01cient software engineers can rapidly learn new languages, and the stacks or frame- works that use them, by mastering a technical vocabulary consisting of three main compo- nents: 1. Learn what\u2019s different about the language: Most imperative OO languages have straightforward machinery for primitives (variables, types, control \ufb02ow), reuse (inher- itance, interfaces), complexity management (composition, inheritance, data hiding), debugging, and library usage (importing, package/dependency management). What idioms or facilities are different from other recently-popular languages? How does the language manage libraries, the learning of which typically consumes far more time than learning the language itself? 2. Understand the app architecture implied by the framework: What is the application structure or set of patterns rei\ufb01ed by the framework? What are the major \u201cmoving parts\u201d of an application built using that framework, and how does their arrangement in\ufb02uence the way we formulate an application\u2019s functionality in terms of that frame- work? 2.1. LEARNING TO LEARN LANGUAGES AND FRAMEWORKS 47 3. Associate the language\u2019s features with the frameworks\u2019 structure. How does the lan- guage help application writers by using language mechanisms to expose the frame- work\u2019s architecture and patterns? One example, as we will see, is that the Rails frame- work relies heavily on convention over con\ufb01guration: if you follow certain naming rules, you need not provide con\ufb01guration \ufb01les explaining (for example) which class in your app mediates access to which database table. Ruby supports convention over con\ufb01guration through its use of re\ufb02ection and metaprogramming. Here, then, is our 8-point plan for learning a new imperative object-oriented language: 1. Types and typing. Is the language strongly or weakly typed, and is typing static or (as in Ruby and JavaScript) dynamic? In C++ and Java, a variable\u2019s type must be declared at compile time and cannot change during program execution (static typing), and only objects of that type or a compatible subtype may ever be assigned to the variable (strong typing). In Java, for example, within the same scope, the same variable cannot be assigned \ufb01rst to an integer and later to a string. In Ruby, as we will see, a variable does not have a type declared at compile time (dynamic typing) and can be assigned to an object of any type (weak typing). This policy makes certain kinds of type errors easier to commit, but also enables an extremely powerful kind of code reuse called mix-ins, which are analogous to interfaces in Java but far more \ufb02exible. 2. Primitives. What are primitive types (numbers, strings, collections, and so on)? What are the rules or conventions for naming things (variables, functions, classes, names- paces, and so on)? What are the basic mechanisms for variable assignment, variable scope, and control \ufb02ow? What are the basic ways in which strings are manipulated, including the use of regular expressions and string interpolation? 3. Methods. How are methods (functions, procedures) de\ufb01ned and called? How are they named? How are class (static) methods differentiated from instance methods? 4. Abstraction and Encapsulation. How are classes de\ufb01ned, subclassed, and composed? What are the mechanics of specifying instance methods and variables, class (static) methods and variables, interfaces, and so on? 5. Idioms. What idioms differentiate the language from others you probably know, and how are they used? Prominent examples in Ruby include symbols (akin to immutable strings), blocks (also known as anonymous lambdas or closures, and heavily used in Ruby to implement iterators), and functional-programming idioms for operating on collections. 6. Libraries. What facilities does the language have for managing libraries? How are libraries and the functions available in them named, imported, and used? What tools for package management (also called dependency management) are available to ensure that an application can be reproducibly deployed by other developers or on production systems with the correct versions of all the libraries on which it depends? We return to this topic in Chapter 12. 7. Debugging. What debugging tools are available? Can you drop into an interactive debugger from a running program? Can you set breakpoints or watchpoints (data- value-based breakpoints) to stop a running program and inspect or modify its state? Scala is an interesting hybrid: it is dynamically but strongly typed, with type inference applied at runtime to determine whether a particular expression is legal. 48 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE Is there easy access to an interactive console, read-eval-print loop (REPL), or other mechanism to try out short bits of code interactively? 8. Testing. How do you create and run automated tests? We will introduce the topic here but we will have much more to say about it in Chapter 8. Heeding Confucius\u2019 \u201cI do and I understand,\u201d we also ask: what tools are available to allow a new developer to quickly start experimenting with the language features and come up to speed, perhaps without requiring an elaborate installation procedure on their own computer? We will use the above steps to learn just enough Ruby to allow us to dive into the pop- ular server-side SaaS framework called Rails. Beware, though: while experience in other languages can help you more quickly learn a new language, avoid the pitfall of trying to map everything directly over. It\u2019s common for two languages to have some features in common or at least some features that are analogous, but if there were no conceptual differences be- tween two languages, one of the two would be redundant. Therefore, resist the temptation to ask \u201cIs feature x in Ruby the same as feature y in Python or Java?\u201d Look for analogies and similarities, but don\u2019t expect complete isomorphism. Summary of how to learn a new language effectively: \u2022 Most imperative object-oriented languages are philosophically more alike than they are different. The basic elements of a new language\u2014types and typing, primitives, method de\ufb01nition, control \ufb02ow, abstraction and encapsulation\u2014are therefore usu- ally easy to pick up. \u2022 That said, a developer learns a new language in order to use a particular framework. Therefore, you should expect that the language may have speci\ufb01c features that make it a particularly good \ufb01t for that framework. Those features, or idioms, are likely to be heavily used by an app framework that uses the language effectively. They are more likely to be unfamiliar to you, but more critical to master in order to wield the language effectively. \u2022 Finally, using a language effectively also requires learning how to use its debugging facilities and its libraries, especially how to manage dependencies among multiple interdependent libraries."
    ]
  },
  {
    "id": "sec_0175",
    "title": "2.2 Pair Programming",
    "pages": [
      60,
      61,
      62,
      63
    ],
    "text_blocks": [
      "Interviewer: At Google, you share an of\ufb01ce, and you even code together. Sanjay: We usually sit, and one of us is typing and the other is looking on, and we\u2019re chatting all the time about ideas, going back and forth. \u2014Interview with Jeff Dean and Sanjay Ghemawat, creators of MapReduce (Hoffmann 2013) The name Extreme Programming (XP), which is the variant of the Agile lifecycle we follow in this book, suggests a break from the way software was developed in the past. One 2.2. PAIR PROGRAMMING 49 Figure 2.1: Sarah Mei and JR Boyens at Pivotal Labs engaged in pair programming. Sarah is driving and JR is observing. Although two keyboards are visible, only Sarah is coding; the computer in front of JR is for documentation and other relevant information such as Pivotal Tracker, as you can see in the right-hand photo. All the pairing stations (visible in the background) are identical and don\u2019t have email or other software installed; other computers away from the pairing stations are provided for checking email. Photo by Tonia Fox, courtesy of Pivotal Labs. new option in this brave new software world is pair programming . The goal is improved software quality by having more than one person developing the same code. But while pair programming emerged as a practice used by Agile teams and developers, your authors believe it\u2019s also a way to accelerate the learning of a new language and framework. That is why we introduce it in this chapter, whose theme is learning how to learn new languages and frameworks. Although pair programming is properly considered a software engineering process rather than being associated with a particular language, we introduce it here to encourage its use early, and especially while learning a new language. As the name suggests, in pair program- ming two developers share one computer. Each takes on a different role: \u2022 The driver enters the code and thinks tactically about how to complete the current task, explaining his or her thoughts out loud as appropriate while typing. \u2022 The observer or navigator\u2014following the automobile analogy more closely\u2014reviews each line of code as it is typed in, and acts as a safety net for the driver. The observer is also thinking strategically about future problems that will need to be addressed, and makes suggestions to the driver. Normally a pair will take alternate driving and observing as they perform tasks. Figure 2.1, shows engineers at Pivotal Labs\u2014makers of Pivotal Tracker\u2014who spend most of the day doing pair programming (Moore 2011). Pair programming is cooperative, and should involve a lot of talking. It focuses effort on the task at hand, and two people working together increases the likelihood of following good development practices. But it is effective only if both collaborators share a common focus throughout the process (Rodr\u00edguez et al. 2017); if one partner is silent or checking email, then it\u2019s not pair programming, just two people sitting near each other. In fact, it is normal for the navigator to talk more than the driver, giving constant feedback. If one collaborator is uncertain about what\u2019s going on, both collaborators should recognize that fact and pause for dialogue to get back in sync. If a large proportion of the pair\u2019s dialogue focuses on uncertainty, the pair may bene\ufb01t from outside help, such as consulting another team member or experienced developer. Dilbert on Pair Programming The comic strip Dilbert comments humorously on pair programming in these two2 strips3. 50 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE Pair programming has the side effect of transferring knowledge between the pair, includ- ing programming idioms, tool tricks, company processes, customer desires, and so on. Thus, to widen the knowledge base, some teams purposely swap partners per task so that eventually everyone is paired together. For example, promiscuous pairing of a team of four leads to six different pairings. The studies of pair programming versus solo programming support the claim of re- duced development time and improvement in software quality. For example, Cockburn and Williams 2001 found a 20% to 40% decrease in time and that the initial code failed to 15% of the tests instead of 30% by solo programmers. However, it took about 15% more hours col- lectively for the pair of programmers to complete the tasks versus the solo programmers. The majority of professional programmers, testers, and managers with 10 years of experience at Microsoft reported that pair programming worked well for them and produced higher-quality code (Begel and Nagappan 2008). A study of pair programming studies concludes that pair programming is quicker when programming task complexity is low\u2014perhaps one point tasks on the Tracker scale\u2014and yields code solutions of higher quality when task complexity is high, or three points on our Tracker scale. In both cases, it took more total effort than solo programming (Hannay et al. 2009). The experience at Pivotal Labs suggests that these studies may not factor in the negative impact on productivity of the distractions of our increasingly interconnected modern world: email, Twitter, Facebook, and so on. Pair programming forces both programmers to pay attention to the task at hand for hours at a time. Indeed, new employees at Pivotal Labs go home exhausted since they were not used to concentrating for such long stretches. Even if pair programming takes more effort, one way to leverage the productivity gains from Agile and Rails is to \u201cspend\u201d it on pair programming. Having two heads develop the code can reduce the time to market for new software or improve quality of end product. We recommend you try pair programming to see if you like it, which some developers love. Summary: When it\u2019s time to start coding, one approach is pair programming, which promises higher quality and shorter development time but perhaps higher programming costs due to two people doing the work. The pair splits into a driver and an observer, with the former working tactically to complete the task at hand and the latter thinking strategically about future challenges and making suggestions to the driver. Self-Check 2.2.1. True or False: Research suggests that pair programming is quicker and less expensive than solo programming. False. While there have not been careful experiments that would satisfy human subject ex- perts, and it is not clear whether they account for the lack of distractions when pair program- ming, the current consensus of researchers is that pair programming is more expensive\u2014more programmer hours per task\u2014than solo programming. Self-Check 2.2.2. True or False: A pair will eventually \ufb01gure out who is the best driver and who is the best observer, and then stick primarily to those roles. False: An effective pair will alternate between the two roles, as it\u2019s more bene\ufb01cial (and more fun) for the individuals to both drive and observe. 2.3. INTRODUCING RUBY, AN OBJECT-ORIENTED LANGUAGE 51"
    ]
  },
  {
    "id": "sec_0176",
    "title": "2.3 Introducing Ruby, an Object-Oriented Language",
    "pages": [
      63,
      64,
      65,
      66,
      67
    ],
    "text_blocks": [
      "Ruby is a minimalist language: while its libraries are rich, there are relatively few mecha- nisms in the language itself. Its world view might be described as \u201cextreme object orienta- tion.\u201d Two principles will help you quickly learn to read and write Ruby: 1. Everything is an object\u2014even an integer\u2014and it is literally the case that every opera- tion is a method call on some object and every method call returns a value. 2. Like Java and Python, Ruby has conventional classes; but unlike Java public at- tributes or Python instance variables, only a class\u2019s instance methods\u2014not its instance variables\u2014are visible outside the class. In other words, all access to instance vari- ables from outside the class must take place via public accessor methods; instance variables lacking public accessor methods are effectively private. (Python supports a similar approach but doesn\u2019t make it mandatory.) Let\u2019s break down our investigation of Ruby according to the elements proposed in the previous section and in light of the above principles. Types, typing, and names. Ruby is dynamically typed: variables don\u2019t have types, though the objects they refer to do. Hence x=\u2019foo\u2019 ; x=3 is legal. As row 1 of Figure 2.2 shows, a single or double @-sign precedes names of instance or class (static) variables, while local variables are \u201cbarewords\u201d; all must begin with lowercase letters, and snake_case is strongly preferred over camelCase. Row 2 shows the syntax for other named entities such as classes and constants; all except globals (which you should never use anyway) must begin with a capital letter, with UpperCamelCase used for class names. (So even though strictly speaking lowerCamelCase is legal for local and instance variables, it\u2019s highly discouraged because it is visually dif\ufb01cult to distinguish from UpperCamelCase and because of the ease with which a typo can change the former into the latter and cause errors.) The namespaces for each kind of named entity are separate, so that foo, @foo, @@foo, FOO, Foo, $FOO are all distinct. In learning any new language, an annoying type-related eye-poke is having to memorize how the language handles Boolean evaluation of non-Boolean expressions. Some languages have special Boolean types and values, such as Python\u2019s True and False (which have spe- cial type Bool), JavaScript true and false (type boolean), and Ruby\u2019s true and false (TrueClass and FalseClass respectively). To avoid confusion with such actual Boolean literals, developers often say truthy or falsy to describe the value of a non-Boolean expression e when used in a conditional of the form if (e).... Unfortunately, the rules for truthiness are different and largely arbitrary in each language. In Ruby, the literals false and nil are falsy, but all other values, including the number zero, the empty string, the empty array, and so forth, are truthy. In contrast, in Python, zero is falsy, but the empty string is truthy; in JavaScript, zero and the empty string are both falsy, as are the special values undefined and null, but the empty array is truthy; and so on. In languages that include both a true Boolean type and unary logical negation (usually !), writing as !!x forces the expression to have a Boolean-valued result (for example, if x is falsy, then !!x is the actual Boolean value for false. Primitives. Figure 2.2 shows the mostly unsurprising syntax of basic Ruby elements. Ruby has special Boolean values (row 3) including the special value nil, which is the usual result of an operation that otherwise would yield no meaningful return value, such as looking up a nonexistent key in a hash or a nonexistent value in an array. An editor with language-speci\ufb01c highlighting and indentation is an essential tool for software writers. Popular choices today include the open-source Ace4 and the commercial product Sublime Text5. Some old-timers, including one of your authors, will use Emacs until it is pried from his cold, dead hands. 52 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE Ruby has no separate \u201cempty result\u201d value such as Python none or JavaScript null. That is to say: a JavaScript variable whose value is null means that the variable references nothing in particular, rather than signi\ufb01ying \u201cfalseness\u201d in a Boolean sense, whereas Ruby nil may signal either Boolean falseness or a variable that refers to nothing. In addition to strings (row 4), Ruby also includes a type called symbol (row 4), such as :octocat, essentially an immutable \u201ctoken\u201d whose value is itself. It is typically used for enumerations, like an enum type in C or Java, though it has other purposes as well. A symbol is not the same as a string, but as the \ufb01gure shows, strings and symbols can be easily converted to each other. Row 6 and Figure 2.3 summarize Ruby\u2019s straightforward support for manipulating regu- lar expressions and capturing the results of regex matches. Given the amount of text handling done by modern SaaS apps, mastering regexes and understanding how a new language pro- vides access to a regex engine is de rigeur for programmers. Collections (rows 7\u20139: arrays and hashes) can combine keys and values of different types. Hashes in particular, also called associative arrays or hashmaps in other languages, are ubiq- uitous in Ruby. Every Ruby statement is an expression that returns a value; assignments return the value of their left-hand side, that is, the value of the variable or other L-value that was just assigned to. Methods. A method is de\ufb01ned with def method_name(arg1,...,argN) and ends with end. All statements in between are the method de\ufb01nition. All methods return a value; if a method doesn\u2019t have an explicit return statement, the value of the last expression eval- uated in the method is its return value, which is always well-de\ufb01ned since every Ruby state- ment results in a value. Everything in Ruby, even a lowly integer, is a full-\ufb02edged object that is an instance of some class. Every operation, without exception, is performed by calling a method on an object. The notation obj.meth() calls method meth on the object obj, which is said to be the receiver and is expected to be able to respond to meth. For example, the expression 5.class() sends the method call class with no arguments to the object 5. The class method happens to return the class that an object belongs to, in this case Fixnum. As we\u2019ll see in more detail in the next section, Ruby allows omitting parentheses around argument lists when doing so does not result in ambiguous parsing. Hence 5.class is equiv- alent to 5.class(). Furthermore, since everything is an object, the result of every expression is, by de\ufb01nition, something on which you can call other methods. Hence (5.class).superclass tells you what Fixnum\u2019s superclass is, by sending the superclass method call with no arguments to Fixnum, an object representing the class to which 5 belongs. Method calls associate to the left, so this example could be written 5.class.superclass. Such method chaining is extremely idiomatic in Ruby. Elaboration: Re\ufb02ection This example gives a glimpse of Ruby\u2019s comprehensive re\ufb02ection\u2014the ability to ask objects about themselves. 5.respond_to?(\u2019class\u2019) tells you that the object 5 would be able to respond to the method class if you asked it to. 5.methods lists all methods to which the object 5 responds, including those de\ufb01ned in its ancestor classes. 5.method(\u2019+\u2019) reveals that the + method is de\ufb01ned in class Fixnum, whereas 5.method(\u2019ceil\u2019) reveals that the ceil method is de\ufb01ned in Integer, an ancestor class of Fixnum. Smalltalk, which inspires Ruby\u2019s object model, was itself inspired by ideas in Simula, the \ufb01rst object-oriented programming language, whose inventors won the Turing Award for their contribution. A Ruby class such as Fixnum is itself an instance of Class, which is a class whose instances are also classes (we say that Class is a metaclass). Unless you\u2019re a languages geek, don\u2019t think too hard about this right away or it will make your head hurt. 2.3. INTRODUCING RUBY, AN OBJECT-ORIENTED LANGUAGE 53 1.Variables 2. Constants 3. Booleans 4. Strings and Symbols 5. Expressions in double-quoted strings 6. Regular expression matching (Fig. 2.3) 7. Arrays 8. Hashes 9. Hashes (alternate notation, Ruby 1.9+) 10. Instance method 11. Class (static) method 12. Special method names Ending these methods\u2019 names in ? and ! is optional but idiomatic Conditionals if cond (or unless cond) statements [ elsif cond statements ] [else statements] Iteration (see Section 2.4) while cond (or until cond) statements end 1.upto(10) do |i|...end 10.times do. . . end collection.each do |elt|. . . end end @@class_variable, local_variable, @instance_variable ClassName, CONSTANT, $GLOBAL, $global false, nil are false; true and everything else (zero, empty string, etc.) is true. \"string\", \u2019also a string\u2019, %q{like single quotes}, %Q{like double quotes}, :symbol special characters (\\n) expanded in double-quoted but not single-quoted strings @foo = 3 ; \"Answer is #{@foo}\"; %Q{Answer is #{@foo+1}} \"hello\" =\u223c /lo/ \"hello\".match(Regexp.new \u2019lo\u2019) a = [1, :two, \u2019three\u2019] ; a[1] == :two h = {:a =>1, \u2019b\u2019 =>\"two\"} ; h[\u2019b\u2019] == \"two\" ; h.has_key?(:a) == true 1, \u2019b\u2019: h = {a: def method(arg, arg)...end (use *args for variable number of arguments def ClassName.method(arg, arg)...end, def self.method(arg, arg)...end def setter=(arg, arg)...end def boolean_method?(arg, arg)...end def dangerous_method!(arg, arg)...end Exceptions begin \"two\"} or statements rescue AnError => e e is an exception of class AnError; multiple rescue clauses OK [ensure this code is always executed] end Figure 2.2: Basic Ruby elements and control structures, with optional items in [square brackets]. Statements are separated by newlines (most commonly) or semicolons (rarely). Indentation is insigni\ufb01cant. Besides the usual basic primitive types and collection types, hashes (also known as associative arrays or hashmaps; Ruby class Hash) are ubiquitous. 54 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE Figure 2.3: Like most modern languages, Ruby supports Perl compatible regular expressions (PCRE), often shortened to regex(es) or regexp(s). The name PCRE is inspired by the vastly expanded regular-expression capabilities that \ufb01rst appeared in the Perl scripting language. 2.3. INTRODUCING RUBY, AN OBJECT-ORIENTED LANGUAGE 55 Sugared"
    ]
  },
  {
    "id": "sec_0177",
    "title": "10 % 3",
    "pages": [
      67,
      68,
      69,
      70,
      71
    ],
    "text_blocks": [
      "5+3 x == y a * x + y a + x * y De-sugared 10.modulo(3) 5.+(3) x.==(y) a.*(x).+(y) a.+(x.*(y)) x[3] x[3] = \u2019a\u2019 /abc/, %r{abc} str =\u223c regex regex =\u223c str $1. . . $n (regex capture) x.[](3) x.[]=(3,\u2019a\u2019) Regexp.new(\"abc\") str.match(regex) regex.match(str) Regexp.last_match(n) Explicit send 10.send(:modulo, 3) 5.send(:+, 3) x.send(:==, y) a.send(:*, x).send(:+, y) a.send(:+, x.send(:*, y)) (operator precedence preserved) x.send(:[], 3) x.send(:[]=, 3, \u2019a\u2019) Regexp.send(:new, \u2019abc\u2019) str.send(:match, regex) regex.send(:match, str) Regexp.send(:last_match,n) Figure 2.4: The \ufb01rst column is Ruby\u2019s syntactic sugar for common operations, the second column shows the explicit method call, and the third column shows how to perform the same method call using Ruby\u2019s send, which accepts either a string or (more idiomatically) a symbol for the method name. As Figure 2.4 shows, even basic math operations and array references are actually method calls on their receivers. Hence, concepts such as type casting rarely apply in Ruby: while you can certainly call 5.to_s or \"5\".to_i to convert between strings and integers, for example, writing a+b means calling method + on receiver a, so the behavior depends entirely on how a\u2019s class (or one of its ancestors or mix-ins) implements the instance method +. Hence, both 3+2 and \"foo\"+\"bar\" are legal Ruby expressions, but the \ufb01rst one calls + as de\ufb01ned in Numeric (the ancestor class of Fixnum) whereas the second calls + as de\ufb01ned in String. Rubyists write ClassName#method to indicate the instance method method in ClassName and ClassName.method to indicate the class (static) method method in ClassName. We can therefore say that the expression 3+2 results in calling Fixnum#+ on the receiver 3. Abstraction and encapsulation. Ruby supports traditional inheritance, using the nota- tion class SubFoo<Foo to indicate that SubFoo is a subclass of Foo. A class can inherit from at most one superclass (Ruby lacks multiple inheritance), and all classes ultimately in- herit from BasicObject, sometimes called the root class, which has no superclass. As with most languages that support inheritance, if an object receives a call for a method not de\ufb01ned in its class, the call will be passed up to the superclass, and so on until the root class is reached or an unde\ufb01ned method exception is raised. The default constructor for a class must be a method named initialize, but it is always called as Foo.new\u2014that is an idiosyncrasy of the language. Classes can have both class (static) methods and instance methods, and both class (static) variables and instance variables. Class variable names begin with @@ and instance variable names begin with @. Class and instance method names look the same. Probably the biggest surprise to newcomers learning about Ruby\u2019s class machinery is that there is no direct access to class or instance variables at all from outside the class. In other languages, certain instance variables of a class can be declared public, such as attributes in Java. In Ruby, access to class or instance state must be through getter and setter methods, also collectively called accessor methods. Figure 2.5 shows examples of getters (lines 10\u2013 12, 16), setters (lines 13\u201315: note that setter methods conventionally have names ending in =, allowing syntax such as line 33 shows), and a simple instance method that accesses other instance variables (line 18). From the caller\u2019s point of view in lines 33\u201334, it is impossible to You can verify this by evaluating \"foobar\".method(:+) and 5.method(:+). Mix-ins The truth is a bit more subtle: mix-ins, which we\u2019ll describe shortly, can handle an unde\ufb01ned method call before punting up to the superclass. 56 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE end # class ( static ) methods - ' self ' refers to the actual class def self . find_in_tmdb ( title_words ) class Movie def initialize ( title , year ) end def title @title @title = title @year = year # call TMDb to search for a movie ... end def title =( new_title ) @title = new_title https://gist.github.com/450367d90330578a8ee4d355979fc7d1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # call TMDb to search for a movie ... def self . find_in_tmdb ( title_words ) end end end def year ; @year ; end # note : no way to modify value of @year after initialized def full_title ; \" #{ @title } (#{ @year }) \" ; end # A more concise and Rubyistic version of class definition : class Movie end attr_accessor : title # can read and write this attribute attr_reader : year def full_title ; \" #{ @title } (#{ @year }) \" ; end # can only read this attribute # Example use of the Movie class beautiful = Movie . new ( ' Life is Beautiful ' , ' 1997 ') beautiful . title = ' La vita e bella ' beautiful . full_title beautiful . year = 1998 # # = > ERROR : no method ' year = ' = > \" La vita e bella (1997) \" Figure 2.5: A simple class de\ufb01nition in Ruby showing that explicit getter and setter methods are the only way to access instance variables from outside a class, and that Ruby provides shortcuts (lines 26\u201327) that avoid having to de\ufb01ne every accessor method explicitly. Rather than distinguish \u201cprivate\u201d vs. \u201cpublic\u201d instance and class variables, one simply provides public accessor methods (read-only, write-only, or read/write) for state that should be publicly visible. tell whether a given method simply \u201cwraps\u201d access to an instance variable (as title does) or produces its result by computing something (as full_title does). This design choice illustrates Ruby\u2019s hard-line position on the Uniform Access Principle, which concerns one aspect of encapsulation in object-oriented programming: It should be impossible to determine the implementation details of an object\u2019s state or its operations from outside the object. Beware! If you\u2019re used to Java or Python, it\u2019s very easy to think of the syntax in line 33 as assignment to an attribute or instance variable, but it is just a method call, and in fact could be written as beautiful.send(\u2019title=\u2019, \u2019La vita e bella\u2019). Furthermore, note that any instance variable that has not previously been assigned to will silently evaluate to nil. 2.3. INTRODUCING RUBY, AN OBJECT-ORIENTED LANGUAGE 57 Time # now , Time #+ and Time # - represent time as ' seconds since 1/1/70 ' # class Fixnum ; self ; end def seconds ; self * 60 ; end def minutes ; self * 60 * 60 ; end def hours ; Time . now - self ; end def ago def from_now ; Time . now + self ; end https://gist.github.com/8d6e400be9b2c2b73dd9635070114cb6 1 2 3 4 5 6 7 8 9 10 11 12 end Time . now 5. minutes . ago 5. minutes - 4. minutes 3. hours . from_now # = > 2018 -11 -22 16:58:04 +0100 # = > 2018 -11 -22 16:53:12 +0100 # = > 60 # = > 2018 -11 -22 19:58:45 +0100 Figure 2.6: By reopening Ruby\u2019s core Fixnum class and adding six new instance methods to it, we get a beautiful syntax for time arithmetic. (Rails includes a more complete version of this facility.) Unix was invented in 1970, so its designers chose to represent time as the number of seconds since midnight (GMT) 1970\u201301\u201301, sometimes called the beginning of the epoch. Summary: \u2022 Everything in Ruby is an object, even primitive types like integers. Ruby objects have types, but the variables that refer to them don\u2019t. \u2022 Every operation is performed by calling a method on an object; the notation a.b means \u201ccall method b on object a.\u201d Object a is said to be the receiver, and if it cannot handle the method call, it will pass the call to its superclass. This process is called looking up a method on a receiver. \u2022 Every Ruby statement is an expression that has a well-de\ufb01ned value (which may be nil). \u2022 Ruby has classes and single inheritance, with the usual instance and class methods and variables. \u2022 Important Ruby idioms include the use of symbols, the use of keyword-based ar- guments to methods, and poetry mode, which allows omitting parentheses around method arguments and curly braces surrounding a hash when the resulting code is syntactically unambiguous. \u2022 An idiomatic primitive type in Ruby is the symbol, an immutable string whose value is itself. Symbols are commonly used in Ruby to denote \u201cspecialness,\u201d such as being one of a set of \ufb01xed choices like an enumeration, and to pass named (keyword) arguments to methods. \u2022 Ruby has comprehensive re\ufb02ection, allowing you to ask objects about themselves. \u2022 attr_accessor is an example of metaprogramming: it creates new code at run- time, in this case getters and setters for an instance variable. This style of metapro- gramming is extremely common in Ruby. 58 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE Elaboration: In Ruby, all programming is metaprogramming attr_accessor is an example of metaprogramming \u2014creating code at runtime that de- \ufb01nes new methods\u2014 because attr_accessor is not built into the Ruby language, but in- stead is a regular method call that de\ufb01nes the getter and setter methods on the \ufb02y. That is, attr_accessor :foo de\ufb01nes instance methods foo and foo= that get and set the value of instance variable @foo. In fact, in a sense all Ruby programming is metaprogramming, since even the class de\ufb01nition in Figure 2.5 is not a declaration as it is in Java but actually code that is executed at runtime, creating a new object representing the Movie class and binding the name Movie to it. Going further, since de\ufb01ning a class happens at runtime, you can modify it later as well, as Figure 2.6 shows. Self-Check 2.3.1. What is the explicit-send equivalent of each of the following expressions: a<b, a==b, x[0], x[0]=\u2019foo\u2019. a.send(:<,b), a.send(:==,b), x.send(:[],0), x.send(:[]=,0,\u2019foo\u2019) Self-Check 2.3.2. Verify in an interactive Ruby interpreter that 5/4 gives 1, but 5/4.0 and 5.0/4 both give 1.25. Explain this behavior by identifying which class\u2019s / method is called in each case, and how you think it handles its argument. In 5/4 and 5/4.0, the Integer class\u2019s / instance method is called on the receiver 5. That method performs integer division if its argument is also an integer, but if its argument is a \ufb02oat, it converts the receiver to a \ufb02oat and performs \ufb02oating-point division. In 5.0/4, the Float class\u2019s / method is called, which always performs \ufb02oating-point division. Self-Check 2.3.3. Why is movie.@year=1998 not a substitute for movie.year=1998? The notation a.b always means \u201ccall method b on receiver a\u201d, but @year is the name of an instance variable, whereas year= is the name of an instance method. Self-Check 2.3.4. Suppose we delete line 12 from Figure 2.5. What would be the result of executing Movie.new(\u2019Inception\u2019,2011).year? Ruby would complain that the year method is unde\ufb01ned. Self-Check 2.3.5. In Figure 2.6, is Time.now a class method or an instance method? The fact that its receiver is a class name (Time) tells us it\u2019s a class method. Self-Check 2.3.6. Why does 5.superclass result in an \u201cunde\ufb01ned method\u201d error? (Hint: consider the difference between calling superclass on 5 itself vs. calling it on the object returned by 5.class.) superclass is a method de\ufb01ned on classes. The object 5 is not itself a class, so you can\u2019t call superclass on it. Self-Check 2.3.7. Which of the following Ruby expressions are equal to each other: (a) :foo (b) %q{foo} (c) %Q{foo} (d) \u2019foo\u2019.to_sym (e) :foo.to_s (a) and (d) are equal to each other; (b), (c), and (e) are equal to each other Self-Check 2.3.8. What is captured by $1 when the string 25 to 1 is matched against each of the following regexps: (a) /(\\d+)$/ (b) /^\\d+([^0-9]+)/ (a) the string \u201c1\u201d (b) the string \u201c to \u201d (including the leading and trailing spaces) 2.4. RUBY IDIOMS: POETRY MODE, BLOCKS, DUCK TYPING 59 https://gist.github.com/c0ec0b8c12c435990319416c056340a3 1 2 3 link_to ( ' Edit ' , {: controller = > ' students ' , : action = > ' edit ' }) link_to ' Edit ' , link_to ' Edit ' , controller : ' students ' , action : ' edit ' : controller = > ' students ' , : action = > ' edit ' Figure 2.7: Three legal and equivalent calls to the method link_to (which we\u2019ll meet in Section 4.4) that takes one string argument and one hash argument. The \ufb01rst is fully parenthesized, the second omits the parentheses around the call arguments and the curly braces around the \ufb01nal hash argument, and the third uses the alternative (Ruby \u2265 2.0) syntax for the hash keys in the second argument. Self-Check 2.3.9. Consider line 18 of Figure 2.5. Explain why the following would be an acceptable alternative way to de\ufb01ne the full_title method, and the pros and cons com- pared to the way it appears in the \ufb01gure: def full_title ; \"#title (#year)\"; end This version calls the accessor methods title and year rather than accessing the in- stance variables directly. Doing so decouples the implementation of this method from the implementations of the underlying state of the movie (title and year)."
    ]
  },
  {
    "id": "sec_0178",
    "title": "2.4 Ruby Idioms: Poetry Mode, Blocks, Duck Typing",
    "pages": [
      71,
      72,
      73,
      74,
      75,
      76
    ],
    "text_blocks": [
      "A programming idiom is a way of doing or expressing something that occurs frequently in code written by experienced users of a given programming language. While there may be other ways to accomplish the same task, the idiomatic way is the one that is most readily intention-revealing to other experienced users of the language. Your goal when learning a new language should be to learn to \u201cthink in\u201d that language by understanding and using its idioms well, or in other words, to avoid the well-known pitfall that \u201cyou can write FORTRAN in any language\u201d6. In this section we explore three key Ruby idioms: passing arguments to methods (\u201cpoetry mode\u201d and named parameters), blocks, and duck typing. Poetry mode and named parameters. Figures 2.7 and 2.8 show two pervasive idioms related to Ruby method calls. The \ufb01rst, poetry mode, allows omitting parentheses around the arguments to a method call when the parsing is unambiguous. In addition, when the last argument to a method call is a hash, the curly braces around the hash literal can be omitted. In early versions of Ruby, hash arguments were often used to emulate the named pa- rameter feature (also called keyword arguments) available in languages such as Python, C#, and others. For example, the documentation for the link_to method used in Figure 2.7 tells us that :controller and :action are just two of many possible additional (and optional) values that can be passed to the method as keys in a hash. True named parameters became available in Ruby 2.0, as Figure 2.8 shows; nonetheless, a great deal of Ruby code written prior to Ruby 2.0 still uses hashes to pass optional arguments or provide default values for arguments. Blocks. Ruby uses the term block somewhat differently than other languages do. In Ruby, a block is just a method without a name, or an anonymous lambda expression in programming-language terminology. Like a regular named method, it has arguments and can use local variables. As Figure 2.9 shows, one of the most common uses of blocks is to implement data struc- ture traversal. The instance method each, available in all Ruby classes that are collection- like, takes a single argument consisting of a block (anonymous lambda) to which each mem- ber of the collection will be passed. each is an example of an internal iterator . Rubyists 60 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE \" #{ greeting } , #{ name } #{ last_name }! \" # Using ' named keyword ' arguments def greet ( name , last_name : \" \" , greeting : \" Hi \" ) https://gist.github.com/4b32d51d724a86029604539dd465c7d6 1 2 3 4 5 6 7 8 9 10 end greet ( \" Dave \" ) greet ( \" Dave \" , last_name : \" Fox \" ) # = > \" Hi , Dave Fox !\" greet ( \" Dave \" , greeting : \" Yo \" ) greet ( \" Dave \" , greeting : \" Hey \" , last_name : \" Patterson \" ) greet ( greeting : \" Yo \" ) # = > \" Hi , Dave ! \" # = > \" Yo , Dave !\" required # = > \" Hey , Dave Patterson !\" - order of keyword args irrelevant # ArgumentError , since first arg is Figure 2.8: The use of keyword arguments or named parameters allows you to de\ufb01ne methods in which some arguments are optional or assume default values. Named parameters can improve clarity for methods that take multiple arguments, though we will see in Chapter 9 that one should usually minimize the number of arguments a method accepts. def print_movies ( movie_list ) https://gist.github.com/c3ea17d28f213c3e08e5503da3f210cf 1 2 3 4 5 puts \" #{ m . title } ( rated : #{ m . rating }) \" movie_list . each do | m | end end Internal iterators \ufb01rst appeared in the research language CLU, an early vehicle for research on data hiding that garnered a Turing Award for Barbara Liskov. Figure 2.9: each takes one argument\u2014a block\u2014and passes each element of the collection to the block in turn. A block is bracketed by do and end, and any arguments expected by the block are enclosed in |pipe symbols| after the do. Each time through the block, m is set to the next element of movie_list. like to say that Ruby collections \u201cmanage their own traversal,\u201d because it\u2019s up to the receiver of each to decide how to implement that method to yield each collection element. (Indeed, in Figure 2.9, we can\u2019t even tell what the underlying type of movie_list is.) Figure 2.10 shows a simple example of such a collection operator, which can be used with any collection that implements each as a way of traversing itself. Note once again that we have no idea how the collection is implemented: all we need to know is that it implements the instance method each to enumerate its elements. Ruby provides a wide variety of such collection methods; Figure 2.11 lists some of the most useful. With some practice, you will automatically start to express operations on collections in terms of these functional idioms rather than in terms of imperative loops. Although Ruby allows for i in collection, each allows us to take better advantage of duck typing , which we\u2019ll see shortly, to improve code reuse. Duck Typing. You may be surprised to learn, though, that the collection methods sum- marized in Figure 2.11 (and several others not in the \ufb01gure) aren\u2019t part of Ruby\u2019s Array class. In fact, they aren\u2019t even part of any superclass from which Array and other collection types inherit. Instead, they take advantage of an even more powerful reuse mechanism: A mix-in is a named collection of related methods that can be added to any class ful\ufb01lling some \u201ccon- tract\u201d with the mixed-in methods. A module is Ruby\u2019s method for packaging together a group of methods as a mix-in. The Ruby statement include ModuleName inside a class de\ufb01nition mixes the instance methods, class methods, and variables of the module into that class. The collection methods in Figure 2.11 are de\ufb01ned in a module called Enumerable that is part of Ruby\u2019s standard library and is mixed in to all of Ruby\u2019s collection classes. As its docu- mentation7 states, Enumerable requires the class mixing it in to provide an each method, since Enumerable\u2019s collection methods are implemented in terms of each. It doesn\u2019t matter what class you mix it into as long as that class de\ufb01nes the each instance method, and neither 2.4. RUBY IDIOMS: POETRY MODE, BLOCKS, DUCK TYPING 61 end maximum ([3 ,4 ,2 ,1]) maximum ([ \" a \" ,\" x \" ,\" b \" ]) # = > \" x \" max ([ RomanNumeral . new ( ' XL ') , RomanNumeral . new ( ' LI ') ] # = > ' LI ' # = > 4 @orig_string = r o m a n _ n u m e r a l _ s t r i n g @value = RomanNumeral . c o nv e rt _ fr o m_ r om a n ( r o m a n _ n u m e r a l _ s t r i n g ) end result class RomanNumeral result = item if item > result result = collection . first collection . each do | item | https://gist.github.com/3f068204f819ace57403adfd66652424 # find largest element in a collection 1 def maximum ( collection ) 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 include Comparable def initialize ( r o m a n _ n u m e r a l _ s t r i n g ) end def self . c o nv e rt _ fr o m_ r om a n ( str ) end def <= >( other ) end def to_s @value <= > other @orig_string end end # ... code to convert Roman numerals from strings ... Figure 2.10: This example \ufb01nds the maximum-valued element in any collection that responds to each, and is agnostic to the type(s) of the element(s) in the collection as long as they respond to >. It even works on Roman numerals if we have a RomanNumeral class that either de\ufb01nes > explicitly, or de\ufb01nes <=> and mixes in the Comparable module to de\ufb01ne <, >, and so on. the class nor the mix-in have to declare their intentions in advance. For example, the each method in Ruby\u2019s Array class iterates over the array elements, whereas the each method in the IO class iterates over the lines of a \ufb01le or other I/O stream. Mix-ins thereby allow reusing whole collections of behaviors across classes that are otherwise unrelated. a class Similarly, that de\ufb01nes its the \u201cspaceship operator\u201d <=>, which returns to, or less second argument than its \ufb01rst argument, can mix in the Comparable module, which de- For example, the allowing you to write \u22121, 0, 1 depending on whether greater \ufb01nes <, <=, >, >=, ==, and between? Time class de\ufb01nes <=> and mixes Time.now.between?(Time.parse(\"19:00\"), Time.parse(\"23:15\")). in terms of <=>. in Comparable, equal than, is The term \u201cduck typing\u201d is a popular description of this capability, because \u201cif something looks like a duck and quacks like a duck, it might as well be a duck.\u201d From Enumerable\u2019s point of view, if a class has an each method, it might as well be a collection, thus allowing Enumerable to provide other methods implemented in terms of each. When Ruby program- mers say that some class \u201cquacks like an Array,\u201d they usually mean that it\u2019s not necessarily an Array nor a descendant of Array, but it responds to most of the same methods as Array and can therefore be used wherever an Array would be used. 62 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE Method c.map c.select c.reject c.uniq c.reverse c.compact c.flatten c.partition c.sort Block? Returns a new collection containing. . . 1 1 1 1 2 elements obtained by applying block to each element of c Subset of c for which block evaluates to true Subset of c obtained by removing elements for which block evaluates to true all elements of c with duplicates removed elements of c in reverse order all non-nil elements of c elements of c and any of its sub-arrays, recursively \ufb02attened to contain only non- array elements Two collections, the \ufb01rst containing elements of c for which the block evaluates to true, and the second containing those for which it evaluates to false Elements of c sorted according to a block that takes 2 arguments and returns -1 if the \ufb01rst element should be sorted earlier, +1 if the second element should be sorted earlier, and 0 if the two elements can be sorted in either order. The following methods require the collection elements to respond to <=>; see Section 2.4. c.sort c.sort_by 1 c.max, c.min If sort is called without a block, the elements are sorted according to how they respond to <=>. Applies the block to each element of c and sorts the result. For example, movies.sort_by { |m| m.title } sorts Movie objects according to how their titles respond to <=>. Largest or smallest element in the collection Figure 2.11: Some common Ruby methods on collections. For those that expect a block, the \u201cBlock\u201d column shows the number of arguments expected by the block; if blank, the method doesn\u2019t expect a block. For example, a call to sort, whose block expects 2 arguments, might look like: c.sort { |a,b| a <=> b }. These methods all return a new object rather than modifying the receiver, but some methods also have a destructive variant ending in !, for example sort!, that modify the receiver in place as well as returning the modi\ufb01ed value. Use destructive methods with extreme care, if at all. 2.4. RUBY IDIOMS: POETRY MODE, BLOCKS, DUCK TYPING 63 Summary \u2022 Poetry mode allows omitting parentheses around method call arguments, and omit- ting curly braces around a hash literal when it is the last argument to a method call. Hash arguments were previously used to emulate named parameters or keyword arguments, but this practice is now discouraged since Ruby supports true named parameters starting with version 2.0. \u2022 Ruby borrows great ideas from functional programming , especially the use of blocks\u2014parameterized chunks of code called lambda expressions that carry their scope around with them, making them closures. \u2022 Because of Ruby\u2019s dynamic typing , calling a method on an object is legal as long as the receiver responds to the method, regardless of the receiver\u2019s class, a behavior sometimes called duck typing. \u2022 A mix-in takes advantage of duck typing by allowing a set of related behaviors to be added to any class that satis\ufb01es the mix-in\u2019s contract; for example, Enumerable just requires the including class to respond to each. A module is mixed into a class by putting include ModuleName after the class ClassName statement. \u2022 Unlike interfaces in Java, mix-ins require no formal declaration. But because Ruby doesn\u2019t have static types, it\u2019s your responsibility to ensure that the class including the mix-in satis\ufb01es the conditions stated in the mix-in\u2019s documentation, or you will get a runtime error. Elaboration: Blocks Are Closures The combination of blocks and iterators like each, which is how most Ruby operations on collections are expressed, is a technique Ruby borrows from functional programming . A Ruby block is a closure: whenever the block executes, it can \u201csee\u201d the entire lexical scope available at the place where the block appears in the program text. In other words, it\u2019s as if the presence of the block creates an instant snapshot of the scope, which can be reconstituted later whenever the block executes. This fact is exploited by many Rails features that improve DRYness, including view rendering (which we\u2019ll see in Section 4.4) and model validations and controller \ufb01lters (Section 5.1), because they allow separating the de\ufb01nition of what is to occur from when in time and where in the structure of the application it occurs. Self-Check 2.4.1. Write one line of Ruby that checks whether a string s is a palindrome, that is, it reads the same backwards as forwards. Hint: Use the methods in Figure 2.11, and don\u2019t forget that upper vs. lowercase shouldn\u2019t matter: ReDivider is a palindrome. s.downcase == s.downcase.reverse You might think you could say s.reverse=\u223cRegexp.new(s), but that would fail if s happens to contain regexp metacharacters such as $. Self-Check 2.4.2. Suppose you mix Enumerable into a class Foo that does not provide the each method. What error will be raised when you call Foo.new.map { |elt| puts elt }? The map method in Enumerable will attempt to call each on its receiver, but since the new Foo object doesn\u2019t de\ufb01ne each, Ruby will raise an Unde\ufb01ned Method error. 64 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE # makes gem 's definitions available within this file require \" stripe \" Stripe . api_key = \" s k _ t e s t _ 4 e C 3 9 H q L y j W D a r j t T 1 z d p 7 d c \" Stripe :: Charge . create ({ https://gist.github.com/2b1976e79ef3c4b6bd6bb6b8e6dd54ab 1 2 3 4 5 6 7 8 : amount = > 2000 , : currency = > \" usd \" , : source = > \" tok_mastercard \" , # obtained with Stripe . js : description = > \" Charge for jenny . rosen@example . com \" }) Figure 2.12: To use a gem, you must install it either directly (as in gem install \u2019stripe\u2019) or preferably via the Bundler tool discussed next. gem help gives brief help for the command-line tool that manages installed gems manually; by default it installs gems from the RubyGems website10, the de\ufb01nitive gem repository. Self-Check 2.4.3. Which statement is correct and why: (a) include \u2019enumerable\u2019 (b) include Enumerable (b) is correct, since include expects the name of a module, which (like a class name) is a constant rather than a string."
    ]
  },
  {
    "id": "sec_0179",
    "title": "2.5 CHIPS: Ruby Intro",
    "pages": [
      76
    ],
    "text_blocks": [
      "CHIPS 2.5: Ruby Intro https://github.com/saasbook/hw-ruby-intro Write and run Ruby code that exercises the basics of control \ufb02ow, classes and inheritance, accessor methods, regular expression and string manipulation, symbols, and common uses of blocks such as iterators and collection idioms. Learn your way around the interactive Ruby interpreter irb and the debugger byebug. Familiarize yourself with RSpec, a tool for creating automated tests, by writing code to get our provided tests to pass."
    ]
  },
  {
    "id": "sec_0180",
    "title": "2.6 Gems and Bundler: Library Management in Ruby",
    "pages": [
      76,
      77,
      78
    ],
    "text_blocks": [
      "Libraries. The Ruby standard library8 includes a large number of useful classes covering \ufb01le and network input/output, time and date manipulation, manipulating strings and collections, and more. An external library is packaged as a Ruby gem, a collection of classes with well-de\ufb01ned interfaces. Gems can be as simple as augmenting existing classes with a few utility functions, or as complex as an entire framework: Rails itself is distributed as a gem that depends on several other gems. Similar to Python import, require makes a gem\u2019s classes and functions available within a \ufb01le of Ruby code, as Figure 2.12 shows. Where Ruby really shines, though, is in managing dependencies among gems. GitLab, a popular open-source application written in Rails, relies on around 400 gems. Since some of those rely in turn on other gems, all in all GitLab depends on over 800 gems, many of which are constantly evolving. It\u2019s therefore critical to specify which version(s) of libraries an app has been developed and tested with, so that when the app is deployed or distributed, it behaves the same way in every environment in which it\u2019s run. To manage complex dependencies, we need a dependency manager or package manager, such as pip for Python, npm for Node.js, or Apache Maven for Java. Ruby\u2019s package man- 2.6. GEMS AND BUNDLER: LIBRARY MANAGEMENT IN RUBY 65 gem install name [-v version] bundle install [--without env] Install version version (default: latest) of gem named name. The default location for downloading gems is rubygems.org. If Gemfile has not changed, inspect Gemfile.lock and ensure that the correct version(s) of gem(s) speci\ufb01ed there are installed. If Gemfile has changed, re- compute the dependency graph to regenerate Gemfile.lock, then ensure correct gems are installed. If --without is given, do not try to install gems associated with environment env. bundle update gem- names Force Bundler to update gemnames to their latest major versions, and recompute dependencies. Passing --all for gemnames forces updating all gems, ignoring and regenerating Gemfile.lock. bundle exec command bundle help Execute command in the context of the current bundle, that is, make sure the correct version(s) of gem(s) are loaded and active before command runs. For example, if command relies a particular version of some gem, but you have other version(s) of that gem also installed, without bundle exec the wrong version of the gem may be active when command is run. Show more detailed help; also see Bundler\u2019s website11. Figure 2.13: Frequently used commands for working with gems and Bundler. We will learn about Bundler \u201cenvironments\u201d in Section 4.1. ager, Bundler, is itself a gem. Once Bundler is installed with gem install bundler, you should allow it to do your dependency management. To use Bundler, a Ruby project should have a \ufb01le called Gemfile in its top-level directory that records the dependencies of the app on particular libraries. Bundler reads this \ufb01le and tries to compute a set of library version(s) that respects all the constraints in the \ufb01le. For example, if the app depends on version \u2265 3.0 and \u2264 4.0 for library X, but the app also depends on library Y which requires version 3.5 of library X, then version 3.5 of library X will be installed. Bundler can also detect when it\u2019s impossible to satisfy all the constraints. In general, when you start a new Ruby project you immediately create a Gem\ufb01le for it, and when you download someone else\u2019s Ruby project to work on, you \ufb01rst run bundle install in the project\u2019s main directory to allow Bundler to locate and download all the necessary libraries. Bundler then arranges to install all needed gems with their proper versions, and records the results in Gemfile.lock. Both Gemfile and Gemfile.lock should be stored as part of the codebase, since the latter records which versions of which libraries were actually used in development, whereas Gemfile just speci\ufb01es constraints on which versions could be com- patibly used. Increasingly, library version numbers follow semantic versioning12, not just for Ruby gems but in other languages as well. The usual arrangement is for a version number to be formatted as major.minor.patch, where each \ufb01eld is an integer, such as 2.3.1. Changes in the value of patch are usually minor, backwards-compatible bug \ufb01xes, including security patches, that do not change the semantics or functionality of the gem. Changes in minor usu- ally indicate that functionality has been added in a backward-compatible manner. Changes in major signal that the Application Programming Interface (API)\u2014the way you call the library\u2019s functions\u2014has changed in a way that may break compatibility with previous ver- sions. Since breaking compatibility is a major decision that may affect thousands of apps using 66 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE a library, a common practice is for such changes to \ufb01rst appear as deprecation warnings in a new minor version or patch version. Such warnings typically manifest as messages emitted at build time or run time to the effect of \u201cWarning: this feature will work differently [or be dropped] in the next major release of this library.\u201d As a general rule, deprecation warnings become errors when the major version changes. The prudent developer faced with a deprecation warning will therefore read the documentation and determine if there is a way to change the current code so that it uses the soon-to-be-new version of the feature or of the feature\u2019s API. Indeed, when upgrading to a new major version, a best practice is to \ufb01rst incrementally upgrade so that you can identify and address deprecations before the major version change. For example, suppose your app uses version 2.7.3 of the Foobaz gem, but the latest version is 3.1.5, and you haven\u2019t been keeping up: 1. First, update to the latest whose major version is still 2\u2014let\u2019s say that turns out to be 2.8.1. 2. Identify and address any deprecation warnings generated by that upgrade. 3. Now upgrade to the \ufb01rst release whose major version is 3. In all likelihood this is 3.0.0, but might be different. Ensure all works well with the new major version. 4. Next, upgrade to the latest minor version\u2014in our example, probably 3.1.0. Ensure all works well. 5. Finally, upgrade to 3.1.5, the latest patch release. Of course, in an ideal world, the developer has been gradually updating the gem over time, so it is not necessary to do all these steps at once. In Chapter 8, we will have a lot to say about \u201censuring all works well,\u201d as this is one of the key roles of having a solid test suite. Bundler uses \u223c>2 to mean \u201clast release whose major version is 2\u201d, or \u223c>2.4 to mean \u201clast release whose major and minor version is 2.4\u201d. So 2.4.6 would satisfy both constraints, whereas"
    ]
  },
  {
    "id": "sec_0181",
    "title": "2.5 would satisfy the \ufb01rst but",
    "pages": [
      78,
      79
    ],
    "text_blocks": [
      "not the second. 2.7. FALLACIES AND PITFALLS 67 Summary of libraries and dependency management in Ruby: \u2022 Besides a language\u2019s standard library, which usually ships with the language distri- bution, most languages enjoy vast external libraries of contributed code. In Ruby, external libraries are distributed as Ruby gems. \u2022 Keeping track of which version(s) of which libraries an app depends on is critical. The Bundler tool largely automates this by allowing the developer to express con- straints on library versions and then \ufb01guring out a set of versions that meet all the constraints. \u2022 Most libraries are semantically versioned as major.minor.patch, where patches \ufb01x bugs, minor releases add new functionality, and major releases overhaul the li- brary in ways that may break compatibility with previous major releases. \u2022 To prepare developers for such breaking changes, updated patch or minor versions will often display deprecation messages warning the developer about the use of a feature that is about to change incompatibly. Frequently upgrading maximizes the likelihood you can see and act on deprecations before they become errors; the Gem- \ufb01le you prepare for Bundler speci\ufb01es what \u201csafe\u201d upgrades are permitted."
    ]
  },
  {
    "id": "sec_0182",
    "title": "2.7 Fallacies and Pitfalls",
    "pages": [
      79,
      80,
      81
    ],
    "text_blocks": [
      "Pitfall: Always watching the driver while pair programming. If one member of the pair has much more experience, the temptation is to let the more senior member do all the driving, with the more junior member becoming essentially the permanent observer. This relationship is not healthy, and will likely lead to disengagement by the junior member. Pitfall: Blindly following \u201ccookbook\u201d tutorials when learning a new lan- guage. Computer science legend and Turing Award winner Donald Knuth, who literally wrote the book(s) on the foundations of theoretical computer science, says that writing code is \u201charder than anything else I\u2019ve ever had to do.\u201d And Peter Norvig, Google\u2019s Director of Research, has eloquently said13 that there is no shortcut around such a challenge: it requires deep study and lots of ongoing practice. Following a step-by-step tutorial without an understanding of the underlying mechanisms being explained will put something on the screen quickly, but you won\u2019t understand how it got there nor be able to replicate this success with your own apps. Pitfall: Forgetting that the compiler won\u2019t save you. In strongly-typed or statically-typed languages, the compiler can usually detect if a vari- able of one type is erroneously being assigned a value of an incompatible type, for example, writing x=foo() where foo returns a numeric value but x has been declared as a string variable. In weakly-typed or dynamically-typed languages (Ruby is both), there are no such \u201ccompile-time\u201d checks\u2014instead you\u2019ll get a runtime error. So you must be that much more 68 CHAPTER 2. HOW TO LEARN A NEW LANGUAGE careful in your testing and in the design of your code. Chapter 8 will introduce techniques for ensuring your code is well tested. The debate over the relative merits of static vs. dynamic typing is a long-running \u201choly war\u201d14 among programmers that we won\u2019t wade into here. Pitfall: Writing Python in Ruby. It takes some mileage to learn a new language\u2019s idioms and how it fundamentally differs from other languages. Common examples for Python programmers new to Ruby include: \u2022 Reading an expression such as person.age as \u201cthe age attribute of the person ob- ject\u201d rather than \u201ccall the instance method age on the object person.\u201d \u2022 Thinking that person.age=40 is an assignment to an attribute when in fact it is a method call. In fact, the age= method called on person is passed the argument (40), and can do whatever it wants. Ruby code often uses this mechanism as a way to provide syntactic sugar for \u201cassignments\u201d that cause side effects. \u2022 Forgetting that any instance variable that has not previously been assigned will silently evaluate to nil. \u2022 Thinking of attr_accessor as a declaration of attributes. This shortcut and related ones save you work if you want to make an attribute publicly readable or writable. But you don\u2019t need to \u201cdeclare\u201d an attribute in any way at all (the existence of the in- stance variable is suf\ufb01cient) and in all likelihood some attributes shouldn\u2019t be publicly visible. Resist the temptation to use attr_accessor as if you were writing attribute declarations in Java. \u2022 Writing explicit for-loops rather than using an iterator such as each and the collection methods that exploit it via mix-ins such as Enumerable. Use functional idioms like select, map, any?, all?, and so on. \u2022 Using lowerCamelCase rather than snake_case to name variables. It seems trivial, but experienced programmer \ufb01nd it jarring to read code that violates the typographical conventions of a language, just as experienced musicians wince when they hear a note played out of tune. If in doubt, \ufb01nd other Ruby code with an example of what you want to do, and emulate it. Pitfall: Thinking of symbols and strings as interchangeable. the two are not While many Rails methods are explicitly constructed to accept either a string interchangeable. A method expecting a it may For example, [\u2019foo\u2019,\u2019bar\u2019].include?(\u2019foo\u2019) is truthy, whereas in general or a symbol, string may throw an error if given a symbol, or depending on the method, simply fail. [\u2019foo\u2019,\u2019bar\u2019].include?(:foo) is falsy. Pitfall: Naming a local variable when you meant a local method. Suppose class C de\ufb01nes a method x=. In an instance method of C, writing x=3 will not have the desired effect of calling the x= method with the argument 3; rather, it will set a local variable x to 3, which is probably not what you wanted. To get the desired effect, write self.x=3, which makes the method call explicit. 2.8. CONCLUDING REMARKS: HOW (NOT) TO LEARN A LANGUAGE BY GOOGLING69 Pitfall: Confusing require with include. require loads an arbitrary Ruby \ufb01le (typically the main \ufb01le for some gem), whereas include mixes in a module. In both cases, Ruby has its own rules for locating the \ufb01les containing the code; the Ruby documentation describes the use of $LOAD_PATH, but you should rarely if ever need to manipulate it directly if you use Rails as your framework and Bundler to manage your gems."
    ]
  },
  {
    "id": "sec_0183",
    "title": "2.8 Concluding Remarks: How (Not) To Learn a Language By Googling",
    "pages": [
      81,
      82,
      83,
      84
    ],
    "text_blocks": [
      "Your authors will allow themselves a literary \ufb02ourish and frame the advice in this section with two quotes. The \ufb01rst is from Tom Knight, one of the principal designers of Lisp machines\u2014 research computers designed at MIT to optimize running programs in the Lisp programming language. A novice was trying to \ufb01x a broken Lisp machine by turning the power off and on. Knight, seeing what the student was doing, spoke sternly: \u201cYou cannot \ufb01x a machine by just power-cycling it with no understanding of what is going wrong.\u201d Knight turned the ma- chine off and on. The machine worked. \u2014\u201cAI Koans\u201d section of The New Hacker\u2019s Dictionary To us, the above quote captures the perils of blindly copy-pasting code without under- standing how it works: the code may appear to work initially, but if you don\u2019t know why, or if it breaks something else, you may get into trouble in the future, and you certainly won\u2019t learn much. While programmer Q&A sites such as StackOver\ufb02ow15 are invaluable for both asking questions and discovering code snippets to perform speci\ufb01c tasks, your strategy should be to \ufb01nd a general pattern matching what you\u2019re trying to do, then once you fully understand how the found example works, adapt it for your speci\ufb01c situation. In other words, search for how, not what. The second quote is from the author of The Cathedral and the Bazaar (Raymond 2001), an early exposition of the potential advantages of open-source development: Ugly programs are like ugly suspension bridges: they\u2019re much more liable to collapse than pretty ones, because the way humans (especially engineer-humans) perceive beauty is intimately related to our ability to process and understand complexity. A language that makes it hard to write elegant code makes it hard to write good code. \u2014Eric S. Raymond Learning to use a new language and making the most of its idioms is a vital skill for software professionals. These are not easy tasks, but we hope that focusing on unique and beautiful features in our exposition of Ruby and JavaScript will evoke intellectual curiosity rather than groans of resignation, and that you will come to appreciate the value of wielding a variety of specialized tools and choosing the most productive one for each new job. If this is your \ufb01rst exposure to Ruby, then functional programming and blocks in Ruby and closures in JavaScript may take some getting used to. But as with any language, not learning to use the idioms properly may result in missing the opportunity to use a mechanism in the new language that might provide a more beautiful solution. Our advice is therefore to persevere in a new language until you\u2019re comfortable with its idioms. Resist the temptation to \u201ctransliterate\u201d your code from other languages without \ufb01rst 70 REFERENCES considering whether there\u2019s a more idiomatic way to express what you need in the target language. If you want to expand your \u201cprogramming language cross training\u201d program, we rec- ommend Seven Languages In Seven Weeks (Tate 2010), which introduces the reader to a set of languages that invite radically different ways of thinking about expressing programming tasks. Finally, we recommend these resources for more detail on Ruby itself. Again, we assume that Ruby is not your \ufb01rst language and that this book and course are not your \ufb01rst exposure to programming, so we omit references aimed at beginners. \u2022 Programming Ruby16 and The Ruby Programming Language (Flanagan and Mat- sumoto 2008), co-authored by Ruby inventor Yukihiro \u201cMatz\u201d Matsumoto, are de\ufb01ni- tive references for Ruby. \u2022 The online documentation for Ruby17 gives details on the language, its classes, and its standard libraries. A few of the most useful classes include IO (\ufb01le and network I/O, including CSV \ufb01les), Set (collection operations such as set difference, set intersection, and so on), and Time (the standard class for representing times, which we recommend over Date even if you\u2019re representing only dates without times). These are reference materials, not a tutorial. \u2022 Learning Ruby (Fitzgerald 2007) takes a more tutorial-style approach to learning the language. \u2022 The Ruby Way is an encyclopedic reference to both Ruby itself and how to use it id- iomatically to solve many practical programming problems. \u2022 Ruby Best Practices (Brown 2009) focuses on how to make the best of Ruby\u2019s \u201cpower tools\u201d like blocks, modules/duck-typing, metaprogramming, and so on. If you want to write Ruby like a Rubyist, this is a great read. \u2022 Many newcomers to Ruby have trouble with yield, which has no equivalent in Java, C or C++ (although recent versions of Python and JavaScript do have similar mech- anisms). The coroutines article on Wikipedia gives good examples of the general coroutine mechanism that yield supports. A. Begel and N. Nagappan. Pair programming: What\u2019s in it for me? In Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement, pages 120\u2013128, Kaiserslautern, Germany, October 2008. G. T. Brown. Ruby Best Practices. O\u2019Reilly Media, 2009. ISBN 0596523009. A. Cockburn and L. Williams. The costs and bene\ufb01ts of pair programming. Extreme Pro- gramming Examined, pages 223\u2013248, 2001. M. J. Fitzgerald. Learning Ruby. O\u2019Reilly Media, 2007. ISBN 0596529864. D. Flanagan and Y. Matsumoto. The Ruby Programming Language. O\u2019Reilly Media, 2008. ISBN 0596516177. NOTES 71 J. Hannay, T. Dyba, E. Arisholm, and D. Sjoberg. The effectiveness of pair programming: A meta-analysis. Information and Software Technology, 51(7):1110\u20131122, July 2009. L. Hoffmann. Q&a: Big challenge. Communications of the ACM (CACM), 56(9):112\u2013ff, Sept. 2013. J. Moore. pivotallabs.com/blabs/categories/pair-programming. ipad 2 as a remote presence device? Pivotal Blabs, 2011. URL http:// E. S. Raymond. The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revoluationary. O\u2019Reilly Media, Inc., 2001. F. J. Rodr\u00edguez, K. M. Price, and K. E. Boyer. Exploring the pair programming pro- cess: Characteristics of effective collaboration. In Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education, SIGCSE \u201917, page 507\u2013512, New York, NY, USA, 2017. Association for Computing Machinery. ISBN 9781450346986. doi: 10.1145/3017680.3017748. URL https://doi.org/10.1145/3017680.3017748. B. Tate. Programming Languages (Pragmatic Programmers). ISBN 193435659X. Programming-Programmers/dp/193435659X. Seven Languages in Seven Weeks: A Pragmatic Guide to Learning Pragmatic Bookshelf, 2010. URL https://www.amazon.com/Seven-Languages-Weeks- Notes 1https://rubular.com 2http://dilbert.com/strips/comic/2003-01-09/ 3http://dilbert.com/strips/comic/2003-01-11/ 4https://ace.c9.io 5https://sublimetext.com 6https://queue.acm.org/detail.cfm?id=1039535 7http://ruby-doc.org/core-2.5.1/Enumerable.html 8https://ruby-doc.org/stdlib 9https://rubygems.org 10https://rubygems.org 11https://bundler.io 12https://semver.org/spec/v2.0.0.html 13http://norvig.com/21-days.html 14https://wiki.c2.com/?HolyWar 15https://stackoverflow.com 16http://ruby-doc.org/docs/ProgrammingRuby 17http://ruby-doc.org/ 3 SaaS Application Architecture: Microservices, APIs, and REST Dennis Ritchie (1941\u20132011) and Ken Thompson (1943\u2013) were co-recipients of the 1983 Turing Award for fundamental contributions to operating systems design in general and the invention of Unix in particular. I think the major good idea in Unix was its clean and simple interface: open, close, read, and write. \u2014Unix and Beyond: An Interview With Ken Thompson, IEEE Computer 32(5), May 1999 . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0184",
    "title": "3.1 The Web\u2019s Client\u2013Server Architecture .",
    "pages": [
      84
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0185",
    "title": "3.2 SaaS Communication Uses HTTP Routes",
    "pages": [
      84
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0186",
    "title": "3.3 CHIPS: HTTP and URIs .",
    "pages": [
      84
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0187",
    "title": "3.4 From Web Sites to Microservices: Service-Oriented Architecture",
    "pages": [
      84
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0188",
    "title": "3.5 RESTful APIs: Everything is a Resource .",
    "pages": [
      84
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0189",
    "title": "3.6 RESTful URIs, API Calls, and JSON .",
    "pages": [
      84
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0190",
    "title": "3.7 CHIPS: Create and Deploy a Simple SaaS App .",
    "pages": [
      84
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0191",
    "title": "3.8 Fallacies and Pitfalls .",
    "pages": [
      84
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0192",
    "title": "3.9 Concluding Remarks: Continuity From CGI to SOA .",
    "pages": [
      84,
      85,
      86
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 76 80 80 84 89 92 92 94 Prerequisites and Concepts Concepts: 73 \u2022 SaaS apps follow the client-server pattern, in which a client makes requests and a server responds to the requests of many clients. \u2022 Fundamental to the Web\u2019s architecture are the Hypertext Transfer Protocol (HTTP), a request-reply protocol over which Web content is delivered, and Universal Resource Identiers (URIs), which name a particular resource on the Web and may specify parameters (options) for accessing it. A basic building block of SaaS is an HTTP route, which combines a method such as GET or POST with a URI. \u2022 Over time, the Web shifted from a collection of static resources to a collection of programs (services) that could be remotely accessed via either a Web browser or another SaaS app. This shift towards service-oriented architecture laid the groundwork for the explosion of microservices. \u2022 An Application Programming Interface (API) for a microservice is a formal de- scription of the operations the microservice can do. The API rst design stance suggests that even when creating a large SaaS app, we get a more modular design by thinking about the app in terms of its smaller components and the APIs by which they communicate. \u2022 Since most mobile apps are just SaaS clients that access a SaaS app in the same way a microservice would, the API-rst design stance espoused in this chapter is an ideal complement to the mobile-rst design stance in Chapter 1. 74 CHAPTER 3. MICROSERVICES, APIS, REST"
    ]
  },
  {
    "id": "sec_0193",
    "title": "3.1 The Web\u2019s ClientServer Architecture",
    "pages": [
      86,
      87
    ],
    "text_blocks": [
      "Every time you use a Web browser to visit a site, or use a mobile app that also makes use of the cloud (such as when a weather app downloads the latest weather forecasts), you are using a Software-as-a-Service (SaaS) client to make one or more requests of a SaaS server. SaaS based on Web protocols is the most widely deployed example of a client-server architec- ture: clients are programs whose specialty is asking servers for information and (usually) allowing the user to interact with that information, and servers are programs whose specialty is ef\ufb01ciently serving large numbers of clients simultaneously. Modern SaaS clients can take many forms. Whether you visit Google Maps using a browser on your PC, a browser on a smartphone, or a smartphone platform app, you\u2019re using a SaaS client. And while the clients differ in how they present and let you interact with Google Maps since each is specialized to its task, all three are communicating with the same Google Maps SaaS service. In contrast to the client software, which is typically a discrete app running on a single device such as a PC or smartphone, the \u201cserver\u201d is in fact typically a collection of comput- ers running multiple different software components (which we will meet in due time) that together comprise the functionality of the actual site. The way these components are dis- tributed over one or many computers depends on the type of hosting environment and the number of users the app must serve. In any case, \u201cthe server\u201d appears as a single logical entity to the client, which can remain blissfully unaware of the server\u2019s deployment topology. Indeed, you will deploy on your own computer a \u201cmini-server\u201d with just enough functionality to let one user at a time (you, the developer) interact with your SaaS app during development and testing. Distinguishing clients from servers allows each type of program to be highly specialized to its task: the client can have a responsive and appealing user interface, while the server concentrates on ef\ufb01ciently serving many clients simultaneously. Client-server is therefore our \ufb01rst example of a design pattern\u2014a reusable structure, behavior, strategy, or technique that captures a proven solution to a collection of similar problems by separating the things that change from those that stay the same. In the case of client-server architectures, what stays the same is the separation of concerns between the client and the server, despite changes across implementations of clients and servers. Of course, client-server isn\u2019t the only architectural pattern found in Internet-based ser- vices. In the peer-to-peer architecture, used in BitTorrent, every participant is both a client and a server\u2014anyone can ask anyone else for information. In such a system where a single program must behave as both client and server, it\u2019s harder to specialize the program to do either job really well. But in the early days of computing, client-server architectures made particularly good sense because client hardware needed to be less expensive than server hardware, so that one could deploy large numbers of clients served by one or a few very ex- pensive servers. Today, with falling hardware costs leading to powerful smartphones and Web browsers that support animation and 3D effects, a better characterization might be that clients and servers are comparably complex but continue to be specialized for their very different roles. Indeed, we will see those distinct roles re\ufb02ected in the design patterns that appear in client frameworks (Angular, React, and so on) vs. those that appear in server frame- works (Rails, Django, Node, and so on). Even terms such as \u201cclient push\u201d re\ufb02ect the built-in assumption that clients are distinct from servers. Although client-server systems long predate the emergence of SaaS, the Web, or even the 3.1. THE WEB\u2019S CLIENT\u2013SERVER ARCHITECTURE 75 Year 1960 1971 System Sabre, airline reserva- tions system for Amer- ican Airlines FTP Trans- (File fer Protocol), which to allowed download \ufb01les from servers clients"
    ]
  },
  {
    "id": "sec_0194",
    "title": "1983 Novell NetWare, which",
    "pages": [
      87
    ],
    "text_blocks": [
      "allowed PCs running the CP/M or MS- DOS operating sys- tems to share \ufb01les on a server POP (Post Of\ufb01ce Pro- tocol), which allowed separation email clients from servers 1984 of"
    ]
  },
  {
    "id": "sec_0195",
    "title": "1990 World Wide Web",
    "pages": [
      87,
      88
    ],
    "text_blocks": [
      "at electrome- terminals travel Client Custom chanical installed agencies Originally, command- line client ftp; today, command-line clients (cURL, NcFTP, Win- apps GUI SCP), (Cyberduck, Fetch), and all Web browsers Custom client software compatible with MS- DOS Server Two IBM 7090 main- frames Various server software packages, including Unix ftpd, FileZilla, Vsftpd Protocol(s) Custom protocol over telephone lines FM-based leased ASCII-based FTP pro- tocol over TCP/IP Custom Novell \ufb01le server appliance based on Motorola 68000 microprocessor Custom protocols over custom PC-compatible network interface PC apps, Various Eudora, including Thunderbird, Ap- ple Mail, Microsoft Outlook, Elm, Pine, Eureka Various PC apps, in- cluding NCSA Mosaic, Netscape Navigator, Microsoft Internet Ex- plorer, Mozilla Firefox, Google Chrome Various server software packages, including Apache James, Nginx, Eudora, Qpopper POP ASCII-based protocol over TCP/IP; largely superseded by IMAP ASCII-based Hyper- Text Transfer Protocol (HTTP) over TCP/IP soft- server Various ware in- packages, cluding Apache Httpd, Internet Microsoft Information Server, Nginx Figure 3.1: The Web inherits a long and rich history of computer-based client-server systems. While all of these examples arguably re\ufb02ect the idea of software as a service, the term as used today refers to client-server systems built using HTTP and other Web standards and protocols. 76 CHAPTER 3. MICROSERVICES, APIS, REST Internet, because of the Web\u2019s ubiquity we will use the term \u201cSaaS\u201d (software as a service) to mean \u201cclient-server systems built to operate using the open standards of the World Wide Web,\u201d that is, in which Web services are accessed using the protocols and data formats de- scribed in this chapter, with Web sites accessed via browsers or via mobile apps being the most common examples. Summary: \u2022 SaaS Web apps are examples of the client-server architectural pattern, in which client software is typically specialized for interacting with the user and sending re- quests to the server on the user\u2019s behalf, and the server software is specialized for handling large volumes of such requests. \u2022 The Web\u2019s heritage as a fundamentally client-server architecture is ubiquitous throughout the software stacks, protocols, and terminology we will encounter throughout the rest of this book. \u2022 Because Web apps use open standards that anyone can implement royalty-free, in contrast to proprietary standards used by older client-server apps, the Web browser has become the \u201cuniversal client.\u201d \u2022 An alternative to client-server is peer-to-peer, in which all entities act as both clients and servers. While arguably more \ufb02exible, this architecture makes it dif\ufb01cult to specialize the software to do either job really well. Self-Check 3.1.1. What is the primary difference between the roles of clients and servers in SaaS? A SaaS client is optimized for allowing the user to interact with information, whereas a SaaS server is optimized for serving many clients simultaneously."
    ]
  },
  {
    "id": "sec_0196",
    "title": "3.2 SaaS Communication Uses HTTP Routes",
    "pages": [
      88,
      89
    ],
    "text_blocks": [
      "How do SaaS clients and SaaS servers communicate? A network protocol is a set of com- munication rules on which agents participating in a network agree. The fundamental proto- col linking all computers on the Internet is TCP/IP, the venerable Transmission Control Protocol/Internet Protocol . TCP/IP allows a pair of communicating agents to exchange ordered sequences of bytes in both directions simultaneously (full duplex), analogous to a telephone conversation in which both parties can speak and listen at the same time. If a pro- gram at one end of the TCP/IP connection (say, the client) emits a string to the connection, the server will receive that exact string, and vice versa. TCP/IP doesn\u2019t distinguish the roles of the agents on either side of the connection\u2014it doesn\u2019t care if one is the server and one is the client, or if they are peers in a peer-to-peer network\u2014and it doesn\u2019t place any restric- tions on what strings are communicated. It is up to the individual programs communicating over a TCP/IP connection to determine the rules of communication. As we will see, in the case of Web browsers and servers, those rules are de\ufb01ned by HTTP, the HyperText Transfer Protocol. How do computers contact each other in a TCP/IP-based network? Each computer is assigned an IP address consisting of four bytes separated by dots, such as 128.32.244.172. Octet is sometimes used in the networking literature to refer to a group of 8 bits\u2014a legacy from the era before the IBM System/360 standardized the 8-bit byte."
    ]
  },
  {
    "id": "sec_0197",
    "title": "65535 (216 \u2212 1) is the",
    "pages": [
      89,
      90,
      91,
      92
    ],
    "text_blocks": [
      "largest unsigned value that will \ufb01t in the 16 bits originally allocated to the port number in IP\u2019s original design. 3.2. SAAS COMMUNICATION USES HTTP ROUTES 77 Most of the time we don\u2019t use IP addresses directly\u2014another Internet service called Domain Name System (DNS), which has its own protocol also based on TCP/IP, is automatically invoked to map hostnames like www.eecs.berkeley.edu to IP addresses. When you type a site name such as www.eecs.berkeley.edu into your browser\u2019s address bar, the browser automatically contacts a DNS server to translate that name into an IP address, in this case 128.32.244.172. For reasons related to the design and history of IP, the IP address 127.0.0.1 and the hostname localhost always refer to the very computer on which the app is running. This capability lets you develop and test Web apps by connecting to the server running on your own computer: from the client\u2019s point of view such a server functions identically to one in the cloud backed by thousands of computers. That is, a TCP/IP based server program provides the same abstraction to the client regardless of where the server software is running and how it is distributed over one or many computers. Because multiple TCP/IP-based programs can be running on the same computer simultaneously\u2014for example, a Web server and an email server\u2014the IP address isn\u2019t suf\ufb01cient to distinguish them. Therefore, establishing a TCP/IP connection also requires a port number from 1 to 65535 to indicate which program on the server is the intended communication partner. Some program must be listening to that port number on the server in order to accept connections. The default ports for production Web servers are 80 for HTTP and 443 for HTTPS. The latter stands for Secure HTTP, which uses public-key cryptography to encrypt HTTP communication and protect it from eavesdroppers, as Chapter 12 describes. When you start up a development server (to test your app) in your own development environment, which port it \u201clistens\u201d on may be determined by the IDE you use, the framework you use (Rails uses port 3000, for example), or the manner in which you start the server. The HTTP protocol \u2014the rules for communication to make a request and receive a response\u2014are well-circumscribed and may be summarized as follows: 1. The client initiates a TCP/IP connection to a server by specifying the IP address and port number (usually 80). If the computer at that IP address does not have an HTTP server process listening on the speci\ufb01ed port, the client immediately experiences an error, which most browsers report as \u201cThis site can\u2019t be reached\u201d or \u201cConnection re- fused.\u201d 2. Otherwise, if the connection succeeds, the client immediately sends an HTTP request describing its intention to perform some operation on a resource. A resource is any entity that the server app manipulates\u2014a Web page, an image, and a form submission that creates a new user account are all examples of resources. 3. The server delivers an HTTP response either satisfying the client\u2019s request or reporting any errors that prevented the request from succeeding. The response may also include information in the form of an HTTP cookie that allows the server to correctly identify this same client on future interactions. What does the client\u2019s HTTP request in step 2 look like? An HTTP request consists of a route, zero or more headers, and possibly a request body, all of which are just strings sent over the TCP/IP connection. As Figure 3.2 shows, an HTTP route consists of an HTTP method\u2014 usually, one of GET, POST, PUT, PATCH, or DELETE\u2014plus a URI , or Uniform Resource Identi\ufb01er . You are familiar with URIs as the strings usually beginning with http:// that you type into a browser\u2019s address bar. Importantly, though, it is the combination of the HTTP 78 CHAPTER 3. MICROSERVICES, APIS, REST URI or URL? URIs are sometimes referred to as URLs, or Uniform Resource Locators. Despite subtle technical distinctions, for our purposes the terms can be used interchangeably. We use URI because it is more general and matches the terminology used by most libraries. Figure 3.2: An HTTP route consists of an HTTP method plus a URI , and expresses the client\u2019s desire to perform some operation on the resource named by the URI. A full URI begins with a scheme such as http or https, which describes what protocol is to be used to access the resource, and includes the above components. Optional components are in parentheses; if the port number is omitted, it defaults to 80 for HTTP or 443 for HTTPS. A partial URI omits any or all of the leftmost components, in which case those components are \ufb01lled in or resolved relative to a base URI determined by the speci\ufb01c application. Best practice is to use full URIs. method and URI that de\ufb01nes a route: the same URI with different HTTP methods can have different meanings to a SaaS app. We will have much more to say about the semantics of routes later in the chapter, but in general, GET typically means \u201cdeliver a copy of the resource to the client without modifying the resource or causing any side effects,\u201d whereas POST, PUT, PATCH, DELETE are typically used to perform an operation that creates, modi\ufb01es, or deletes a resource. When you visit a URI by typing it into a browser\u2019s address bar, your browser performs a GET to that URI; when you submit a \ufb01ll-in form, the browser may perform either a GET or a POST to a speci\ufb01ed URI, depending on how the page is authored. For historical reasons, most browsers don\u2019t generate PUT, PATCH, or DELETE directly; we will return to their use shortly. You\u2019ll get hands-on practice with HTTP in an upcoming CHIPS exercise, but this back- ground will serve to orient you in advance. HTTP\u2019s simplicity derives from two characteris- tics. First, HTTP is a request-response protocol: every HTTP interaction begins with the client making a request, to which the server delivers a response (unless the server crashes or the network becomes unavailable, of course!) The HTTP request must include the route and HTTP protocol version, and usually also includes some request headers that provide infor- mation about the client. The HTTP protocol version tells the server which HTTP features the client can understand, so that (for example) servers can avoid using newer HTTP features if the client only understands an older protocol version. The server reply must include the HTTP version and 3-digit status code indicating the result of the requested operation; any text following the status code on the \ufb01rst response line is optional and ignored, but is often used to provide a human-readable version of the status. The response also includes headers de- scribing the rest of the response data, followed by a blank line and then the response payload itself. Second, HTTP is a stateless protocol : every HTTP request is independent of and un- related to all previous requests. If this is so, how can a web site keep track of information such as whether you have logged in? HTTP provides a mechanism called cookies for this purpose. The \ufb01rst time a client makes a request to a particular server, the server can include in the response a Set-Cookie: header, containing a chunk of information that the server can use to identify this client on future HTTP requests. It is the client\u2019s responsibility to store that information and pass it back via a Cookie: header on every subsequent request to that same server. Analogously to a coat-check token, a cookie should be both tamper-evident and opaque to (not interpretable by) the client, but if presented later to the server, is suf\ufb01cient to identify the client, thereby enabling the concept of a continuing session between the server 3.2. SAAS COMMUNICATION USES HTTP ROUTES 79 and that client. Stateless protocols therefore simplify server design at the expense of more complex application design, but happily, successful frameworks such as Rails shield you from much of this complexity. Summary Cookie in hacker jargon has long meant1 \u201can uninterpretable blob of data that must be presented later to identify yourself or achieve some task.\u201d \u2022 Web browsers and servers communicate using the HyperText Transfer Proto- col . HTTP relies on TCP/IP (Transmission Control Protocol/Internet Protocol) to reliably exchange an ordered sequence of bytes. \u2022 Each computer connected to a TCP/IP network has an IP address such as 128.32.244.172, although the Domain Name System (DNS) allows the use of human-friendly names instead. The special name localhost refers to the local computer and resolves to the special IP address 127.0.0.1. \u2022 Each application running on a particular computer must \u201clisten\u201d on a distinct TCP port, numbered from 1 to 65535 (216 \u2212 1). Port 80 is used by HTTP (Web) servers. \u2022 A Uniform Resource Identi\ufb01er (URI) names a resource available on the Internet. The interpretation of the resource name varies from application to application. \u2022 An HTTP route consists of both an HTTP method (such as GET or POST) and a URI. The same URI with different methods results in different routes, which may or may not behave the same way in a particular SaaS app. \u2022 HTTP is a stateless protocol in that every request is independent of every other request, even from the same user. HTTP cookies allow the association of HTTP requests from the same user. It\u2019s the browser\u2019s responsibility to accept a cookie from an HTTP server and ensure that the cookie is included with future requests sent to that server. Elaboration: Multi-homing, IPv6 We have drastically simpli\ufb01ed many aspects of TCP/IP, including multi-homed devices and the slow phase-out of the current version of IP (IPv4) in favor of version 6 (IPv6), which uses a different format for addresses. However, since SaaS app writers rarely have to deal directly with IP addresses, these simpli\ufb01cations don\u2019t materially alter our explanations. Self-Check 3.2.1. Is DNS a client\u2013server protocol? Why or why not? Yes. DNS clients only ask for lookup services (DNS resolution). DNS servers provide the responses, though they may consult other servers (in effect temporarily acting as clients) as part of doing so. Self-Check 3.2.2. Can you make a TCP connection without specifying a port number, and if so, what happens? All TCP connections must specify a port number. However, speci\ufb01c types of clients (Web browsers, email readers, and so on) have the knowledge built into them of the default port numbers for those services, so end users of such clients rarely have to know this information. 80 CHAPTER 3. MICROSERVICES, APIS, REST Self-Check 3.2.3. True or false: HTTP as a protocol has no concept of a \u201csession\u201d consist- ing of a sequence of related HTTP requests to the same site. True. HTTP is stateless, with every request being completely independent of all other requests from the same client. Therefore a mechanism such as HTTP Cookies must be used to create the abstraction of a session. Self-Check 3.2.4. Many HTTP servers rely on using HTTP cookies to identify a client on repeated requests to the same site, for example, to track information such as whether that user has logged in. What happens if you completely disable cookies in your browser and try to visit such a site? Try it and see. Use a search engine to \ufb01nd instructions on how to (temporarily) disable cookies entirely in your browser, and try to log in to a site where you have an account. Don\u2019t forget to re-enable cookies when you \ufb01nish your experiment."
    ]
  },
  {
    "id": "sec_0198",
    "title": "3.3 CHIPS: HTTP and URIs",
    "pages": [
      92
    ],
    "text_blocks": [
      "CHIPS 3.3: HTTP and URIs https://github.com/saasbook/hw-http-intro Construct URIs and make direct HTTP requests using command-line power tools that all SaaS developers should know. Examine and understand HTTP request and response headers, error codes, and cookies."
    ]
  },
  {
    "id": "sec_0199",
    "title": "3.4 From Web Sites to Microservices: Service-Oriented Architecture",
    "pages": [
      92,
      93
    ],
    "text_blocks": [
      "Nobody should start to undertake a large project. You start with a small trivial project, and you should never expect it to get large. If you do, you\u2019ll just overdesign and generally think it is more important than it likely is at that stage. Or worse, you might be scared away by the sheer size of the work you envision. So start small, and think about the details. Don\u2019t think about some big picture and fancy design. If it doesn\u2019t solve some fairly immediate need, it\u2019s almost certainly over-designed. And don\u2019t expect people to jump in and help you. That\u2019s not how these things work. You need to get something half- way useful \ufb01rst, and then others will say \u201chey, that almost works for me,\u201d and they\u2019ll get involved in the project. \u2014Linus Torvalds, interviewed by Preston St. Pierre in Linux Times, Oct 25, 2004. When the Web began in 1990, HTTP servers existed primarily to serve static content (originally the text and images of scienti\ufb01c papers) that browsers would display. Each time the browser made another HTTP request, the server would deliver a new web page for the browser to show. But the emergence of SaaS around 1995 soon shifted the functionality of servers: rather than simply returning copies of static Web pages, servers would now run a program, and create HTML pages \u201con the \ufb02y\u201d that implemented that program\u2019s user interface. However, it was still the case that every new HTTP request resulted in the browser loading and displaying a new page. The next evolutionary step was the appearance of AJAX , or Asynchronous JavaScript And XML. If a browser supported AJAX, pages could include code written in the JavaScript language, and that code could make subsequent HTTP requests to the Internet Explorer 5, predecessor to Microsoft Edge, was the \ufb01rst browser to support AJAX, in 1998. Google Maps, launched in 2005, was a dramatic demonstration of using AJAX to build truly interactive Web apps. 3.4. FROM WEB SITES TO MICROSERVICES 81 server without causing a page reload. In response to those requests, the server would return not an HTML page, but a data structure in either XML or JSON format, both of which we\u2019ll meet shortly. The JavaScript code running in the browser would use that data to determine how to change the appearance or behavior of the displayed page, all without causing a page reload. AJAX marked a turning point in the relationship between a Web site and a client: instead of receiving HTML pages and functioning primarily as a display engine, the client was es- sentially calling a function on the remote server and expecting to get some data back, just as if the client was calling a library function. This shift in perspective invited a new way of looking at the Web: as a set of independent services that could be composed to produce larger sites\u2014a so-called Service Oriented Architecture (SOA). SOA had long suffered from lack of clarity and direction.. . . SOA could in fact die\u2014not due to a lack of substance or potential, but simply due to a seemingly endless proliferation of misinformation and confusion. \u2014Thomas Erl, About the SOA Manifesto, 2010 SOA as an architectural pattern may have been a new perspective on structuring the Web, but it was certainly not a new idea. Despite initial skepticism about whether SOA was more than just a marketing \u201cbuzzword,\u201d one very prominent company was internally (and, at the time, silently) making SOA quite concrete. The e-commerce giant Amazon.com launched its retail site in 1995 powered by a monolithic application\u2014a single large application that handled all aspects of the site. According to the blog of former Amazonian Steve Yegge2, in"
    ]
  },
  {
    "id": "sec_0200",
    "title": "2002 the CEO and founder of Amazon mandated a change to what we would today call SOA.",
    "pages": [
      93,
      94,
      95,
      96
    ],
    "text_blocks": [
      "Yegge claims that Jeff Bezos broadcast an email to all employees along the following lines (we are paraphrasing the main points of Yegge\u2019s description for conciseness): All teams responsible for different subsystems of Amazon.com will hence- forth expose their subsystem\u2019s data and functionality through service interfaces only. No subsystem is to be allowed direct access to the data \u201cowned\u201d by an- other subsystem; the only access will be through an interface that exposes spe- ci\ufb01c operations on the data. Furthermore, every such interface must be designed so that someday it can be exposed to outside developers, not just used within Amazon.com itself. In this decree, Bezos captures the critical distinction of SOA: the only way one service can name or access another service\u2019s data is to request speci\ufb01c operations on that data through an external interface that provides those operations. As an example, suppose we wanted to create a simple bookstore service where users can post reviews of books they\u2019ve bought and maintain a pro\ufb01le of their reading interests. We\u2019d need three subsystems: book reviews, user pro\ufb01les, and buying. The left side of Figure 3.3 shows the silo version, similar to how Amazon.com worked in 1995. Each subsystem can internally share access to data directly in different subsystems. For example, the reviews subsystem can get user pro\ufb01le info out of the users subsystem. The only externally visible interface is \u201cthe bookstore.\u201d In other words, you as an independent web developer cannot access Amazon\u2019s User Pro- \ufb01le service to manage users pro\ufb01les for your own e-commerce site; it\u2019s for Amazon\u2019s internal use only. In contrast, the right side of Figure 3.3 shows the SOA version of the bookstore service, in which all subsystems are separate and independent. Even though all are inside the 82 CHAPTER 3. MICROSERVICES, APIS, REST Figure 3.3: Left: Silo version of a \ufb01ctitious bookstore service, with all subsystems behind a single API. Right: SOA version of a \ufb01ctitious bookstore service, where all three subsystems are independent and available via APIs. \u201cboundary\u201d of the bookstore, which is shown as a dotted rectangle, the subsystems interact with each other as if they were separate. For example, if the reviews subsystem wants to up- date a user\u2019s pro\ufb01le to indicate that the user has written a review, the reviews subsystem can\u2019t reach directly into the users database. Instead, it has to ask the users service to update the user\u2019s information, via whatever interface is provided for that purpose. If no such operation is provided, the reviews team must negotiate with the user database team to get them to expose the necessary operation. A microservice, in contrast, is a standalone service that performs just one type of task, and is speci\ufb01cally designed to be accessible from and incorporated into the functionality of any other outside service (perhaps for a fee). Though there is no hard-and-fast criterion dis- tinguishing the scope of a microservice from that of a service, the pre\ufb01x micro is intended to promote an \u201cextreme SOA\u201d design stance in which each microservice is responsible for a single narrowly-de\ufb01ned function. For example, Google Maps feels like a single app when you use it in a browser, but the different \u201cclusters\u201d of related functionality used by that app\u2014 drawing the map, computing driving directions, geocoding addresses, and so on\u2014appear as distinct microservices to the underlying JavaScript code that implements the app. A rough rule of thumb is that the scope of a microservice should correspond to a set of closely re- lated operations on a very tightly integrated set of resources. Notwithstanding, since there is no hard distinction between a service and a microservice, we will use the term service throughout. We will adopt the following rough de\ufb01nition, found in Nadareishvili et al. 2016: \u201cA (micro)service is an independently deployable component of bounded scope that supports interoperability though message-based communication.\u201d Based on this de\ufb01nition, we can see that the monolithic bookstore fails to be \u201cmicro\u201d not just because of its size, but because its components are not independently deployable since they share access to databases. As Figure 3.4 shows, there are both pros and cons to preferring a service-oriented archi- tecture over a monolithic one. In short, we can think of microservices as a manifestation 3.4. FROM WEB SITES TO MICROSERVICES 83 Pro Reusability: Others can recombine existing services to create new apps, as in Figure 3.3, and each microser- vice can be implemented using the most appropriate language or framework, since its implementation is completely hidden behind its API. Easier testing: a microservice does only one thing, so testing each microservice is easier. Con Performance: each invocation of a service involves the higher cost of wading through the deeper software stack of a network interface, so there is a possible per- formance penalty to SOA. Managing partial failure: a monolithic system is either working or not, but in an SOA, some services may fail while others are working, making dependability more challenging. More Agile-friendly: Chapter 1 reveals that Agile works best with small-to-medium projects and teams. SOA allows large services to be created by composing smaller ones, each of which can be built and operated by a small Agile team. More development work: you must design and imple- ment an interface for each service component, rather than a single interface for the entire site. Fortunately, an approach called REST, which we describe next, simpli\ufb01es this task. \u201cYou build it, you run it\u201d (as Amazon Web Services CTO Werner Vogels has said): the same tightly-knit team is responsible for developing, testing, and oper- ating the microservice, allowing the microservice to be improved more quickly in response to customer re- quests. Developers must learn about operations, and vice versa; hence \u201cdev/ops.\u201d This is a reality of modern SaaS to which we return in Chapter 12. Figure 3.4: Each bene\ufb01t of SOA in the left-hand column comes at a cost, as shown in the right-hand column. Nonetheless, in practice the bene\ufb01ts of SOA seem to outweigh the costs, if SOA is done well. 84 CHAPTER 3. MICROSERVICES, APIS, REST of extreme programming (XP) as applied to service-oriented architecture: If it\u2019s good for services to be independently evolvable, make each one as compact as possible to maximize that independence. Microservices may also arise by design or by splitting up an existing large service, as occurred with Twitter. Around 2013, their monolithic Rails application, which they humorously called \u201cthe MonoRail\u201d internally, was split up into a large number of microservices, most of which were written in Java, Scala, or Clojure. Summary of Service-Oriented Architecture and Microservices \u2022 Although the term was nearly lost in a sea of confusion, Service Oriented Archi- tecture (SOA) just means an approach to software development in which subsys- tems can only access each others\u2019 data via external interfaces. \u2022 From 1990 to 2010, the Web underwent a transformation from serving static con- tent (Web 1.0) to serving dynamically-generated user interfaces (SaaS) to allowing ongoing interactions after the initial page load (AJAX) to architecting large apps by composing independent services (SOA). \u2022 Although there is no bright line separating a service from a microservice, a mi- croservice should perform a related set of operations on a well-circumscribed set of resources, should be independently deployed and operated (usually by the same team that builds it), and should be designed to be readily incorporated with other external services. Elaboration: Microservices and the Unix philosophy The in\ufb02uence of the Unix operating system is pervasive throughout software engineering, due in part to its careful design choices. In particular, the \u201cUnix philosophy\u201d promotes the building of simple components that perform just one task and are easily composable, in that the output from any component should constitute legal input to any other. Microservices can be seen as the triumph of the Unix philosophy in the world of SaaS: a microservice should do just one thing very well, and make the fewest possible assumptions about how it will be integrated into a larger SOA. Self-Check 3.4.1. Another take on SOA is that it is just a common sense approach to im- proving programmer productivity. Which productivity mechanism does SOA best exemplify: Clarity via conciseness, Synthesis, Reuse, or Automation and Tools? Reuse! The purpose of making internal interfaces visible is so that programmers can stand on the shoulders of others."
    ]
  },
  {
    "id": "sec_0201",
    "title": "3.5 RESTful APIs: Everything is a Resource",
    "pages": [
      96,
      97,
      98,
      99
    ],
    "text_blocks": [
      "An API that isn\u2019t comprehensible isn\u2019t usable. SaaS microservices using HTTP are just the latest manifestation of remote procedure call , an idea with a long history (Birrell and Nelson 1984). The premise of service-oriented architecture is that each service provides a well-de\ufb01ned set of operations on one or a few related types of resources\u2014analogous to a library for a programming language. In other words, clients need a way to name the server function to \u2014James Gosling, inventor of Java 3.5. RESTFUL APIS: EVERYTHING IS A RESOURCE 85 Python program (caller) calls a method in a Python package or library (callee) SaaS client (caller) invokes SaaS service (callee) 1. How does the caller identify the callee? Same computer and same process as caller; import makes a particular named as in library available to the caller, import numpy 2. Which operation is called? 3. How does the caller pass required and optional param- eters to the callee? 4. How does the caller receive a re- turn value? 5. How does the callee signal an er- ror? in named Method numpy.array(...) Passed as arguments to method call, e.g. numpy.array([1,2,3]) code, e.g. a to assigned variable, Returned from method call and usu- ally e.g. n=numpy.array([1,2,3]) Callee may return a \u201csentinel\u201d error value (such as None in Python), or raise an ex- ception An endpoint is a logical address that clients contact in order to use the service. In our case, it usually takes the form of a \u201cbase URI,\u201d that is, a URI pre\ufb01x (includ- ing the microservice\u2019s hostname and port number if necessary) that is common to all API calls made through that endpoint Operation named in path portion of URI May be passed as part of URI path, as key- value pairs in URI query string, or as a data payload in JSON or XML format in the re- quest body Service typically returns a data structure in JSON or XML format Service returns an appropriate HTTP sta- tus code to indicate error type, and usually provides an error message as part of the re- turned data structure Figure 3.5: APIs describe any caller\u2013callee contract, whether calling a service in an SOA or a Python library function. API documentation speci\ufb01es which operations are available, how URIs should be constructed to invoke those operations, how errors are reported, and what other operational requirements must be met (for example, limiting the number of calls made per day to a microservice, or including an account identi\ufb01er or password with each API call). be called, pass arguments to it, consume return values, detect and handle server exceptions (errors in execution), and so on, just as when an application calls a library function, but all subject to the constraints of using HTTP for communication. The term API , or Application Programming Interface, refers to the \u201ccontract\u201d between a caller and callee, whether these are a program calling a library function or a SaaS client invoking a service on a SaaS server, as Figure 3.5 shows. Unfortunately, rows 2 and 3 in the \ufb01gure are problematic, because HTTP does not pre- scribe a way to \u201cname a remote function\u201d or \u201cpass parameters\u201d since those tasks were never part of its original design. In particular, the HTTP and URI speci\ufb01cations offer no conven- tions regarding the semantics (implied meaning) of how URIs are constructed or how these tasks should occur. There was early and widespread recognition that standardizing the con- ventions for such communication would enable the creation of an ecosystem in which any client, not just a Web browser, could make use of a given server in different ways. In most of the microservices world, these conventions are articulated by REST, short for REpresentational State Transfer. In 2000, computer scientist Roy Fielding proposed REST in his Ph.D. dissertation as a way of mapping requests to actions that is particularly well suited to a service-oriented architecture. REST is not a standard, but a design stance regarding how a service should be constructed, and by extension, what its API should look like. Fielding\u2019s idea was to represent the various entities manipulated by a Web app as resources (hence representational), and to construct routes so that any HTTP request would contain all the information necessary to identify both a resource and the action to be performed on it, which 86 CHAPTER 3. MICROSERVICES, APIS, REST might cause a change of state in one or more resources (hence state transfer). An API that adheres to Fielding\u2019s guidelines is said to be RESTful, and the routes (HTTP method plus URI) de\ufb01ned by the API to invoke particular actions are said to be RESTful routes. Although simple to explain, REST is an unexpectedly powerful principle for simplifying and organizing SaaS applications, because it makes the app designer think carefully about how each type of entity manipulated by the app can be represented as a resource, what oper- ations can be done to that resource, and what conditions or assumptions must hold in order for a request for such an operation to be self-contained. For any RESTful API operation, it should be straightforward to answer the following questions: 1. What is the primary resource affected by the operation? 2. What is the operation to be done on that resource? What are the possible results? What are the possible side effects, if any? 3. What other data is necessary to complete the operation, if any, and how is it speci\ufb01ed? For example, consider the answers to the above questions in the case of posting a review for the movie \u201c2001: A Space Odyssey,\u201d a classic favorite of one of your authors: 1. The primary resource is the new review for the speci\ufb01c movie \u201c2001: A Space Odyssey,\u201d which might include (for example) a numerical rating and a few lines of text. 2. The operation is to create a new review using that information. One possible result is success, with the side effect that a new review is created. The other possible result is that creating the review fails for a variety of possible reasons (perhaps this client is not authorized to post reviews, or the database is full, or no more reviews are allowed for this movie), in which case there are no side effects. 3. Besides the review itself, the additional necessary data is some identi\ufb01cation of which movie the review is intended to be linked to. As we will see, this identi\ufb01er will likely be passed as part of the route, either as a component in the path portion of the URI or as a parameter in the query-string portion of the URI. Also, if the review app allows optionally associating a reviewer name or reviewer ID with the review, an identi\ufb01er representing the reviewer may similarly be necessary. The API documentation should describe what operations are available and how the re- quired and optional arguments should be provided for each operation. As we\u2019ll learn in Chapter 4, Rails and other frameworks have built-in support for easily de\ufb01ning RESTful routes. In its purest form, a RESTful API de\ufb01nes up to \ufb01ve operations on a resource, captured by the acronym CRUDI: Create a new instance of a resource, Read (retrieve) a copy of a resource, Update (make changes to) a resource, Delete a resource, and list an Index of all available resources of a given type, possibly \ufb01ltered by particular criteria. Many APIs go further and de\ufb01ne additional operations speci\ufb01c to the resource types used by that service. Nearly always, each resource is given a unique ID\u2014usually a number\u2014that will serve as the \u201cpermanent handle\u201d to that resource and is never reused even if the resource is deleted. A common usage pattern for RESTful APIs is to return a list of resources (with their IDs) corresponding to a search operation; the client can then retrieve the desired resources one by 3.5. RESTFUL APIS: EVERYTHING IS A RESOURCE 87 one via their IDs. Consistent with Section 3.2, RESTful routes whose actions have no side effects typically use GET, while those with side effects use POST, PUT, or PATCH. We can now describe concretely how RESTful service APIs address the requirements of rows 1\u20133 of Figure 3.5. (You\u2019re strongly encouraged to consult the API documentation at https://developers.themoviedb.org3 as you read the rest of this section.) Recall Figure 3.2, which shows the various parts of a URI. RESTful APIs observe several conventions for how those parts of the URI are constructed when making an API call: \u2022 The hostname component of the URI tells us which server provides the service: https://api.themoviedb.org. \u2022 In addition, most servers providing RESTful APIs specify a base URI , or common URI pre\ufb01x that should be prepended to all API calls. You can see from the API doc- umentation that all of the URIs begin with https://api.themoviedb.org/4/; this base URI or hostname-plus-pre\ufb01x is sometimes referred to as the API endpoint, or logical address that clients contact in order to use the service. \u2022 In this case, the API documentation tells us that the component 4 of the end- point name refers to the version number of the API. Making the version number part of the URI allows the API to evolve while preserving compatibility with older clients. You may also see variants such as https://themoviedb.org/api/v4/, https://api.themoviedb.org/v4/, and others. \u2022 The URI path components following the pre\ufb01x specify the operation to be performed and the resource on which to perform it. API documentation frequently uses a colon (:) or curly braces to indicate a URI component corresponding to a resource ID, so the API documentation might state that the route GET /movie/{movie_id} or GET /movie/ :movie_id requests detailed information for the speci\ufb01c movie whose numeric ID is substituted for {movie_id} or :movie_id in the URI. In the next section we describe exactly how the data associated with these requests is formatted and how errors are handled\u2014rows 4 and 5 of Figure 3.5. A common though not universal feature of RESTful APIs is that the structure of the URI path itself reveals information about the relationships among resource types. For example, the TMDb API route GET /movie/{movie_id}/reviews, retrieves all the reviews for a par- ticular movie\u2014effectively, the Index operation on reviews, constrained to a particular movie. The structure of the URI suggests that the same movie can have many associated reviews (a so-called \u201chas-many\u201d relationship, which we\u2019ll meet in Chapter 5). Similarly, a hypothetical route such as GET /movies/5/reviews/22, to request the content of review ID 22 associ- ated with movie ID 5, might seem redundant since the review ID must be unique anyway; but the route structure reveals an otherwise non-obvious relationship. Not all RESTful sites fol- low this practice, though: the TMDb route for a particular review is simply GET /reviews/ {review_id}, and some TMDb routes use multiple path components (terms separated by slashes) to express different sub-operations on a resource rather than relationships among resource types. You can verify by reading the TMDb API docs that the call for retrieving all reviews for a movie actually returns some of the content of each review. In a \u201cpurer\u201d RESTful API, such an Index call might just return a list of review IDs, and the client could then retrieve the"
    ]
  },
  {
    "id": "sec_0202",
    "title": "contents of individual reviews by their review ID. It\u2019s possible that the TMDb API sought to",
    "pages": [
      99,
      100,
      101
    ],
    "text_blocks": [
      "Singular or plural? Some styles of REST API, including that used by Rails, use plural resource names when there can be more than one resource of that type, as in GET /movies/35, and singular names when there\u2019s exactly one such resource, as in GET /homepage. 88 CHAPTER 3. MICROSERVICES, APIS, REST 1. Login to site 2. Welcome page 3. Add item ID 427 to cart 4. View cart 5. Checkout Non-RESTful site URI POST /login/dave GET /welcome POST /add/427 /cart GET POST /checkout RESTful site URI POST /login/dave GET /user/301/welcome POST /user/301/add/427 /user/301/cart GET POST /user/301/checkout Figure 3.6: Non-RESTful requests and routes are those that depend on the results of previous requests but don\u2019t make those dependencies visible or explicit as part of the current request. In a Service-Oriented Architecture, a client of the RESTful site could immediately request to view the cart (line 4), but a client of the non-RESTful site would \ufb01rst have to perform steps 1\u20133 to set up the implicit information on which step 4 depends. make things more ef\ufb01cient so that enough information is returned for each review that the client could decide which reviews were worth getting more details on. But if a movie had thousands of reviews, returning review data rather than just review IDs for all those reviews might become unwieldy. RESTfulness may seem an obvious design choice, but until Fielding crisply character- ized the REST philosophy and began promulgating it, many Web apps were designed non- RESTfully. Figure 3.6 shows how a hypothetical non-RESTful e-commerce site might im- plement the functionality of allowing a user to login, adding a speci\ufb01c item to his shopping cart, and proceeding to checkout. For the hypothetical non-RESTful site, every step after the login (step 1) relies on implicit information: step 2 assumes the site \u201cremembers\u201d who the currently-logged-in user is to show them the welcome page, and step 5 assumes the site \u201cremembers\u201d who has been adding items to their cart for checkout. In contrast, each URI for the RESTful site contains enough information to satisfy the request without relying on such implicit information: after Dave logs in, the fact that his user ID is 301 is present in every request, and his cart is identi\ufb01ed explicitly by his user ID rather than implicitly based on the notion of a currently-logged-in user. Summary \u2022 To treat one or more SaaS apps as \u201cservices\u201d that can accept remote procedure calls on behalf of a client, we need to be able to identify the service, identify which operation (which function) is to be called, pass data to and receive data from the service, and handle errors. \u2022 While there is no enforced standard regarding the mapping between HTTP routes and API operations on a service, REST (REpresentational State Transfer) has emerged as a simple, consistent way to do so that works well with Web technologies. \u2022 The key idea of REST is to represent each type of thing managed by the service as a resource, and provide a limited set of operations (typically Create, Read, Update, Delete, and Index) that can be performed on a resource. The corresponding RESTful request includes all the information necessary to complete the speci\ufb01ed action on that resource. 3.6. RESTFUL URIS, API CALLS, AND JSON 89 Elaboration: Command-Query Separation Noted software engineering researcher Bertrand Meyer has long advocated (Meyer 1997) command-query separation: a given method or operation should either be data-altering (command) or read-only (query) but not both. REST respects this principle by not only separating these operations but, in the \u201cpure REST\u201d formulation, giving each operation only a single responsibility: a given API call either returns data\u2014an individual resource, or a possibly \ufb01ltered collection of resources of one particular type\u2014or it creates, updates, or deletes a single resource of a particular type. Self-Check 3.5.1. Which of these routes for updating the information of movie ID 35 follow good HTTP and REST practices: (a) POST /movie/35, (b) POST /movies/35, (c) PUT / movie/35, (d) PUT /movies/35, (e) GET /movie/35, (f) GET /movies/35, All except (e) and (f) follow defensible practices. Whether to use singular or plural is a matter of style and convention, but GET should not be used for routes whose actions have side effects."
    ]
  },
  {
    "id": "sec_0203",
    "title": "3.6 RESTful URIs, API Calls, and JSON",
    "pages": [
      101,
      102,
      103,
      104
    ],
    "text_blocks": [
      "In considering how to treat a collection of SOA servers as a fabric for programming, we\u2019ve addressed rows 1\u20133 of Figure 3.5. We next describe how data is passed to or received from such services, and some operational considerations such as authorization (is the client allowed to make this API call on this resource?) and how errors are handled. At the highest level, there are three ways to pass parameters from an HTTP client to a service: in the URI, in the request body (for POST or PUT requests), and rarely, as the value of an HTTP header. When the number of parameters is small, and in particular when the parameters are sim- ple types such as strings or numbers, they can often be passed as parameters embedded in the URI, as Figure 3.2 showed: param1=value1&param2=value2&...&paramN=valueN. This situation is typical for GET requests, where we\u2019re usually asking for data based on an ID and perhaps some optional parameters. For example, verify using the TMDb API documenta- tion that the route GET /search/movies?query=Batman+Returns will search TMDb for a movie whose title matches the query string \u201cBatman Returns\u201d. When the data to be passed is more complex, or when the API operation involves a state- changing HTTP method such as POST or PUT, the data is sent as part of the request body, as browsers do when submitting the values entered on a \ufb01ll-in form. (Recall that GET re- quests have no request body.) How is this data presented to the server? While there are many choices, there is no question that the SOA community has rapidly converged on JSON (pronounced \u201cJAY-sahn\u201d), or JavaScript Object Notation, as the common interchange for- mat. JSON is so called because its syntax resembles, though is not identical to, the syntax of a JavaScript object literal\u2014a set of unordered key/value pairs, like a Ruby hash, Python In JSON, each key (or \u201cslot,\u201d as we\u2019ll learn in Chapter 6) must be dict, or Java HashMap. a double-quoted string, and its value may be a simple type (string, numeric, true, false, null), a linear array each of whose elements can be any of these, or another object whose slots are constrained to these same types. The JSON web site4 shows some simple exam- ples, and because of JSON\u2019s popularity as the default data format for SOA, virtually every modern language comes with libraries to both generate and parse JSON. Whitespace (spaces, Like JavaScript itself, the JSON standard is stewarded by ECMA, the European Computer Manufacturers Association. 90 CHAPTER 3. MICROSERVICES, APIS, REST https://gist.github.com/c428409170320d32ba60934e1d29b190 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # set endpoint for TMDb API export BASE = https :// api . themoviedb . org / v3 # set our API key for use in other calls export KEY = \" my API key here \" # Search for a movie by keywords curl \" $BASE / search / movie ? api_key = $KEY & query = Batman + Returns \" # For better legibility , pipe the output to json_pp : curl \" $BASE / search / movie ? api_key = $KEY & query = Batman + Returns \" | json_pp # Start a new guest session curl \" $BASE / authentication / guest_session / new \" | json_pp # capture the guest session ID from Curl 's output : export SESSION = e 9 1 f 0 7 c c a 8 1 6 6 b 7 b 1 e 7 0 7 d 8 a 8 2 6 e 8 a 3 8 # Create a file containing echo '{ \" rating \": 6.5 } ' > myrating . json # Use Curl to POST a movie rating request using the file 's contents : curl -X POST -H \" Content - Type : application / json \" -d @myrating . json \\ \" $BASE / movie /364/ rating ? api_key = $KEY & guest_session_id = $SESSION \" the JSON object for rating a movie : Figure 3.7: Try the lines of this shell script one at a time, replacing the value of KEY with your TMDb API key. After line 8 you\u2019ll have to visually parse out the correct movie ID from the JSON response, and after line 10 the correct guest session ID to use in line 12. If your system doesn\u2019t have json_pp installed, you can omit it. tabs, newlines) is optional in JSON, and most servers return whitespace-free JSON. Unix command-line tools such as json_pp and browser extensions like JSONView restore spac- ing and indentation to make JSON more readable. Note that calls that require sending JSON data may also allow (or require) sending some parameter values encoded in the URI; you must check the API documentation for details. some APIs For example, HTTP headers are sometimes used to pass very specialized types of pa- require you to add the HTTP header rameters. that will be accompanied by a Content-Type: application/json to a request JSON payload, while others don\u2019t. Finally, nearly all APIs require authorization\u2014the client must prove it has the right to make each API call. While authorization schemes vary, the most common is to include a client-speci\ufb01c API key with each request. API keys are usually requested manually and may be free or paid (TMDb\u2019s are free), and the service may impose limits such as the number of calls made per day. Depending on the API, the key may be sent as an argument in the URI (as with TMDb), as the value of an HTTP Authorization: header, or either. Putting this all together, Figure 3.7 shows the use of the curl tool to do a sequence of RESTful API requests\u2014all but the last are GETs\u2014exercising the TMDb API. Note in particular that the API key is a required URI parameter for every request, and verify against the API documentation the correct format for the object in line 14 representing the desired rating you wish to submit for a movie. What if an error occurs? Recall from Section 3.2 that every HTTP response begins with a 3-digit status code; these are catalogued and maintained6 by the World Wide Web Consor- tium. Services use status codes to indicate various types of errors: \u2022 2xx codes indicate success. For example, code 200 (\u201cOK\u201d) would be the usual success status for a GET, whereas code 201 (\u201cCreated\u201d) would be more typical for a POST that creates a new resource. \u2022 3xx codes indicate the client must take further action to complete the request\u2014that is, a redirect. Perhaps the requested resource has moved to a different URI, which would be speci\ufb01ed in the response body. Chapter 12 explains why HTTPS makes it OK to transmit what amounts to a password as part of a Web request. Scopes let a caller specify, at token request time, what kinds of operations it wants to do using the API. The GitHub API5 supports a variety of scopes; simpler APIs such as TMDb\u2019s usually don\u2019t support scopes. 3.6. RESTFUL URIS, API CALLS, AND JSON 91 \u2022 4xx codes indicate that the service encountered an application error processing the re- quest. 400 means the request was malformed, but other codes for well-formed requests include 401 (Unauthorized), 402 (Payment required), and others. \u2022 5xx codes indicate a problem with the service infrastructure itself\u2014an error that pre- vented the remote call from even completing, such as the server encountering an inter- nal error so severe that it is too broken to even explain what went wrong. In case of an error (any status other than 2xx), the response body usually contains a message explaining what went wrong. Depending on the API, the response body will consist of either just this string, or more commonly, a JSON object with a single string-valued slot named message or error or something similar. Summary \u2022 One way to apply the RESTful design stance to HTTP routes is to use the HTTP method (GET, POST, and so on) and the URI path to encode the resource and oper- ation to be performed. For GET requests, optional arguments can be encoded in the URI itself (?param1=value1&...&paramN=valueN). For POST or PUT requests, typically used for form submission, both the form\u2019s \ufb01eld values and additional op- tional arguments can be transmitted as part of the request body. \u2022 Requests to a service may require that the client present some credentials to prove it is authorized to use the service. Many schemes exist, but among the simplest is HTTP Basic Authentication, in which a username and password (possibly collected from the user by the browser\u2019s UI) are embedded in the HTTP headers. The use of Secure HTTP (HTTPS), which we describe in Chapter 12, ensures that eavesdrop- pers cannot read this sensitive data. \u2022 JSON (JavaScript Object Notation), based on JavaScript language syntax, has be- come the most popular data format for sending data to and receiving data from SaaS services. \u2022 No one \u201clegislated\u201d that REST would defeat dozens of competing proposals to be- come the preferred way to design services. Instead, REST became widely adopted because it was simple to understand and implement, well matched to the underlying Web protocols, and unencumbered by intellectual property restrictions. 92 CHAPTER 3. MICROSERVICES, APIS, REST Elaboration: Why did REST win? The road to today\u2019s microservices is littered with acronyms of proposed conventions and standards for interoperation that never fully caught on: SOAP, WSDL, UDDI , XML-RPC , DCOM, Jini , and CORBA, to name just a few. Since no single entity controls the Internet and gets to \u201cpick the winner,\u201d a winner usually emerges by rough consensus for practical reasons: it is easy for developers to understand and use (especially to get simple common cases working quickly), it is well matched to the underlying technology stack (in this case the Web\u2019s protocols and standards, especially HTTP), and it is not subject to a costly or restrictive developer license. REST meets these criteria\u2014it is simple enough to be described in this one textbook section\u2014but it achieves the goal of being a good match for HTTP by cheating: it is a retrospective codi\ufb01cation of the practices that were observed to work well as the Web went through its growing pains, such as an emphasis on stateless design, a scheme for constructing URIs that plays nicely with Web caching (Chapter 12), no reliance on an implicit notion of a session, and so on. Most of the competing protocols ignored one or more of these lessons and so failed to hit the \u201csweet spot.\u201d Self-Check 3.6.1. You try an API call on TMDb and the status code of the response is 400. Assuming TMDb adheres to the of\ufb01cial W3C semantics of the status codes, which of the following could be the reason for the error: (a) your request was malformed so could not be attempted; (b) you forgot to include your API key; (c) your request and API key were well-formed, but you are attempting an operation that you\u2019re not authorized to do. (a) is most likely. 401 Unauthorized would be more likely for the other two cases."
    ]
  },
  {
    "id": "sec_0204",
    "title": "3.7 CHIPS: Create and Deploy a Simple SaaS App",
    "pages": [
      104
    ],
    "text_blocks": [
      "CHIPS 3.7: Create and Deploy a Simple SaaS app https://github.com/saasbook/hw-sinatra-saas-hangperson Create and deploy a SaaS app that plays the \u201cHangman\u201d game using Ruby and the simple Sinatra SaaS framework. Design how game actions map to HTTP routes, how game state is represented, how cookies are used to manage that state, and how to detect and prevent cheating (that is, realizing that you cannot trust any HTTP client)."
    ]
  },
  {
    "id": "sec_0205",
    "title": "3.8 Fallacies and Pitfalls",
    "pages": [
      104,
      105
    ],
    "text_blocks": [
      "Fallacy: Splitting a large \u201cmonolithic\u201d service into many microservices de- creases complexity. The complexity of a system\u2019s application logic does not disappear from splitting it or designing it to be service-oriented; the complexity is simply distributed among the microser- vices, and in particular, how the interaction among those microservices is managed. The two main structural patterns for coordination among microservices are orchestration (the com- position layer has a higher level of complexity and holds more of the application\u2019s logic) and choreography (the services interact among themselves without a separate composition 3.8. FALLACIES AND PITFALLS 93 layer). Finally, splitting a large service into microservices requires thinking about module boundaries just as one would in designing a large service in the \ufb01rst place. Fallacy: Publishing my API makes my service RESTful (or makes it a mi- croservice, or SOA-friendly, and so on). A published API just means that external calls are allowed; the API\u2019s understandability and usability will determine whether the API or service is widely adopted, since the API de\ufb01nes the boundary negotiation for what the service will do (expected output) and how the caller will access it (expected input). REST is not the only good way to design an API, but there are certainly many bad ways to design an API, and carefully following REST makes it less likely you\u2019ll accidentally choose one of those ways. Fallacy: I haven\u2019t published an API, so clients cannot call my app. Every publicly-accessible website already has a de facto HTTP API, because URIs can be constructed to interact with the site. Of course, such an \u201caccidental\u201d API will rarely adhere to good design practices; a client wishing to use it might have to (for example) pick apart a returned HTML page to extract the information it wants, a process sometimes called HTML scraping. Nonetheless, if your app is publicly available, it has an API whether you intended it or not. If you do intend for your app to be used programmatically as a service or microservice, you should design and expose an API according to the guidelines in this chapter. Pitfall: Thinking in terms of URIs, user actions, and views instead of thinking in terms of resources. Consider a sequence of steps for a hypothetical e-commerce site: in step 1, a user visits a product page; in step 2, they add a product to a shopping cart; perhaps they repeat steps"
    ]
  },
  {
    "id": "sec_0206",
    "title": "1 and 2 to add multiple products; and in step 3, they pay for the product(s). If you design",
    "pages": [
      105,
      106
    ],
    "text_blocks": [
      "the business logic for such an app from a \"Web-page-centric\" point of view, you might be tempted to simply keep track of which step the user is on (say, as part of the session or by including the step number as a parameter in a URL) and include logic that dispatches to the appropriate internal action for each step. But such a design approach doesn\u2019t force you to think about important questions such as: If the user leaves the site and returns later, how can we ensure their cart contents haven\u2019t changed? If the user abandons the order without paying, at what point do we decide to delete it? If the payment step fails, can we easily direct the user to retry only that step without going through all the previous steps again? In contrast, a RESTful API design approach would begin by asking: What kind of resource is an order, and what operations are available on it? What kind of resource is a product, and what operations are available on it? What can go wrong during each type of operation? How is each kind of resource stored on the server, and under what conditions can it be deleted? How does the client refer to a particular resource that was created earlier, even if the user has been away from the keyboard for a long time? Thoughtful answers to such questions result in a clean service design that is suitable for use both as a standalone (micro)service and as the back end of a browser-based experience. Pitfall: Poor design of API resulting from misunderstanding of the domain or of the customers\u2019 use cases. We noted that the TMDb API call for \u201cget reviews associated with this movie\u201d actually returns the reviews\u2019 contents, not just their IDs. This design makes sense if most requests of 94 CHAPTER 3. MICROSERVICES, APIS, REST this type are likely to inspect the content of most of the reviews. But if the more common use case was (for example) to allow an end user to display details of reviews with particular characteristics such as numerical rating, a leaner API might allow specifying those options to constrain the result. In general, insuf\ufb01cient understanding of how customers will use your API may lead to inef\ufb01cient resource representation internally, but as we will see, the good news is that the internal representation of resources can be changed later as long as the details of that repre- sentation haven\u2019t leaked into the API."
    ]
  },
  {
    "id": "sec_0207",
    "title": "3.9 Concluding Remarks: Continuity From CGI to SOA",
    "pages": [
      106,
      107,
      108
    ],
    "text_blocks": [
      "Because an early use of the Web was to serve static \ufb01les stored in a \ufb01le system, early HTTP servers such as Apache could be con\ufb01gured to expose a subdirectory of the \ufb01le system as a browsable tree of \ufb01les, so early URIs typically mimicked the hierarchical structure of a \ufb01le system. For example, the URI http://www.cs.berkeley.edu/reports/1997/ daedalus.ps very likely referred to the actual \ufb01le daedalus.ps located in subdirectory reports/1997/ somewhere on the computer whose hostname is www.cs.berkeley.edu. In 1993 the Common Gateway Interface or CGI protocol marked the emergence of SaaS. A CGI-capable Web server could interpret certain URIs not as the name of a local \ufb01le, but as a directive to run a program and send its output back to the client. While no conventions were proposed for how to construct such URIs, a common one was to place all such \u201cCGI programs\u201d under a single subdirectory, often called cgi-bin, and use a combination of URI path components and parameters in the query string to \u201cpass arguments\u201d to the program to be run. The CGI program had to emit a complete well-formed HTTP response, including appropriate HTTP response headers and a content payload such as an HTML page. As SaaS became an increasingly common way to deploy Web sites, application server frameworks began to emerge that automatically took care of some of this \u201cplumbing,\u201d such as building an HTTP response or handling common HTTP errors, freeing the application writer to focus only on the content. The rapid rise in popularity of the \u201cmicroservices with RESTful APIs\u201d model has led to a renewed focus on API design and tools to support it. Joshua Bloch\u2019s article How To Design a Good API And Why It Matters (Bloch 2006), and the accompanying technical talk given at Google7, provide a good overview of how to think about API design. Bloch compares API design decisions to language design decisions, which have been debated for decades, and offers a concise operational de\ufb01nition of an API as \u201cthe methods of operation by which com- ponents in a system use one another.\u201d (Another talk8 by the same author provides a wry and opinionated history of APIs since 1950.) Furthermore, since the API is the visible \u201ccontract\u201d with callers of the service, formally documenting the API itself has become increasingly im- portant, along with ensuring that as the service evolves, the API documentation stays current. The OpenAPI (formerly Swagger) tools9 include an API editor for designing APIs with the OpenAPI speci\ufb01cation, a code generator to generate server and client stubs for using an API, and tools to automatically extract and publish documentation with \u201clive\u201d API exercisers from an OpenAPI description. A recent alternative to purely-procedural REST APIs is GraphQL, which is based on describing data structures rather than procedure calls. In a RESTful API, the server decides what operations to expose and what data structures are required to invoke them. In contrast, a GraphQL client de\ufb01nes the data structures it needs, and the same structures are returned from bin is short for binary (executable) almost everywhere in computing, even though later CGI programs were not binary \ufb01les but scripts in languages like Perl or Python. REFERENCES 95 the server. The richness and complexity of GraphQL may not be worthwhile for simpler APIs, but it is an interesting emerging alternative to REST for data-intensive services. Lastly, it is worth remembering that such APIs are really just the latest manifestation of a key factor in the Web\u2019s success: separating the things that change from those that stay the same. TCP/IP, HTTP, and HTML have all gone through several major revisions, but all include ways to detect which version is in use, so a client can tell if it\u2019s talking to an older server (or vice versa) and adjust its behavior accordingly. Today, APIs allow separation of interface from implementation at the level of entire services. Although dealing with multiple protocol and language versions puts an additional burden on browsers and other clients, it has led to a remarkable result: A Web page created in 2019, using a markup language based on 1960s technology, can be retrieved using network protocols developed in 1969 and displayed by a browser \ufb01rst created in 1992. Separating the things that change from those that stay the same is part of the path to creating long-lasting software. A. D. Birrell and B. J. Nelson. Implementing remote procedure calls. ACM Trans. Comput. Syst., 2(1):39\u201359, Feb. 1984. ISSN 0734-2071. doi: 10.1145/2080.357392. URL http: //doi.acm.org/10.1145/2080.357392. In Proc. 21st ACM SIGPLAN J. Bloch. How to design a good api and why it matters. Conference (OOPSLA), pages 506\u2013507, Portland, Oregon, 2006. URL http://portal. acm.org/citation.cfm?id=1176617.1176622. B. Meyer. Object-Oriented Software Construction. Prentice-Hall, 1997. I. Nadareishvili, R. Mitra, M. McLarty, and M. Amundsen. Microservice Architecture. O\u2019Reilly Media, Sebastopol, CA, 2016. Notes 1http://www.catb.org/~esr/jargon/html/M/magic-cookie.html 2https://gist.github.com/chitchcock/1281611 3https://developers.themoviedb.org 4https://json.org/example.html 5https://docs.github.com/en/developers/apps/scopes-for-oauth-apps 6https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html 7https://www.youtube.com/watch?v=heh4OeB9A-c 8https://www.youtube.com/watch?v=ege-kub1qtk 9https://swagger.io/tools 10http://info.cern.ch 11http://w3.org Tim Berners-Lee, a computer scientist at CERN10, led the development of HTTP and HTML in 1990. All open Web standards, including these, are now stewarded by the nonpro\ufb01t vendor-neutral World Wide Web Consortium (W3C)11. 4 SaaS Framework: Rails as a ModelViewController Framework Alan Perlis (1922\u20131990) was the \ufb01rst recipient of the Turing Award (1966), conferred for his in\ufb02uence on advanced programming languages and compilers. In"
    ]
  },
  {
    "id": "sec_0208",
    "title": "1958 he helped design",
    "pages": [
      108
    ],
    "text_blocks": [
      "ALGOL, which has in\ufb02uenced virtually every imperative programming language including C and Java. To avoid FORTRAN\u2019s syntactic and semantic problems, ALGOL was the \ufb01rst language described in terms of a formal grammar, the Backus-Naur form (named for Turing Award winner John Backus and his colleague Peter Naur). In programming, everything we do is a special case of something more general\u2014and often we know it too quickly. . ."
    ]
  },
  {
    "id": "sec_0209",
    "title": "4.1 The Model\u2013View\u2013Controller (MVC) Architecture .",
    "pages": [
      108
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0210",
    "title": "4.2 Rails Models: Databases and Active Record .",
    "pages": [
      108
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0211",
    "title": "4.3 CHIPS: ActiveRecord Basics",
    "pages": [
      108
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0212",
    "title": "4.4 Routes, Controllers, and Views",
    "pages": [
      108
    ],
    "text_blocks": [
      ". . . . . ."
    ]
  },
  {
    "id": "sec_0213",
    "title": "4.5 CHIPS: Rails Routes .",
    "pages": [
      108
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0214",
    "title": "4.6 Forms .",
    "pages": [
      108
    ],
    "text_blocks": [
      ". . . . . . . ."
    ]
  },
  {
    "id": "sec_0215",
    "title": "4.7 CHIPS: Hangperson on Rails .",
    "pages": [
      108
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0216",
    "title": "4.8 Debugging: When Things Go Wrong .",
    "pages": [
      108
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0217",
    "title": "4.9 CHIPS: Hello Rails .",
    "pages": [
      108
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0218",
    "title": "4.10 Fallacies and Pitfalls .",
    "pages": [
      108
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0219",
    "title": "4.11 Concluding Remarks: Rails as a Service Framework .",
    "pages": [
      108,
      109,
      110
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \u2014Alan Perlis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 . 100 . 105 . 105 . 110 . 111 . 116 . 116 . 120 . 120 . 121 97 Prerequisites and Concepts Like most modern SaaS frameworks, Rails captures two decades\u2019 worth of developer experience by encapsulating common operations (so SaaS app writers don\u2019t have to handle them) and by exposing proven SaaS design patterns (so SaaS app writers can easily apply them). Prerequisites: You should be familiar with basic operations in SQL (the Structured Query Language), such as INSERT, SELECT...WHERE, UPDATE, and DELETE. An excellent free resource for learning SQL basics is the Khan Academy SQL tutorial1: the sections on SQL Basics, More Advanced SQL Queries, and Modifying Databases with SQL will sufce for this chapter. Concepts: \u2022 A Rails app is best viewed as a collection of RESTful resources on which the app provides an interface for performing various operations. \u2022 Well designed software systems reect organization at multiple levels of granularity, often based on identiable architectural patterns. A Rails app implements the server side of the client-server pattern introduced in Chapter 3. The structure of the app itself introduces another architectural pattern called ModelViewController, or MVC. \u2022 In the Rails implementation of MVC, modelsthe main data managed by the app are stored in a relational database using the Active Record design pattern. Views, which allow users to see and interact with the data, use the Template View pattern to create HTML or JSON representations of the app\u2019s resources (models). Controllers, which mediate interaction between the views and models, follow Representational State Transfer (REST), in which each controller action describes a single self- contained operation on one of the app\u2019s resources. \u2022 Rails\u2019 mechanisms can be used to build both SaaS apps designed for use from a browser and microservices adapted to work in a service-oriented architecture. \u2022 Rails uses Ruby\u2019s features of metaprogramming and introspection to provide con- vention over con\ufb01guration: if you follow certain conventions regarding the nam- ing of classes, variables, and les, nearly all manual conguration can be avoided, making apps smaller and simpler to understand and maintain. \u2022 Unlike debugging PaaS, debugging SaaS requires understanding the different places something could go wrong during the ow of a SaaS request, and how to surface that information to the developer. 98 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK"
    ]
  },
  {
    "id": "sec_0220",
    "title": "4.1 The ModelViewController (MVC) Architecture",
    "pages": [
      110,
      111,
      112
    ],
    "text_blocks": [
      "All well-written and nontrivially-sized applications re\ufb02ect some macroarchitectural organi- zation, that is, they can be thought of as ensembles of large communicating subsystems. Put another way, while we established in Section 3.1 that SaaS apps follow a client\u2013server archi- tecture, we have said nothing about the organization of the server application. In this section we use an architectural pattern called Model-View-Controller (usually shortened to MVC) to do so. An application organized according to MVC consists of three main types of code. Models are concerned with the data manipulated by the application: how to store it, how to operate on it, and how to change it. An MVC app typically has a model for each type of entity ma- nipulated by the app. For example, for a movie database app in which moviegoers (users) can write reviews, the entities would include (at least) movies, moviegoers, and reviews. (To- wards the end of this chapter, a CHIPS exercise will introduce such an app, RottenPotatoes, which we\u2019ll use throughout the rest of the book.) Views are presented to the user and contain information about the models with which users can interact. The views serve as the interface between the system\u2019s users and its data; for example, in RottenPotatoes you can list movies and add new movies by clicking on links or buttons in the views. There is only one kind of model in RottenPotatoes, but it is associated with a variety of views: one view lists all the movies, another view shows the details of a particular movie, and yet other views appear when creating new movies or editing existing ones. Finally, controllers mediate the interaction in both directions: when a user interacts with a view (for example, by clicking something on a Web page or submitting a form), a speci\ufb01c controller action corresponding to that user activity is invoked. Each controller corresponds to one model, and in Rails, each controller action is handled by a particular Ruby method within that controller. The controller can ask the model to retrieve or modify information; depending on the results of doing this, the controller decides what view will be presented next to the user, and supplies that view with any necessary information. Since RottenPotatoes has only one model (Movies), it also has only one controller, the Movies controller. The actions de\ufb01ned in that controller can handle each type of user interaction with any Movie view (clicking on links or buttons, for example) and contain the necessary logic to obtain Model data to render any of the Movie views. Given that SaaS apps have always been view-centric and have always relied on a persis- tence tier, Rails\u2019 choice of MVC as the underlying architecture might seem like an obvious \ufb01t, but there are caveats. Technically, while a View in the MVC sense means \u201cany logic needed to display something,\u201d a Rails view is really a special case called a template or template view, in which static markup interspersed with variable substitution is processed by a generic logic engine. As Figure 4.1 shows, other patterns are possible for view-oriented frameworks. Model-View-Presenter can be thought of as an embellishment of Model-View-Controller, and Model-View-ViewModel provides two-way interaction between the model and the view so that updates to the view automatically occur in the model, in contrast to MVC in which the focus is on re\ufb02ecting model changes in the view. As a software engineer who is experienced at learning new stacks, you will be in a position to learn by asking other experienced colleagues to give you a \u201cdeveloper\u2019s-eye view\u201d of a new language or framework. If you asked an experienced Rails developer to concisely describe the framework to you, you might get something like the following description. 4.1. THE MODEL\u2013VIEW\u2013CONTROLLER (MVC) ARCHITECTURE 99 Figure 4.1: Three architectural patterns for Web apps that include a GUI. In all cases, the Model contains the main business logic. Model-View-Controller (MVC, right), which Rails implements, makes sense when the views (HTML pages) are passive and all user interaction (clicks, form \ufb01eld events, and so on) must be handled by the controller, which in Rails is part of the server code. But modern Rails apps are no longer \u201cpure\u201d MVC: Model-View-Presenter (MVP, center) concentrates all UI-handling for the view in a Presenter module, which more accurately describes rich Web apps in which client-side JavaScript explicitly handles many UI interactions. Model-View-ViewModel (MVVM, left), also called Model-View-Binder and originally invented for developing GUI applications with Microsoft .NET, goes a step further and rei\ufb01es two-way binding between a view and its data: UI interactions on the view automatically affect the data, and updating the data automatically updates the view. JavaScript frameworks such as Angular and Vue largely follow this pattern. \u2022 Rails is designed to support apps that follow the Model\u2013View\u2013Controller pattern. The framework provides powerful base classes from which your app\u2019s models, views, and controllers inherit. \u2022 Each Rails model is a resource type whose instances are rows in a particular table of a relational database. The database-stored models are exposed to Ruby code via a design pattern known as Active Record (Section 4.2), in which each type of model behaves more or less like a data structure whose \ufb01elds (attributes) are semi-automatically seri- alized to the database. \u2022 A Rails app is best viewed as a collection of RESTful resources, each consisting of its own model, controller, and set of views. Resources may have relationships to each other; for example, in a movie-reviewing application, we might say that Movie and Review are each a type of resource, that a single Movie can have many Reviews, and that any given Review belongs to some Movie. Foreign keys in the database tables (Section 5.4) capture such relationships. \u2022 Because Rails is a server-side framework, it needs a way to map an HTTP route (Sec- tion 3.2) to code in the app that performs the correct action. The Rails routing sub- system (Section 4.4) provides a \ufb02exible way to map routes to Ruby methods located in Rails controllers. You can de\ufb01ne routes any way you like, but if you choose to use some \u201cstandard\u201d routes based on RESTful conventions, most of the routing is set up for you automatically. \u2022 Rails was originally designed for apps whose client was a Web browser, so its view sub- system is designed around generating HTML pages. But it is equally easy to generate 100 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK (for example) JSON data structures to return via a RESTful API. \u2022 Rails embodies strong opinions about many mechanical details of your app\u2019s imple- mentation, such as how classes and \ufb01les are named and where they are stored. If you follow these opinions, Rails uses convention over con\ufb01guration to save you a lot of work. For example, rather than explicitly specifying a mapping from a model class to the name of its corresponding database table or the \ufb01lenames and class names of its associated controller and view \ufb01les, Rails infers all these things based on simple naming rules. Summary \u2022 The Model-View-Controller or MVC design pattern is one of a family of patterns for structuring interactive applications. MVC distinguishes models that implement business logic, views that present information to the user and allow the user to in- teract with the app, and controllers that mediate the interaction between views and models. \u2022 In MVC SaaS apps such as those built using Rails, every user action that can be per- formed on a web page\u2014clicking a link or button, submitting a \ufb01ll-in form, or using drag-and-drop\u2014is eventually handled by some controller action, which will consult the model(s) as needed to obtain information and generate a view in response. \u2022 Rails heavily uses convention over con\ufb01guration: if you agree to follow certain rules about naming \ufb01les and classes, you are freed from having to specify explicitly which \ufb01le or class supports the functionality of each model, view, or controller. Self-Check 4.1.1. In which element of the MVC model is the app code \u201cfarthest away\u201d from the user? Brie\ufb02y explain your answer. The model code is \u201cfarthest away\u201d from the user. Users interact directly with views (which should have little to no code) and code in controllers handles users\u2019 requests for interaction, but model code is invoked only by the controller when needed."
    ]
  },
  {
    "id": "sec_0221",
    "title": "4.2 Rails Models: Databases and Active Record",
    "pages": [
      112
    ],
    "text_blocks": [
      "Every nontrivial application needs to store and manipulate persistent data. For many SaaS applications, the two key requirements may be expressed as follows: 1. The app must be able to store different types of data items, or entities, in which all instances of a particular type of entity share a common set of attributes. For example, in RottenPotatoes, the attributes for a movie entity might include title, release date, MPAA rating, and so on. All movies have the same attributes, though the attribute values are different for each movie. 2. The app must be able to express relationships among different kinds of entities. Return- ing to RottenPotatoes, two other entities might be movie reviews and moviegoers. A movie has many reviews and a moviegoer has many reviews, though any single review is associated with exactly one movie and one moviegoer. Edgar F. \u201cTed\u201d Codd (1923\u20132003) received the"
    ]
  },
  {
    "id": "sec_0222",
    "title": "1981 Turing Award for",
    "pages": [
      112,
      113,
      114,
      115,
      116,
      117
    ],
    "text_blocks": [
      "inventing the relational algebra formalism underlying relational databases. 4.2. RAILS MODELS: DATABASES AND ACTIVE RECORD 101 id 1 2 title Hamilton Casablanca rating PG-13 PG release_date 2020-07-03 1942-11-26 description The groundbreaking American musical. . . Casablanca is a. . . Figure 4.2: A possible RDBMS table for storing movie information. The id column gives each row\u2019s primary key \u2014a permanent and unique identi\ufb01er that is never reused, even if that row is deleted. Most databases can be con\ufb01gured to assign primary keys automatically in various ways; Rails uses the very common convention of assigning integers in increasing order as new rows are created. The above two requirements are so common in business that Relational database man- agement systems (RDBMSs) evolved in the early 1970s as elegant structured-storage systems whose design was based on a formalism for representing such structure and relationships. An RDBMS stores a collection of tables, each of which stores entities with a common set of attributes. One row in the table corresponds to one entity, and the columns in that row correspond to the attribute values for that entity. The movies table for RottenPotatoes would include columns for title, rating, release_date, and description, and the rows of the table look like Figure 4.2. In Rails, data takes the form of a set of resources stored in a relational database. Amaz- ingly, you don\u2019t need to know much about how RDBMSs work to get started with Rails, though understanding their basic operation becomes more important as your apps begin to comprise multiple types of resources with relationships among them. Therefore, the key questions to address in order to understand the role of the database in the Rails Model\u2013View\u2013Controller architecture are as follows: 1. What is the correspondence between how an instance of a resource (say, the informa- tion about a speci\ufb01c movie) is stored in the database and how it is represented in the programming language used by the framework (in this case, Ruby)? 2. What software mechanisms mediate between those two representations, and what pro- gramming abstractions do those mechanisms expose? In our case, the answer is that Rails implements the Active Record architectural pat- tern. In this pattern, a Rails model is a class backed by a speci\ufb01c table of an RDBMS. An instance of the class (for example, the entry for a single movie) corresponds to a single row in that table. The model has built-in behaviors that directly operate on the database: \u2022 Create a new row in the table (representing a new object), \u2022 Read an existing row into a single object instance, \u2022 Update an existing row with new attribute values from a modi\ufb01ed object instance, \u2022 Delete a row (destroying the object\u2019s data forever). This collection of four commands is often abbreviated CRUD. The combination of table name and id uniquely identi\ufb01es a model instance stored in the database, and as we will see, is therefore how objects are usually referenced in RESTful routes in Rails apps. Unlike some other SaaS frameworks in which the abstraction exposed to the developer is the connection to the database itself, Active Record gives each model the knowledge of how to create, read, update, and delete instances of itself in the database (CRUD). That is, all of the logic for \u201ctalking to\u201d the database, and (critically) for how to marshal and unmarshal Active Record refers to the pattern itself; ActiveRecord refers to the code module that instantiates the pattern in the Rails framework. 102 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK (serialize or deserialize) attributes, is implicitly included in each model. Rails accomplishes this by providing a class ActiveRecord::Base from which your models will inherit. In OOP terms, Create and Read are class methods, since they de\ufb01ne actions on the collection of model instances as a whole, whereas Update and Delete are instance methods, since they de\ufb01ne actions on a speci\ufb01c model instance. Remarkably, as Figure 4.3 shows, simply de\ufb01ning a class that descends from Rails\u2019 ActiveRecord::Base class provides all the necessary machinery to \u201cconnect\u201d the model to the database. Speci\ufb01cally: \u2022 The directory app/models is expected to contain one Ruby code \ufb01le per model. The \ufb01le name is determined by converting the model\u2019s class name to lower_snake_case, so the \ufb01le app/models/movie.rb is expected to de\ufb01ne the class Movie. \u2022 The database table name is determined by converting the model\u2019s class name instances of model to lower_snake_case and pluralizing it. AccountCode would be stored in table account_codes. For example, YAML (\u201cYAML Ain\u2019t Markup Language\u201d) can express hierarchical data structures comparable to those covered by JSON. \u2022 The attributes of the model, and their types (string, integer, date, and so on), are inferred from the names and types of the table\u2019s columns. \u2022 The model automatically has class (static) methods new and create, among others, that expect a hash of arguments whose keys match those attribute names and whose values supply the attribute values for a movie instance to be created in memory (new) or immediately persisted in the database (create). In fact, just about the only thing this class de\ufb01nition doesn\u2019t do is create the actual table in the database; we must do that ourselves, by \ufb01rst telling Rails how to actually connect to the database, and then providing instructions for creating the necessary model table(s) in our schema. When a new Rails app is created from scratch, the automatically-generated \ufb01le config/database.yml speci\ufb01es how to connect to the database. By default, Rails apps are initially con\ufb01gured to use SQLite, a lightweight single-user RDBMS, but later we will see how to modify this \ufb01le to connect to \u201cindustrial strength\u201d database servers such as Postgres or MySQL. To create the actual table, we create and apply a migration\u2014a Ruby script describing a set of changes to make to the database schema. Why use migrations rather than directly issuing SQL statements such as create table? There are many reasons, but as we will see, Rails de\ufb01nes three environments in which your app can run: development (when you\u2019re coding), production (the live app containing real customer data), and test (used only when running automated tests). Each environment gets its own completely separate database, but of course, the schemata of all three databases need to be kept in sync. It is much less error-prone to write a single migration script and run it against each environment than to ensure you issue the exact same set of SQL commands three times. To create and apply a migration, you \ufb01rst give the command rails generate migration name, where name is some descriptive name for what the migration does; in this example, we might say rails generate migration create_movies_table. Rails will create a Ruby \ufb01le whose name consists of your migration\u2019s name plus a times- tamp. The \ufb01le de\ufb01nes a migration class with your speci\ufb01ed name that descends from ActiveRecord::Migration and has an empty change instance method. You \ufb01ll in that method with the desired schema changes, save the \ufb01le, and then run the command 4.2. RAILS MODELS: DATABASES AND ACTIVE RECORD 103 https://gist.github.com/0fa79aaa81f0ec133a38de8bf9a2150a 1 2 class Movie < ActiveRecord :: Base end def change create_table ' movies ' do | t | class CreateMovies < ActiveRecord :: Migration https://gist.github.com/9170d0cedfc2c7897f28feb134190ce2 1 2 3 4 5 6 7 8 9 10 11 12 13 t . string ' title ' t . string ' rating ' t . text ' description ' t . datetime ' release_date ' # Add fields that let Rails automatically keep track # of when movies are added or modified : t . timestamps end end end {: title = > ' When Harry Met Sally ' , : rating = > 'R ' , # Seed the RottenPotatoes DB with some movies . more_movies = [ : release_date = > '21 - Jul -1989 '} , {: title = > ' Aladdin ' , : rating = > 'G ' , : release_date = > '25 - Nov -1992 '} , https://gist.github.com/aa0a53221b45188929d2c91dc98424a0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 : release_date = > '10 - Aug -2011 '} , : release_date = > '12 - Jun -1981 '} {: title = > ' The Help ' , : rating = > 'PG -13 ' , more_movies . each do | movie | Movie . create ( movie ) end ] {: title = > ' Raiders of the Lost Ark ' , : rating = > ' PG ' , Figure 4.3: Top: A minimal valid ActiveRecord class. Middle: A migration makes changes to the database schema, in this case to create the table that the model expects to \ufb01nd. Bottom: the create class method creates a movie instance in the database from a hash whose keys are the table\u2019s column names. 104 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK rake db:migrate, which invokes the Rails utility tool rake to run the task db:migrate. (rake -T shows a list of available tasks with brief descriptions.) Notice that you don\u2019t have to specify the \ufb01lename of which migration to apply: Rails tracks which migrations have been applied to which environments\u2019 databases. The db:migrate task examines the environment variable RAILS_ENV to determine which en- vironment to apply the migration in, defaulting to development if not set, and then applies all pending migrations not yet applied to that database. Running rake db:migrate multi- ple times is harmless, since migrations already applied will simply be ignored on subsequent runs. The next CHIPS exercise gives you some hands-on practice with how the Rails imple- mentation of Active Record actually works. Summary \u2022 The Rails implementation of ActiveRecord uses convention over con\ufb01guration to infer database table names from the names of model classes, and to infer the names and types of the columns (attributes) associated with a given kind of model. \u2022 Basic Active Record support focuses on the CRUD actions: create, read, update, delete. \u2022 Every model instance saved in the database receives an ID number unique within its table called the primary key, whose attribute name (and therefore column name in the table) is id and which is never \u201crecycled\u201d (even if the corresponding row is deleted). The combination of table name and id uniquely identi\ufb01es a model instance stored in the database, and is therefore how objects are usually referenced in RESTful routes. \u2022 Changing the database schema, including creating the tables needed by your mod- els, is accomplished by creating and running migrations. Rails itself tracks which migrations have been applied in each of the three environments\u2014development, pro- duction, and testing. Elaboration: Overriding convention over con\ufb01guration Convention over con\ufb01guration is great, but there are times you may need to override it. For example, if you\u2019re trying to integrate your Rails app with a non-Rails legacy app, the database tables may already have names that don\u2019t match the names of your models, or you may want friendlier attribute names than those given by taking the names of the table\u2019s columns. All of these defaults can be overridden at the expense of more code, as the ActiveRecord documentation describes. In this book we choose to reap the bene\ufb01ts of conciseness by sticking to the conventions. Self-Check 4.2.1. What do you think would happen if you tried to run the code in the top and bottom parts of Figure 4.3 without having created and run the migration in the middle part of the \ufb01gure? An error would occur upon the \ufb01rst call to any method in the Movie class that requires accessing the database, since it would be unable to \ufb01nd any table named movies. 4.3. CHIPS: ACTIVERECORD BASICS 105 Helper method movies_path movies_path new_movie_path edit_movie_path(m) movie_path(m) movie_path(m) movie_path(m) URI returned /movies /movies /movies/new /movies/1/edit /movies/1 /movies/1 /movies/1 RESTful route and action GET /movies POST /movies GET /movies/new GET /movies/:id/edit GET /movies/:id PUT /movies/:id DELETE /movies/:id index create new edit show update destroy Figure 4.4: The set of RESTful routes generated by the single line resources \u2019movies\u2019 in a Rails app\u2019s routes.rb \ufb01le. You can display a table like this by running the command rake routes in the root directory of your app."
    ]
  },
  {
    "id": "sec_0223",
    "title": "4.3 CHIPS: ActiveRecord Basics",
    "pages": [
      117
    ],
    "text_blocks": [
      "CHIPS 4.3: ActiveRecord Basics https://github.com/saasbook/hw-activerecord-practice Write ActiveRecord operations to manipulate a database of \ufb01ctional customers, as a way of learning ActiveRecord\u2019s basic features before using it in Rails apps."
    ]
  },
  {
    "id": "sec_0224",
    "title": "4.4 Routes, Controllers, and Views",
    "pages": [
      117,
      118,
      119,
      120
    ],
    "text_blocks": [
      "We\u2019ve now been introduced to how Rails implements the models in MVC, but when users interact with a SaaS app via a browser, they\u2019re interacting with views and invoking controller actions, either by typing URIs into their browser (resulting in an HTTP GET) or interacting with page elements that generate GET requests (links) or POST requests (forms). In this section we take a tour through views and controllers to understand the lifecycle of such a request when it hits a Rails app. We \ufb01rst explore the controllers and views corresponding to REST actions that only read model data: Index and Read. In Section 4.6 we consider controllers and views corresponding to actions the modify data: Create, Update, and Delete. As we know from Section 3.2, our app will receive a request in the form of an HTTP route. The \ufb01rst step in a Rails app is therefore to determine which code in the app should be invoked to handle that route. Rails provides a \ufb02exible routing subsystem that maps routes to speci\ufb01c Ruby methods in each controller using the contents of the \ufb01le config/routes.rb. You can de\ufb01ne any routes you like there, but if your app is RESTful (centered around CRUD requests against a set of resources) and you abide by convention over con\ufb01guration, the single line resources \u2019movies\u2019 (in our case) de\ufb01nes a complete set of RESTful routes for a model (resource) called Movies, as Figure 4.4 shows. Although \u201cRESTful route and action\u201d column in the table should look familiar from Sec- tion 3.2, we raise four questions about it: 1. The four CRUD actions plus the Index action should only need \ufb01ve routes; why are there seven? 2. Most Web browsers can only generate HTTP GET and POST requests; how can a browser generate a route such as Update, which uses HTTP PUT? resources :movies would also work: like table and column names in migrations, resource names in the routes \ufb01le may be either strings or symbols. Actually, most browsers also implement HEAD, which requests metadata about a resource, but we needn\u2019t worry about that here. 106 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK 3. Some routes such as show include a variable (parameter) as part of the route URI, and others such as create must also provide the attribute values of the entity to be created as parameters. How are these parameters and their values made available to the controller action? 4. Finally, what are the \u201croute helper methods\u201d referred to in the table and why are they needed? The \ufb01rst question\u2014why seven routes rather than \ufb01ve\u2014is easy but subtle. We preview the answer here and will return to it when we discuss HTML forms in Section 4.6. A RESTful request to create a movie would typically include information about the movie itself\u2014title, rating, and so on. But in a user-facing app, we need a way to collect that information in- teractively from the user, usually by displaying a form the user can \ufb01ll in. Submitting the form would clearly correspond to the create action, but what route describes displaying the form? The Rails approach is to de\ufb01ne a default RESTful route new that displays whatever is necessary to allow collecting information from the user in preparation for a create request. A similar argument applies to update, which requires a way to show the user an editable ver- sion of the existing resource so the user can make changes; this latter action is called edit in rails, and typically displays a form pre-populated with the existing resource\u2019s attribute values. Turning to the second question, for historical reasons Web browsers only implement GET (for following a link) and POST (for submitting forms). To compensate, Rails\u2019 routing mech- anism lets browsers use POST for requests that normally would require PUT or DELETE. Rails annotates the Web forms associated with such requests so that when the request is submit- ted, Rails internally changes the HTTP method \u201cseen\u201d by the controller to PUT or DELETE as appropriate. The result is that the Rails programmer can operate under the assumption that PUT and DELETE are actually supported, even though browsers don\u2019t implement them. As a result, the same set of routes can handle either requests coming from a browser (that is, from a human being) or requests coming from another service in a SOA. What about routes that include a parameter in the URI, such as show, or those that must also include parameters corresponding to attribute values for a resource, such as create? As we will see in the code examples in this section (and you will have an opportunity to experi- ment with in the next CHIPS), the Rails routing subsystem prepares a hash called params[] that is made available to the controller. With the above routes.rb \ufb01le as part of an app, typ- ing rake routes at the command line (within the root directory of your app) will list all the routes implied by that \ufb01le, showing wildcard parameters with the colon notation introduced in Section 3.5. For example, the route for show will appear as GET /movies/:id, which tells us that params[:id] will hold the actual ID value parsed from the URI. Further, as we will see, Rails provides an easy way to generate an HTML form in which the form \ufb01elds are named in such a way that another value in params, in this example params[:movie], is itself a hash of key/value pairs corresponding to a Movie object\u2019s attributes and their desired values. This mechanism sounds more confusing than it actually is, as the code examples below will show. Finally, what are \u201croute helpers\u201d? By convention over con\ufb01guration, the route URIs will match the resource name, but as we\u2019ll see later, you can override this behavior. You might, for example, decide later that you\u2019d rather have your routes built around film rather than movie. But then any view in your app that references the old-style movie route URIs\u2014for example, the page that serves the form allowing users to edit a movie\u2019s info\u2014would have to be changed to film. This is the problem that route helpers solve: they decouple what the 4.4. ROUTES, CONTROLLERS, AND VIEWS 107 route does (create, read, and so on) from the actual route URI. As the table suggests, the Ruby method movies_path will return the correct URI for the route \u201clist all movies,\u201d even if the URI text itself is changed later (or for \u201ccreate new movie,\u201d if POST is used as the route\u2019s verb). Similarly movie_path(23) will always return the correct URI for \u201cshow movie ID 23\u201d (or update or destroy movie ID 23, depending on which HTTP verb is used). The route helpers also make explicit what the route is supposed to do, improving readability. What about the controller methods (called controller actions in Rails) that handle each RESTful operation? Once again, convention over con\ufb01guration comes to the res- cue. By default, the routes created by resources \u2019movies\u2019 will expect to \ufb01nd a \ufb01le controllers/movies_controller.rb that de\ufb01nes a class MoviesController (which descends from the Rails-provided ApplicationController, just as models descend from ActiveRecord::Base). That class will be expected to de\ufb01ne instance methods index, new, create, show (read), edit, update, and destroy, corresponding to the RESTful actions of Figure 4.4. Each of these controller actions generally follows a similar pattern: 1. Collect the information accompanying the RESTful request: parameters, resource IDs in the URI, and so on 2. Determine what ActiveRecord operations are necessary to ful\ufb01ll the request. For exam- ple, the Index action might just require retrieving a list of all movies from the Movies table; the Update action might require identifying a resource ID from the URI, parsing the contents of a form, and using the form data to update the movie with the given ID (primary key); and so on. 3. Set instance variables for any information that will need to be displayed in the view, such as information retrieved from the database. 4. Render a view that will be returned as the result of the overall request. That leaves only the last bullet point: how does each controller action select a view, and how is the information generated in the controller action made available to that view? You should no longer be surprised to hear that part of the answer lies once again in convention over con\ufb01guration. Controller actions do not return a value; instead, when a con- troller action \ufb01nishes executing, by default Rails will identify and render a view named app/ views/model-name/action.html.erb, for example app/views/movies/show.html.erb for the show action in MoviesController. The Rails module that choreographs how views are handled is ActionView::Base. This view consists of HTML interspersed with Erb (Embedded Ruby) tags that allow the results of evaluating Ruby code to be interpolated into the HTML view. In particular, any instance variables set in the controller method become available in the view. Rereading the previous sentence should give you pause. Why would instance variables of one class (MoviesController) be accessible to an object of a completely different class (ActionView::Base), violating all OOP orthodoxy? The simple reason is that the design- ers of Rails thought it would make coding easier. What actually happens is that Rails cre- ates an instance of ActionView::Base to handle rendering the view, and then uses Ruby\u2019s metaprogramming facilities to \u201ccopy\u201d all of the controller\u2019s instance variables into that new object! Warning! Counterintuitively, if there is no controller action matching a route but there is a view, Rails will render that view. See Fallacies & Pitfalls for details. 108 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK \u2022 The controller code is in class MoviesController, de\ufb01ned in app/controllers/ the model\u2019s class name is pluralized to movies_controller.rb (note that inherit from your form the controller \ufb01le name.) Your app\u2019s controllers all app\u2019s app/controllers/ ApplicationController application_controller.rb), which contains controller behaviors common to multiple controllers (we will meet some in Chapter 5) and in turn inherits from ActionController::Base. controller root (in \u2022 Each instance method of the controller is named using lower_snake_case according to the RESTful action it handles, plus the two \u201cpseudo-actions\u201d new and edit. \u2022 The view template for each action is named the same as the controller method itself, so the view for Showing a movie would be in app/views/movies/show.html.erb. Strangely but conveniently, each view has access to the instance variables set in the controller action that caused the view to be rendered. There\u2019s one last thing to notice about these views: they aren\u2019t legal HTML! In particular, they lack an HTML DOCTYPE, the <html> element, and its children <head> and <body>. In fact, we need to put those elements in views/application.html.erb, which \u201cwraps\u201d all views by default, as Figure 4.6 shows. Sanitization To help thwart cross-site scripting and similar attacks described in Chapter 12, Erb sanitizes2 Ruby output before interpolating it into the HTML. Summary: \u2022 Rails provides various helper methods that take advantage of the RESTful route URIs, including link_to for generating HTML links whose URIs refer to RESTful actions. \u2022 Convention over con\ufb01guration is used to determine the \ufb01le names for controllers and views corresponding to a given model. If the RESTful route helpers are used, as in resources :movies, convention over con\ufb01guration also maps RESTful action names to controller action (method) names. \u2022 Although the most common way to \ufb01nish a controller action is to render the view corresponding to that action, for some actions such as create it\u2019s more helpful to send the user back to a different view. Using redirect_to replaces the default view rendering with a redirection to a different action. \u2022 Although redirection triggers the browser to start a brand-new HTTP request, the flash can be used to save a small amount of information that will be made available to that new request, for example, to display useful information to the user regarding the redirect. Elaboration: Metaprogramming in Rails So far we have seen two examples of how Rails combines convention over con\ufb01guration with on-the-\ufb02y code generation. In ActiveRecord, getter and setter instance methods for ActiveRecord models are de\ufb01ned at runtime by inspecting the database schema. In the rout- ing subsystem, route helpers such as new_movie_path are de\ufb01ned at runtime based on the"
    ]
  },
  {
    "id": "sec_0225",
    "title": "contents of config/routes.rb. (While controller methods automatically knowing how to",
    "pages": [
      120,
      121,
      122
    ],
    "text_blocks": [
      "locate the default view to render is also an example of convention over con\ufb01guration, there\u2019s no new code that needs to be generated at runtime to support it.) 4.4. ROUTES, CONTROLLERS, AND VIEWS 109 # This file is app / controllers / m ov ies _co nt r oll er . rb class M ovi e sController < A p p l i c a t i o n C o n t r o l l e r def index @movies = Movie . all https://gist.github.com/f27917e167b6e7953fd4ee646f1313be 1 2 3 4 5 6 7 8 9 10 id = params [: id ] @movie = Movie . find ( id ) end def show end end # retrieve movie ID from URI route # look up movie by unique ID <%= link_to ' Add Movie ' , new_movie_path , : class = > ' btn btn - primary ' % > < div id = \" movies \" > < div class = \" row \" > <h1 > All Movies </ h1 > < div class = \" col -8 \" > Movie Title </ div > < div class = \" col -2 \" > Rating </ div > < div class = \" col -2 \" > Release Date </ div > https://gist.github.com/ef90ccfad3b471295ba0286434413121 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 </ div > <% - @movies . each do | movie | % > </ div > <% end % > < div class = \" row \" > </ div > </ ul > <h1 > Details about <%= @movie . title % > </ h1 > < div id = \" metadata \" > < ul id = \" details \" > https://gist.github.com/e497afd7a26\ufb006d79c80f0dc3cbed65b 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 <h2 > Description : </ h2 > <p > <%= @movie . description % > </p > < div id = \" description \" > </ div > </ div > <li > Rating : <%= @movie . rating % > </ li > <li > Released on : <%= @movie . release_date . strftime ( '% F ') % > </ li > <%= link_to ' Edit this movie ' , edit_movie_path ( @movie ) , : class = > ' btn ' % > <%= link_to ' Back to movie list ' , movies_path , : class = > ' btn btn - primary ' % > Figure 4.5: The controller code and template markup to support the RESTful actions index and show. The index method just retrieves all movies, while the show method examines params[], which has been prepared by the routing subsystem, to retrieve the desired movie\u2019s id \ufb01eld from the route URI. Controller instance variables de\ufb01ned in each action are available in the corresponding view. The row and col-n classes applied to the div elements in the movie list take advantage of the Bootstrap framework\u2019s 12-column grid system to display a tabular view. < div class = \" col -8 \" > <%= link_to movie . title , movie_path ( movie ) % > </ div > < div class = \" col -2 \" > <%= movie . rating % > </ div > < div class = \" col -2 \" > <%= movie . release_date . strftime ( '% F ') % > </ div > 110 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK <! DOCTYPE html > < html > https://gist.github.com/edf3975ee0a14025bf25739a719b6347 1 2 3 4 5 < head > bootstrap . min . css \" > < title > RottenPotatoes ! </ title > < link rel = \" stylesheet \" href = \" https :// getbootstrap . com / docs /4.0/ dist / css / 6 7 8 9 10 11 12 13 14 15 16 17 18 19 <%= j a v a s c r i p t _ i n c l u d e _ t a g : application % > <%= csrf_meta_tags % > </ head > < body > < div class = \" container \" > <% - if flash [: notice ] % > < div class = \" alert alert - info text - center \" > <%= flash [: notice ]% > </ div > <% - elsif flash [: alert ] % > < div class = \" alert alert - danger text - center \" > <%= flash [: alert ]% > </ div > <% end % > <%= yield % > </ div > </ body > </ html > Figure 4.6: Our generic application template \u201cwraps\u201d every view. Rails provides a generic version of this \ufb01le when you start a new app; in our version, we have added a line to use the Bootstrap CSS framework, and annotated the HTML elements in our individual views to use Bootstrap\u2019s classes. Section 4.6 explains the meaning and purpose of lines 11\u201315. Self-Check 4.4.1. The route helpers for Show and Update take an argument, as in movie_path(@movie), but the route helpers for New and Create (new_movie_path and movies_path) do not. Why the difference? The argument to the Show and Update route helpers is either an existing Movie instance or the ID (primary key) of an existing instance. Show and Update operate on existing movies, so they take an argument to identify which movie to operate on. New and Create operate on not-yet-existing movies. Self-Check 4.4.2. Why doesn\u2019t the route helper movies_path for the Index action take an argument? (Hint: The reason is slightly different than the answer to the previous question!) The Index action just shows a list of all the movies, so no argument is needed to distinguish which movie to operate on."
    ]
  },
  {
    "id": "sec_0226",
    "title": "4.5 CHIPS: Rails Routes",
    "pages": [
      122,
      123
    ],
    "text_blocks": [
      "CHIPS 4.5: Rails Routes https://github.com/saasbook/rails-routing-practice Specify routes in a Rails app and identify how parts of a route map to parameters and other data made available to Rails controllers, using the Rails routing practice app at http://rails-routing-practice.saasbook.info. 4.6. FORMS 111 https://gist.github.com/7af0ab0fe2db36f7723998e9d56\ufb00637 1 2 3 4 5 6 <h2 > Create New Movie </ h2 > <%= form_tag movies_path , : method = > : post , : class = > ' form ' do % > <%= label : movie , : title , ' Title ' , : class = > ' form - control ' % > <%= text_field : movie , : title , : class = > ' form - control ' % > <%= label : movie , : rating , ' Rating ' , : class = > ' form - control ' % > <%= select : movie , : rating , [ 'G ' , ' PG ' , 'PG -13 ' , 'R ' , 'NC -17 '] , : class = > ' form - control ' % > 7 8 9 10 <%= label : movie , : release_date , ' Released On ' % > <%= date_select : movie , : release_date , : class = > ' form - control ' % > <%= submit_tag ' Save Changes ' % > <% end % > Figure 4.7: The form the user sees for creating and adding a new movie to RottenPotatoes. Rather than coding HTML form elements directly, we use Rails\u2019 form helpers, which will name the form \ufb01elds in such a way that the controller can parse them easily to populate a new Movie object. The :class=>name option sets the HTML class(es) of an element; we apply Bootstrap\u2019s classes form and form-control to the form and its elements respectively."
    ]
  },
  {
    "id": "sec_0227",
    "title": "4.6 Forms",
    "pages": [
      123,
      124,
      125,
      126,
      127,
      128
    ],
    "text_blocks": [
      "So far we\u2019ve looked at views that display data to the user, but not views that collect data from the user. The simplest mechanism for doing so consist of HTML forms. To create them, we address the following steps: 1. How do we display a \ufb01ll-in form to the user? 2. How is the information \ufb01lled in by the user made available to the controller action, so that it can be used in a create or update ActiveRecord call? The \ufb01rst step is straightforward: As Section 4.4 described, Rails by default de\ufb01nes a new action (and route) for this purpose. Following the pattern seen so far and illustrated in Figure 4.4: \u2022 The route GET /movies/new names the action, and the route helper new_movie_path will generate the URI portion of the route; \u2022 The action will be handled by the method MoviesController#new; \u2022 By default, the controller action will end by rendering a view app/views/movies/ new.html.erb. It seems logical to assume that that view should contain an HTML form that submits to the create RESTful route. When that HTML form is submitted, a controller action will need to parse the form data and do something with it\u2014in our case, use it to populate the attributes of a new Movie object. To do so, the controller action must have knowledge about how the HTML form \ufb01elds are named, so that it can extract data from each \ufb01eld and use that data to populate attributes of an instance of the Movie model. Such a scenario\u2014a form whose \ufb01elds represent attributes of an ActiveRecord model object\u2014is so common that Rails streamlines the process by using form tag helper methods3. These helpers are Ruby methods that generate HTML form tags whose names follow particular conventions that make them easy to parse by the controller action. Figure 4.7 shows an example; watch Screencast 4.6.1 for a description of what\u2019s going on in it. 112 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK Screencast 4.6.1: Views with \ufb01ll-in forms. http://youtu.be/2tvI8tPyy9c The form_tag method for generating a form requires a route to which the form should be submitted\u2014that is, a URI and an HTTP verb. We use the RESTful URI helper and HTTP POST method to generate a route to the create action, as rake routes reminds us. Speci\ufb01cally, the form_tag helper takes two arguments. The \ufb01rst is the URI to which the form should submit; in this case, the RESTful route helper (Figure 4.4) is used to generate that URI. The second argument is a hash of optional arguments, one of which may be the HTTP method that should be used to submit the form. POST is the default so we didn\u2019t need to specify it here; GET is acceptable if submitting the form doesn\u2019t change any application data. If you specify PUT, PATCH, or DELETE, as Section 4.4 described, the browser will still use POST to submit the form but Rails will \u201cautomagically\u201d make it appear that the form was submitted using the method you speci\ufb01ed. Not all input \ufb01eld types are supported by the form tag helpers (in this case, the date \ufb01elds aren\u2019t supported), and in some cases you need to generate forms whose \ufb01elds don\u2019t necessarily correspond to the attributes of some ActiveRecord object. The Rails guide on form tag helpers4 and Rails API documentation5 describe the various form tag helper options in detail. Note that just as with the RESTful route helpers (Figure 4.4), you are not required to use form tag helpers, but as we\u2019ll see next, given the common \ufb02ow of submitting a form related to a model and using the form\u2019s information to create or update a model instance, using them actually saves you work and results in less code in your views. To recap where we are, we created the new controller method that will render a view giving the user a form to \ufb01ll in, placed that view in new.html.erb, and arranged to have the form submitted to the create controller method. All that remains is to have the create controller action parse the form information and use it to create a new movie in the database. Recall from the examples in Section 4.2 that the Movie.create call takes a hash of attribute names and values to create a new movie instance in the database (in contrast to Movie.new, which creates an instance of the Ruby class Movie but does not save it in the database). The reason to use form tag helpers now becomes clear: if you look at the HTML page generated by the new.html.erb template, you\u2019ll see that the form \ufb01elds created by the form tag helpers have names of the form \u2019movie[title]\u2019, \u2019movie[rating]\u2019, and so on. As a result, the value of params[\u2019movie\u2019] is a hash of movie attribute names and values, which we can pass along directly using Movie.create!(params[\u2019movie\u2019]). It is worth reading the above paragraph again: the form tag helpers give names to the form \ufb01elds that result in params[\u2019movie\u2019] containing exactly what needs to be passed to ActiveRecord\u2019s create or update_attributes methods. This streamlining is not only a great example of convention over con\ufb01guration, but also an example of how a framework can simplify the \u201cmechanical work\u201d of making the models, views, and controllers in a SaaS app work smoothly together. We must, however, attend to an important detail before our controller action will work. \u201cMass assignment\u201d of a whole set of attributes, as occurs when we pass the hash params[\u2019movie\u2019] to an ActiveRecord call, is a mechanism that could be used by a ma- licious attacker to set model attributes that shouldn\u2019t be changeable by regular users6. As Figure 4.8 shows, Rails requires us to declare in the controller which elements of params are required to be present (if any) for a given action, and critically, which elements are permitted Or params[:movie], since params is another example of a Rails hash-like object whose keys can be referenced as either strings or symbols. 4.6. FORMS 113 class M ovi e sController < A p p l i c a t i o n C o n t r o l l e r def create https://gist.github.com/2156d1ba12108d25463fb9d8563b13d5 1 2 3 4 5 6 7 8 end end params . require (: movie ) params [: movie ]. permit (: title ,: rating ,: release_date ) # shortcut : params . require (: movie ) . permit (: title ,: rating ,: release_date ) # rest of code ... Figure 4.8: Rails\u2019 \u201cstrong parameters\u201d mechanism requires us to declare which values from params are required to be present and which values are permitted to be used to update the model. require and permit operate on the params hash or any of its sub-hashes, as the Rails documentation8 explains. In Section 5.1 we introduce before-\ufb01lters, which can be used to DRY out this code rather than repeating it in any controller action that might try to create or modify a model instance. to be assigned to model attributes. This mechanism follows the principle of least privilege in computer security, a topic to which we return in Section 12.9 when discussing how to defend customer data. The screencast shows how mass-assignment works in practice, and also shows the helpful technique of using debug breakpoints to provide a detailed look \u201cunder the hood\u201d during execution of a controller action. Screencast 4.6.2: The Create action. http://youtu.be/SJ2wnTxPXC4 Inside the create controller action, we placed a debug breakpoint to inspect what\u2019s going on, and used a subset of the debugger commands in Figure 4.10 to inspect the params hash. In particular, because our form\u2019s \ufb01eld names all looked like movie[...], params[\u2019movie\u2019] is itself a hash with the various movie \ufb01elds, ready for assigning to a new Movie object. At this point, the controller action has used params[\u2019movies\u2019] to create a new movie record, ostensibly successfully. But what should we display when the create action completes? Strict convention over con\ufb01guration suggests a view app/views/movies/ create.html.erb that simply con\ufb01rms the movie was created, and provides a link or other mechanism to go back to the list of movies, but it seems clumsy to have a separate view just to do that. One alternative would be to streamline the user experience by just sending the user back to the newly-updated list of all movies (Index action), but arrange to display a con\ufb01rmation message somewhere on the page that the movie was added successfully. Since we already have an action and view to handle Index, the DRY way to proceed is to have the controller action issue an HTTP redirect, telling the Web browser to start an entirely new request for the Index action. But this approach presents a small problem. Since HTTP is stateless, when this new Index request is routed by Rails to our controller\u2019s index method, all of the variables associated with the prior create request are gone. That is a problem if we want to display a friendly message at the top of the movie list, since at the moment of the index call, we no longer know the name or ID of the previously-created movie. To address this common scenario, the flash[] is a special object available in a controller that quacks like a hash, but whose contents persist only from the current request to the next. In other words, if we put something into flash[] during the current controller action, we can access it during the very next action, but not during any subsequent actions. The entire hash is persisted, but by convention, flash[:notice] is used for informational messages 114 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK class MoviesController < A p p l i c a t i o n C o n t r o l l e r # ' index ' and ' show ' methods from Section 4.4 omitted for clarity def new if ( @movie = Movie . create ( movie_params ) ) redirect_to movies_path , : notice = > \" #{ @movie . title } created . \" flash [: alert ] = \" Movie #{ @movie . title } could not be created : \" + @movie . errors . full_messages . join ( \" ,\" ) end else render ' new ' end def edit @movie = Movie . new end def update end def create @movie = Movie . find params [: id ] https://gist.github.com/579c3846f57f8133cd6e1953ef259c74 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 end private def movie_params end def destroy render ' edit ' else end end end @movie = Movie . find params [: id ] if ( @movie . u pda te _at tri but es ( movie_params ) ) redirect_to movie_path ( @movie ) , : notice = > \" #{ @movie . title } updated . \" flash [: alert ] = \" #{ @movie . title } could not be updated : \" + @movie . errors . full_messages . join ( \" ,\" ) @movie = Movie . find ( params [: id ]) @movie . destroy redirect_to movies_path , : notice = > \" #{ @movie . title } deleted . \" params . require (: movie ) params [: movie ]. permit (: title ,: rating ,: release_date ) Figure 4.9: Putting together the main ideas of this section, here is a simple controller that handles the CRUD actions for the Movie model. The create and update actions make use of the fact that Rails form helpers arrange to populate params[\u2019movies\u2019] with a hash of attribute values ready to pass to ActiveRecord, but the private movie_params method tells Rails which params are required and which are \u201csafe\u201d to pass along to ActiveRecord. and flash[:alert] is used for messages about things going wrong. Using the \ufb02ash in conjunction with a redirect is so common that the Rails redirect_to method provides a special syntax for it, as Figure 4.9 shows. In fact, the \ufb02ash is just a special case of the more general session[], whose contents persist \u201cforever\u201d across requests from the same browser (until you clear it out manually). But which view(s) should attempt to display the contents of the \ufb02ash? In this example, we chose to redirect the user to the movies listing, so perhaps we should add code to the Index view to display the message. But in the future we might decide to redirect the user someplace else instead, and in any case, the idea of displaying a con\ufb01rmation message or warning message is so common that it makes sense to factor it out rather than putting it into one speci\ufb01c view. Recall that app/views/layouts/application.html.erb is the template used to \u201cwrap\u201d all views by default. This is a good candidate for displaying \ufb02ash messages since any pending messages will be displayed no matter what view is rendered, as lines 11\u201315 of Figure 4.6 show. 4.6. FORMS Summary 115 \u2022 When creating a form, you specify the controller action that will receive the form submission by passing form_tag the appropriate RESTful URI and HTTP method (as displayed by rake routes). It\u2019s convenient, but not required, to use RESTful URI helpers like movies_path and edit_movie_path rather than creating the URIs manually. \u2022 When the form is submitted, the controller action can inspect params[], whose keys are the form \ufb01eld names and whose values are the user-supplied contents of the \ufb01elds. If you use Rails form helpers, the \ufb01eld names are chosen such that params[:model] is a hash whose keys and values are the user-supplied values for an instance of model. \u2022 When creating or updating a model object, for user friendliness it\u2019s common to simply redirect_to a view such as index, rather than rendering a dedicated view. \u2022 When \ufb01nishing a controller action using a redirect, flash[:notice] or flash[:alert] can be set to a message that will persist until the next request. It\u2019s conventional to modify the application layout to display such messages, so they get displayed no matter where the redirect points. Elaboration: How does form submission using PUT work? What exactly happens when you specify :method=>:put in the options to form_tag? Rails actually arranges to insert a \u201chidden \ufb01eld\u201d in your form whose value serves as a cue to the routing and dispatching system that the form \u201cshould have been\u201d submitted via HTTP PUT rather than POST. The dispatching system then modi\ufb01es the HTTP request object seen by the routing system to make it appear that PUT was used, and removes the hidden form \ufb01eld from the actual form contents the controller will see. At that point, the Rails routing subsystem can do its job and route the request as if PUT had been used. This scheme may seem convoluted, but it allows the same set of routes and actions to be used to handle both user-generated requests (from a browser) and programmatic RESTful requests made to an API in a service- oriented architecture. Self-Check 4.6.1. Why does the form for creating a new movie submit to the create method rather than the new method? Creating a new record requires two interactions. The \ufb01rst one, new, loads the form. The second one, create, causes the actual creation of the new record based on values in the \ufb01lled-in form. Self-Check 4.6.2. Why must every controller action either render a view or perform a redi- rect? HTTP is a request-reply protocol, so every action must generate a reply. One kind of reply is a view (Web page) but another kind is a redirect, which instructs the browser to issue a new request to a different URI. Self-Check 4.6.3. Why does it make no sense to have both a render and a redirect (or two renders, or two redirects) along the same code path in a controller action? 116 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK Each request needs exactly one reply. Render and redirect are two different ways to reply to a request. In line 2 of Figure 4.7, what would be the effect of changing Self-Check 4.6.4. :method=>:post to :method=>:get and why? The form submission would result in listing all movies rather than creating a new movie. The reason is that a route requires both a URI and a method: The movies_path helper with the GET method would route to the index action, whereas the movies_path helper with the POST method routes to the create action. Self-Check 4.6.5. Given that submitting the form shown in Figure 4.7 will create a new movie, why is the view called new.html.erb rather than create.html.erb? A RESTful route and its view should name the resource being requested. In this case, the resource requested when the user loads this form is the form itself, that is, the ability to create a new movie; hence new is an appropriate name for this resource. The resource requested when the user submits the form, named by the route speci\ufb01ed for form submission on line 3 of the \ufb01gure, is the actual creation of the new movie."
    ]
  },
  {
    "id": "sec_0228",
    "title": "4.7 CHIPS: Hangperson on Rails",
    "pages": [
      128
    ],
    "text_blocks": [
      "CHIPS 4.7: Hangperson on Rails https://github.com/saasbook/hw-rails-hangperson You\u2019re already familiar with the Hangperson game logic and how the Sinatra framework supports the SaaS version of the app. In this assignment, we give you the complete code for a Rails version of the same app, using the unmodi\ufb01ed game logic, so you can readily understand the differences between how Rails and Sinatra support SaaS apps."
    ]
  },
  {
    "id": "sec_0229",
    "title": "4.8 Debugging: When Things Go Wrong",
    "pages": [
      128,
      129,
      130,
      131,
      132
    ],
    "text_blocks": [
      "Debugging is an annoying but invaluable skill. The amazing sophistication of today\u2019s soft- ware stacks makes it possible to be highly productive, but with so many \u201cmoving parts,\u201d it also means that things inevitably go wrong, especially when learning new languages and tools. Errors might happen because you mistyped something, because of a change in your environment or con\ufb01guration, or any number of other reasons. The best way to debug, of course, is to stop a bug in its tracks and \ufb01x it before it manifests. Two fundamental suggestions can help. First, use good tools, including a text editor that supports automatic indentation and syntax highlighting. Syntax errors such as incomplete block structure, missing quotation marks, and so on become easy to catch. If your editor isn\u2019t so equipped, you can either write your code on stone tablets, or switch to a more productive modern editor. Second, use good colleagues! Many, many students taught by your authors report that they saved huge amounts of time by always pair programming (Section 2.2), because their partner caught a \u201csilly\u201d bug before it became a work stopper. If you\u2019re not pairing but you\u2019re in an \u201copen seating\u201d con\ufb01guration, or have instant messaging enabled using a tool such as Slack, put the message out there. Try explaining your code line by line to a colleague, or if Test-driven development (Chapter 8) requires the same skills as debugging but can be much more ef\ufb01cient at preventing bugs before they are hard to track down, and leaves you with better-designed code besides. Rubber duck debugging comes from an anecdote in the book The Pragmatic Programmer: From Journeyman to Master (Hunt and Thomas 1999) in which programmers would debug their code by forcing themselves to explain it to a rubber duck they carried around. An amusing perspective on the perils of blind \u201cshotgun problem solving\u201d is the Jargon File\u2019s hacker koan \u201cTom Knight and the Lisp Machine.\u201d9 4.8. DEBUGGING: WHEN THINGS GO WRONG 117 no colleague is available, to a pet or even an inanimate object. The act of trying to explain in detail may lead you to discover the \ufb02aw in your own reasoning. But neither good tools nor good colleagues can substitute for your own thinking and debugging skills\u2014after all, it\u2019s your code! Debugging usually involves a gradient of activities you can think of as a rising TIDE: 1. Trace the source of the error as closely as possible by really examining the error mes- sage(s) and log \ufb01le(s) closely. 2. Instrument the code near the error, such as by inserting statements to print intermediate values of variables, to see where things go off the rails (so to speak). 3. Debug interactively using the facilities provided in your language or framework, such as the byebug gem for Ruby, so you can inspect and modify application state around the bug. 4. Explore question boards such as StackOver\ufb02ow for similar bugs, and if all else fails, post a question there and ask for help. We consider each of these in turn. Trace. If the bug causes your app to crash or report an error message, take the time to really read the error message. Ruby\u2019s error messages can look disconcertingly long, but a long error message is your friend because it gives the backtrace showing not only the method where the error occurred, but also its caller, its caller\u2019s caller, and so on. Don\u2019t throw up your hands when you see a long error message; use the information to understand both the proximate cause of the error (the problem that \u201cstopped the show\u201d) and the possible paths towards the root cause of the error. What is the last line of your code implicated in the backtrace? What happened before then? This step can be challenging if the bug occurs in code that you blindly cut-and-pasted with no understanding of how it works or what assumptions it makes. For example, a particularly common proximate cause of Ruby errors is Undefined method \u2019foobar\u2019 for nil:NilClass. (NilClass is a special class whose only in- stance is the constant nil.) This error occurs when some computation fails and returns nil instead of the object you expected, but you forgot to check for this error and subsequently tried to call a method on what you assumed was a valid object. If the computation occurred in another method \u201cupstream,\u201d the backtrace can help you \ufb01gure out where. In SaaS apps, this confusion can be compounded if the failed computation happens in the controller action but the invalid object is referenced in the view, as in this example: https://gist.github.com/ca1c2cb80a75a77a2d64adc1e059bb71 1 2 3 4 5 6 7 8 @movie = Movie . where (: id = > params [: id ]) # what if this movie not in DB ? # BUG : we should check @movie for validity here ! # later , in the view - this will fail since @movie is nil <h1 > <%= # in controller action : def show @movie . title % > </ h1 > end If you\u2019re not sure you even understand the error message, use a search engine to look up key words or key phrases in the error message. You can also search sites like StackOver- \ufb02ow10, which specialize in helping out developers and allow you to vote for the most helpful answers to particular questions so that they eventually percolate to the top of the answer list. 118 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK n[ext] s[tep] f[inish] ps expr execute next line steps into blocks or methods \ufb01nish current method call and return print and evaluate expr, which can be anything that\u2019s in scope within the current stack frame, and can be used to set variables that are in scope, as in eval x=5 go up the call stack, to caller\u2019s stack frame go down the call stack, to callee\u2019s stack frame display where you are in the call stack up down where b[reak] \ufb01le:num set a breakpoint at line num of \ufb01le (current \ufb01le if \ufb01le: omitted) b method c[ontinue] q[uit] set a breakpoint when method called continue execution until next breakpoint quit program printf debugging is an old name for this technique, from the C library function that prints a string on the terminal. Figure 4.10: Command summary of the interactive Ruby debugger, byebug. Lastly, don\u2019t forget that the log \ufb01le development.log (or production.log in the pro- duction environment, or test.log during a testing run) contains information such as what speci\ufb01c HTTP request was received, what controller action was invoked, whether the action succeeded or failed or redirected, what database queries if any were performed, and so on. With so many moving parts, there is a lot of \u201cinvisible\u201d machinery that gets invoked before your controller code is even reached, and problems that happen there can be hard to \ufb01nd. Instrument. Instrumentation consists of extra statements you insert to record values of important variables at various points during program execution. There are various places you can instrument a Rails SaaS app: \u2022 Display a detailed description of an object in a view. For example, try inserting <%= debug(@movie)%> or <%= @movie.inspect%> in any view to insert the result of the corresponding Ruby expression into the view itself. \u2022 \u201cStop the show\u201d inside a controller method by raising an exception whose for example, message is a representation of the value you want raise params.inspect to see the detailed value of the params hash inside a controller method. Rails will display the exception message as the Web page resulting from the request. to inspect, \u2022 Use Rails.logger.debug( message) in a model or controller to emit message to the log. Debug interactively. The byebug gem is already installed via the default Rails Gem\ufb01le. To use the debugger in a Rails app, insert the statement byebug at the point in your code where you want to stop the program. When you hit that statement, the terminal window where you started the server will give you a debugger prompt. Explore question boards. Many bugs are not unique to a speci\ufb01c app but have happened to others in the past. Before you think about posting a question to a board such as StackOver- \ufb02ow, remember that it can take hours or days to get a response (if you get one), so 15 minutes spent carefully searching previous posts could save you a lot of time. If that approach fails and you decide to post a question, remember that everyone else on StackOver\ufb02ow is as busy as you, so write your question in a way that makes it easy for a knowledgeable person to \ufb01nd and answer. Choose your keywords speci\ufb01cally and carefully: 4.8. DEBUGGING: WHEN THINGS GO WRONG 119 rails is extremely common, but the conjunction rails controller redirect narrows the topic down signi\ufb01cantly. In the question post itself, be as speci\ufb01c as possible about what went wrong, what your environment is, and how to reproduce the problem. The ideal question post will express as concisely and speci\ufb01cally as possible (a) what your code is supposed to do, (b) the result you expected, (c) the result you actually observe. Here are some examples and anti-examples: \u2022 Vague: \u201cThe sinatra gem doesn\u2019t work on my system.\u201d There\u2019s not enough infor- mation here for anyone to help you. \u2022 Better, but annoying: \u201cThe sinatra gem doesn\u2019t work on my system. Attached is the 85-line error message.\u201d Other developers are just as busy as you and probably won\u2019t take the time to extract relevant facts from a long trace. \u2022 Best: Look at the actual transcript11 of this question on StackOver\ufb02ow. At 6:02pm, the developer provided speci\ufb01c information, such as the name and version of their operat- ing system, the speci\ufb01c commands they successfully ran, and the unexpected error that resulted. Other helpful voices chimed in asking for speci\ufb01c additional information, and by 7:10pm, two of the answers had identi\ufb01ed the problem. While it\u2019s impressive that this developer got their answer in just over an hour, it means they also lost an hour of coding time, which is why you should post a question only after you\u2019ve exhausted the other alternatives. Summary \u2022 Use a language-aware editor with syntax highlighting and automatic indentation to help \ufb01nd syntax errors. \u2022 Instrument your app by inserting the output of debug or inspect into views, or by making them the argument of raise, which will cause a runtime exception that will display message as a Web page. \u2022 To debug using the interactive debugger, make sure your app\u2019s Gem\ufb01le includes byebug and place the statement byebug at the point in your code where you want to break. Self-Check 4.8.1. Why can\u2019t you just use print or puts to display messages to help debug your SaaS app? Unlike command-line apps, SaaS apps aren\u2019t attached to a terminal window, so there\u2019s no obvious place for the output of a print statement to go. Self-Check 4.8.2. Which of the debugging methods described in this section are appropriate for collecting instrumentation or diagnostic information once your app is deployed and in production? Only the logger method is appropriate, since the other two methods (\u201cstopping the show\u201d in a controller or inserting diagnostic information into views) would interfere with the usage of real customers if used on a production app. 120 CHAPTER 4. RAILS, A MODEL\u2013VIEW\u2013CONTROLLER FRAMEWORK"
    ]
  },
  {
    "id": "sec_0230",
    "title": "4.9 CHIPS: Hello Rails",
    "pages": [
      132
    ],
    "text_blocks": [
      "CHIPS 4.9: Hello Rails https://github.com/saasbook/hw-hello-rails Build and deploy a simple app based on Rails."
    ]
  },
  {
    "id": "sec_0231",
    "title": "4.10 Fallacies and Pitfalls",
    "pages": [
      132,
      133
    ],
    "text_blocks": [
      "Pitfall: Route with a matching view but no controller action. If you specify a route (say GET /movies) that lacks a corresponding controller action (MoviesController#index in this case) but does have a matching view (app/views/ movies/index.html.erb in this case), Rails will behave as if the controller action exists but has an empty method de\ufb01nition. That is, it will render the view, but any instance variables used in the view will be nil. If the matching view template does not exist, Rails will signal an error when the route is used. This inconsistency is non-intuitive, so be careful when you set up a route that you immediately add both the controller action and the view template, or else add neither. Pitfall: Modifying the database manually rather than using migrations, or managing gems manually rather than using Bundler. Especially if you\u2019ve come from other SaaS frameworks, it may be tempting to use the SQLite command line or a GUI database console to manually add or change database tables or to install libraries. Don\u2019t do it. If you modify the database manually, you\u2019ll have no consistent way to reproduce these steps in the future (for example at deployment time) and no way to roll back the changes in an orderly way. Also, since migrations and Gem\ufb01les are just \ufb01les that become part of your project, you can keep them under version control and see the entire history of your changes. Pitfall: Bulky controller actions or views. Because controller actions are the \ufb01rst place in your app\u2019s code to be called when a user request arrives, it\u2019s remarkably easy for them to slowly absorb logic that really belongs some- where else, such as the model or a service object. Similarly, it\u2019s easy for code to creep into views\u2014most commonly, a view may \ufb01nd itself calling a model method such as Movie.all, rather than having the controller method set up a variable such as @movies=Movie.all and having the view just use @movies. Besides violating MVC, coupling views to models can interfere with caching, which we\u2019ll explore in Chapter 5. The view should focus on display- ing content and facilitating user input, and the controller should focus on mediating between the view and the model and set up any necessary variables to keep code from leaking into the view. Pitfall: Overstuf\ufb01ng the session[] hash. You should minimize what you put in the session[] for two reasons. First, with the de- fault Rails con\ufb01guration, the session is packed into a cookie (Section 3.2), which the HTTP 4.11. CONCLUDING REMARKS: RAILS AS A SERVICE FRAMEWORK 121 speci\ufb01cation limits to 4 KiB in size. Second, and more importantly, bulky sessions are a warning that your app\u2019s actions aren\u2019t very self-contained and therefore probably not REST- ful, and may be dif\ufb01cult to use as part of a Service-Oriented Architecture. Although nothing stops you from assigning arbitrary objects to the session, you should keep just the ids of nec- essary objects in the session and keep the objects themselves in model tables in the database. Pitfall: Adopting a framework without a good reason. Software breeds complexity. The more numerous and complex the libraries on which your app relies, the more you\u2019ll have to learn to write the app properly; the more resource- intensive (thus possibly slower) the app will run; the harder it will be to maintain; and perhaps most importantly, the more exposure surface it will have for being attacked. Use the simplest framework that will solve most of your problems. The answer to the question \u201cShould my app use framework X\u201d should be NO by default, unless you can come up with good technical reasons why it should. Some examples of good reasons: the framework encapsulates a solution to a hard technical problem, as Stripe does for credit card processing; the framework provides low-level machinery to instantiate an ar- chitecture that the app follows closely, as Rails does for Model\u2013View\u2013Controller; or there are technological constraints requiring you to use the framework (\u201call our apps are built on framework X and that\u2019s all we know how to maintain\u201d). Bad reasons include: \u201cIt\u2019s the hot new framework\u201d; \u201cAll the popular apps use it\u201d; \u201cI will be more marketable if I learn this framework, and this app is a good excuse to learn it\u201d. The last one is doubly false: the most sought-after software engineers are those who can learn new frameworks quickly, and at any rate, a new customer-facing app is not an excuse to learn a framework but an artifact that your customers will rely on, and that whoever comes after you will have to maintain (if you\u2019re lucky; otherwise it will just die)."
    ]
  },
  {
    "id": "sec_0232",
    "title": "4.11 Concluding Remarks: Rails as a Service Framework",
    "pages": [
      133,
      134,
      135,
      136
    ],
    "text_blocks": [
      "The introduction to Rails in this chapter may seem to introduce a lot of very general ma- chinery to handle a fairly simple and speci\ufb01c task: implementing a Web-based UI to CRUD actions. However, we will see in Chapter 5 that this solid groundwork will position us to appreciate the more advanced mechanisms that will let you truly DRY out and beautify your Rails apps. For example, adapting your app into an API-based service or microservice is much easier if the app mostly follows the structure of a collection of resources supporting the CRUD actions and perhaps some others. Controller actions such as index and show would need few changes to emit a JSON representation of an object instead of displaying an HTML representation. The new action wouldn\u2019t need to be adapted at all: it\u2019s only there so that the human user can \ufb01ll in the values that will be used for create, so an API wouldn\u2019t need to provide any version of it. Similarly, in an API-based service, create and update could simply return a JSON representation of the created or updated object, or even the created object\u2019s ID, rather than redirecting back to some other view. Thus, as with many tools we will use in this book, the initial learning curve to do a simple task may seem a bit steep, but you will quickly reap the rewards by using this strong foundation to add new functionality and features quickly and concisely. That said, Rails is an opinionated framework, and over the years it has been critiqued for 122 REFERENCES being too large, too complex, and employing too much \u201cmagic\u201d to make things work, such as the trick of how instance variables set by controller actions are available to the view, despite the view and controller not sharing any ancestor class and not really being \u201cinstances\u201d of any- thing in any meaningful way. Over the years, modules have been extracted from Rails, more attention has been given to making controllers API-friendly, and many parts of ActiveRecord have been extracted into separate modules that can be mixed in or used without ActiveRecord and even without Rails. In fact, Rails itself was originally extracted from a standalone app written by the consulting group 37signals. To understand the architecture of a software system is to understand its organizing princi- ples. In Chapter 3 we identi\ufb01ed the client-server pattern and the REST API pattern as domi- nant characteristics of SaaS. In this chapter we identi\ufb01ed Model\u2013View\u2013Controller and Active Record as architectural patterns within the boundary of a software artifact. Such patterns are a powerful way to manage complexity in large software systems; we will have much more to say about them in Chapter 11. For now, we observe that by choosing to build a SaaS app, we have predetermined the use of some patterns and excluded others. By choosing to use Web standards, we have predetermined a client-server system; by choosing cloud computing, we have predetermined the three-tier architecture (which Chapter 12 discusses further) to permit horizontal scaling. Model\u2013View\u2013Controller is not predetermined, but we choose it because it is a good \ufb01t for Web apps that are view-centric and have historically relied on a persis- tence tier, notwithstanding other possible patterns such as those in Figure 4.1. REST is not predetermined, but we choose it because it simpli\ufb01es integration into a Service-Oriented Ar- chitecture and can be readily applied to the CRUD operations, which are so common in MVC apps. Active Record is perhaps more controversial\u2014as we will see in Sections 5.8 and 12.7, its powerful facilities simplify apps considerably, but misusing those facilities can lead to scalability and performance problems that are less likely to occur with simpler persistence models. A good framework should also be closely wedded to the language in which it\u2019s imple- mented: the framework should not only provide a well-de\ufb01ned abstraction for the applica- tion\u2019s architecture, but also use the language\u2019s features to support those abstractions. For example, Rails uses Ruby\u2019s introspection and metaprogramming to provide an elegant imple- mentation of both the Model\u2013View\u2013Controller application architecture and the Active Record design pattern for storing model data. And not all server-side or client-side stacks are appli- cation frameworks: while Node.js provides some low-level abstractions for event-driven programming (about which we will have much more to say in Chapter 6), it provides no abstractions for any particular architectural pattern on which one might want to base an ap- plication. If we were building a SaaS app in 1995, none of the above would have been obvious because practitioners had not accumulated enough examples of successful SaaS apps to \u201cex- tract\u201d successful patterns into frameworks like Rails, software components like Apache, and middleware like Rack. By following the successful footsteps of software architects before us, we can take advantage of their ability to separate the things that change from those that stay the same across many examples of SaaS and provide tools, frameworks, and design princi- ples that support building things this way. As we mentioned earlier, this separation is key to enabling reuse. A. Hunt and D. Thomas. The Pragmatic Programmer: From Journeyman to Master. Addison-Wesley Professional, 1999. ISBN 020161622X. NOTES Notes 123 1https://www.khanacademy.org/computing/computer-programming/sql 2http://en.wikipedia.org/wiki/HTML_sanitization 3https://guides.rubyonrails.org/form_helpers.html 4https://guides.rubyonrails.org/form_helpers.html 5https://apidock.com/rails 6http://homakov.blogspot.com/2012/03/how-to.html 7http://api.rubyonrails.org/classes/ActionController/Parameters.html 8http://api.rubyonrails.org/classes/ActionController/Parameters.html 9http://catb.org/jargon/html/koans.html 10http://stackoverflow.com 11http://stackoverflow.com/questions/2945228/i-see-gem-in-gem-list-but-have-no-such- file-to-load 5 SaaS Framework: Advanced Programming Abstractions for SaaS Kristen Nygaard (left, 1926\u20132002) and Ole-Johan Dahl (right, 1931\u20132002) shared the 2001 Turing Award for inventing fundamental OO concepts including objects, classes, and inheritance, and demonstrating them in Simula, the ancestor of every object-oriented language. Programming is understanding. \u2014Kristen Nygaard . . . . ."
    ]
  },
  {
    "id": "sec_0233",
    "title": "5.1 DRYing Out MVC: Partials, Validations and Filters .",
    "pages": [
      136
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0234",
    "title": "5.2 Single Sign-On and Third-Party Authentication .",
    "pages": [
      136
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0235",
    "title": "5.3 CHIPS: Rails Intro .",
    "pages": [
      136
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0236",
    "title": "5.4 Associations and Foreign Keys",
    "pages": [
      136
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0237",
    "title": "5.5 Through-Associations",
    "pages": [
      136
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0238",
    "title": "5.6 RESTful Routes for Associations",
    "pages": [
      136
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0239",
    "title": "5.7 CHIPS: Associations .",
    "pages": [
      136
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0240",
    "title": "5.8 Other Types of Code .",
    "pages": [
      136
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0241",
    "title": "5.9 Fallacies and Pitfalls .",
    "pages": [
      136
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0242",
    "title": "5.10 Concluding Remarks: Languages, Productivity, and Beauty .",
    "pages": [
      136,
      137,
      138
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126 . 131 . 136 . 136 . 140 . 143 . 146 . 147 . 149 . 149 125 Prerequisites and Concepts This chapter covers advanced features of Rails that you can use to make your code more DRY and concise, including how to reuse entire external services such as Twitter to integrate with your apps. Prerequisites: You should be familiar as a Web user with the Log in using. . . single sign-on ow supported by many apps, such as Log in with Google or Log in with GitHub. You should have a basic understanding of join operations in relational databases, and in particular on how tables are joined using foreign keys. We review this material only briey before showing how Rails uses it to provide exible mechanisms for expressing associations among ActiveRecord models in a SaaS app. To brush up on this material, complete the Relational queries in SQL section of the Khan Academy SQL tutorial1. Concepts: \u2022 Rails mechanisms such as controller lters, model lifecycle hooks, and model valida- tions provide a limited form of aspect-oriented programming , which allows code about crosscutting concerns to be centralized in a single place and automatically called when needed. \u2022 Single sign-on (SSO), such as Log in using your GitHub account, lets a user identify themselves to service B by their credentials on service A, without revealing those credentials to service B. Using SSO relieves your app of having to manage passwords and provides some convenience to the user, though at the expense of sacricing some privacy. \u2022 ActiveRecord associations use metaprogramming and reection to map relation- ships among resources in your app, such as belongs to or has many, to queries that mirror those relationships in the app\u2019s database. From ActiveRecord all the way through the routing system, Rails provides comprehensive facilities for managing such relationships. \u2022 ActiveRecord scopes are composable lters you can dene on your model data, enabling DRY reuse of model logic. \u2022 Some important pieces of code in your app don\u2019t really belong in a model, view, or controller. We introduce some other kinds of code that play important roles and suggest where to put it and how to structure it. 126 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS ... other code from index . html . erb here ... --> <! - - < div class = \" row bg - dark text - white \" > https://gist.github.com/be580b19585cd2e77d6ce7fcacfd5508 1 2 3 4 5 6 7 < div class = \" col -6 text - center \" > Title and More Info </ div > < div class = \" col -2 text - center \" > Rating </ div > < div class = \" col -4 text - center \" > Release Date </ div > </ div > <%= render partial : ' movie ' , collection : @movies % > < div class = \" row \" > https://gist.github.com/8e8dba742ccb8de1850456bc498f5f65 1 2 3 4 5 </ div > < div class = \" col -8 \" > <%= link_to movie . title , movie_path ( movie ) % > </ div > < div class = \" col -2 \" > <%= movie . rating % > </ div > < div class = \" col -2 \" > <%= movie . release_date . strftime ( '% F ') % > </ div > As Section 6.7 explains, the partial is also the basic unit of view updating for JavaScript-enabled pages. Figure 5.1: (Top) Main view that uses a partial for each row of the movies table; (Bottom) Partial containing the code to render one row. To leverage convention over con\ufb01guration, we name it _movie.html.erb: Rails uses the \ufb01lename (without the underscore) to set a local variable (movie) to each item of the @movies collection in turn."
    ]
  },
  {
    "id": "sec_0243",
    "title": "5.1 DRYing Out MVC: Partials, Validations and Filters",
    "pages": [
      138,
      139,
      140,
      141,
      142,
      143
    ],
    "text_blocks": [
      "One of the core tenets of Rails is DRY\u2014Don\u2019t Repeat Yourself. In this section we introduce three mechanisms Rails provides to help you DRY out your code: model validations, view partials, and controller \ufb01lters. We start with views. A partial is Rails\u2019 name for a reusable chunk of a view. When similar content must appear in different views, putting that content in a partial and \u201cincluding\u201d it in the separate \ufb01les helps DRY out repetition. Our simple app already presents one opportunity: the Index (list all movies) view includes a chunk of HTML that is repeated for each movie in the list. We can factor out that code into a partial, and include it by reference, as Figure 5.1 shows. Partials rely heavily on convention over con\ufb01guration. Their names must begin with an underscore (we used _movie.html.erb) which is absent from the code that references the partial. A partial may be in a different directory than the view that uses it, in which case a path such as \u2019layouts/footer\u2019 would cause Rails to look for app/views/layouts/ _footer.html.erb. A partial can access all the same instance variables as the view that in- cludes it, but partials that may be used from different views usually do not reference controller instance variables, since those may be set differently (or not at all) by different controller ac- tions. A particularly nice use of a partial is to render a table or other collection in which all elements are the same, as Figure 5.1 demonstrates. Partials are simple and straightforward, but the mechanisms provided by Rails for DRYing out models and controllers are more subtle and sophisticated. It\u2019s common in SaaS apps to want to enforce certain validity constraints on a given type of model object or constraints on when certain actions can be performed. For example, when a new movie is added to RottenPotatoes, we may want to check that the title isn\u2019t blank, that the release year is a valid date, and that the rating is one of the allowed ratings. (You may think there\u2019s no way for the user to specify an invalid rating if they\u2019re choosing it from a dropdown menu, but the request might be constructed by a malicious user or a bot.) With SaaS, you can\u2019t trust anyone: the server must always check its inputs rather than trust them, or risk attack by methods we\u2019ll see in Chapter 12. As another example, perhaps we want to allow any user to add new movies, but only 5.1. DRYING OUT MVC: PARTIALS, VALIDATIONS AND FILTERS 127 https://gist.github.com/89adee067f097c7167e38e2c40a555aa 1 2 class Movie < ActiveRecord :: Base def self . all_ratings ; % w [ G PG PG -13 R NC -17] ; end # strings shortcut : array of 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 validates : title , : presence = > true validates : release_date , : presence = > true validate : r e l e a s e d _ 1 9 3 0 _ o r _ l a t e r # uses custom validator below validates : rating , : inclusion = > {: in = > Movie . all_ratings } , : unless = > : grandfathered ? def r e l e a s e d _ 1 9 3 0 _ o r _ l a t e r errors . add (: release_date , ' must be 1930 or later ') if release_date && release_date < Date . parse ( '1 Jan 1930 ') end @ @ g r a n d f a t h e r e d _ d a t e = Date . parse ( '1 Nov 1968 ') def grandfathered ? release_date && release_date < @ @ g r a n d f a t h e r e d _ d a t e end end # try in console : m = Movie . new (: title = > ' ' , : rating = > ' RG ' , : release_date = > ' 1929 -01 -01 ') # force validation checks to be performed : m . valid ? m . errors [: title ] # = > [\" can 't be blank \"] m . errors [: rating ] # = > [] - validation skipped for grandfathered movies m . errors [: release_date ] # = > [\" must be 1930 or later \"] m . errors . full_messages # = > [\" Title can 't be blank \" , \" Release date # = > false must be 1930 or later \" ] Figure 5.2: Lines 3\u20135 use prede\ufb01ned validation behaviors in ActiveModel::Validations::ClassMethods3. Lines 6\u201315 show how you can create your own validation methods, which receive the object to be validated as an argument and add error messages describing any problems. Note that we \ufb01rst validate the presence of release_date, otherwise the comparisons in lines 10 and 14 could fail if release_date is nil. allow special \u201cadmin\u201d users to delete movies. Both examples involve specifying constraints on entities or actions, and although there might be many places in an app where such con- straints should be considered, the DRY philosophy urges us to centralize them in one place. Rails provides two analogous facilities for doing this: validations for models and \ufb01lters for controllers. Model validations, like migrations, are expressed in a mini-DSL embedded in Ruby, as Figure 5.2 shows. Validation checks are triggered when you call the instance method valid? or when you try to save the model to the database (which calls valid? before doing so). Any validation errors are recorded in the ActiveModel::Errors4 object associated with each model; this object is returned by the instance method errors. As line 7 shows, validations can be conditional: the movie\u2019s rating is validated unless the movie was released before the ratings system went into effect (in the USA, 1 November 1968). We can now understand lines 10\u201312 and 23\u201325 from Figure 4.9 in the last chapter. When creating or updating a movie fails (as indicated by a falsy return value from create or update_attributes), we set flash[:alert] to an error message informed by the con- tents of the movie errors object. We then render (not redirect to) the form that brought us here, with @movie still holding the values the user entered the \ufb01rst time, so the form will be prepopulated with those values. A redirect would start an entirely new request cycle, and @movie would not be preserved. In fact, validations are just a special case of a more general mechanism, Active Record lifecycle callbacks7, which allow you to provide methods that \u201cintercept\u201d a model object at various relevant points in its lifecycle. Figure 5.3 shows what callbacks are available; Figure 5.4 illustrates how to use this mechanism to \u201ccanonicalize\u201d (standardize the format of) Validations store error messages but do not actually raise an error; this is another example of command-query separation, explained at the end of Section 3.5. 128 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS Figure 5.3: The various points at which you can \u201chook into\u201d the lifecycle of an ActiveRecord model object. All ActiveRecord operations that modify the database (update, create, and so on) all eventually call save, so a before_save callback can intercept every change to the database. See this Rails Guide6 for additional details and examples. self . title = self . title . split (/\\ s +/) . map (&: downcase ) . class Movie < ActiveRecord :: Base before_save : capitalize_title def capit alize_title https://gist.github.com/9e961598f5b8f69c2c37dbe5c6c3a917 1 2 3 4 5 6 7 8 9 end # now try in console : m = Movie . create !(: title = > ' STAR map (&: capitalize ) . join ( ' ') end rating = > ' PG ') wars ' , : release_date = > ' 27 -5 -1977 ' , : 10 m . title # = > \" Star Wars \" Figure 5.4: This before_save hook capitalizes each word of a movie title, downcases the rest of the word, and compresses multiple spaces between words to a single space, turning STAR wars into Star Wars. Coincidentally, Rails\u2019 ActiveSupport::Inflector#titleize provides this functionality. 5.1. DRYING OUT MVC: PARTIALS, VALIDATIONS AND FILTERS 129 class A p p l i c a t i o n C o n t r o l l e r < ActionController :: Base before_filter : set_current_user protected # prevents method from being invoked by a route def s et _c u rrent_user https://gist.github.com/d9d5cb0fa2f9c4343b21b18bfda7ccf1 1 2 3 4 5 6 7 8 9 end end # we exploit the fact that the below query may return nil @current_user ||= Moviegoer . where (: id = > session [: user_id ]) redirect_to login_path and return unless @current_user Figure 5.5: If there is a logged-in user, the redirect will not occur, and the controller instance variable @current_user will be available to the action and views. Otherwise, a redirect will occur to login_path, which is assumed to correspond to a route that takes the user to a login page, as Section 5.2 explains. (and is just like && but has lower precedence, thus it parses as ((redirect_to login_path) and (return)) unless...) certain model \ufb01elds before the model is saved. We will see another use of lifecycle callbacks when we discuss the Observer design pattern in Section 11.7 and caching in Section 12.6. Analogous to a validation is a controller \ufb01lter\u2014a method that checks whether certain conditions are true before an action is run, or sets up common conditions that many actions rely on. If the conditions are not ful\ufb01lled, the \ufb01lter can choose to \u201cstop the show\u201d by rendering a view template or redirecting to another action. If the \ufb01lter allows the action to proceed, it will be the action\u2019s responsibility to provide a response, as usual. As an example, an extremely common use of \ufb01lters is to enforce the requirement that a user be logged in before certain actions can be performed. Assume for the mo- ment that we have veri\ufb01ed the identity of some user and stored her primary key (ID) in session[:user_id] to remember the fact that she has logged in. Figure 5.5 shows a \ufb01lter that enforces that a valid user is logged in. In Section 5.2 we will show how to combine this \ufb01lter with the other \u201cmoving parts\u201d involved in dealing with logged-in users. Filters normally apply to all actions in the controller, but as the documentation on \ufb01lters states, :only or :except can be used to restrict a \ufb01lter to guarding only certain actions. You can de\ufb01ne multiple \ufb01lters: they are run in the order in which they are declared. You can also de\ufb01ne after-\ufb01lters, which run after certain actions are completed, and around-\ufb01lters, which contain code to run before and after, as you might do for auditing or timing. 130 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS Summary of DRYing out MVC in Rails: \u2022 Partials allow you to reuse chunks of views across different templates, collecting common view elements in a single place. \u2022 Validations let you collect constraints on a model in a single place. Validations are checked anytime the database is about to be modi\ufb01ed; failing validation is one of the ways that non-dangerous save and update_attributes can fail. \u2022 The errors \ufb01eld of a model, an ActiveRecord::Errors object, records is up to you to take action if it errors that occurred during validation, but model.errors.empty? is not true. \u2022 Controller \ufb01lters let you collect conditions affecting many controller actions in a single place, or set up instance variables used by many actions in a single place, by de\ufb01ning a method that runs before those actions. Elaboration: Aspect-oriented programming Aspect-oriented programming (AOP) is a programming methodology for DRYing out code by separating crosscutting concerns such as model validations and controller \ufb01lters from the main code of the actions to which the concerns apply. In our case, we specify model validations declaratively in one place, rather than invoking them explicitly at each join point in the code where we\u2019d want to perform a validity check. A set of join points is collectively called a pointcut, and the code to be inserted at each join point (such as a validation in our example) is called advice. Rather than supporting fully general AOP, which would allow you to specify arbitrary pointcuts along with what advice applies to each, Rails de\ufb01nes pointcuts for model validations and controller \ufb01lters. A critique of AOP is that the source code can no longer be read in linear order. For example, when a before-\ufb01lter prevents a controller action from proceeding, the problem can be hard to track down, especially for someone unfamiliar with Rails who doesn\u2019t realize the \ufb01lter method isn\u2019t even being called explicitly but is an advice method triggered by a particular join point. A response to the critique is that if AOP is applied sparingly and tastefully, and all developers understand and agree on the pointcuts, it can improve DRYness and modular- ity. Validations and \ufb01lters are the Rails designers\u2019 attempt to identify this bene\ufb01cial middle ground. Self-Check 5.1.1. Why didn\u2019t the Rails designers choose to trigger validation when you \ufb01rst instantiate a movie using Movie.new, rather than waiting until you try to persist the object? As you\u2019re \ufb01lling in the attributes of the new object, it might be in a temporarily invalid state, so triggering validation at that time might make it dif\ufb01cult to manipulate the object. Persisting the object tells Rails \u201cI believe this object is ready to be saved.\u201d In line 5 of Figure 5.2, why can\u2019t we write validate that is, why must the argument to validate be either Self-Check 5.1.2. released_1930_or_later, a symbol or a string?",
      "ate it at released_1930_or_later to be called at the time any validation is to occur. If the argument is just the \u201cbare\u201d name of the method, Ruby will try to evalu- it executes validate, which isn\u2019t what we want\u2014we want the moment 5.2. SINGLE SIGN-ON AND THIRD-PARTY AUTHENTICATION 131 Authorization refers to whether a principal is allowed to do something. Although separate from authentication, the two are often con\ufb02ated because many standards handle both. Facebook was an early example of SSO. Figure 5.6: Third-party authentication enables SSO by allowing a SaaS app to request that the user authenticate himself via a third-party provider. Once the user has done so, the provider sends a token to the requesting app proving that the user authenticated themselves correctly and possibly encoding additional privileges the user grants to the requesting app. The \ufb02ow shown is a simpli\ufb01ed version of OAuth, an evolving (and mildly controversial) open standard for authentication and authorization used by Twitter, Facebook, Microsoft, Google, Net\ufb02ix, and many others. Twitter logo and image copyright"
    ]
  },
  {
    "id": "sec_0244",
    "title": "2012 Twitter Inc., used for instructional purposes only.",
    "pages": [
      143
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0245",
    "title": "5.2 Single Sign-On and Third-Party Authentication",
    "pages": [
      143,
      144,
      145,
      146,
      147,
      148
    ],
    "text_blocks": [
      "One way to be more DRY and productive is to avoid implementing functionality that you can instead reuse from other services. One example of this today is authentication\u2014the process by which an entity or principal proves that it is who it claims to be. In SaaS, end users and servers are two common types of principals that may need to authenticate themselves. Typ- ically, a user proves their identity by supplying a username and password that (presumably) nobody else knows, and a server proves its identity with a server certi\ufb01cate (discussed in Chapter 12) whose integrity can be veri\ufb01ed using cryptography. In the early days of SaaS, users had to establish separate usernames and passwords for each site. Today, an increasingly common scenario is single sign-on (SSO), in which the credentials established for one site (the provider) can be used to sign in to other sites that are administratively unrelated to it. Clearly, SSO is central to the usefulness of service-oriented architecture: It would be dif\ufb01cult for services to work together on your behalf if each had its own separate authentication scheme. Given the prevalence and increasing importance of SSO, our view is that new SaaS apps should use it rather than \u201crolling their own\u201d authentication. However, SSO presents the dilemma that while you may be happy to use your credentials on site A to login to site B, you usually don\u2019t want to reveal those credentials to site B. (Imag- ine that site A is your \ufb01nancial institution and site B is a foreign company from whom you want to buy something.) Figure 5.6 shows how third-party authentication solves this prob- lem using RottenPotatoes and Twitter as an example. First, the app requesting authentication (RottenPotatoes) creates a request to an authentication provider on which the user already has an account, in this case Twitter. The request often includes information about what privileges the app wants on the provider, for example, to be able to tweet as this user or learn who the user\u2019s followers are. A typical SSO process is illustrated by the OAuth28 protocol, which begins with a link or button the user must click. That link takes the user to a login page served securely by the provider. The user is then given the chance to login to the provider and decide what privileges to grant the requesting app. Critically, this interaction takes place entirely between the user and the provider: the requesting app has no access to any part of this interaction. 132 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS https://gist.github.com/533907757ee761982af7b3b00b3f517f 1 rails generate model Moviegoer name : string provider : string uid : string # Edit app / models / moviegoer . rb to look like this : class Moviegoer < ActiveRecord :: Base def self . c r e a t e _ w i t h _ o m n i a u t h ( auth ) https://gist.github.com/897d2dace6a3cbb68859778f5c4ba032 1 2 3 4 5 6 7 8 9 : provider = > auth [ \" provider \" ] , : uid = > auth [ \" uid \" ] , : name = > auth [ \" info \" ][ \" name \" ]) Moviegoer . create !( end end Figure 5.7: Top (a): Type this command in a terminal to create a moviegoers model and migration, and run rake db:migrate to apply the migration. Bottom (b): Then edit the generated app/models/moviegoer.rb \ufb01le to match this code, which the text explains. Once authentication succeeds, the provider generates an HTTP POST to a particular route on the requesting app. This post request contains an access token\u2014a string created using cryptographic techniques that can be passed back to the provider later, allowing the provider to verify that the token could only have been created as the result of a successful login process. At this point, the requesting app is able to do two things: 1. It can believe that the user has proven her identity to the provider, and optionally record the provider\u2019s persistent user-ID (uid) for that user, usually provided as part of the access token. For example, Armando Fox\u2019s uid on Twitter happens to be 318094297, though this information isn\u2019t useful unless accompanied by an access token granting the right to obtain information about that uid. 2. It can use the token to request further information about the user from the provider, de- pending on what speci\ufb01c privileges were granted along with successful authentication. For example, a token from Facebook might indicate that the user gave permission for the app to learn who his friends are, but denied permission for the app to post on his Facebook wall. Happily, adding third-party authentication to Rails apps is straightforward. Of course, before we can enable a user to log in, we need to be able to represent users! So before continuing, create a basic model and migration following the instructions in Figure 5.7. There are three aspects to managing third-party authentication in SaaS: 1. How to authenticate the user via a third party authentication provider (\u201cauth provider\u201d) such as Google or GitHub 2. How to remember that the user has logged in successfully 3. How to link the user\u2019s ID in our own app with that provider\u2019s ID, so that we can recognize this user in the future By far the simplest way to accomplish the \ufb01rst task in Rails is to use the excellent Om- niAuth9 gem, which provides a uniform API to many different SSO providers, abstracting away the entire process in Figure 5.6. No matter which provider is used, OmniAuth arranges to send the user to the provider\u2019s login page, handles the providers\u2019 callbacks for successful or 5.2. SINGLE SIGN-ON AND THIRD-PARTY AUTHENTICATION 133 https://gist.github.com/e47a5afb49af3cef6cf24438e521c451 1 2 3 4 ' auth /: provider / callback ' = > ' sessions # create ' get ' auth / failure ' = > ' sessions # failure ' get ' auth / twitter ' , : as = > ' login ' get post ' logout ' = > ' sessions # destroy ' Moviegoer . where ( provider : auth [ \" provider \" ] , uid : auth [ \" uid \" ]) || Moviegoer . c r e a t e _ w i t h _ o m n i a u t h ( auth ) # login & logout actions should not require user to be logged in s ki p _b e f o r e_ f il t er : set_current_user def create class S e s s i o ns C on t ro l le r < A p p l i c a t i o n C o n t r o l l e r auth = request . env [ \" omniauth . auth \" ] user = https://gist.github.com/11f56e2f654393f34eb87009e3a25c2c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 session [: user_id ] = user . id redirect_to movies_path end def destroy session . delete (: user_id ) flash [: notice ] = ' Logged out successfully . ' redirect_to movies_path end end # Replace API_KEY and API_SECRET with the values you got from Twitter Rails . application . config . middleware . use OmniAuth :: Builder do https://gist.github.com/e309ab308e1de682960b2a29e7f13c26 1 2 3 4 provider : twitter , \" API_KEY \" , \" API_SECRET \" end Figure 5.8: (a) Top: If auth succeeds (line 1), OmniAuth will generate a GET to the create action in SessionsController. Line 3 makes the route helper login_path route to GET auth/twitter, which OmniAuth will redirect to Twitter\u2019s login page, so that line 7 in Figure 5.5 will work correctly. (b) Middle: Line 3 skips the before_filter that we added to ApplicationController in Figure 5.5. Upon successful login, the create action remembers the user\u2019s ID in the session until the destroy action is called to forget it. (c) Bottom: Files in config/initializers are loaded before the app starts. This one, omniauth.rb, speci\ufb01es the API keys to use for Twitter SSO. 134 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS failed authentication, and \ufb01nally generates GET requests to well-known routes in your app to handle these cases. To use OmniAuth, you install both the OmniAuth gem and the necessary additional gems for each auth provider strategy. Figure 5.8 shows the changes necessary to your routes, controllers, and con\ufb01guration to use OmniAuth. Most auth providers require you to register any apps that will use their site for authentication, so in this example you would need to create a Twitter developer ac- count, which will assign you an API key and an API secret that you specify in config/ initializers/omniauth.rb, as Figure 5.8(c) shows. The second aspect of handling au- thentication is keeping track of whether the current user has been authenticated. You may have already guessed that this information can be stored in the session[]. However, we should keep session management separate from the other concerns of the app, since the session may not be relevant if our app is used in a service-oriented architecture set- ting. To that end, Figure 5.8(b) shows how we can \u201ccreate\u201d a session when a user suc- cessfully authenticates (lines 4\u201311) and \u201cdestroy\u201d it when they log out (lines 12\u201316). The \u201cscare quotes\u201d are there because the only thing actually being created or destroyed is the value of session[:user_id], which is set to the primary key of the logged-in user dur- ing the session and nil at other times. Figure 5.5 shows how this check is abstracted by a before_filter in ApplicationController (which will be inherited by all controllers) that sets @current_user accordingly, so that controller methods or views can just look at @current_user without being coupled to the details of how the user was authenticated. The third aspect is linking our own representation of a user\u2019s identity\u2014that is, her pri- mary key in the moviegoers table\u2014with the auth provider\u2019s representation, such as the uid in the case of Twitter. Since we may want to expand which auth providers our customers can use in the future, the migration in Figure 5.7(a) that creates the Moviegoer model speci\ufb01es both a uid \ufb01eld and a provider \ufb01eld. What happens the very \ufb01rst time Alice logs into Rot- tenPotatoes with her Twitter ID? The query in line 7 of the sessions controller (Figure 5.8(b)) will return nil, so Moviegoer.create_with_omniauth (Figure 5.7(b), lines 3\u20138) will be called to create a new record for this user. Note that \u201cAlice as authenticated by Twitter\u201d would therefore be a different user from our point of view than \u201cAlice as authenticated by Facebook,\u201d because we have no way of knowing that those represent the same person. That\u2019s why some sites that support multiple third-party auth providers give users a way to \u201clink\u201d two accounts to indicate that they identify the same person. This may seem like a lot of moving parts, but compared to accomplishing the same task without an abstraction such as OmniAuth, this is very clean code: we added fewer than two dozen lines, and by incorporating more OmniAuth strategies, we could support additional third-party auth providers with essentially no new work. Screencast 5.2.1 shows the user experience associated with this code. Screencast 5.2.1: Logging into RottenPotatoes with Twitter. http://youtu.be/R3S3efTtwmI This version of RottenPotatoes, modi\ufb01ed to use the OmniAuth gem as described in the text, allows moviegoers to login using their existing Twitter IDs. However, we must be careful to avoid creating a security vulnerability. What if a mali- cious attacker crafts a form submission that tries to modify params[:moviegoer][:uid] or params[:moviegoer][:provider]\u2014\ufb01elds that should only be modi\ufb01ed by the au- thentication logic\u2014by posting hidden form \ufb01elds named moviegoer[uid] and so on? Section 4.4 explained how the \u201cstrong parameters\u201d feature of Rails can be used to block as- 5.2. SINGLE SIGN-ON AND THIRD-PARTY AUTHENTICATION 135 signment of model attributes that regular users shouldn\u2019t be able to set. While it\u2019s \ufb01ne for the create_with_omniauth method to create a moviegoer with the appropriate uid, a regular moviegoer should not be able to set their own uid since it would allow them to impersonate being logged in! To ensure this can\u2019t happen, we must make sure uid does not appear in any calls to params.permit or params.require in the Moviegoers controller. Summary \u2022 Single sign-on refers to an end-user experience in which a single set of credentials (such as their Google or Facebook username and password) will sign them in to a variety of different services. \u2022 Third-party authentication using standards such as OAuth is one way to achieve single-sign on: the requesting app can verify the identity of the user via an authenti- cation provider, without the user revealing her credentials to the requesting app. \u2022 The cleanest way to factor out authentication in Rails apps is to abstract the concept of a session. When a user successfully authenticates (perhaps using a framework such as OmniAuth10), a session is created by storing the authenticated user\u2019s id (primary key) in the session[]. When they sign out, the session is destroyed by deleting that information from the session[]. \u2022 Use Rails\u2019 strong parameters to ensure that model attributes that are \u201csensitive\u201d and should be excluded from mass assignment do not appear in params.require or params.permit calls in your controllers. Elaboration: SSO side effects In some cases, using SSO enables other features as well; for example, Facebook Connect enables sites to take advantage of Facebook\u2019s social network, so that (for example) Marsalis can see which New York Times articles his friends have been reading once he authenticates himself to the New York Times using Facebook. While these appealing features further strengthen the case for using SSO rather than \u201crolling your own\u201d authentication, they are separate from the basic concept of SSO, on which this discussion focuses. Self-Check 5.2.1. Brie\ufb02y describe how RottenPotatoes could let you log in with your Twitter ID without you having to reveal your Twitter password to RottenPotatoes. RottenPotatoes redirects you to a page hosted by Twitter where you log in as usual. The redirect includes a URL to which Twitter posts back a message con\ufb01rming that you\u2019ve au- thenticated yourself and specifying what actions RottenPotatoes may take on your behalf as a Twitter user. Self-Check 5.2.2. True or false: If you log in to RottenPotatoes using your Twitter ID, Rot- tenPotatoes becomes capable of tweeting using your Twitter ID. False: authentication is separate from permissions. Most third-party authentication providers, including Twitter, allow the requesting app to ask for permission to do speci\ufb01c things, and leave it up to the user to decide whether to allow it. 136 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS Figure 5.9: Each end of an association is labeled with its cardinality, or the number of entities participating in that \u201cside\u201d of the association, with an asterisk meaning \u201czero or more\u201d. In the \ufb01gure, each Review belongs to a single Moviegoer and a single Movie, and a Review without a Moviegoer or without a Movie is not allowed. (A cardinality notation of \u201c0..1\u201d rather than \u201c1\u201d would allow \u201corphaned\u201d reviews.)"
    ]
  },
  {
    "id": "sec_0246",
    "title": "5.3 CHIPS: Rails Intro",
    "pages": [
      148
    ],
    "text_blocks": [
      "CHIPS 5.3: Rails Intro https://github.com/saasbook/hw-rails-intro Starting with RottenPotatoes, a Rails app we provide for keeping track of movie info and reviews, we will add some simple features to sort and \ufb01lter the list of movies and to allow a moviegoer to establish an account and log in using single sign-on."
    ]
  },
  {
    "id": "sec_0247",
    "title": "5.4 Associations and Foreign Keys",
    "pages": [
      148,
      149,
      150,
      151,
      152
    ],
    "text_blocks": [
      "An association is a logical relationship between two types of entities in a software archi- tecture. For example, the previous CHIPS added a Moviegoer class to RottenPotatoes; we could now add a Review class to allow a moviegoer to write reviews of their favorite movies. Because each review is about exactly one movie, but a single movie can have many reviews, we say that there is a one-to-many association from movies to reviews. Similarly, there is a one-to-many association from moviegoers to reviews. Figure 5.9 shows these associations us- ing one type of Uni\ufb01ed Modeling Language (UML) diagram. We will see more examples of UML in Chapter 11. In Rails parlance, Figure 5.9 shows that: \u2022 A Moviegoer has many Reviews \u2022 A Movie has many Reviews \u2022 A Review belongs to one Moviegoer and to one Movie In Rails, the \u201cpermanent home\u201d for our model objects is the database, so we need a way to represent associations for objects stored there. Fortunately, associations are so common that relational databases provide a special mechanism to support them: foreign keys. A foreign key is a column in one table whose job is to reference the primary key of another table to establish an association between the objects represented by those tables. Recall that by default, Rails migrations create tables whose primary key column is called id. Figure 5.10 shows a Moviegoers table to keep track of different users and a Reviews table with foreign key columns moviegoer_id and movie_id, allowing each review to refer to the primary keys (ids) of the user who authored it and the movie it\u2019s about. 5.4. ASSOCIATIONS AND FOREIGN KEYS 137 Figure 5.10: In this \ufb01gure, Alice has given 5 potatoes to Star Wars and 4 potatoes to Inception, Bob has given 3 potatoes to Inception, Carol hasn\u2019t provided any reviews, and no one has reviewed It\u2019s Complicated. For brevity and clarity, the other \ufb01elds of the movies and reviews tables are not shown. https://gist.github.com/7e9140734d37ed46fd683e85519e9f65 # it would be nice if we could do this : 1 inception = Movie . where (: title = > ' Inception ') 2 alice , bob = Moviegoer . find ( alice_id , bob_id ) 3 # alice likes Inception , bob less so 4 alice_review = Review . new (: potatoes = > 4) 5 = Review . new (: potatoes = > 3) bob_review 6 # a movie has many reviews : 7 inception . reviews = [ alice_review , bob_review ] 8 # a moviegoer has many reviews : 9 alice . reviews << alice_review 10 bob . reviews << bob_review 11 # can we find out who wrote each review ? 12 inception . reviews . map { | r | r . moviegoer . name } # = > [ ' alice ',' bob '] 13 Figure 5.11: A straightforward implementation of associations would allow us to refer directly to associated objects, even though they\u2019re stored in different database tables. For example, to \ufb01nd all reviews for Star Wars, we would \ufb01rst form the Cartesian prod- uct of all the rows of the movies and reviews tables by concatenating each row of the movies table with each possible row of the reviews table. This would give us a new table with 9 rows (since there are 3 movies and 3 reviews) and 7 columns (3 from the movies table and 4 from the reviews table). From this large table, we then select only those rows for which the id from the movies table equals the movie_id from the reviews table, that is, only those movie-review pairs in which the review is about that movie. Finally, we select only those rows for which the movie id (and therefore the review\u2019s movie_id) are equal to 41, the primary key ID for Star Wars. This simple example (called a join in relational database parlance) illustrates how complex relationships can be represented and manipulated using a small set of operations (relational algebra) on a collection of tables with uniform data layout. In SQL, the Structured Query Language used by substantially all relational databases, the query would look something like this: https://gist.github.com/cbf6e0db3e759d83fe7cf88d1f58c392 1 2 3 FROM movies JOIN reviews ON movies . id = reviews . movie_id WHERE movies . id = 41; SELECT reviews .* If we weren\u2019t working with a database, though, we\u2019d probably come up with a design in which each object of a class has \u201cdirect references\u201d to its associated objects, rather than constructing the query plan above. A Moviegoer object would maintain an array of references to Reviews authored by that moviegoer; a Review object would maintain a reference to the Moviegoer who wrote it; and so on. Such a design would allow us to write code that looks like Figure 5.11. Rails\u2019 ActiveRecord::Associations11 module supports exactly this design, as we\u2019ll learn by doing. Apply the code changes in Figure 5.12 as directed in the caption, and you 138 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS # Run ' rails generate migration create_reviews ' and then # class CreateReviews < ActiveRecord :: Migration edit db / migrate /* _create_reviews . rb to look like this : def change create_table ' reviews ' do | t | https://gist.github.com/fc8fd0b1a47b0c080edd750bd7d03733 1 2 3 4 5 6 7 8 9 10 11 12 t . integer t . text t . references ' moviegoer ' t . references ' movie ' ' potatoes ' ' comments ' end end end class Review < ActiveRecord :: Base https://gist.github.com/9d29abef00dfb898cf95b3de40f39530 1 2 3 4 belongs_to : movie belongs_to : moviegoer end https://gist.github.com/c716c414b5bb050aacc03a18c6f43057 1 2 3 4 # place a copy of the following line anywhere inside the Movie class AND inside the Moviegoer class ( idiomatically , it should go right # after ' class Movie ' or ' class Moviegoer ') : # has_many : reviews Figure 5.12: Top (a): Create and apply this migration to create the Reviews table. The new model\u2019s foreign keys are related to the existing movies and moviegoers tables by convention over con\ufb01guration. Middle (b): Put this new Review model in app/models/review.rb. Bottom (c): Make this one-line change to each of the existing \ufb01les movie.rb and moviegoer.rb. should then be able to start rails console and successfully execute the examples in Fig- ure 5.11. How does this work? Since everything in Ruby is a method call, we know that Line 8 in Figure 5.11 is really a call to the instance method reviews= on a Movie object. This instance method remembers its assigned value (an array of Alice\u2019s and Bob\u2019s reviews) in memory. Recall, though, that since a Review is on the \u201cbelongs to\u201d side of the association (Review belongs to a Movie), to associate a review with a movie we must set the movie_id \ufb01eld for that review. We don\u2019t actually have to modify the movies table. So in this simple example, the call to inception.reviews= isn\u2019t actually updating the movie record for Inception at all: it\u2019s setting the movie_id \ufb01eld of both Alice\u2019s and Bob\u2019s reviews to \u201clink\u201d them to Inception. Figure 5.13 lists some of the most useful methods added to a movie object by virtue of declaring that it has_many reviews. Of particular interest is that since has_many implies a collection of the owned object (Reviews), the reviews method quacks like a collection. That is, you can use all the collection idioms of Figure 2.11 on it\u2014iterate over its elements with each, use functional idioms like sort, map, and so on, as in lines 8, 10 and 13 of Figure 5.11. What about the belongs_to method calls in review.rb? As you might guess, belongs_to :movie gives Review objects a movie instance method that looks up and returns the movie to which the review belongs. Since a review belongs to at most one movie, the method name is singular rather than plural, and returns a single object rather than an enumerable. has_one is a close relative of has_many that singularizes the association method name and operates on a single owned object rather than a collection. 5.4. ASSOCIATIONS AND FOREIGN KEYS 139 m.reviews m.reviews=[r1,r2] m.reviews<<r1 r = m.reviews.build(:potatoes=>5) r = m.reviews.create(:potatoes=>5) Returns an Enumerable of all owned reviews. Replaces the set of owned reviews with the set r1,r2, adding or delet- ing as appropriate, by setting the movie_id \ufb01eld of each of r1 and r2 to m.id (m\u2019s primary key) in the database immediately. Adds r1 to the set of m\u2019s reviews by setting r1\u2019s movie_id \ufb01eld to m.id. The change is written to the database immediately (you don\u2019t need to do a separate save). Makes r a new, unsaved Review object whose movie_id is pre- set to indicate that it belongs to m. Arguments are the same as for Review.new. Like build but saves the object immediately (analogous to the differ- ence between new and save). Note: if the parent object m has never been saved, that is, m.new_record? is true, then the child objects aren\u2019t saved until the parent is saved. m = r.movie r.movie = m Returns the Movie instance associated with this review. Sets m as the movie associated with review r. Figure 5.13: A subset of the association methods created by movie has_many :reviews and review belongs_to :movie, assuming m is an existing Movie object and r1,r2 are Review objects. Consult the ActiveRecord::Associations documentation13 for a full list. Method names of association methods follow convention over con\ufb01guration based on the name of the associated model. Summary: \u2022 Associations are one-to-one, one-to-many, or many-to-many relationships among application entities. \u2022 Relational databases (RDBMSs) use foreign keys to represent these relationships. \u2022 ActiveRecord\u2019s Associations module uses Ruby metaprogramming to create new methods to \u201ctraverse\u201d associations by constructing the appropriate database queries. You must still add the necessary foreign key \ufb01elds yourself with a migration. 140 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS Elaboration: Associations in a NoSQL world The use of foreign keys to represent associations relies on relational algebra. Rails\u2019 imple- mentation of ActiveRecord makes associations particularly convenient by providing meth- ods for automatic traversal of associations by synthesizing and optimizing the appropriate foreign-key joins in SQL. But such traversal, if not handled carefully, can lead to perfor- mance bottlenecks, as we will see in Section 12.7. One response to such bottlenecks has been the deployment of \u201cNoSQL\u201d databases, such as Cassandra and MongoDB, which omit all but the simplest foreign key support in order to achieve horizontal scalability superior to most RDBMSs. An example of an alternative implementation choice for associations with such databases is Data Mapper (Figure 5.14). In this pattern, each model is associated with a corresponding Mapper class that de\ufb01nes how that model\u2019s instances are stored, and provides its own code to represent and traverse model associations. Depending on the complexity of the associations, this code may \ufb01nd itself essentially reimplementing parts of a traditional RDBMS, but without the bene\ufb01t of the millions of engineer-hours that have gone into op- timizing the latter. Indeed, as Chapter 12 describes, \u201ctraditional\u201d relational databases can scale impressively far when combined with careful development and operations techniques (dev/ops), so today\u2019s SaaS developers can enjoy the expressiveness and advantages of tradi- tional RDBMSs for a long time before the database becomes the bottleneck. Self-Check 5.4.1. In Figure 5.12(a), why did we add foreign keys (references) only to the reviews table and not to the moviegoers or movies tables? Since we need to associate many reviews with a single movie or moviegoer, the foreign keys must be part of the model on the \u201cowned\u201d side of the association, in this case Reviews. In Figure 5.13, are the association accessors and setters (such as Self-Check 5.4.2. m.reviews and r.movie) instance methods or class methods? Instance methods, since a collection of reviews is associated with a particular movie, not with movies in general."
    ]
  },
  {
    "id": "sec_0248",
    "title": "5.5 Through-Associations",
    "pages": [
      152,
      153,
      154,
      155
    ],
    "text_blocks": [
      "Referring back to Figure 5.9, there are direct associations between Moviegoers and Reviews as well as between Movies and Reviews. But since any given Review is associated with both a Moviegoer and a Movie, we could say that there\u2019s an indirect association between Moviegoers and Movies. For example, we might ask \u201cWhat are all the movies Alice has reviewed?\u201d or \u201cWhich moviegoers have reviewed Inception?\u201d Indeed, line 13 in Figure 5.11 essentially answers the second question. This kind of indirect association is so common that Rails and other frameworks provide an abstraction to simplify its use. It\u2019s sometimes called a through-association, since Moviegoers are related to Movies through their reviews and vice versa. Figure 5.15 shows how to use the :through option to Rails\u2019 has_many to represent this indirect association. You can similarly add has_many :moviegoers, :through=>:reviews to the Movie model, and write movie.moviegoers to ask which moviegoers are associated with (wrote reviews for) a given movie. How is a through-association \u201ctraversed\u201d in the database? Referring again to Figure 5.10, \ufb01nding all the movies reviewed by Alice \ufb01rst requires forming the Cartesian product of the three tables (movies, reviews, moviegoers), resulting in a table that conceptually has 27 5.5. THROUGH-ASSOCIATIONS 141 Figure 5.14: In the Active Record design pattern (left), used by Rails and implemented in the ActiveRecord module, the model object itself knows how it\u2019s stored in the persistence tier, and how its relationship to other types of models is represented there. In the Data Mapper pattern (right), used by Google AppEngine, PHP and Sinatra, a separate class isolates model objects from the underlying storage layer. Each approach has pros and cons. This class diagram is one form of Uni\ufb01ed Modeling Language (UML) diagram, which we\u2019ll learn more about in Chapter 11. # in moviegoer . rb : class Moviegoer has_many : reviews has_many : movies , : through = > : reviews # ... other moviegoer model code https://gist.github.com/38c7992c280c175cc6e732ee8b44157d 1 2 3 4 5 6 7 8 9 10 end alice = Moviegoer . where (: name = > ' Alice ') alice_movies = alice . movies # MAY work , but a bad idea - see caption : alice . movies << Movie . where (: title = > ' Inception ') # Don 't do this ! Figure 5.15: Using through-associations in Rails. As before, the object returned by alice.movies in line 8 quacks like a collection. Note, however, that since the association between a Movie and a Moviegoer occurs through a Review belonging to both, the syntax in line 10 will cause a Review object to be created to \u201clink\u201d the association, and by default all its attributes will be nil. This is almost certainly not what you want, and if you have validations on the Review object (for example, the number of potatoes must be an integer), the newly-created Review object will fail validation and cause the entire operation to abort. 142 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS class Review < ActiveRecord :: Base https://gist.github.com/5576ce01f90d288484a9d917462c099c 1 2 3 4 5 6 7 # review is valid only if it 's associated with a movie : validates : movie_id , : presence = > true # can ALSO require that the referenced movie itself be valid # v a l i d a t e s _ a s s o c i a t e d : movie in order for the review to be valid : end Figure 5.16: This example validation on an association ensures that a review is only saved if it has been associated with some movie. rows and 9 columns in our example. From this table we then select those rows for which the movie\u2019s ID matches the review\u2019s movie_id and the moviegoer\u2019s ID matches the review\u2019s moviegoer_id. Extending the explanation of Section 5.4, the SQL query might look like this: https://gist.github.com/2c08943e4810a88ed8c0806992d5d22d 1 2 3 4 FROM movies JOIN reviews ON movies . id = reviews . movie_id JOIN moviegoers ON moviegoers . id = reviews . moviegoer_id WHERE moviegoers . id = 1; SELECT movies .* For ef\ufb01ciency, the intermediate Cartesian product table is usually not materialized, that is, not explicitly constructed by the database. Indeed, Rails 3 has a sophisticated relational algebra engine that constructs and performs optimized SQL join queries for traversing asso- ciations. The point of this section and the previous one, though, is not only to explain how to use associations, but also to point out the elegant use of duck typing and metaprogramming that makes them possible. In Figure 5.12(c) you added has_many :reviews to the Movie class. The has_many method performs some metaprogramming to de\ufb01ne the new instance method reviews= that we used in Figure 5.11. has_many is not a declaration, but a regular method call that does all of this work at runtime, adding several new instance methods to your model class to help manage the association. As you\u2019ve no doubt guessed, convention over con\ufb01guration determines the name of the new method, the table it will use in the database, and so on. Associations are one of the most feature-rich aspects of Rails, so take a good look at the full documentation14 for them. In particular: \u2022 Just like ActiveRecord lifecycle hooks, associations provide additional hooks that can be triggered when objects are added to or removed from an association (such as when new Reviews are added for a Movie), which are distinct from the lifecycle hooks of Movies or Reviews themselves. \u2022 Validations can be declared on associated models, as Figure 5.16 shows. \u2022 Because calling save or save! on an object that uses associations also affects the associated objects, various caveats apply to what happens if any of the saves fails. For example, if you have just created a new Movie and two new Reviews to link to it, and you now try to save the Movie, any of the three saves could fail if the objects aren\u2019t valid (among other reasons). \u2022 Additional to \u201cowned\u201d objects when an \u201cowning\u201d object association methods options control what is destroyed. happens to For example, 5.6. RESTFUL ROUTES FOR ASSOCIATIONS 143 has_many :reviews, dependent: destroy speci\ufb01es longing to a movie should be deleted from the database if the movie is destroyed. the reviews be- that Through-associations summary: \u2022 When two models A and B each have a has-one or has-many relationship to a com- mon third model C, a many-to-many association between A and B can be established through C. \u2022 The :through option to has_many allows you to manipulate either side of a through-association just as if it were a direct association. However, if you modify a through-association directly, the intermediate model object must be automatically created, which is probably not what you intended. Elaboration: Has and belongs to many Given that has_many :through creates \u201cmany-to-many\u201d associations between the two outer entities (Movies and Moviegoers in our running example), could we create such many- to-many relationships directly, without going through an \u201cintermediate\u201d table? ActiveRe- cord provides another association we don\u2019t discuss here, has_and_belongs_to_many (HABTM), for pure many-to-many associations in which you don\u2019t need to maintain any other information about the relationship besides the fact that it exists. For example, on Face- book, a given user might \u201clike\u201d many wall posts, and a given wall post might be \u201cliked by\u201d many users; thus \u201clike\u201d is a many-to-many relationship between users and wall posts. How- ever, even in that simple example, to keep track of when someone liked or unliked a wall post, the concept of a \u201clike\u201d would then need its own model to track these extra attributes. In most cases, therefore, has_many :through is more appropriate because it allows the relation- ship itself (in our example, the movie review) to be represented as a separate model. In Rails, HABTM associations are represented by a join table that by convention has no primary key and is created with a special migration syntax. Self-Check 5.5.1. Describe in English the steps required to determine all the moviegoers who have reviewed a movie with some given id (primary key). Find all the reviews whose movie_id \ufb01eld contains the id of the movie of interest. For each review, \ufb01nd the moviegoer whose id matches the review\u2019s moviegoer_id \ufb01eld."
    ]
  },
  {
    "id": "sec_0249",
    "title": "5.6 RESTful Routes for Associations",
    "pages": [
      155,
      156,
      157,
      158
    ],
    "text_blocks": [
      "How should we RESTfully refer to actions associated with movie reviews? In particular, at least when creating or updating a review, we need a way to link it to a moviegoer and a movie. Presumably the moviegoer will be the @current_user we set up in Figure 5.5 (Section 5.1). But what about the movie? Chapter 7 discusses Behavior-Driven Design, which emphasizes that development should be driven by scenarios that describe actual user behaviors. According to this view, since it only makes sense to create a review when you have a movie in mind, most likely the \u201cCreate Review\u201d functionality will be accessible from a button or link on the Show Movie Details page for a particular movie. Therefore, at the moment we display this form element, we 144 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS https://gist.github.com/7979dd386c876060a9ed9e3e01445d10 1 2 3 4 # in routes . rb , change the line ' resources : movies ' to : resources : movies do resources : reviews end Helper method movie_reviews_path(m) movie_review_path(m) new_movie_review_path(m) edit_movie_review_path(m,r) movie_review_path(m,r) movie_review_path(m,r) movie_review_path(m,r) RESTful route and action GET /movies/:movie_id/reviews POST /movies/:movie_id/reviews GET /movies/:movie_id/reviews/new GET /movies/:movie_id/reviews/:id/edit GET /movies/:movie_id/reviews/:id PUT /movies/:movie_id/reviews/:id DELETE /movies/:movie_id/reviews/:id index create new edit show update destroy Figure 5.17: Specifying nested routes in routes.rb (top) also provides nested URI helpers (bottom), analogous to the simpler ones provided for regular resources. know what movie the review is going to be associated with. The question is how to get this information to the new or create method in the ReviewsController. One method we might use is that when the user visits a movie\u2019s Show Movie De- tails page, we could use the session[], which persists across requests, to remember the ID of the movie whose details have just been rendered as the \u201ccurrent movie.\u201d When ReviewsController#new is called, we\u2019d retrieve that ID from the session[] and asso- ciate it with the review by populating a hidden form \ufb01eld in the review\u2019s form, which in turn will be available to ReviewsController#create. However, this approach isn\u2019t RESTful, since the movie ID\u2014a critical piece of information for creating a review\u2014is \u201chidden\u201d in the session. A more RESTful alternative, which makes the movie ID explicit, is to make the REST- ful routes themselves re\ufb02ect the logical \u201cnesting\u201d of Reviews inside Movies, as the top part of Figure 5.17 shows. Since Movie is the \u201cowning\u201d side of the association, it\u2019s the outer re- source. Just as the original resources :movies provided a set of RESTful URI helpers for CRUD actions on movies, this nested resource route speci\ufb01cation provides a set of RESTful URI helpers for CRUD actions on reviews that are owned by a movie. The bottom part of Figure 5.17 summarizes the new routes, which are provided in addition to the basic RESTful routes on Movies that we\u2019ve been using all along. Note that via convention over con\ufb01gu- ration, the URI wildcard :id will match the ID of the resource itself\u2014that is, the ID of a review\u2014and Rails chooses the \u201couter\u201d resource name to make :movie_id capture the ID of the \u201cowning\u201d resource. The ID values will therefore be available in controller actions as params[:id] (the review) and params[:movie_id] (the movie with which the review will be associated). Figure 5.18 shows a simpli\ufb01ed example of using such nested routes to create the views and actions associated with a new review. Of particular note is the use of a before-\ufb01lter in ReviewsController to ensure that before a review is created, two conditions are true: 1. @current_user is set (that is, someone is logged in and will \u201cown\u201d the new review). 2. The movie captured from the route (Figure 5.17) as params[:movie_id] exists in 5.6. RESTFUL ROUTES FOR ASSOCIATIONS 145 class R ev i ew sCo ntr oll er < A p p l i c a t i o n C o n t r o l l e r before_filter : has_moviegoer_and_movie , : only = > [: new , : create ] protected def h a s _ m o v i e g o e r _ a n d _ m o v i e flash [: warning ] = ' You must be logged in to create a review . ' redirect_to login_path end unless ( @movie = Movie . where (: id = > params [: movie_id ]) ) flash [: warning ] = ' Review must be for an existing movie . ' redirect_to movies_path end unless @current_user https://gist.github.com/77a5457f6727787aa6b25802cac2905c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @review = @movie . reviews . build end public def new end def create end end # since moviegoer_id is a protected attribute that won 't get # assigned by the mass - assignment from params [: review ] , we set it # by using the << method on the association . # set it manually with review . moviegoer = @current_user . @current_user . reviews << @movie . reviews . build ( params [: review ]) redirect_to movie_path ( @movie ) We could also <h1 > New Review for <%= @movie . title % > </ h1 > https://gist.github.com/f19bf92a35686d87a5e2b8d4e0384970 1 2 3 4 5 <%= form_tag m ovi e_r evi ew _pa th ( @movie ) , class : ' form ' do % > < label class = \" col - form - label \" > How many potatoes : </ label > <%= select_tag ' review [ potatoes ] ' , o p ti o ns _ fo r _s e le c t (1..5) , class : ' form - control ' % > 6 7 <%= submit_tag ' Create Review ' , : class = > ' btn btn - success ' % > <% end % > Figure 5.18: Top (a): a controller that manipulates Reviews that are \u201cowned by\u201d both a Movie and a Moviegoer, using before-\ufb01lters to ensure the \u201cowning\u201d resources are properly identi\ufb01ed in the route URI. Bottom (b): A possible view template for creating a new review, that is, app/views/reviews/new.html.erb. 146 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS the database. If either condition is not met, the user is redirected to an appropriate page with an er- ror message explaining what happened. If both conditions are met, the controller instance variables @current_user and @movie become accessible to the controller action and view. The view uses the @movie variable to create a submission path for the form using the movie_review_path helper (Figure 5.17 again). When that form is submitted, once again movie_id is parsed from the route and checked by the before-\ufb01lter prior to calling the create action. Similarly, we could link to the page for creating a new review by calling link_to with the route helper new_movie_review_path(@movie) as its URI argument. Summary: controller and view support for associations \u2022 The RESTful way to create routes for associations is to capture the IDs of both the resource itself and its associated item(s) in a \u201cnested\u201d route URI. \u2022 When manipulating \u201cowned\u201d resources that have a parent, such as Reviews that are \u201cowned by\u201d a Movie, before-\ufb01lters can be used to capture and verify the validity of the IDs embedded in the RESTful nested route. Elaboration: SOA, RESTful association routes, and the session RESTful SOA design guidelines suggest that every request be self-contained, so that there is no concept of a session (nor any need for one). In our example, we used nested RESTful resource routes to keep the movie and review IDs together and relied on our authentication framework to set up @current_user as the moviegoer who owns the review. For a pure SOA API, we would need to capture the moviegoer ID and review ID along with the movie ID. Rails\u2019 routing subsystem is \ufb02exible enough to allow de\ufb01ning routes with multiple wild- card components for this purpose. In general, this design problem arises whenever you need to create an object with multiple \u201cowners\u201d such as a Review. If not all the owning objects are required in order for the owned object to be valid\u2014for example, if it were possible for a Review to be \u201canonymous\u201d\u2014another solution would be to separate creation of the review and assigning it to a moviegoer into different RESTful actions. for a review\u2019s movie_id and Self-Check 5.6.1. Why must we provide values moviegoer_id to the new and create actions in ReviewsController, but not to the edit and update actions? Once the review is created, the stored values of its movie_id and moviegoer_id \ufb01elds tell us the associated movie and moviegoer."
    ]
  },
  {
    "id": "sec_0250",
    "title": "5.7 CHIPS: Associations",
    "pages": [
      158,
      159
    ],
    "text_blocks": [
      "CHIPS 5.7: Associations https://github.com/saasbook/hw-associations-reviews We add a Reviews model to RottenPotatoes, and make it possible for a logged-in moviegoer to leave a review and to view all reviews for a movie. 5.8. OTHER TYPES OF CODE"
    ]
  },
  {
    "id": "sec_0251",
    "title": "5.8 Other Types of Code",
    "pages": [
      159,
      160,
      161
    ],
    "text_blocks": [
      "147 The basic Rails app structure is apparent from the arrangement of the app directory: there are models backed by the database; views that render to HTML; controllers that should contain the bare minimum code to mediate between models and views; and view helpers (subdirec- tory helpers) for code whose only job is to \u201cprettify\u201d model information in the views. In this section we describe many other types of code necessary in large apps that don\u2019t \ufb01t neatly into any of the above categories. There\u2019s no \ufb01xed consensus on where these go in a Rails app, but it\u2019s probably helpful to create additional subdirectories under app, since anything in that directory is automatically loaded and available within your Rails app. Our short (and incomplete) list of examples of other types of useful objects can be divided into three categories, based on the main role of each object type: 1. Objects that factor out code (presenter, value object, adapter/decorator) provide a place to put additional code that works directly to help a particular model, view, or controller, but isn\u2019t part of the core functionality of the class it helps. 2. Objects that DRY out code (concerns, automations) allow reuse of behaviors. 3. Objects that encapsulate coupling (service object, form object, query object, policy object) perform operations that express inherent dependencies among different classes, so that those dependencies don\u2019t creep into the classes themselves. Presenters (sometimes called view objects) contain code that helps in rendering complex views. Recall from Section 4.1 that Rails views are really view templates: ideally they contain little or no code other than calls to view helpers. But sometimes the code needed to gracefully manipulate and present a view starts getting too heavyweight to stuff into a view helper, which is just a namespace of methods that get mixed into views. Presenters are full classes and provide a more appropriate place for complex view logic. Value objects encapsulate a type of object whose comparisons are based on values. For example, consider an object representing a range of dates. Depending on your app\u2019s needs, you might de\ufb01ne one such object instance to be \u201cless than\u201d another if its starting date is earlier, or if its ending date is earlier; you could also come up with a de\ufb01nition for \u201cbetween.\u201d Encapsulating such an object in a class lets you de\ufb01ne the spaceship comparison operator <=> on instances of that class, so mixed-in methods like sort will \u201cjust work.\u201d Adapters and decorators are design patterns related to the Open-Closed Principle (Sec- tion 11.4) and Dependency Injection Principle (Section 11.6). As their name suggests, these typically provide extra functionality to a particular class, usually a model. Concerns are complex behaviors mixed into multiple models. For example, the Apache Solr15 engine adds sophisticated full-text searching to any database-backed app. Any Ac- tiveRecord model that \u201cmixes in\u201d Solr gets new search methods added in. A simpler example might be allowing any model to be \u201cvoted on\u201d (likes/dislikes): the functionality of manag- ing and storing vote information is generic, but each model needs to track it separately. A third example might be allowing any model to be associated with an uploaded \ufb01le. Concerns should be used with care because they represent a kind of inheritance, whereas (as Chapter 11 describes) cleaner code can often be achieved by preferring composition over inheritance. Automations are just that\u2014automated work\ufb02ows that save you from having to manually repeat actions, usually related to app management and deployment. For example, creating fake staging data for your app would be a great candidate for automation, since the data 148 CHAPTER 5. ADVANCED SAAS ABSTRACTIONS needs to be re-created each time the app is deployed to staging. Most Rails app automations are best accomplished by adding rake tasks, since these have access to the app\u2019s classes, environment settings, and so on, though that\u2019s certainly not the only way to do it. Service objects typically perform a complex operation that touches multiple models, so its logic doesn\u2019t naturally \ufb01t into a single model. For example, \ufb01nalizing a purchase on an e-commerce site might touch a table of sales transactions, a table of inventory, and a table representing the customer\u2019s orders. These tables probably back three different models. A service object is often stateless (not backed by its own database table) but it can be helpful to include an instance of ActiveModel::Errors as part of the object, so the object\u2019s er- ror reporting is just like that of ActiveRecord models, making it easy for controllers to call the object and report its errors. Service objects in Rails apps are particularly useful when combined with a database transaction to ensure that either all the updates occur or none do. Form objects encapsulate the processing of a single form that may update multiple mod- els. Continuing the example above, a single form for completing a purchase may include information that updates the customer\u2019s shipping address, the history of all orders, and so on. The form object contains logic that coordinates the changes to the various models when the form is submitted. Query objects can similarly encapsulate queries that touch many different models. While a query in model A can use joins and eager loading (Section 12.7) to reference \ufb01elds in model B, such queries often end up exposing substantial details of each of the models, introducing coupling between them. While this coupling is necessary in order to perform the query, encapsulating it in a query object allows the models themselves to remain decoupled from each other and easier to test. Policy objects can be thought of as a special case of service object: they encapsulate policies, such as \u201cwho is allowed to do what,\u201d especially those that touch multiple models and therefore don\u2019t naturally belong in any of them. For example, consider an airline loy- alty program that reserves its best seats for VIP frequent \ufb02yers. The policy decision of \u201cIs customer X allowed to reserve seat Y on \ufb02ight Z\u201d may depend on many factors, including the customer\u2019s status level, how full the \ufb02ight is, and so on. A policy object knows how to retrieve the necessary details from the relevant model classes and make a policy decision. Summary: A Model\u2013View\u2013Controller app will make use of other kinds of code in addi- tion to models, views, and controllers. While some such code is there to DRY out the app or provide support beyond the core functionality of a speci\ufb01c class, an important category of \u201cother types of code\u201d encapsulates dependencies among multiple classes, so that the classes themselves can remain relatively decoupled. Self-Check 5.8.1. Rails database migrations are an example of which of the kinds of code described in this section? Migrations are an example of automation, since the same migration code is used to update the development, test, and production databases. Self-Check 5.8.2. True or false: Query objects exist because Rails makes it illegal/impossible for an ActiveRecord query de\ufb01ned in model A to make reference to \ufb01elds in model B. False: ActiveRecord queries constructed as a result of associations (such as \u201cA has many 5.9. FALLACIES AND PITFALLS 149 Bs\u201d) necessarily refer to other models, and any query de\ufb01ned in model A can join with and refer to any \ufb01elds in model B. But a query object lets you extract such logic into its own class when the queries get so complex that they expose too much detail about model B to model A."
    ]
  },
  {
    "id": "sec_0252",
    "title": "5.9 Fallacies and Pitfalls",
    "pages": [
      161
    ],
    "text_blocks": [
      "Pitfall: Too many \ufb01lters or model lifecycle callbacks, or overly complex logic in \ufb01lters or callbacks. Filters and callbacks provide convenient and well-de\ufb01ned places to DRY out duplicated code, but too many of them can make it dif\ufb01cult to follow the app\u2019s logic \ufb02ow. For example, when there are numerous before-\ufb01lters, after-\ufb01lters and around-\ufb01lters that trigger on different sets of controller actions, it can be hard to \ufb01gure out why a controller action fails to execute as expected or which \ufb01lter \u201cstopped the show.\u201d Things can be even worse if some of the \ufb01lters are declared not in the controller itself but in a controller from which it inherits, such as ApplicationController. Filters and callbacks should be used when you truly want to centralize code that would otherwise be duplicated. Pitfall: Not checking for errors when saving associations. Saving an object that has associations implies potentially modifying multiple tables. If any of those modi\ufb01cations fails, perhaps because of validations either on the object or on its associated objects, other parts of the save might silently fail. Be sure to check the return value of save, or else use save! and rescue any exceptions. Pitfall: Nesting resources more than 1 level deep. Although it\u2019s technically possible to have nested resources multiple levels deep, the routes and actions quickly become cumbersome, which may be a sign that your design isn\u2019t properly factored. Perhaps there is an additional entity relationship that needs to be modeled, using a shortcut such as has_many :through to represent the \ufb01nal association."
    ]
  },
  {
    "id": "sec_0253",
    "title": "5.10 Concluding Remarks: Languages, Productivity, and Beauty",
    "pages": [
      161,
      162,
      163,
      164
    ],
    "text_blocks": [
      "This chapter showed two examples of using language features to support the productive cre- ation of beautiful and concise code. The \ufb01rst is the use of metaprogramming, closures and higher-order functions to allow model validations and controller \ufb01lters to be DRYly declared in a single place, yet called from multiple points in the code. Validations and \ufb01lters are an example of aspect-oriented programming (AOP), a methodology that has been criticized because it obfuscates control \ufb02ow but whose well-circumscribed use can enhance DRYness. All in all, validations, \ufb01lters, and association helper methods are worth studying as successful examples of tastefully exploiting programming language features to enhance code beauty and productivity. The second example is the design choices re\ufb02ected in the association helper methods. For example, you may have noticed that while the foreign key \ufb01eld for a Movie object associ- ated with a review is called movie_id, the association helper methods allow us to reference AOP has been compared with the \ufb01ctitious COME FROM programming language construct, which began as a humorous response to Edsger Dijkstra\u2019s letter Go To Statement Considered Harmful (Dijkstra 1968) promoting structured programming. 150 NOTES review.movie, allowing our code to focus on the architectural association between Movies and Reviews rather than the implementation detail of the foreign key names. You could certainly manipulate the movie_id or review_id \ufb01elds in the database directly, as Web applications based on less-powerful frameworks are often forced to do, or do so in your Rails app, as in review.movie_id=some_movie.id. But besides being harder to read, this code hardwires the assumption that the foreign key \ufb01eld is named movie_id, which may not be true if your models are using advanced Rails features such as polymorphic associations, or if ActiveRecord has been con\ufb01gured to interoperate with a legacy database that follows a differ- ent naming convention. In such cases, review.movie and review.movie= will still work, but referring to review.movie_id will fail. Since someday your code will be legacy code, help your successors be productive\u2014keep the logical structure of your entities as separate as possible from the database representation. We might similarly ask, now that we know how associations are stored in the RDBMS, why movie.save actually also causes a change to the reviews table when we save a movie after adding a review to it. In fact, calling save on the new review object would also work, but having said that a Movie has many Reviews, it just makes more sense to think of saving the Movie when we update which Reviews it has. In other words, it\u2019s designed this way in order to make sense to programmers and make the code more beautiful. Finally, as we saw in Section 5.8, an application framework provides direct support for the major architectural components of the application (in our case, models, views, and con- trollers), but any large software system contains many other kinds of code as well. Indeed, some of the examples of that section are best understood as additional patterns for solving software problems\u2014a theme to which we will frequently return, and that we treat in depth in Chapter 11. E. Dijkstra. Go to statement considered harmful. Communications of the ACM, 11(3): 147\u2013148, March 1968. URL https://dl.acm.org/purchase.cfm?id=362947&CFID= 100260848&CFTOKEN=27241581. Notes 1https://www.khanacademy.org/computing/computer-programming/sql 2http://api.rubyonrails.org/classes/ActiveModel/Validations/ClassMethods.html# method-i-validates 3http://api.rubyonrails.org/classes/ActiveModel/Validations/ClassMethods.html# method-i-validates 4http://api.rubyonrails.org/classes/ActiveModel/Errors.html 5http://guides.rubyonrails.org/v3.2.19/active_record_validations_callbacks.html 6http://guides.rubyonrails.org/v3.2.19/active_record_validations_callbacks.html 7http://api.rubyonrails.org/v3.2.19/classes/ActiveRecord/Callbacks.html 8https://oauth.net/2 9http://www.omniauth.org 10http://www.omniauth.org 11http://api.rubyonrails.org/v3.2.19/classes/ActiveRecord/Associations/ClassMethods. html 12http://api.rubyonrails.org/v3.2.19/classes/ActiveRecord/Associations/ClassMethods. html 13http://api.rubyonrails.org/v3.2.19/classes/ActiveRecord/Associations/ClassMethods. html 14http://api.rubyonrails.org/v3.2.19/classes/ActiveRecord/Associations/ClassMethods. html 15https://lucene.apache.org/solr/ NOTES 151 6 Mobile and Desktop SaaS Clients: JavaScript Introduction John Backus (1924\u20132007) received the 1977 Turing Award in part for \u201cprofound, in\ufb02uential, and lasting contributions to the design of practical high-level programming systems, notably through his work on Fortran,\u201d which was the \ufb01rst widely used high-level language. Much of my work has come from being lazy. I didn\u2019t like writing programs, and so, when I was working on the IBM 701, writing programs for computing missile trajectories, I started work on a programming system to make it easier to write programs. \u2014John Backus, quoted in IBM employee magazine Think in 1979 . . . . . . . . . . . . . . . . . . . . . . . . . . . JavaScript: The Big Picture . . Introducing ECMAScript . . . 6.1 . . . 6.2 ."
    ]
  },
  {
    "id": "sec_0254",
    "title": "6.3 Classes, Functions and Constructors .",
    "pages": [
      164
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0255",
    "title": "6.4 The Document Object Model (DOM) and jQuery .",
    "pages": [
      164
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0256",
    "title": "6.5 The DOM and Accessibility .",
    "pages": [
      164
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0257",
    "title": "6.6 Events and Callbacks",
    "pages": [
      164
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0258",
    "title": "6.7 AJAX: Asynchronous JavaScript And XML .",
    "pages": [
      164
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0259",
    "title": "6.8 Testing JavaScript and AJAX .",
    "pages": [
      164
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0260",
    "title": "6.9 CHIPS: AJAX Enhancements to RottenPotatoes .",
    "pages": [
      164
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0261",
    "title": "6.10 Single-Page Apps and JSON APIs .",
    "pages": [
      164
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0262",
    "title": "6.11 Fallacies and Pitfalls .",
    "pages": [
      164
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0263",
    "title": "6.12 Concluding Remarks: JavaScript Past, Present and Future .",
    "pages": [
      164,
      165,
      166
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154 . 157 . 163 . 166 . 169 . 173 . 178 . 183 . 190 . 190 . 195 . 199 153 Prerequisites and Concepts Concepts: JavaScript is a dynamic, interpreted scripting language built into modern browsers. This chapter describes its main features, including some that we recommend avoiding because they represent questionable design choices, and how to use it to extend the types of content and applications that can be delivered as SaaS. \u2022 A browser represents a web page as a data structure called the Document Object Model (DOM). JavaScript code running in the browser can inspect and modify this data structure, causing the browser to redraw the modied page elements. \u2022 When a user interacts with the browser (for example, by typing, clicking, or moving the mouse) or the browser makes progress in an interaction with a server, the browser generates an event indicating what happened. Your JavaScript code can take app-specic actions to modify the DOM when such events occur. \u2022 Using AJAX , or Asynchronous JavaScript And XML, JavaScript code can make HTTP requests to a Web server without triggering a page reload. The information in the response can then be used to modify page elements in place, giving a richer and often more responsive user experience than traditional Web pages. Rails partials and controller actions can be readily used to handle AJAX interactions. \u2022 Just as we use the highly-productive Rails framework (Chapter 4) and RSpec TDD tool (Chapter 8) for server-side SaaS code, here we use the highly-productive jQuery framework and Jasmine1 TDD tool to develop client-side code. \u2022 We follow the best practice of graceful degradation, also referred to as progres- sive enhancement: legacy browsers lacking JavaScript support will still provide a good user experience, while JavaScript-enabled browsers will provide an even better experience. JavaScript, Microsoft JScript, and Adobe ActionScript are dialects of ECMAScript, the 1997 standard that codi\ufb01es the language. We follow standard usage and use \u201cJavaScript\u201d to refer to the language generically. 154 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT"
    ]
  },
  {
    "id": "sec_0264",
    "title": "6.1 JavaScript: The Big Picture",
    "pages": [
      166,
      167,
      168,
      169
    ],
    "text_blocks": [
      "JavaScript had to \u201clook like Java\u201d only less so\u2014be Java\u2019s dumb kid brother or boy- hostage sidekick. Plus, I had to be done in ten days or something worse than JavaScript would have happened. \u2014Brendan Eich, creator of JavaScript Despite its name, JavaScript is unrelated to Java: LiveScript, the original name cho- sen by Netscape Communications Corp., was changed to JavaScript to capitalize on Java\u2019s popularity. Brendan Eich, creator of JavaScript, originally proposed embedding Scheme in the browser (Seibel 2009). Although pressure to create a Java-like syntax prevailed, many Scheme ideas survive in JavaScript, including higher-order functions (HOFs), which take functions as arguments and/or produce a function as a return value, which make possible AJAX programming and the Jasmine TDD tool. Indeed, JavaScript has almost nothing in common with Java except super\ufb01cial syntax, and is actually much more similar to Ruby. Its dynamic type system is similar to Ruby\u2019s and plays a similarly prominent role in how the language is used. If you have a solid grasp of these concepts from Chapters 2 and 8, and are comfortable using CSS selectors as you did in Chapters 3 and 7, getting started with JavaScript will be easy. JavaScript has acquired a bad reputation that isn\u2019t entirely deserved. It began as a lan- guage intended to allow Web browsers to run simple client-side code to validate form inputs, animate page elements, or communicate with Java applets. Inexperienced programmers be- gan to copy-and-paste simple JavaScript examples to achieve appealing visual effects, albeit with terrible programming practices, giving the language itself a bad reputation. This is not to say the language has no quirks or pitfalls, but it is certainly possible to use it well. Nonetheless, even when used well, JavaScript still presents a fundamental tension for SaaS. While JavaScript is de\ufb01nitively the language of client-side code, there are many lan- guages for creating the server side. Thus when creating SaaS we must either \ufb01nd ways to integrate two (or more) languages in the same app, as we do in this chapter, or commit to creating both the front and back ends in a single language, as is done when using server-side JavaScript frameworks such as Node or Express. While it seems appealing to simply pick one language, it is a decision your authors believe to be on the wrong side of history. Few modern complex software systems are written entirely in a single language simply because different languages solve different problems well. For example, the routing layer of Heroku, which receives and distributes incoming traf\ufb01c from SaaS clients, is written in Erlang, a somewhat obscure language developed for programming highly-reliable telecommunications switches. Erlang is so good at simplifying the creation of code to manages event-driven tasks like handling multiple simultaneous connections that it is worth specializing the routing layer in this way. This philosophy is consistent with that of microservices: each service should be engineered to optimize its focused set of tasks, and as long as the external API stays the same, the implementation language matters little and can even be changed without harming interoperability. Heroku apps have access to shared or dedicated databases using PostgreSQL and Redis (both written mostly in C) and provides runtime support for apps written in a variety of languages. Systems that combine languages are more challenging to develop because of the need to pass information between subsys- tems in different languages in a disciplined way. Nonetheless, your authors believe that such \u201cpolyglot\u201d (multilanguage) systems are the future, and managing such challenges is part of the domain of software engineering. The browser determines what version of ECMAScript is available. Especially if you plan to support mobiles, it\u2019s worth checking which browser versions your chosen JavaScript libraries are compatible with. 6.1. JAVASCRIPT: THE BIG PICTURE 155 Therefore, we concentrate primarily on the use of JavaScript for SaaS clients, showing how the above problems are addressed with respect to Rails as a speci\ufb01c example. We can differentiate four major approaches, which we list in order of \u201cleast JavaScript-intensive\u201d to \u201cmost JavaScript-intensive\u201d: 1. Adding JavaScript to HTML and CSS to enhance the user experience of server-centric SaaS apps. In this scenario, the user experience is that the app consists of a set of different HTML pages, some of which are JavaScript-enhanced. JavaScript requests. 2. Creating single-page applications (SPAs) in which the user experience is that once the initial page is loaded, no further page reloads or redraws occur, although elements on the page are updated continuously in response to communication with the server. In this scenario, the server appears to the app as one or several service endpoints that return data\u2014most commonly encoded as JSON or XML, though in principle any data format is possible. 3. Writing full client-side applications such as Google Docs, comparable in complexity to desktop apps and possibly able to operate while disconnected from the Internet. Like all complex software, such apps re\ufb02ect some underlying architecture and are increasingly built using JavaScript frameworks that support that architecture, such as Model-View- ViewModel (Vue), Model-View-Controller (Angular), and others. 4. Creating full server-side apps similar to those we\u2019ve been building using Rails, but using JavaScript frameworks such as Node.js. In this chapter we focus on cases 1 and 2. But how to choose among the ever-expanding selection of purely front-end JavaScript frameworks? Recall from Chapters 3 and 4 the ben- e\ufb01ts of choosing a framework whose model is a good \ufb01t for your app versus the pain of \ufb01ghting a framework that is a poor \ufb01t. Rails is highly opinionated, and if the app you\u2019re trying to build matches Rails\u2019 MVC architecture, its facilities save you a lot of work. The same lesson applies to front-end frameworks, which we can classify on a spectrum from in- cremental to opinionated. Roughly speaking, an incremental framework is one in you can selectively use for parts of the front end of your SaaS app without having to commit the en- tire front end to a very speci\ufb01c (opinionated) app structure. For example, React is primarily a reactive view framework that you can choose to use for some but not all of your app\u2019s views. However, most React components in practice rely on JSX , an XML-like extension to JavaScript\u2019s syntax. The Vue view framework does not, making it perhaps easier to in- crementally incorporate2 into projects that otherwise have no need for JSX. In contrast to both React and Vue, Angular and Ember are full Model\u2013View\u2013Controller frameworks for the front end, and it is dif\ufb01cult to combine them with other (non-MVC) structures, so using them represents a serious commitment to (re)structuring the app\u2019s front end. We will stake out a conservative position in this introduction and introduce enhanc- In general, unobtrusive ing SaaS with unobtrusive JavaScript and the jQuery library. JavaScript emphasizes: \u2022 Separation of HTML markup (content) from JavaScript (behavior): JavaScript mixed into HTML pages (as was sadly common for early SaaS apps) is hard to read and maintain. JavaScript should instead reside in separate \ufb01les, using event handlers to \u201ctie\u201d JavaScript code to page elements, as Section 6.7 describes. 156 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT Language Framework Client-Server Architecture over HTTP Debugging Testing Server Ruby Rails Controller request, receives interacts with model, renders new page (view) rails debugger, Ruby console RSpec with rspec-rails; isolate tests from database us- ing ActiveRecord model \ufb01x- tures and factories Client JavaScript jQuery Controller receives request, interacts with model, and renders a partial or an XML- or JSON-encoded object, which is used by JavaScript code running in browser to mod- ify current page in place Firebug, browser\u2019s JavaScript console Jasmine, jasmine-jquery; isolate tests from server using HTML and JSON \ufb01xtures Figure 6.1: The correspondence between our exposition of server-side programming with Ruby and Rails and client-side programming with JavaScript continues our focus on productively creating DRY, concise code that is well covered by tests. quirksmode.org tells you more about JSAPI browser incompatibilities than you want to know. \u2022 Progressive enhancement: While JavaScript may enhance aspects of the site\u2019s user experience, the site should remain accessible to users with disabilities (Section 6.5) and users whose browsers have compatibility issues related to the JavaScript Application Programming Interface (JSAPI), the browser functionality that lets JavaScript code manipulate the content of the current HTML page. Both conditions can be largely but not completely addressed by using JavaScript libraries such as jQuery (Section 6.4). Testing JavaScript is particularly important since most browsers do not display user- visible error messages as a result of JavaScript bugs; instead, the site often simply refuses to work (\u201csilent failure\u201d), or the UI freezes, or the user sees a confusing error message result- ing from a cascading failure rather than directly describing the actual failure. As we will see, integration-level testing of JavaScript-enhanced SaaS apps is straightforward and requires few or no changes to your existing skills using Cucumber and Capybara, but unit-testing of JavaScript is somewhat trickier. The rest of this chapter introduces the JavaScript language and jQuery framework and how they interact with Rails. Figure 6.1 compares our exposition of server-side and client- side programming. Screencast 6.1.1 demonstrates the two JavaScript features we will add to RottenPotatoes in this chapter. Screencast 6.1.1: Adding JavaScript features to RottenPotatoes. http://youtu.be/fFe_tdWil2E We will \ufb01rst add a checkbox that allows \ufb01ltering the RottenPotatoes movie list to exclude \ufb01lms unsuitable for children. This behavior can be implemented entirely in client-side JavaScript using techniques described in Sections 6.4 and 6.6. Next we will change the behavior of the \u201cMore info\u201d link for each movie to display the extra info in a \u201c\ufb02oating\u201d window rather than loading a new page. This will require AJAX, since fetching the movie info requires communicating with the server. Section 6.7 introduces AJAX programming. Both behaviors will be implemented with graceful degradation so that legacy browsers still have a good experience. Section 6.2 introduces the language and how code is connected to Web pages and Sec- tion 6.3 describes how its functions work, an understanding of which is the basis of writing jQuery can be viewed as an enhanced Adapter (Section 11.6) to the various browsers\u2019 JSAPIs. Ironically, modern AJAX programming involves much less XML than originally, as we\u2019ll see. 6.2. INTRODUCING ECMASCRIPT 157 clean and unobtrusive JavaScript code. Section 6.4 introduces jQuery3, which overlays the separate browsers\u2019 incompatible JSAPIs with a single API that works across all browsers. Section 6.5 discusses how the use of JavaScript to manipulate the DOM intersects with considerations of accessibility for Web users with disabilities. Section 6.6 describes how jQuery\u2019s features make it easy to program interactions between page elements and JavaScript code, setting the stage for introducing AJAX in Section 6.7. In 1998, Internet Explorer 5 (the Microsoft browser that preceded Edge) introduced a new mechanism that allowed JavaScript code to communicate with a SaaS server after a page had been loaded, and use information from the server to update the page \u201cin place\u201d without the user having to reload a new page. Other browsers quickly copied the technology. Developer Jesse James Garrett coined the term AJAX , for Asynchronous JavaScript And XML, to describe how the combination of this technology to power impressive \u201cWeb 2.0\u201d apps like Google Maps. Testing client-side JavaScript is challenging because browsers will fail silently when an error occurs rather than displaying JavaScript error messages to unsuspecting users. Fortu- nately, the Jasmine TDD framework will help you test your code, as Section 6.8 describes. Finally, Section 6.10 describes the mechanisms for both developing and testing browser- based single-page apps (SPAs), which are becoming increasingly popular. Summary of JavaScript background: \u2022 JavaScript resembles Java in name and syntax only; despite nontrivial \ufb02aws, it em- bodies great ideas found in Scheme and Ruby. \u2022 While all browser-based SaaS apps must use JavaScript as the client-side language, there are many choices for the server-side language. Combining languages in a sys- tem brings challenges, but in the end, your authors believe, and the history of suc- cessful software systems con\ufb01rms, that the bene\ufb01ts of engineering good \u201cpolyglot\u201d (multi-language) systems outweigh the costs. \u2022 We focus on client-side JavaScript, that is, on using the language to enhance the user experience of pages delivered by a server-centric SaaS app. To that end, we choose to use jQuery, which is much closer to the \u201cincremental\u201d end of the front- end framework spectrum than to the \u201copinionated\u201d end. Self-Check 6.1.1. With respect to the challenges of combining multiple languages in one software system, which challenge do you think the JSON data format (introduced in Sec- tion 3.6) addresses? JSON provides a language-independent way to represent hierarchical data structures con- sisting of basic types such as numbers, strings, Booleans, hash maps (dicts), and arrays. Since virtually all modern languages support these basic types, languages can easily con- vert between JSON and their own internal representations of these types, allowing for data interchange among them."
    ]
  },
  {
    "id": "sec_0265",
    "title": "6.2 Introducing ECMAScript",
    "pages": [
      169,
      170,
      171,
      172,
      173,
      174,
      175
    ],
    "text_blocks": [
      "Stop me if you think you\u2019ve heard this before. \u2014variously attributed 158 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT Our fast-paced introduction to JavaScript follows the same structure proposed in Sec- tion 2.1 and used in Section 2.3 to introduce Ruby. We\u2019ll \ufb01rst review the things that are fairly standard about the language\u2014syntax, types and names, control \ufb02ow, and so on, as Figure 6.2 summarizes. We then introduce the idioms that are central to using the language but less com- mon: prototypes, \ufb01rst-class functions, and higher-order functions. An excellent resource to lend depth to this brief overview is the JavaScript documentation maintained by the Mozilla Developer Network4. Types and typing. Almost everything is an object. There are only a few primitive (built- in) types: String, Number (64-bit double precision \ufb02oating point), undefined (having no value), null (a speci\ufb01c value different from undefined), Boolean (either true or false), and BigInt (rarely needed, for expressing integers of arbitrary magnitude that would over\ufb02ow the Number type). There is a new Symbol type (which behaves similar to Ruby\u2019s) The most important compound type is Object, which is a collection of unordered key/- value pairs; the keys are called properties or sometimes slots. JavaScript objects look and behave like Ruby hashes except that the property names must be strings, although JavaScript syntax allows omitting quotes around those strings under some circumstances. Properties can be added or removed after an object is created. Finally, JavaScript has Arrays that can be indexed numerically, but they are actually implemented as objects (hashes) in which there is a particular relationship between property names that are integers and the array\u2019s length property. Variables and Names. As in Ruby, variables don\u2019t have types, but the objects they refer to do, so the same variable can refer to objects of different types at different times (though that\u2019s rarely a good idea). Variable names must start with a letter, underscore, or dollar sign, and can also include digits, and idiomatically use UpperCamelCase or lowerCamelCase naming. A variable declaration preceded by var or let declares and optionally initializes the variable, as in var s=\"Hello world\", and sets the scope of that variable to be its enclosing block. Unlike Ruby, but like C, JavaScript allows blocks of code to be nested; a variable declared with var is visible to blocks nested inside the one in which it\u2019s declared, whereas a variable declared with let is not. If your functions are short (as Chapter 9.5 suggests) Functions are closures that carry their environment around with them, allowing them to execute properly at a different place and time than where they were de\ufb01ned. Just as anonymous blocks (do...end) are ubiquitous in Ruby, anonymous functions (function() {...}) are ubiquitous in JavaScript. Classes and types matter even less than they do in Ruby\u2014in fact, despite the syntactic appearance of much JavaScript code in the wild, JavaScript does not have classes that behave the way they would in class-oriented OO languages like Ruby and Java, despite the appearance of the new class keyword in ECMAScript 6. Figure 6.2 shows JavaScript\u2019s basic syntax and constructs, which should look familiar to Java and Ruby programmers. The Fallacies & Pitfalls section describes several JavaScript pitfalls associated with the \ufb01gure; read them carefully after you\u2019ve \ufb01nished this chapter, or you may \ufb01nd yourself banging your head against one of JavaScript\u2019s unfortunate misfeatures or a JavaScript mechanism that looks and works almost but not quite like its Ruby counterpart. For example, whereas Ruby uses nil to mean both \u201cunde\ufb01ned\u201d (a variable that has never been given a value) and \u201cempty\u201d (a value that is always false), JavaScript\u2019s null is distinct from its undefined, which is what you get as the \u201cvalue\u201d of a variable that has never been initialized. As the \ufb01rst row of Figure 6.2 shows, JavaScript\u2019s fundamental type is the object, an let signals the JavaScript interpreter that the variable is likely to be reassigned later. Using const instead makes it an error to reassign the variable later. Using var, which was the only option in older version of JavaScript, leaves it ambiguous but may prevent the interpreter from doing certain optimizations. 6.2. INTRODUCING ECMASCRIPT 159 Objects Types Strings &Regexps Arrays Numbers Conversions Booleans Naming Control \ufb02ow 1972, \u2019PG\u2019}} \u2019The Godfather\u2019, \u2019releaseInfo\u2019: {\u2019year\u2019: movie={title: rating: Quotes optional around property name if it\u2019s a legal variable name; objects can be nested. Access an object\u2019s properties with movie.title, or movie[\u2019title\u2019] if property name isn\u2019t a legal variable name or isn\u2019t known until runtime. for (var in obj) {...} iterates over obj\u2019s property names in arbitrary order. typeof x returns a string representation of x\u2019s primitive type: one of \"object\", \"string\", \"array\", \"number\", \"boolean\", \"function\", \"undefined\". All numbers are doubles. \"string\", \u2019also a string\u2019, \u2019joining\u2019+\u2019strings\u2019 \u2019mad, mad world\u2019.split(/[, ]+/) == [\"mad\",\"mad\",\"world\"] \u2019mad, mad world\u2019.slice(3,8)==\", mad\" ; \u2019mad, mad world\u2019.slice(-3)==\"rld\" \u2019mad\u2019.indexOf(\u2019d\u2019)==2, \u2019mad\u2019.charAt(2)==\u2019d\u2019, \u2019mad\u2019.charCodeAt(4)==100 \u2019mad\u2019.replace(/(\\w)$/,\u2019$1$1er\u2019)==\"madder\" /regexp/.exec(string) if no match returns null, if match returns array whose zeroth el- ement is whole string matched and additional elements are parenthesized capture groups. string.match(/regexp/) does the same, unless the /g regexp modi\ufb01er is present. /regexp/.test(string) (faster) returns true or false but no capture groups. Alternate constructor: new RegExp(\u2019[Hh]e(l+)o\u2019) var a = [1, {two: 2}, \u2019three\u2019] ; a[1] == {two: 2} Zero-based, grow dynamically; objects whose keys are numbers (see Fallacies & Pitfalls) arr.sort(function (a,b) {...}) Function returns -1, 0 or 1 for a<b,a==b,a>b + - Math.round(n), Math.ceil(n), Math.floor(n) round their argument to nearest, higher, or lower integer respectively Math.random() returns a random number in (0,1) \u2019catch\u2019+22==\u2019catch22\u2019, \u20194\u2019+\u201911\u2019==\u2019411\u2019 parseInt(\u20194oneone\u2019)==4, parseInt(\u2019four11\u2019)==NaN parseInt(\u20190101\u2019,10)==101, parseInt(\u20190101\u2019,2)==5, parseInt(\u20190101\u2019)==65 (numbers beginning with 0 are parsed in octal by default, unless radix is speci\ufb01ed) parseFloat(\u20191.1b23\u2019)==1.1, parseFloat(\u20191.1e3\u2019)==1100 false, null, undefined (unde\ufb01ned value, different from null), 0, the empty string \u2019\u2019, and NaN (not-a-number) are falsy (Boolean false); true and all other values are truthy. localVar, local_var, ConstructorFunction, GLOBAL All are conventions; JavaScript has no speci\ufb01c capitalization rules. var keyword scopes variable to the function in which it appears, otherwise it becomes a global (technically, a property of the global object, as Section 6.3 describes). Variables don\u2019t have types, but the objects they refer to do. while(), for(;;), if...else if...else, ?: (ternary operator), switch/case, try/catch/throw, return, break Statements separated by semicolons; interpreter tries to auto-insert \u201cmissing\u201d ones, but this is perilous (see Fallacies & Pitfalls) / %, also +=, etc., ++ --, Math.pow(num,exp) Figure 6.2: Analogous to Figure 2.2, this table summarizes basic constructs of JavaScript. See the text for important pitfalls. Whereas Ruby uses nil as both an explicit null value and the value returned for nonexistent instance variables, JavaScript distinguishes undefined, which is returned for undeclared or unassigned variables, from the special value null and Boolean false. However, all three are \u201cfalsy\u201d\u2014they evaluate to false in a conditional. 160 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT let potatoReview = { \" potatoes \" : 5 , \" reviewer \" : \" armandofox \" , \" movie \" : { https://gist.github.com/707970f51340686283f71858a4f02c7a 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 }; potatoReview [ ' potatoes '] potatoReview [ ' movie ' ]. title potatoReview . movie . title potatoReview [ ' movie ' ][ ' title '] // = > \" Casablanca \" potatoReview [ ' blah '] \" 1942 -11 -26 T07 :00:00 Z \" // = > \" Casablanca \" // = > \" Casablanca \" // = > undefined // = > 5 } \" title \" : \" Casablanca \" , \" description \" : \" Casablanca is a classic and iconic film starring ... \" , \" rating \" : \" PG \" , \" release_date \" : Figure 6.3: JavaScript notation for object literals, that is, objects you specify by enumerating their properties and values explicitly. If the property name is a legal JavaScript variable name, quotes can be omitted or the idiomatic dot-notation shortcut (lines 13\u201314) can be used, although quotes are always required around all strings when an object is expressed in JSON format. Since objects can contain other objects, hierarchical data structures can be built (line 5) and traversed (lines 13\u201315). unordered collection of key/value pairs, or as they are called in JavaScript, properties or slots. The name of a property can be any string, including the empty string. The value of a property can be any JavaScript expression, including another object; it cannot be undefined. JavaScript allows you to express object literals by specifying their properties and values directly, as Figure 6.3 shows. This simple object-literal syntax is the basis of JSON, or JavaScript Object Notation, which we introduced in Section 3.6. Despite its name, JSON has become a language-independent way to represent data that can be exchanged between SaaS services or between a SaaS client and server. In fact, lines 2\u201311 in the \ufb01gure (minus the trailing semicolon on line 11) are a legal JSON representation. Of\ufb01cially, each property value in a JSON object can be a Number, Unicode String, Boolean (true or false are the only possible values), null (empty value), or a nested Object recursively de\ufb01ned. Unlike full JavaScript, though, in the JSON representation of an object all strings must be quoted, so the example in the top row of Figure 6.2 would need quotes around the word title to comply with JSON syntax. Figure 6.4 summarizes a variety of tools for checking the syntax and style of both JavaScript code and JavaScript-related data structures and protocols that we\u2019ll meet in the rest of this chapter. The fact that a JavaScript object can have function-valued properties is used by well- engineered libraries to collect all their functions and variables into a single namespace. For example, as we\u2019ll see in Section 6.4, jQuery de\ufb01nes a single global variable jQuery through which all features of the jQuery library are accessed, rather than littering the global namespace with the many objects in the library. We will follow a similar practice by de\ufb01ning a small number of global variables to encapsulate all our JavaScript code. The term client-side JavaScript refers speci\ufb01cally to JavaScript code that is asso- ciated with HTML pages and therefore runs in the browser. Each page in your app that wants to use JavaScript functions or variables must include the necessary JavaScript code itself. The recommended and unobtrusive way to do this is using a script tag referencing the \ufb01le containing the code, as Figure 6.5 shows. The Rails view helper javascript_include_tag \u2019application\u2019, which generates the above tag, can be placed in your app/views/layouts/application.html.erb or other layout template JSON.org de\ufb01nes JSON\u2019s precise syntax and lists parsing libraries available for other languages. 6.2. INTRODUCING ECMASCRIPT 161 Name JSLint Tool type Web-based Description Copy and paste your code into the form at jslint.com to check it for errors and stylistic pitfalls according to the guidelines in Doug Crockford\u2019s JavaScript: The Good Parts. Also checks for legal but unsafe constructions; some developers \ufb01nd it overly pedantic. JavaScript Lint Closure Command-line Matthias Miller\u2019s command-line tool, installed by our setup script, reports errors and warnings based on the same JavaScript interpreter used by the Firefox browser. To run it, type jsl -process \ufb01le.js Command-line Google\u2019s source-to-source compiler5 to better JavaScript, removing dead code and minifying as it goes, and giving er- rors and warnings. Its associated Linter tool goes even further and enforces Google\u2019s JavaScript style guidelines. JavaScript translates YUI Command-line Yahoo\u2019s YUI Compressor6 mini\ufb01es JavaScript and CSS more aggressively JSONlint Web-based than some other tools and looks for stylistic problems in the process. This tool at jsonlint.com7 checks your JSON data structures for syntax er- rors. Figure 6.4: A variety of tools for debugging your JavaScript code and associated data structures and server interactions. One challenge is that just as with the C language, there are many competing coding guidelines for JavaScript\u2014Google\u2019s, Yahoo\u2019s, the Node.js project\u2019s, and others\u2014and different tools check and enforce different coding styles. https://gist.github.com/b23448e3c5ddd3c066ddb3153\ufb00a11e6 1 < script src = \" / public / javascripts / application . js \" > </ script > <! - - BAD : embedding scripts directly in page , esp . in body --> < script > <! - - // BAD : \" hide \" script body in HTML comment ( modern browsers may not see script at all ) if !( fieldsValid ( getElementById ( ' addr ') ) ) { // BAD : > and < may confuse browser 's HTML parser alert ( ' >>> Please fix errors & resubmit . <<< ') ; // BAD : checkValid is global // < html > function checkValid () { < head > < title > Update Address </ title > </ head > < body > https://gist.github.com/b6968a45858d79e5f5edb2a76670e1a3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 </ form > </ body > </ html > } // BAD : \" hide \" end of HTML comment ( l .3) in JS comment : --> </ script > <! - - BAD : using HTML attributes for JS event handlers --> < form onsubmit =\" return checkValid () \" id =\" addr \" action =\"/ update \" > < input onchange =\" RP . filter_adult \" type =\" checkbox \"/ > <! - - BAD : URL using ' javascript : ' --> <a href =\" javascript : back () \" > Go Back </ a > Figure 6.5: Top: The unobtrusive and recommended way to load JavaScript code in your HTML view(s). Bottom: Three obtrusive ways to embed JavaScript into HTML pages, all deprecated because they mix JavaScript code with HTML markup. Sadly, all are common in the \u201cstreet JavaScript\u201d found on poorly-engineered sites, yet all are easily avoided by using the script src= method and by using the unobtrusive techniques described in the rest of this chapter for connecting JavaScript code to HTML elements. The Rails asset pipeline performs similar operations on CSS \ufb01les in your project, and can even arrange (with the help of external plug-ins or gems) to have images and other large static assets served from a content distribution network. 162 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT that is part of every page served by your app. If you then place your code in one or more separate .js \ufb01les in app/assets/javascripts, when you deploy to production Rails will do the following steps automatically: 1. Concatenate the contents of all JavaScript \ufb01les in this directory; 2. Minify the result by removing whitespace and comments, and possibly compress the result; 3. Place the result in a single large \ufb01le in the public subdirectory that will be served directly by the presentation tier with no Rails intervention; 4. Adjust the URLs emitted by javascript_include_tag so that the user\u2019s browser loads not only your own JavaScript \ufb01les but also the jQuery library. This automatic behavior, supported by modern production environments including Heroku, is called the asset pipeline and is described more fully in this guide8. You might think it wasteful for the user\u2019s browser to load a single enormous JavaScript \ufb01le, especially if only a few pages in your app use JavaScript and any given page only uses a small sub- set of your JavaScript code. But the user\u2019s browser only loads the large \ufb01le once and then caches it until you redeploy your app with changed .js \ufb01les. Also, in development mode, the asset pipeline skips the \u201cprecompilation\u201d process and just loads each of the JavaScript \ufb01les separately, since they\u2019re likely to be changing frequently while you\u2019re developing. Summary of Client-Side JavaScript and HTML: \u2022 Like Ruby, JavaScript is interpreted and dynamically typed. The basic object type is a hash with keys that are strings and values of arbitrary type, including other hashes. \u2022 The fundamental JavaScript data type is an object, which is an unordered collection of property names and values, similar to a hash. Since objects can nest, they can represent hierarchical data structures. JavaScript\u2019s simple object-literal notation is the inspiration for the JSON data interchange format. \u2022 The preferred unobtrusive way to associate JavaScript with an HTML page is to include in the HTML document\u2019s head element a script tag whose src attribute gives the URL of the script itself, so that the JavaScript code can be kept separate from HTML markup. The Rails helper javascript_include_tag generates the correct URL that takes advantage of Rails\u2019 asset pipeline. Self-Check 6.2.1. Is every valid JSON object parsable by JavaScript? If not, give an example of one that isn\u2019t. Yes, every valid JSON object is a valid JavaScript object. Whereas JSON requires quotes around every slot name, JavaScript sometimes does and sometimes doesn\u2019t, but it is always safe to use quotes. Self-Check 6.2.2. If we make sure to put slot names in quotes, is every valid JavaScript object a valid JSON object? If not, give an example of one that isn\u2019t. No, even if all the slot names are quoted, some JavaScript objects are not valid JSON. For 6.3. CLASSES, FUNCTIONS AND CONSTRUCTORS 163 example, if one of the object\u2019s slots is a function, that object would not be valid JSON, since JSON slot values are limited to simple types (numbers, strings, Booleans) and collections (arrays or other JSON objects)."
    ]
  },
  {
    "id": "sec_0266",
    "title": "6.3 Classes, Functions and Constructors",
    "pages": [
      175,
      176,
      177,
      178
    ],
    "text_blocks": [
      "In Chapter 2 we mentioned that object-orientation and class inheritance are distinct language design concepts, although many people mistakenly con\ufb02ate them because popular languages like Java use both. While JavaScript is object-oriented and supports inheritance, it does not have classes, despite the addition of a new class keyword in the ECMAScript 6 standard9. However, classes have not been added to JavaScript; the keyword is syntactic sugar for JavaScript\u2019s built-in mechanism of prototype inheritance, in which every object inherits from some prototype object and delegates to its prototype any slot lookup that fails on the object itself. Unfortunately, the design of this mechanism has led to confusion for newcomers to JavaScript, especially regarding the behavior of the keyword this. We will concern our- selves with three common uses of this. In this section we introduce the \ufb01rst two of these uses, and an associated pitfall. In Section 6.6 we introduce the third use. Lines 1\u20138 of Figure 6.6 show a function called Movie. This syntax for de\ufb01ning functions may be unfamiliar, whereas the alternate syntax in lines 9\u201311 looks comfortably familiar. Nonetheless, we will use the \ufb01rst syntax for two reasons. First, unlike Ruby, functions in JavaScript are true \ufb01rst-class objects\u2014you can pass them around, assign them to variables, and so on. The syntax in line 1 makes it clear that Movie is simply a variable whose value happens to be a function. Second, although it\u2019s not obvious, the variable Movie in line 9 is being declared in JavaScript\u2019s global namespace\u2014hardly beautiful. In general we want to minimize clutter in the global namespace, so we will usually create one or a few objects named by global variables associated with our app, and all of our JavaScript functions will be the values of properties of those objects. If we call the Movie function using JavaScript\u2019s new keyword (line 13), the value of this in the function body will be a new JavaScript object that will eventually be returned by the function, similar to Ruby\u2019s self inside an initialize constructor method. In this case, the returned object will have properties title, year, rating, and full_title, the last of which is a property whose value is a function. If line 14 looks like a function call to you, then you\u2019ve been hanging around Ruby too long; since functions are \ufb01rst-class objects in JavaScript, this line just returns the value of full_title, which is the function itself, not the result of calling it! To actually call it, we need to use parentheses, as in line 15. When we make that call, within the body of full_title, this will refer to the object whose property the function is, in this case pianist. Remember, though, that while these examples look just like calling a class\u2019s constructor and calling an instance method in Ruby, JavaScript has no concept of classes or instance methods. In fact, there is nothing about a particular JavaScript function that makes it a con- structor; instead, it\u2019s the use of new when calling the function that makes it a constructor, causing it to create and return a new object. The reason this works is because of JavaScript\u2019s prototype inheritance mechanism, which we don\u2019t discuss further (but see the Elaboration below to learn more). Nonetheless, forgetting this subtle distinction may confuse you when you expect class-like behaviors and don\u2019t get them. However, a JavaScript misfeature can trip us up here. It is (unfortunately) perfectly legal Prototype inheritance comes from the experimental language Self developed at the legendary Xerox PARC (Palo Alto Research Center), where many technologies that de\ufb01ne personal computing were invented, and appeared in the NewtonScript language that powered Apple\u2019s \ufb01rst ill-fated \u201cpersonal digital assistant.\u201d Check your browser\u2019s documentation for how to display its built-in JavaScript console, where you can try these examples interactively. 164 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT }; let Movie = function ( title , year , rating ) { return ( this . title + ' ( ' + this . year + ') ') ; }; function Movie ( title , year , rating ) { this . title = title ; this . year = year ; this . rating = rating ; this . full_title = function () { // \" instance method \" https://gist.github.com/e6bf83dabd38ebde2a25e22b0a98957b 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 } // using ' new ' makes Movie the new objects ' prototype : pianist = new Movie ( ' The Pianist ' , 2002 , 'R ') ; pianist . full_title ; pianist . full_title () ; // = > \" The Pianist (2002) \" // BAD : without ' new ' , ' this ' is bound to global object in Movie call !! juno = Movie ( ' Juno ' , 2007 , 'PG -13 ') ; // DON 'T DO THIS !! juno ; juno . title ; juno . full_title () ; // undefined // error : ' undefined ' has no properties // error : ' undefined ' has no properties // = > function () {...} // this syntax may look familiar ... // ... Node.js provides a different global object, called global, that provides these values. The JavaScript identi\ufb01er globalThis always refers to the global object, whatever it happens to be named. Figure 6.6: Since functions are \ufb01rst-class objects, it is \ufb01ne for an object to have a property whose value is a function, as full_title is. We will make extensive use of this characteristic. Note the pitfall in lines 14\u201318. to call Movie as a plain old function without using the new keyword, as in line 17. If you do this, JavaScript\u2019s behavior is completely different in two horrible, horrible ways. First, in the body of Movie, this will not refer to a brand-new object but instead to the global object, which de\ufb01nes various special constants such as Infinity, NaN, and null, and supplies vari- ous other parts of the JavaScript environment. When JavaScript is run in a browser, the global object happens to be a data structure representing the browser window. Therefore, lines 2\u20135 will be creating and setting new properties of this object\u2014clearly not what we intended, but unfortunately, when this is used in a scope where it would otherwise be unde\ufb01ned, it refers to the global object, a serious design defect in the language. (See Fallacies and Pitfalls and To Learn More if you want to learn about the reasons for this odd behavior, a discussion of which is beyond the scope of this introduction to the language.) Second, since Movie doesn\u2019t explicitly return anything, its return value (and therefore the value of juno) will be undefined. Whereas a Ruby function returns the value of the last expression in the function by default, a JavaScript function returns undefined unless it has an explicit return statement. (The return in line 6 belongs to the full_title function, not to Movie itself.) Hence, lines 19\u201320 give errors because we\u2019re trying to reference a property (title) on something that isn\u2019t even an object. You can avoid this pitfall by rigorously following the widespread JavaScript convention that a function\u2019s name should be capitalized if and only if the function is intended to be called as a constructor using new. Functions that are not \u201cconstructor-like\u201d should be given names beginning with lowercase letters. 6.3. CLASSES, FUNCTIONS AND CONSTRUCTORS 165 Summary: Functions and Constructors \u2022 JavaScript functions are \ufb01rst-class objects: they can be assigned to variables, passed to other functions, or returned from functions. \u2022 Although JavaScript doesn\u2019t have classes, one way of managing namespaces in an orderly way in JavaScript is to store functions as object properties, allowing a single object (hash) to collect a set of related functions as a class would. \u2022 If the new keyword is used to call a function, this in the function body will refer to a new object whose property values can be initialized in the \u201cconstructor.\u201d This mechanism is similar to creating new instances of a class, though JavaScript lacks classes. \u2022 However, if a function is called without the new keyword, this in the function body will refer to the global object, which is almost never what you wanted, and the function will return undefined. To avoid this pitfall, capitalize the names of constructor-like functions intended to be called with new, but don\u2019t capitalize the names of any other functions. \u2022 JavaScript has no classes; the new keyword class in ES6 does not introduce any new mechanisms into JavaScript, but is syntactic sugar to make the syntax for prototype-based inheritance look more similar to the syntax for de\ufb01ning classes in class-based languages. Elaboration: Prototypal inheritance Every JavaScript object inherits from exactly one prototype object\u2014new strings inherit from String.prototype, new arrays from Array.prototype, and so on, up to Object (the empty object). If you look up a property on an object that doesn\u2019t have that property, its prototype is checked, then its prototype\u2019s prototype, and so on until one of the prototypes responds with the property or undefined is returned. Given this background, the effect of calling a function using the new keyword is to create a new object whose prototype is the same as the function\u2019s prototype. Prototypes come from Self, a language originally designed at the legendary Xerox PARC and which heavily in\ufb02uenced NewtonScript, the programming language for the ill-fated Apple Newton \u201chandheld.\u201d Proper use of prototypal inheritance affords an effective kind of im- plementation reuse that is different from what classes provide. Unfortunately, as Crockford notes in JavaScript: The Good Parts (Crockford 2008), JavaScript\u2019s implementation of proto- typal inheritance is halfhearted and uses a confusing syntax, perhaps in an effort to resemble \u201cclassical\u201d languages with class inheritance. the difference between evaluating square.area and is let square = { Self-Check 6.3.1. What square.area() in the following JavaScript code? https://gist.github.com/cc72ba2\ufb0092c2f387ebac8ab56e54af7 1 2 3 4 5 6 side : 3 , area : function () { return this . side * this . side ; }; } 166 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT Figure 6.7: A simpli\ufb01ed view of the DOM tree corresponding to the RottenPotatoes \u201clist of movies\u201d page with skeletal HTML markup. An open triangle indicates places where we\u2019ve elided the rest of the subtree for brevity. this.document is set to point to the DOM tree\u2019s root when a page is loaded. square.area() is a function call that in this case will return 9, whereas square.area is an unapplied function object. Self-Check 6.3.2. Given the code in Self-Check 6.3.1, explain why it\u2019s is incorrect to write s=new square. square is just an object, not a function, so it cannot be called as a constructor (or at all). Self-Check 6.3.3. In Ruby, when a method call takes no arguments, the empty parentheses following the method call are optional. Why wouldn\u2019t this work in JavaScript? Because JavaScript functions are \ufb01rst-class objects, a function name without parentheses would be an expression whose value is the function itself, rather than a call to the function."
    ]
  },
  {
    "id": "sec_0267",
    "title": "6.4 The Document Object Model (DOM) and jQuery",
    "pages": [
      178,
      179,
      180,
      181
    ],
    "text_blocks": [
      "The World Wide Web Consortium Document Object Model (W3C DOM)10 is \u201ca platform- and language-neutral interface that will allow programs and scripts to dynamically access and update the content, structure and style of documents\u201d\u2014in other words, a standard represen- tation of an HTML, XML, or XHTML document consisting of a hierarchy of elements. A DOM element is recursively de\ufb01ned in that one of its properties is an array of child elements, as Figure 6.7 shows. Hence a DOM node representing the <html> element of an HTML page is suf\ufb01cient to represent the whole page, since every element on a well-formed page is a descendant of <html>. Other DOM element properties correspond to the HTML element\u2019s attributes (href, src, and so on). When a browser loads a page, the HTML of the page is parsed into a DOM tree similar to Figure 6.7. How does JavaScript get access to the DOM? When JavaScript is embedded in a browser, the global object, named by the global variable window, de\ufb01nes additional browser-speci\ufb01c properties and functions, collectively called the JSAPI. Whenever a new page is loaded, a new global window object is created that shares no data with the global objects of other visible pages. One of the properties of the global object is window.document, which is the root element of the current document\u2019s DOM tree and also de\ufb01nes some functions to query, DOM technically refers to the standard itself, but developers often use it to mean the speci\ufb01c DOM tree corresponding to the current page. The call jQuery.noConflict() \u201cunde\ufb01nes\u201d the $ alias, in case your app uses the browser\u2019s built-in $ (usually an alias for document.- getElementById) or loads another JavaScript library that also tries to de\ufb01ne $. Some jQuery developers use $ to pre\ufb01x variable names that refer to jQuery-wrapped objects, as in var $h1=$(\u2019#h1\u2019). 6.4. THE DOCUMENT OBJECT MODEL (DOM) AND JQUERY 167 traverse, and modify the DOM; one of the most common is getElementById, which you may have run across while perusing others\u2019 JavaScript code. However, to avoid compatibility problems stemming from different browsers\u2019 implemen- tations of the JSAPI, we will bypass the \u201cplain\u201d JSAPI functions entirely in favor of jQuery\u2019s jQuery also adds additional features and behav- more powerful \u201cwrappers\u201d around them. iors absent from the baseline JSAPIs, such as animations and better support for CSS and AJAX (Section 6.7). jQuery de\ufb01nes a global function jQuery() (aliased as $()) that, when passed a CSS selector, returns all of the current page\u2019s DOM elements matching that se- For example, jQuery(\u2019#movies\u2019) or $(\u2019#movies\u2019) would return the single lector. element whose ID is movies, if one exists on the page; $(\u2019h1.title\u2019) would return all the h1 elements whose CSS class is title. A more general version of this functionality is .find(selector), which only searches the DOM subtree rooted at the target. To illustrate the distinction, $(\u2019p span\u2019) \ufb01nds any span element that is contained inside a p element, whereas if elt already refers to a particular p element, then elt.find(\u2019span\u2019) only \ufb01nds span elements that are descendants of elt. Whether you use $() or find, the return value is a node set (collection of one or more el- ements) matching the selector, or null if there were no matches. Each element is \u201cwrapped\u201d in jQuery\u2019s DOM element representation, giving it abilities beyond the browser\u2019s built-in JSAPI. From now on, we will refer to such elements as \u201cjQuery-wrapped\u201d elements, to dis- tinguish them from the representation that would be returned by the browser\u2019s JSAPI. In particular, you can do various things with jQuery-wrapped elements in the node set, as Fig- ure 6.8 shows: \u2022 To change an element\u2019s visual appearance, de\ufb01ne CSS classes that create the desired appearances, and use jQuery to add or remove CSS class(es) from the element at run- time. \u2022 To change an element\u2019s content, use jQuery functions that set the element\u2019s HTML or plain text content. \u2022 To animate an element (show/hide, fade in/out, and so on), invoke a jQuery function on that element that manipulates the DOM to achieve the desired effect. Note, however, that even when a node set includes multiple matching elements, it is not a JavaScript array and you cannot treat it like one: you cannot write $(\u2019tr\u2019)[0] to select the \ufb01rst row of a table, even if you \ufb01rst call jQuery\u2019s toArray() function on the node set. Instead, following the Iterator design pattern, jQuery provides an each iterator de\ufb01ned on the collection that returns one element at a time while hiding the details of how the elements are stored in the collection, just as Array#each does in Ruby. Screencast 6.4.1 shows some simple examples of these behaviors from the browser\u2019s JavaScript console. We will use these to implement the features of Screencast 6.1.1. Screencast 6.4.1: Manipulating the DOM with jQuery. http://youtu.be/kwdYHc5M0Ac jQuery makes it easy to manipulate the DOM from JavaScript and provides a built-in library of useful visual effects. These simple examples show that JavaScript can not only read element and content information on the page, but also modify the elements, causing the browser to redraw them. This behavior is the key to client-side JavaScript. 168 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT Property or function, example $(dom-element) $(this) is(cond) addClass(), removeClass(), hasClass() insertBefore(), insertAfter() remove() replaceWith(new) clone() html(), text() val() attr(attr,[newval]) $(\u2019img\u2019).attr(\u2019src\u2019, \u2019http://imgur.com/xyz\u2019) hide(duration,callback), show(), toggle() slideUp(), slideDown(), slideToggle() fadeOut(), fadeIn(), fadeTo(duration,target,callback) evt(func) $(\u2019li\u2019).click(function() { $(this).hide(); }); Value/description Returns a set of jQuery-wrapped DOM element(s) speci\ufb01ed by the argument, which can be a CSS3 selector (such as \u2019span.center\u2019 or \u2019#main\u2019), the ele- ment object returned by the browser\u2019s getElementById function, or in an event handler, the element that received the event, named by this. The return value of this function is suitable as the target for any of the below calls. (Recall that the term target is used in JavaScript the way receiver is used in Ruby.) the element if Test \u2019:disabled\u2019. Note that symbols, though JavaScript doesn\u2019t have symbols. is \u2019:checked\u2019, \u2019:selected\u2019, \u2019:enabled\u2019, these strings were chosen to resemble Ruby the target element(s) before or after Shortcuts for manipulating the class attribute: add or remove the speci\ufb01ed CSS class (a string) from the element, or test whether the given class is currently associated with the element. Insert newElt.insertBefore(existingElt) existingElt, which must exist. Remove the target element(s) from the DOM. Replace the target element(s) with the new element(s) provided. Return a complete copy of the target element, recursively cloning its descendants. Return (with no argument) or set (with one argument) the element\u2019s complete HTML content or plain-text content. If the element has other elements nested inside it, you can replace its HTML with nested elements but don\u2019t have to, but replacing its text will obliterate the nested elements. the argument. newElt is, before inserts That just Return (with no argument) or set (with one argument) the current value of the element. For text boxes, value is the current string contents; for buttons, the button\u2019s label; for select menus, the text of the currently selected value. Return or (with second argument) set the value of the given attribute on the ele- ment. Hide or show elements selected by the target. Optional duration is one of \u2019fast\u2019, \u2019slow\u2019, or the integer number of milliseconds that the animation should last. Optional callback is a function to call when animation completes. Other sets of animations with same arguments include slideDown/slideUp/ slideToggle and fadeOut/fadeIn. For fadeTo, second argument is target opacity, from 0.0 (transparent) to 1.0 (opaque). Set func as the handler for event evt on the element(s) selected by the target. func can be an anonymous function or a named function. See Figure 6.9 for some of the most important event types. Figure 6.8: Some attributes and functions de\ufb01ned on jQuery\u2019s enhanced DOM element objects; they should be called with the appropriate element or collection of elements as the target of the call (like receiver in Ruby). Functions that only make sense applied to a single element, such as attr, apply to the \ufb01rst element when used on a collection of elements. Functions that can both read and modify element properties act as getters when the \ufb01nal (or only) argument is absent, and setters when it\u2019s present. Unless otherwise noted, all functions return their target, so calls can be chained, as in elt.insertBefore(...).hide(). See the jQuery documentation12 for more features beyond this subset. 6.5. THE DOM AND ACCESSIBILITY 169 Finally, as we will see, the jQuery() or $() function is overloaded : its behavior de- pends on the number and types of arguments with which it\u2019s called. In this section we intro- duced just one of its four behaviors, namely for selecting elements in the DOM; we will soon see the others. Summary of the DOM and jQuery: \u2022 The World Wide Web Consortium Document Object Model (W3C DOM) is a language-independent representation of the hierarchy of elements that constitute an HTML document. \u2022 All JavaScript-enabled browsers provide JavaScript language bindings to access and traverse the DOM. This set of functionality, together with JavaScript access to other browser features, is collectively called the JavaScript Application Programming In- terface or JSAPI. \u2022 The powerful jQuery library provides a uniform adapter to browsers\u2019 differing JS- APIs and adds many enhanced functions such as CSS-based DOM traversal, anima- tion, and other special effects. Elaboration: To jQuery or not to jQuery? jQuery has evolved over many years, and many packages now build on it, including the Bootstrap front-end framework. As of this writing, Bootstrap version 5 is aiming to eliminate jQuery as a dependency by rewriting the code that relies on it using \u201cplain JavaScript\u201d and browsers\u2019 JSAPIs. Some developers see this as a welcome change: it eliminates a dependency on legacy code, eliminates some cases where jQuery and Bootstrap CSS styles con\ufb02ict with each other, and reduces the total footprint of Bootstrap. Others question its utility since the amount of code actually saved is not very much by today\u2019s standards, and re-creating jQuery\u2019s well-tested functionality from scratch is hardly DRY and is likely to introduce new bugs. This debate is a modern example of the ever-present tension between continuing to rely on well-tested legacy code versus reimplementing a subset of the legacy code\u2019s functionality from scratch as other frameworks evolve. Self-Check 6.4.1. Why is this.document, when it appears outside the scope of any func- tion, equivalent to window.document? Outside of any function, the value of this is the global object. When JavaScript runs in a Web browser, the global object is the window object. Self-Check 6.4.2. True or false: even after the user closes a window in her Web browser, the JavaScript code associated with that window can still access and traverse the HTML docu- ment the window had been displaying. False. Each new HTML document gets its own global object and DOM, which are de- stroyed when the document\u2019s window is closed."
    ]
  },
  {
    "id": "sec_0268",
    "title": "6.5 The DOM and Accessibility",
    "pages": [
      181,
      182,
      183,
      184,
      185
    ],
    "text_blocks": [
      "Many people navigate a website by clicking on buttons or links. This relies on using a mouse or touchscreen as well as being able to perceive the visual affordances of the web page. Ac- The HTML Speci\ufb01cation13 is constantly evolving and is the de\ufb01nitive list of existing elements. 170 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT cessibility, sometimes abbreviated a11y, is about ensuring that your users can access your applications using different input methods. For example, some users may need (or prefer) to navigate a website using the keyboard, so they must have a way of \u201cclicking\u201d on a button, perhaps by pressing the space bar on their keyboards. Blind or low-vision users may use screen reader software or other assistive technology that translates text and interactions on screen into audio, and to include these users you must ensure there\u2019s a way for the com- puter to generate a text-based description of your page elements. The alt attribute of an img element, which has been part of HTML since the beginning, is one simple example of providing a textual alternative to visual element. Section 1.8 motivated the use of HTML/CSS frameworks. One advantage of a good framework is that it provides some built-in support for using the techniques we describe in this section to improve your app\u2019s accessibility: using Semantic HTML to structure your pages, and adding ARIA (Accessible Rich Internet Applications) attributes to give hints to screen readers. Semantic HTML. HTML is very \ufb02exible: in principle you can accomplish just about any visual styling using only div (\u201cdivider\u201d) elements with appropriate CSS rules. However, a div doesn\u2019t convey much about the purpose of that element. Semantic HTML involves choosing the most appropriate HTML element type tag that describes the element\u2019s logical role on the page, so that (for example) a screen reader can convey that a particular element is a button, heading, paragraph, or maybe even a timestamp. Beyond accessibility, using the proper HTML element type communicates your intentions to other developers on the project, and allows search engines to improve their search results. We distinguish three categories of HTML elements: structural, content, and interactive. Structural elements break down large and often visually-distinct sections of a web page, allowing screen readers to quickly jump between sections: \u2022 h1. . . h6 are elements that give your page an outline. Most pages start with h1. \u2022 nav is used for sections of links that direct users to different parts of your website. Commonly, this is used in a \u201cnavigation bar\u201d at the top of a web page. \u2022 main This is for the body of your web page. There should only be one of these per page. \u2022 header and footer These are common sections that you might include. They should be outside of the main content. \u2022 section should be used to group elements into a larger component, like a toolbar. Content elements give meaningful descriptions to content that is primarily designed to be read, such as text and graphics: \u2022 p is for a \u201cparagraph\u201d, which can include other elements inside, like img, a, and so on. \u2022 strong and em for bold and italic text, respectively. \u2022 time is useful for dates and times, and many browsers give users additional features, like the ability to easily create a calendar link. Interactive elements are those with which users interact, so they are perhaps the most important to target for accessibility. 6.5. THE DOM AND ACCESSIBILITY 171 \u2022 a (\u201canchor\u201d) links to another page or another part of the same page. \u2022 button is the main way to take some action. When you use a button, the browser automatically provides functions for keyboard accessibility, as well as describing the button as \u201cclickable\u201d to a screen reader. \u2022 input is the primary method for accepting user input, such as within a form. inputs have a type attribute that can take on one of 22 different values14 such as email, password, checkbox, and so on. \u2022 select builds simple dropdown lists. Buttons and inputs come with quite a few default features that are critical for accessibility. However, each of these components can be controlled individually. \u2022 Focus: An interactive element needs to be able to \u201creceive focus\u201d, which means that when a user is navigating a web page with a keyboard, they are able to take actions on a focused element. (This is analogous to how the styling of an element might change when you hover over it.) Focusability is controlled by the tabindex attribute. DOM elements like a button have a property tabindex=\"0\" internal to them. If you\u2019re trying to make a span interactive, you\u2019ll need to take care to manually set this. \u2022 Keyboard Actions: When a button or link has focus, a button is activated when Enter or Space is pressed, but links are followed only when Enter is pressed. When adding interactivity to other element types, take care to add an onkeypress event handler that responds to the appropriate keys. The keypress handler will often call the onclick handler, mirroring the behavior of the built-in button. \u2022 Visual Focus: Using the :focus CSS pseudo-selector allows styling an element differ- ently when it has focus, so that when users tab with the keyboard they can see which element is active. A corollary of the Semantic HTML guideline of using the most appropriate element for a given task is that you shouldn\u2019t deliberately make non-interactive elements interactive unless you have no other alternatives, such as having a plain p (paragraph) element respond to clicks. Instead, \ufb01nd a way to achieve your goal using existing interactive elements such as buttons and links. Going beyond using Semantic HTML to select the right elements, we can further improve accessibility using WAI-ARIA, or simply ARIA: The Web Accessibility Initiative/Accessible Rich Internet Applications speci\ufb01cation15 stewarded by the World Wide Web Consortium (W3C), which speci\ufb01es how to increase the accessibility of web pages, in particular those enhanced by JavaScript. The \ufb01rst rule of ARIA is \u201cDon\u2019t use ARIA\u201d\u2014that is, try to structure your HTML and JavaScript so that the additional support ARIA provides is unnecessary. ARIA is a purely descriptive tool: Adding ARIA attributes to an element will not change how the element works, but only how it is read aloud by the screen reader. ARIA applies to both interactive and non-interactive elements. In ARIA, every HTML element has a role and a label. The ARIA speci\ufb01cation de\ufb01nes the allowed roles16. Many roles such as link and button follow from the HTML element type 172 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT itself, but others describe more complex UI elements such as \u201ctooltip\u201d that do not correspond directly to a speci\ufb01c HTML element type. The label, sometimes called an accessible name, is typically generated from the visual text of the element, and sometimes includes the role. For example a button (<button>Submit</button>) might be read as \u201cSubmit, button\u201d by a screen reader. But when there is no text content in an interactive element, such as button whose content is an icon, for accessibility you must provide a label using ARIA. For example, adding the at- tribute aria-label=\"add to cart\" to an element will cause the screen reader to read the phrase \u201cadd to cart.\u201d Labels should be detailed enough to convey the element\u2019s purpose, but as concise as possible. Finally, in this chapter we\u2019ve seen many examples of how JavaScript can \u201clive-update\u201d the page\u2019s DOM (and therefore the rendered HTML) after the page has been loaded, even if the user doesn\u2019t do anything, as in the case of a page change triggered by a timer event. But if a page doesn\u2019t specify when and where content might be updated, then screen-reader users might not realize something has changed. Adding the aria-live attribute to an element tells a screen reader to notify the user when the content in that element changes. Most often, you should use aria-live=\"polite\", which tries to minimize interruptions to the user, but in special cases, you can use aria-live=\"assertive\" to convey an urgent message. Although mature HTML/CSS frameworks such as Bootstrap include appropriate ARIA notations on the elements and components they provide, accessibility is an ongoing con- cern during app development. The Web Content Accessibility Guidelines17WCAG are the requirements that applications need to follow to be considered legally accessible in many ju- risdictions. The axe browser extension18, available for Chrome and Firefox, runs numerous checks for WCAG 2 compliance on any displayed page. Similarly, the W3C maintains the ARIA Authoring Practices19 speci\ufb01cation, which contains dozens of examples (with working JavaScript) for common UI patterns across applications. Summary of DOM and Accessibility: \u2022 Accessibility, sometimes abbreviated a11y, is about ensuring that your users can interact with your app using a variety of input and output methods. \u2022 One way to make the page friendly to assistive technologies that accomplish this is to clearly identify the logical role of each element in the page, not just its visual appearance. \u2022 Semantic HTML categorizes elements into structural (describe page structure), con- tent (generic text, images, specialized text such as dates and times), or interactive (allows user input). The page\u2019s logical structure and the roles of different portions of the page are suggested by appropriate choices of HTML elements during page authoring. \u2022 When Semantic HTML is not enough, such as for components (logical structures on a page made up of multiple elements) or JavaScript-enhanced UI effects, the ARIA (Accessible Rich Internet Applications) standard provides ways to attach additional attributes to elements that cue a11y behaviors in assistive software. 6.6. EVENTS AND CALLBACKS 173 Events on arbitrary elements Events on user-editable con- trols (forms, checkboxes, ra- dio buttons, text boxes, text \ufb01elds, menus) mouseenter/mouseleave, dblclick, mousedown/mouseup, click, keypress (event.which gives the ASCII code of the key pressed) focus/blur (element gains/loses gains/loses focus) change \ufb01res when any control\u2019s state or content is changed. select (user selects text; string event.which is selected text) submit \ufb01res when the user attempts to submit the form by any means. focus), focusin/focusout (parent The less precise term Dynamic HTML was sometimes used in the past to refer to the effects of combining JavaScript-based DOM manipulation and CSS. Figure 6.9: A few of the JavaScript events de\ufb01ned by the jQuery API. Set a handler for an event with element.on(\u2019evt\u2019, func) or as a shortcut, element.evt(func). Hence, $(\u2019h1\u2019).on(\u2019click\u2019, function() {...}) is equivalent to $(\u2019h1\u2019).click(function() {...}). The callback func will be passed an argument (which you\u2019re free to ignore) whose value is the jQuery Event object describing the event that was triggered. Remember that on and its shortcuts will bind the callback to all elements matching the selector, so be sure the selector you pass is unambiguous, for example by identifying an element by its ID."
    ]
  },
  {
    "id": "sec_0269",
    "title": "6.6 Events and Callbacks",
    "pages": [
      185,
      186,
      187,
      188,
      189,
      190
    ],
    "text_blocks": [
      "So far all of our DOM manipulation has been by typing JavaScript commands directly. As you\u2019ve no doubt guessed, much more interesting behaviors are possible when DOM manip- ulation can be triggered by user actions. As part of the JSAPI for the DOM, browsers allow attaching JavaScript event handlers to the user interface: when the user performs a certain UI action, such as clicking a button or moving the mouse into or out of a particular HTML element, you can designate a JavaScript function that will be called and have the opportunity to react. This capability makes the page behave more like a desktop UI in which individ- ual elements respond visually to user interactions, and less like a static page in which any interaction causes a whole new page to be loaded and displayed. Figure 6.9 summarizes the most important events de\ufb01ned by the browser\u2019s JSAPI and improved upon by jQuery. While some are triggered by user actions on DOM elements, others relate to the operation of the browser itself or to \u201cpseudo-UI\u201d events such as form submission, which may occur via clicking a Submit button, pressing the Enter key (in some browsers), or another JavaScript callback causing the form to be submitted. To attach a behavior to an event, simply provide a JavaScript function that will be called when the event \ufb01res. We say that this function, called a callback or event handler, is bound to that event on that DOM element. Although events are automatically triggered by the browser, you can also trigger them yourself: for example, e.trigger(\u2019click\u2019) triggers the click event handler for element e. As we will see in Section 6.8, this ability is useful when testing: you can simulate user interaction and check that the correct changes are applied to the DOM in response to a UI event. Browsers de\ufb01ne built-in behavior for some events and elements: for example, clicking on a link visits the linked page. If such an element also has a programmer-supplied click handler, the handler runs \ufb01rst; if the handler returns a truthy value (Figure 6.2), the built-in behavior runs next, but if the handler returns a falsy value, the built-in behavior is suppressed. What if an element has no handler for a user-initiated event, as is the case for images? In that case, its parent element in the DOM tree is given the chance to respond to the event handler. For example, if you click on an img element inside a div and the img has no click handler, then the div will receive the click event. This process continues until some element handles the event or it \u201cbubbles\u201d all the way up to the top-level window, which may or may not have a built-in response depending on the event. 174 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT // ' this ' is * unwrapped * element that received event ( checkbox ) if ( $ ( this ) . is ( ': checked ') ) { }; } else { $ ( '. adult ') . hide () ; $ ( '. adult ') . show () ; let MovieListFilter = { filter_adult : function () { https://gist.github.com/d6d0e7d7554f93f952d0200d3121fa29 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // construct checkbox with label let labelAndCheckbox = } , setup : function () { } $ ( ' < label for =\" filter \" > Only movies suitable for children </ label > ' + ' < input type =\" checkbox \" id =\" filter \"/ > ' ) ; labelAndCheckbox . insertBefore ( '# movies ') ; $ ( '# filter ') . change ( MovieListFilter . filter_adult ) ; } $ ( MovieListFilter . setup ) ; // run setup function when document ready Figure 6.10: Using jQuery to add a \u201c\ufb01lter movies\u201d checkbox to RottenPotatoes\u2019 list of movies page; put this code in app/assets/javascripts/movie_list_filter.js. The text walks through the example in detail, and additional \ufb01gures in the rest of the chapter generalize the techniques shown here. Our examples use jQuery\u2019s DOM manipulation features rather than the browser\u2019s built-in ones because the jQuery API is more consistent across different browsers than the of\ufb01cial W3C DOM speci\ufb01cation. Our discussion of events and event handlers motivates the third common use of JavaScript\u2019s this keyword (recall that Section 6.3 introduced the \ufb01rst two uses). When an event is handled, in the body of the event handler function, jQuery will arrange for this to refer to the element to which the handler is attached (which may not be the element that originally received the event, if the event \u201cbubbled up\u201d from a descendant). However, if you were programming without jQuery, the value of this in an event handler is the global object (document.window), and you have to examine the event\u2019s data structure (usually passed as the \ufb01nal argument to the handler) to identify the element that handled the event. Since han- dling events is such a common idiom, and most of the time an event handler wants to inspect or manipulate the state of the element on which the event was triggered, jQuery is written to explicitly set this to that DOM element. Putting all these pieces together, Figure 6.10 shows the client-side JavaScript to imple- ment a checkbox that, when checked, will hide any movies with ratings other than G or PG. Our general strategy for JavaScript can be summarized as: 1. Identify the DOM elements we want to operate on, and make sure there is a convenient and unambiguous way of selecting them using $(). 2. Create the necessary JavaScript functions to manipulate the elements as needed. For this simple example we can just write them down, but as we\u2019ll see in Section 6.8, for AJAX or more complex functions we will use TDD (Chapter 8) to develop the code. 3. De\ufb01ne a setup function that binds the appropriate JavaScript functions to the elements and performs any other necessary DOM manipulation. 4. Arrange to call the setup function once the document is loaded. For Step 1, we modify our existing Rails movie list view to attach the CSS class adult to any table rows for movies rated other than G or PG. All we have to do is change line 12 6.6. EVENTS AND CALLBACKS 175 of the Index template (Figure 4.5) as follows, thereby allowing us to write $(\u2019.adult\u2019) to select those rows: https://gist.github.com/c857168c2c367c4cd1649efb3c643c5c 1 < div class = \" row <%= ( ' adult ' unless movie . rating =~ /^ G | PG$ /) % > \" > For Step 2, we provide the function filter_adult, which we will arrange to be called whenever the checkbox is checked or unchecked. As lines 4\u20138 of Figure 6.10 show, if the checkbox is checked, the adult movie rows are hidden; if unchecked, they are revealed. Recall from Figure 6.8 that :checked is one of jQuery\u2019s built-in behaviors for checking the state of an element. Remember also that jQuery selectors such as $(\u2019.adult\u2019) generally return a collection of matching elements, and actions like hide() are applied to the whole collection. Why does line 4 refer to $(this) rather than just this? The mechanism by which user interactions are dispatched to JavaScript functions is part of the browser\u2019s JSAPI, so the value of this is the browser\u2019s representation of the checkbox (the element that handled the event). In order to use the more powerful jQuery features such as is(\u2019:checked\u2019), we have to \u201cwrap\u201d the DOM element as a jQuery element by calling $ on it in order to give it these special powers. The \ufb01rst row of Figure 6.12 shows this usage of $. For Step 3, we provide the setup function, which does two things. First, it creates a label and a checkbox (lines 12\u201314), using the $ mechanism shown in the second row of Figure 6.12, and inserts them just before the movies table (line 15). Again, by creating a jQuery element we are able to call insertBefore on it, which is not part of the browser\u2019s built-in JSAPI. Most jQuery functions such as insertBefore return the target object itself, allowing \u201cchaining\u201d of function calls as we\u2019ve seen in Ruby. Second, the setup function binds the filter_adult function to the checkbox\u2019s change handler. You might have expected to bind to the checkbox\u2019s click handler, but change is more robust because it\u2019s an example of a \u201cpseudo-UI\u201d event: it \ufb01res whether the checkbox was changed by a mouse click, a keypress (for browsers that have keyboard navigation turned on, such as for users with disabilities that prevent use of a mouse), or even by other JavaScript code. The submit event on forms is similar: it\u2019s better to bind to that event than to bind to the click handler on the form-submit button, in case the user submits the form by hitting the Enter key. Why didn\u2019t we just add the label and checkbox to the Rails view template? The reason is our design guideline of graceful degradation: by using JavaScript to create the checkbox, legacy browsers will not render the checkbox at all. If the checkbox was part of the view template, users of legacy browsers would still see the checkbox, but nothing would happen when they clicked on it. Why does line 16 refer to MovieListFilter.filter_adult? Couldn\u2019t it just refer to filter_adult? No, because that would imply that filter_adult is a variable name visible in the scope of the setup function, but in fact it\u2019s not a variable name at all\u2014it\u2019s just a function-valued property of the object MovieListFilter, which is a (global) variable. It is good JavaScript practice to create one or a few global objects to \u201cencapsulate\u201d your functions as properties, rather than writing a bunch of functions and polluting the global namespace with their names. The last step is Step 4, which is to arrange for the setup function to be called. For historical reasons, JavaScript code associated with a page can begin executing before the entire page has been loaded and the DOM fully parsed. This feature was more important for responsiveness when browsers and Internet connections were slower. Nonetheless, we usually want to wait until the page is \ufb01nished loading and the entire DOM has been parsed, 176 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT var m = new Movie(); pianist.full_title(); $(\u2019#filter\u2019).change( MovieListFilter.filter_adult); (Figure 6.6, line 13) In the body of the Movie function, this will be bound to a new object that will be returned from the function, so you can use this.title (for example) to set its properties. The new object\u2019s prototype will be the same as the function\u2019s prototype. (Figure 6.6, line 15) When full_title executes, this will be bound to the object that \u201cowns\u201d the function, in this case pianist. (Figure 6.10, line 16) When filter_adult is called to handle a change event, this will refer to the element on which the handler was bound, in this case one of the element(s) matching the CSS selector #filter. Figure 6.11: The three common uses of this introduced in Sections 6.3 and 6.6. See Fallacies and Pitfalls for more on the use and misuse of this. Uses of $() or jQuery() with example $(sel) $(\u2019.mov span\u2019) $(elt) $(this), $(document), $(document.getElementById(\u2019main\u2019)) $(HTML[, attribs]) $(\u2019<p><b>bold</b>words</p>\u2019), $(\u2019<img/>\u2019, { src: click: \u2019/rp.gif\u2019, handleImgClick }) $(func) $(function () {...}); is call JSAPI Value/side effects, line number in Figure 6.10 return collection of jQuery-wrapped elements selected by CSS3 selec- tor sel (line 16) When an element such as returned by a getElementById or supplied to an event-handler callback, use this function to create a jQuery-wrapped version of the element, on which you can call the operations in Figure 6.8 (line 4) Returns a new jQuery-wrapped HTML element corresponding to the passed text, which must contain at least one HTML tag with angle brackets (otherwise jQuery will think you\u2019re passing a CSS selector and calling it as in the previous table row). If a JavaScript object is passed for attribs, it is used to construct the element\u2019s attributes. (Lines 13\u201314) The new element is not automatically inserted into the docu- ment; Figure 6.8 shows some methods for doing that, one of which is used in line 15. Run the provided function once the document has \ufb01nished loading and the DOM is ready to be manipulated. This is a shortcut for $(document).ready(func), which is itself a jQuery wrapper around the onLoad() handler of the browser\u2019s built-in JSAPI. (line 19) Figure 6.12: The four ways to invoke the overloaded function jQuery() or $() and the effects of each. All four are demonstrated in Figure 6.10. or else we might be trying to bind callbacks on elements that don\u2019t exist yet! Line 19 does this, adding MovieListFilter.filter_adult to the list of functions to be executed once the page is \ufb01nished loading, as the last row of Figure 6.12 shows. Since you can call $() multiple times to run multiple setup functions, you can keep each \ufb01le\u2019s setup function together with that \ufb01le\u2019s functionality, as we\u2019ve done here. To run this example place all the code from Figure 6.12 in app/assets/javascripts/movie_list_filter.js. This was a dense example, but it illustrates the basic jQuery functionality you\u2019ll need for many UI enhancements. The \ufb01gures and tables in this section generalize the techniques introduced in the example, so it\u2019s worth spending some time perusing them. In particular, Figure 6.12 summarizes the four different ways to use jQuery\u2019s $, all of which we\u2019ve now seen. Finally, most of jQuery\u2019s events are based on the built-in events recognized by browsers, but you can also de\ufb01ne your own custom events and use trigger to trigger them, and many jQuery-based libraries do just that. For example, Bootstrap\u2019s plugin for showing a modal 6.6. EVENTS AND CALLBACKS 177 window de\ufb01nes a custom event show that is generated when a modal window is displayed and another custom event shown that is generated when that window is dismissed. Your own code can listen for these events in order to take actions before or after the modal is displayed. In your own code, you might enclose menus for month and day in a single outer element such as a div, and then de\ufb01ne a custom update event on the div that checks that the month and day are compatible. You could then isolate the checking code in a separate event handler for update, and use trigger to call it from within the change handlers for the individual month and day menus. This is one way that custom handlers help DRY out your JavaScript code. Elaboration: JavaScript functions are closures Throughout these examples, it\u2019s easy to forget while writing an event handler that the time and place the handler code is de\ufb01ned is very different from the time and place (runtime scope) in which it will run when the event actually occurs. Fortunately, because JavaScript functions are true closures, wherever and whenever your event handler runs, it will have access to all of the same variables that were visible when the handler code was de\ufb01ned. This property\u2014that a function can always see all the variables that were in scope at the time of its de\ufb01nition\u2014will prove even more important for AJAX callbacks, which we discuss in the next section. Summary of jQuery\u2019s DOM and event handlers: \u2022 You can set or override how various HTML elements react to user input by binding JavaScript handlers or callbacks to speci\ufb01c events on speci\ufb01c elements. jQuery allows you to bind both \u201cphysical\u201d user events such as mouse clicks and \u201clogical\u201d pseudo-events such as form submission. Figure 6.9 summarizes a subset of jQuery events. \u2022 Inside an event handler, jQuery causes this to be bound to the browser\u2019s DOM representation of the element that handled the event. We usually \u201cwrap\u201d the ele- ment to get $(this), a \u201cjQuery-wrapped\u201d element that supports enhanced jQuery operations, such as $(this).is(\u2019:checked\u2019). \u2022 One of jQuery\u2019s advanced features is the ability to apply transformations such as show() and hide() to a collection of elements (for example, a group of elements named by a single CSS selector) as well as a single element. \u2022 For both DRYness and graceful degradation, the binding of event handlers to ele- ments should occur in a setup function that is called when the document is loaded and ready; that way, legacy non-JavaScript browsers will not run the function at all. Passing a function to $() adds it to the list of setup functions that will be run once the document is \ufb01nished loading. Self-Check 6.6.1. Explain why $(window.document).find(selector). calling $(selector) is equivalent to calling document is a property of the browser\u2019s built-in global object (window) that refers to the browser\u2019s representation of the root of the DOM. Wrapping the document element using $ 178 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT gives it access to jQuery functions such as find, which locates all elements matching the selector that are in the subtree of its target; in this case, the target is the DOM root, so it will \ufb01nd any matching elements in the entire document. Self-Check 6.6.2. In Self-Check 6.6.1, why did we need to write $(document).find rather than document.find? document, also known as window.document, is the browser\u2019s internal representation of the document object. Since find is a jQuery function, we need to \u201cwrap\u201d document to give it special jQuery powers. Self-Check 6.6.3. What would happen if we omitted the last line of Figure 6.10, which ar- ranges to call the setup function? The browser would behave like a legacy browser without JavaScript. The checkbox wouldn\u2019t be drawn (since that happens in the setup function) and even if it were, nothing would happen when it was clicked, since the setup function binds our JavaScript handler for the checkbox\u2019s change event."
    ]
  },
  {
    "id": "sec_0270",
    "title": "6.7 AJAX: Asynchronous JavaScript And XML",
    "pages": [
      190,
      191,
      192,
      193,
      194,
      195
    ],
    "text_blocks": [
      "In 1998, Microsoft added a new function to the JavaScript global object de\ufb01ned by Internet Explorer 5. XmlHttpRequest (usually shortened to XHR) allowed JavaScript code to ini- tiate HTTP requests to a server without loading a new page and use the server\u2019s response to modify the DOM of the current page. This new function, key to AJAX apps, allowed creat- ing a rich interactive UI that more closely resembled a desktop application, as Google Maps powerfully demonstrated. Happily, you already know all the ingredients needed for \u201cAJAX on Rails\u201d programming: 1. Create a controller action or modify an existing one (Section 4.4) to handle the AJAX requests made by your JavaScript code. Rather than rendering an entire view, the action will render a partial (Section 5.1) to generate a chunk of HTML for insertion into the page. 2. Construct your RESTful URI in JavaScript and use XHR to send the HTTP request to a server. As you may have guessed, jQuery has helpful shortcuts for many common cases, so we will use jQuery\u2019s higher-level and more powerful functions rather than calling XHR directly. 3. Because JavaScript is by de\ufb01nition single-threaded \u2014it can only work on one task at a time until that task completes\u2014the browser\u2019s UI would be \u201cfrozen\u201d while JavaScript awaited a response from the server. Therefore XHR instead returns immediately and lets you provide an event handler callback (as you did for browser-only programming in Section 6.6) that will be triggered when the server responds or an error occurs. 4. When the response arrives at the browser, your callback is passed the response content. It can use jQuery\u2019s replaceWith() to replace an existing element entirely, text() or html() to update an element\u2019s content in place, or an animation such as hide() to hide or show elements, as Figure 6.8 showed. Because JavaScript functions are closures (like Ruby blocks), the callback has access to all the variables visible at the time the XHR call was made, even though it executes at a later time and in a different environment. 6.7. AJAX: ASYNCHRONOUS JAVASCRIPT AND XML 179 <p > <%= movie . description % > </p > https://gist.github.com/52a502b7240baf1945806d94624e41f4 1 2 3 % > <%= link_to ' Edit Movie ' , edit_movie_path ( movie ) , : class = > ' btn btn - primary ' 4 <%= link_to ' Close ' , ' ' , : id = > ' closeLink ' , : class = > ' btn btn - secondary ' % > class M ovi e sController < A p p l i c a t i o n C o n t r o l l e r def show https://gist.github.com/18c678c940549b1fa7468f0d2\ufb0053401 1 2 3 4 5 6 7 8 id = params [: id ] # retrieve movie ID from URI route @movie = Movie . find ( id ) # look up movie by unique ID render (: partial = > ' movie ' , : object = > @movie ) if request . xhr ? # will render app / views / movies / show . < extension > by default end end Figure 6.13: (a) Top: a simple partial that will be rendered and returned to the AJAX request. We give the \u201cClose\u201d link a unique element ID so we can conveniently bind a handler to it that will hide the popup. (b) Bottom: The controller action that renders the partial, obtained by a simple change to Figure 4.5: if the request is an AJAX request, line 5 performs a render and immediate return. The :object option makes @movie available to the partial as a local variable whose name matches the partial\u2019s name, in this case movie. If xhr? is not true, the controller method will perform the default rendering action, which is to render the show view as usual. Let\u2019s illustrate how each step works for an AJAX feature in which clicking on a movie title shows the movie details in a \ufb02oating window, rather than loading a separate page. Step 1 requires us to identify or create a new controller action that will handle the request. We will just use our existing MoviesController#show action, so we don\u2019t need to de\ufb01ne a new route. This design decision is defensible since the AJAX version of the action performs the same function as the original version, namely the RESTful \u201cshow\u201d action. We will modify the show action so that if it\u2019s responding to an AJAX request, it will render the simple partial in Figure 6.13(a) rather than an entire view. You could also de\ufb01ne separate controller actions exclusively for AJAX, but that might be non-DRY if they duplicate the work of existing actions. How does our controller action know whether show was called from JavaScript code or by a regular user-initiated HTTP request? Fortunately, every major JavaScript library and most browsers set an HTTP header X-Requested-With: XMLHttpRequest on all AJAX HTTP requests. The Rails helper method xhr?, de\ufb01ned on the controller instance\u2019s request object representing the incoming HTTP request, checks for the presence of this header. Fig- ure 6.13(b) shows the controller action that will render the partial. Moving on to step 2, how should our JavaScript code construct and \ufb01re off the XHR request? We want the \ufb02oating window to appear when we click on the link that has the movie name. As Section 6.6 explained, we can \u201chijack\u201d the built-in behavior of an element by attaching an explicit JavaScript click handler to it. Of course, for graceful degradation, we should only hijack the link behavior if JavaScript is available. So following the same strategy as the example in Section 6.6, our setup function (lines 2\u20138 of Figure 6.14) binds the handler and creates a hidden div to display the \ufb02oating window. Legacy browsers won\u2019t run that function and will just get the default behavior of clicking on the link. The actual click handler getMovieInfo must \ufb01re off the XHR request and provide a callback function that will be called with the returned data. For this we use jQuery\u2019s ajax function, which takes an object whose properties specify the characteristics of the AJAX request, as lines 10\u201315 of Figure 6.14 show. Our example shows a subset of the properties you can specify in this object; one important property we don\u2019t show is data, which can be HiJax is sometimes humorously used to describe this technique. Of course, $.ajax is just an alias for jQuery.ajax. 180 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT // add hidden ' div ' to end of page to display popup : let popupDiv = $ ( ' < div id =\" movieInfo \" > </ div > ') ; popupDiv . hide () . appendTo ( $ ( ' body ') ) ; $ ( document ) . on ( ' click ' , '# movies a ' , MoviePopup . getMovieInfo ) ; var MoviePopup = { setup : function () { https://gist.github.com/8101873022c2b3542451850446b85ba2 1 2 3 4 5 6 7 8 9 10 11 12 13 } , getMovieInfo : function () { $ . ajax ({ type : ' GET ' , } url : $ ( this ) . attr ( ' href ') , timeout : 5000 , success : MoviePopup . showMovieInfo , error : function ( xhrObj , textStatus , exception ) { alert ( ' Error ! ') ; 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // ' success ' and ' error ' functions will be passed 3 args }) ; return ( false ) ; } , showMovieInfo : function ( data , requestStatus , xhrObject ) { // center a floater 1/2 as wide and 1/4 as tall as screen let oneFourth = Math . ceil ( $ ( window ) . width () / 4) ; $ ( '# movieInfo ') . css ({ ' left ': oneFourth , html ( data ) . show () ; ' width ': 2* oneFourth , ' top ': 250}) . // make the Close link in the hidden element work $ ( '# closeLink ') . click ( MoviePopup . hideMovieInfo ) ; return ( false ) ; // prevent default link action } , hideMovieInfo : function () { $ ( '# movieInfo ') . hide () ; return ( false ) ; } }; $ ( MoviePopup . setup ) ; Figure 6.14: The ajax function constructs and sends an XHR request with the given characteristics. type speci\ufb01es the HTTP verb to use, url is the URL or URI for the request, timeout is the number of milliseconds to wait for a response before declaring failure, success speci\ufb01es a function to call with the returned data, and error speci\ufb01es a function to call if a timeout or other error occurs. Many more options to the ajax function are available, in particular for more robust error handling. 6.7. AJAX: ASYNCHRONOUS JAVASCRIPT AND XML 181 # movieInfo { https://gist.github.com/82017db9284e2d3f5daa4b3\ufb00848e953 1 2 3 4 5 6 padding : 2 ex ; position : absolute ; border : 2 px double grey ; background : wheat ; } Figure 6.15: Adding this code to app/assets/stylesheets/application.css speci\ufb01es that the \u201c\ufb02oating\u201d window should be positioned at absolute coordinates rather than relative to its enclosing element, but as the text explains, we don\u2019t know until runtime what those coordinates should be, so we use jQuery to dynamically modify #movieInfo\u2019s CSS style properties when we are ready to display the \ufb02oating window. either a string of arguments to append to the URI (as in Figure 3.2) or a JavaScript object, in which case the object\u2019s properties and their values will be serialized into a string that can be appended to the URI. As always, such arguments would then appear in the params[] hash available to our Rails controller actions. Looking at the rest of the code in Figure 6.14, getting the URI that is the target of the XHR request is easy: since the link we\u2019re hijacking already links to the RESTful URI for showing movie details, we can query its href attribute, as line 10 shows. Lines 12\u201313 remind us that function-valued properties can specify either a named function, as success does, or an anonymous function, as error does. To keep the example simple, our error behavior is rudi- mentary: no matter what kind of error happens, including a timeout of 5000 ms (5 seconds), we just display an alert box. In case of success, we specify showMovieInfo as the callback. Some interesting CSS trickery happens in lines 20 and 23 of Figure 6.14. Since our goal is to \u201c\ufb02oat\u201d the popup window, we can use CSS to specify its positioning as absolute by adding the markup in Figure 6.15. But without knowing the size of the browser window, we don\u2019t know how large the \ufb02oating window should be or where to place it. showMovieInfo computes the dimensions and coordinates of a \ufb02oating div half as wide and one-fourth as tall as the browser window itself (line 20). It replaces the HTML contents of the div with the data returned from the server (line 22), centers the element horizontally over the main window and 250 pixels from the top edge (line 23), and \ufb01nally shows the div, which up until now has been hidden (line 24). There\u2019s one last thing to do: the \ufb02oated div has a \u201cClose\u201d link that should make it dis- appear, so line 26 binds a very simple click handler to it. Finally, showMovieInfo returns false (line 27). Why? Because the handler was called as the result of clicking on a link (<a>) element, we need to return false to suppress the default behavior associated with that action, namely following the link. (For the same reason, the \u201cClose\u201d link\u2019s click handler returns false in line 31.) With so many different functions to call for even a simple example, it can be hard to trace the \ufb02ow of control when debugging. While you can always use console.log(string) to write messages to your browser\u2019s JavaScript console window, it\u2019s easy to forget to remove these in production, and as Chapter 8 describes, such \u201cprintf debugging\u201d can be slow, inef\ufb01cient and frustrating. In Section 6.8 we\u2019ll introduce a better way by creating tests with Jasmine. Lastly, there is one caveat we need to mention which could arise when you use JavaScript to dynamically create new elements at runtime, although it didn\u2019t arise in this particular example. We know that $(\u2019.myClass\u2019).on(\u2019click\u2019,func) will bind func as the click handler for all current elements that match CSS class myClass. But if you then use JavaScript 182 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT to create new elements matching myClass after the initial page load and initial call to on, those elements won\u2019t have the handler bound to them, because on can only bind handlers to already-existing elements. A common solution to this problem is to take advantage of a jQuery mechanism that allows an ancestor element to delegate event handling to a descendant, by using on\u2019s poly- morphism: $(\u2019body\u2019).on(\u2019click\u2019,\u2019.myClass\u2019,func) binds the HTML body element (which always exists) to the click event, but delegates the event to any descendant matching the selector .myClass. Since the delegation check is done each time an event is processed, new elements matching .myClass will \u201cautomagically\u201d have func bound as their click han- dler when created. Summary of AJAX: \u2022 To create an AJAX interaction, \ufb01gure out what elements will acquire new behaviors, what new elements may need to be constructed to support the interaction or display responses, and so on. \u2022 An AJAX interaction will usually involve three pieces of code: the handler that initiates the request, the callback that receives the response, and the code in the document.ready function (setup function) to bind the handler. It\u2019s more readable to do each in a separate named function rather than providing anonymous functions. \u2022 Just as we did in the example of Section 6.6, for graceful degradation, any page elements used only in AJAX interactions should be constructed in your setup func- tion(s), rather than being included on the HTML page itself. \u2022 Both interactive debuggers such as Firebug or the JavaScript consoles in Google Chrome and Safari and \u201cprintf debugging\u201d using console.log() can help you \ufb01nd JavaScript problems, but a better way is through testing, which we show how to do in Section 6.8. Elaboration: Event-driven programming The programming model in which operations specify a completion callback rather than wait- ing for completion to occur is called event-driven programming . As you might conclude from the number of handlers and callbacks in this simple example, event-driven programs are considered harder to write and debug than task-parallel programs such as Rails apps, in which separate machinery in the app server effectively creates multiple copies of our app to handle multiple simultaneous users. Of course, behind the scenes, the operating system is switching among those tasks just as programmers do manually in JavaScript: when one user\u2019s \u201ccopy\u201d of the app is blocked waiting for a response from the database, for example, another user\u2019s copy is allowed to make progress, and the \ufb01rst copy gets \u201ccalled back\u201d when the database response arrives. In this sense, event-driven and task-parallel programming are duals, and emerging standards such as WebWorkers20 enable task parallelism in JavaScript by allowing different copies of a JavaScript program to run simultaneously on different op- erating system threads. However, JavaScript itself lacks concurrency abstractions such as Java\u2019s synchronized and inter-thread communication, so concurrency must be managed explicitly by the application. 6.8. TESTING JAVASCRIPT AND AJAX 183 What Libraries Setup Test \ufb01les Naming conven- tions RSpec/Ruby rspec, rspec-rails gems rails generate rspec:install spec/models/, spec/ controllers/, spec/helpers spec/models/movie_spec.rb tains tests for app/models/movie.rb con- Con\ufb01g- uration \ufb01le Run tests all .rspec rake spec Jasmine/JavaScript jasmine gem, jasmine-jquery add-on rails generate jasmine:install spec/javascripts/ spec/javascripts/movie_popup_spec.js contains tests for app/assets/javascripts/ movie_popup.js; spec/javascripts/ moviePopupSpec.js contains tests for app/ assets/javascripts/moviePopup.js spec/javascripts/support/jasmine.yml then visit rake jasmine, http://localhost:8888; rake Seleni- jasmine:ci um/Webdriver and capture the output; or use jasmine-headless-webkit21 from command line with no browser or using once run run to to Figure 6.16: Comparison of setting up and using Jasmine and RSpec. All paths are relative to the app root and all commands should be run from the app root. As you can see, the main difference is the use of lower_snake_case for \ufb01lenames and method names in Ruby, versus lowerCamelCase in JavaScript. Self-Check 6.7.1. In line 13 of Figure 6.14, why did we write MoviePopup.showMovieInfo instead of MoviePopup.showMovieInfo()? The former is the actual function, which is what ajax expects as its success property, whereas the latter is a call to the function. Self-Check 6.7.2. In line 33 of Figure 6.14, why did we write $(MoviePopup.setup) rather than $(\u2019MoviePopup.setup\u2019) or $(MoviePopup.setup())? We need to pass the actual function to $(), not its name or the result of calling it. Self-Check 6.7.3. Continuing Self-Check 6.7.2, called $(\u2019MoviePopup.setup\u2019), would the result be a syntax error or legal but unintended behavior? Recall that $() is overloaded, and when called with a string, it tries to interpret the string as HTML markup if it contains any angle brackets or a CSS selector otherwise. The latter applies in this case, so it would return an empty collection, since there are no elements whose tag is MoviePopup and whose CSS class is setup. if we had accidentally"
    ]
  },
  {
    "id": "sec_0271",
    "title": "6.8 Testing JavaScript and AJAX",
    "pages": [
      195,
      196,
      197,
      198,
      199,
      200,
      201,
      202
    ],
    "text_blocks": [
      "Even our simple AJAX example has many moving parts. In this section we show how to test it using Jasmine, an open-source JavaScript TDD framework developed by Pivotal Labs. Jasmine is designed to mimic RSpec and support the same TDD practices RSpec supports. The rest of this section assumes you\u2019ve read Chapter 8 or are otherwise pro\ufb01cient with TDD and RSpec; as Figure 6.16 shows, we will reuse all those TDD concepts in Jasmine. To start using Jasmine, add the jasmine-rails and jasmine-jquery-rails gems to the development and test groups in your Gem\ufb01le,and run bundle as usual, then run the 184 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT https://gist.github.com/59575a6276a4c9db68ba3fc5a8e801da 1 2 3 rails generate jasmine_rails : install mkdir spec / javascripts / fixtures git add spec / javascripts Figure 6.17: Creating the Jasmine-related directories in your app. Line 1 creates a spec/javascripts directory where our tests will go, with subdirectories support and helper analogous to RSpec\u2019s setup. Line 2 adds a subdirectory for \ufb01xtures (Section 8.6). Line 3 adds these new JavaScript TDD \ufb01les to your project. commands in Figure 6.17 from your app\u2019s root directory. Create a simple example spec \ufb01le spec/javascripts/basic_check_spec.js containing the following code: https://gist.github.com/63184132fe4e8f08b2b5d72f2e5c08af 1 2 3 describe ( ' Jasmine basic check ' , function () { expect ( true ) . toBe ( true ) ; }) ; it ( ' works ' , function () { }) ; Self-checking? rake spec:javascript runs the Jasmine suite just once using the PhantomJS headless webkit and collects the output, making it suitable for use in continuous integration (Section 10.4). To run Jasmine tests, just start your app as usual with the rails server command, and once it\u2019s running, browse to the specs subdirectory of your app (so, for example, http:// localhost:3000/specs if developing on your own computer) to run all the specs and see the results. From now on, when you change any code in app/assets/javascripts or tests in spec/javascripts, just reload the browser page to rerun all the tests. Testing AJAX code must address two problems, and if you have read about TDD in Chap- ter 8, you\u2019re already familiar with the solutions to both. First, just as we did in Section 8.4, we must be able to \u201cstub out the Internet\u201d by intercepting AJAX calls, so that we can return \u201ccanned\u201d AJAX responses and test our JavaScript code in isolation from the server. We will solve this problem using stubs. Second, our JavaScript code expects to \ufb01nd certain elements on the rendered page, but as we just saw, when running Jasmine tests the browser is viewing the Jasmine reporting page rather than our app. Happily, we can use \ufb01xtures to test JavaScript code that relies on the presence of certain DOM elements on the page, just as we used them in Section 8.6 to test Rails app code that relies on the presence of certain items in the database. Figure 6.18 gives an overview of Jasmine for RSpec users. We will walk through \ufb01ve happy-path Jasmine specs for the popup-window functionality developed in Section 6.7. While these tests are hardly exhaustive even for the happy path, our goal is to illustrate Jas- mine testing techniques generally and the use of Jasmine stubs and \ufb01xtures in AJAX testing speci\ufb01cally. like The basic structure of Jasmine test cases is immediately evident in Figure 6.20: RSpec, Jasmine uses it to specify a single example and nestable describe blocks to group related sets of examples. Just as in RSpec, describe and it take a block of code as an argument, but whereas in Ruby code blocks are delimited by do...end, in JavaScript they are anonymous functions (functions without a name) of zero arguments. The punctuation sequence }); is so prevalent because describe and it are JavaScript functions of two arguments, the second of which is a function of no arguments. The describe(\u2019setup\u2019) examples check that the MoviePopup.setup function cor- rectly creates the #movieInfo container but keeps it hidden from display. toExist and toBeHidden are expectation matchers provided by the Jasmine-jQuery add-on. Since Jas- mine loads all your JavaScript \ufb01les before running any examples, the call to setup (line 34 of Figure 6.14) occurs before our tests run; hence it\u2019s reasonable to test whether that function did its work. The describe(\u2019AJAX call to server\u2019) examples are more interesting because 6.8. TESTING JAVASCRIPT AND AJAX 185 Structure of test cases \u2022 it(\"does something\", function() {...}) Speci\ufb01es a single test (spec) by giving a descriptive name and a function that performs the test. \u2022 describe(\"behaviors\", function(){...}) Collects a related set of specs; the function body consists of calls to it, beforeEach, and afterEach. describes can be nested. \u2022 beforeEach and afterEach Setup/teardown functions that are run before each it block within the same describe block. As with RSpec, if describes are nested, all beforeEach are run from the outside in, and all afterEach from the inside out. expectation Expectations An expect(object).not.expectation Commonly used expectations built into Jasmine: takes spec in a the form expect(object).expectation or \u2022 toEqual(val), toBeTruthy(), toBeFalsy() Test for equality using ==, or that an expression evaluates to Boolean true or false. Commonly used expectations provided by the Jasmine jQuery add-on\u2014in this case, the argument of expect should be a jQuery-wrapped element or set of elements: \u2022 toBeSelected(), toBeChecked(), toBeDisabled(), toHaveValue(stringValue) Expectations on input elements in forms. \u2022 toBeVisible(), toBeHidden() Hidden is true if the element has zero width and height, if it is a form input with type=\"hidden\", or if the element or one of its ancestors has the CSS property display: none. \u2022 toExist(), toHaveClass(class), toHaveId(id), toHaveAttr(attrName,attrValue) Tests various attributes and characteristics of an element. \u2022 toHaveText(stringOrRegexp), toContainText(string) Tests if the element\u2019s text exactly matches the given string or regexp, or contains the given substring. Figure 6.18: A partial summary of a small subset of commonly used features in Jasmine and Jasmine-jQuery, following the structure of Figures 8.10 and 8.11 and extracted from the complete Jasmine documentation24 and Jasmine jQuery add-on25 documentation. 186 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT Stubs (Spies) \u2022 spyOn(obj, \u2019func\u2019) Creates and returns a spy (mock) of an existing function, which must be a function-valued prop- erty of obj named by func. The spy replaces the existing function. \u2022 calls is a property of a spy that tracks calls that have been made to it, and the array args[] of the arguments of each call. The following modi\ufb01ers can be called on a spy to control its behavior: \u2022 and.returnValue(value) \u2022 and.throwError(exception) \u2022 and.callThrough() \u2022 and.callFake(func) func must be a function of zero arguments, though it has access to the arguments with which the spy was called via spy.calls.mostRecent().args[], and can call other functions using these arguments. Fixtures and factories (requires jasmine-jquery) \u2022 sandbox({class: \u2019myClass\u2019, id: \u2019myId\u2019}) Creates an empty div with the given HTML attributes, if any; default is an empty div with no CSS class and an ID of sandbox. An alternative way to create the argument to setFixtures that avoids putting literal HTML strings into your test code. \u2022 loadFixtures(\"\ufb01le.html\") Load HTML content from in spec/javascripts/fixtures/\ufb01le.html and put it inside a div with ID jasmine-fixtures, which is cleaned out between test cases. \u2022 setFixtures(HTMLcontent) Create a \ufb01xture directly instead of loading it from a \ufb01le. HTMLcontent can be a literal string of HTML such as <p class=\"foo\">text</p> or a jQuery-wrapped element such as $(\u2019<p class=\"foo\">text</p>\u2019). \u2022 getJSONFixture(\"\ufb01le.json\") Returns the JSON object in spec/javascripts/fixtures/\ufb01le.json. Useful for storing mock data to simulate the result of an AJAX call without having to put literal JSON objects into your test code. Figure 6.19: Continuation of Figure 6.18 describing stubs (spies in Jasmine) and \ufb01xtures. 6.8. TESTING JAVASCRIPT AND AJAX 187 it ( ' adds popup Div to main page ' , function () { }) ; describe ( ' clicking on movie link ' , function () { beforeEach ( function () { loadFixtures ( ' movie_row . html ') ; }) ; it ( ' calls correct URL ' , function () { spyOn ($ , ' ajax ') ; $ ( '# movies a ') . trigger ( ' click ') ; expect ( $ . ajax . calls . mostRecent () . args [0][ ' url ' ]) . toEqual ( '/ movies /1 ') ; }) ; describe ( ' when successful server call ' , function () { expect ( $ ( '# movieInfo ') ) . toBeHidden () ; }) ; expect ( $ ( '# movieInfo ') ) . toExist () ; }) ; it ( ' hides the popup Div ' , function () { describe ( ' MoviePopup ' , function () { describe ( ' setup ' , function () { https://gist.github.com/b7c08e54899a87178d606f7c74c4fc77 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 }) ; $ ( '# movies a ') . trigger ( ' click ') ; beforeEach ( function () { }) ; }) ; }) ; }) ; let htmlResponse = readFixtures ( ' movie_info . html ') ; spyOn ($ , ' ajax ') . and . callFake ( function ( ajaxArgs ) { ajaxArgs . success ( htmlResponse , ' 200 ') ; }) ; it ( ' makes # movieInfo visible ' , function () { expect ( $ ( '# movieInfo ') ) . toBeVisible () ; }) ; it ( ' places movie title in # movieInfo ' , function () { expect ( $ ( '# movieInfo ') . text () ) . toContain ( ' Casablanca ') ; Figure 6.20: Five happy-path Jasmine specs for the AJAX code developed in Section 6.7. Lines 2\u20139 check whether the MoviePopup.setup function correctly sets up the \ufb02oating div that will be used to display movie info. Lines 10\u201332 check the behavior of the AJAX code without actually calling the RottenPotatoes server by stubbing around the AJAX call. < div id = \" movies \" > < div class = \" row \" > https://gist.github.com/a08c97b3b1b4990c613ce25985572b40 1 2 3 4 5 6 7 </ div > </ div > < div class = \" col -8 \" ><a href = \" / movies /1 \" > Casablanca </ a > </ div > < div class = \" col -2 \" >PG </ div > < div class = \" col -2 \" >1943 -01 -23 </ div > Figure 6.21: This HTML \ufb01xture mimics a row of the #movies table generated by the RottenPotatoes list-of-movies view (Figure 4.5). Note that we omit the table header from the \ufb01xture, since the spec doesn\u2019t require it to be present. This \ufb01xture would go in spec/javascripts/fixtures/movie_row.html. You can generate such \ufb01xtures by copy-and-pasting HTML code from \u201cView Source\u201d in the browser, or for source that was generated dynamically by JavaScript (such as the \u201cHide adult movies\u201d checkbox), by inspecting $(\u2019#movieInfo\u2019).html() in the JavaScript console. Fallacies and Pitfalls describes a way to prevent such \ufb01xtures from getting out of sync if you change your app\u2019s views. 188 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT Figure 6.22: Top: Normally, our getMovieInfo function calls jQuery\u2019s ajax, which calls xhr in the browser\u2019s JSAPI, which sends the request to the server. The server\u2019s reply triggers callback logic in the browser\u2019s JSAPI, which calls an internal jQuery method that eventually calls our showMovieInfo callback. If we stub the ajax function, we can cause showMovieInfo to be called immediately; we can also stub \u201cfarther away\u201d by stubbing xhr (using the Jasmine-Ajax plugin), causing the jQuery internal dispatcher to be called immediately. Bottom: Graphical representation of the discussion in Section 8.4. they use stubs and \ufb01xtures to isolate our client-side AJAX code from the server with which it communicates. Figure 6.19 summarizes the stubs and \ufb01xtures available in Jasmine and Jasmine-jQuery. Like RSpec, Jasmine allows us to run test setup and teardown code using In this set of examples, our setup code loads the HTML beforeEach and afterEach. \ufb01xture shown in Figure 6.21, to mimic the environment the getMovieInfo handler would see if it was called after movie list was displayed. The \ufb01xtures functionality is provided by Jasmine-jQuery; each \ufb01xture is loaded inside of div#jasmine-fixtures, which is inside of div#jasmine_content on the main Jasmine page, and all the \ufb01xtures are cleared out after each spec to preserve test independence. The \ufb01rst example (line 12 of Figure 6.20) checks that the AJAX call uses the correct movie URL derived from the table. To do this, it uses Jasmine\u2019s spyOn to stub out the $.ajax function. Like RSpec\u2019s stub, this call replaces any existing function of the same name, so when we manually trigger the click action on the (only) a element in the #movies table, if all is working well we should expect our spy function to have been called. Because in JavaScript it\u2019s common for functions to be the values of object properties, spyOn takes two arguments, an object ($) and the name of the function-valued property of that object on which to spy (\u2019ajax\u2019). Line 15 looks complex, but it\u2019s straightforward. Each Jasmine spy remembers the argu- ments passed to it in each of its calls, e.g. calls.mostRecent(), and as you recall from the explanation in Section 6.7, a real call to the AJAX function takes a single object (lines 9\u201315 of Figure 6.14) whose url property is the URL to which the AJAX call should go. Line 15 of the spec is simply checking the value of this URL. In effect, it\u2019s testing whether $(this).attr(\u2019href\u2019) is the correct JavaScript code to extract the AJAX URL from the table. Figure 6.22 shows the similarity between the challenges of stubbing the Internet for test- 6.8. TESTING JAVASCRIPT AND AJAX 189 <p > Casablanca is a classic and iconic film starring https://gist.github.com/39925bd69d7d6e12af94e4b9bac5f5b2 1 2 3 Humphrey Bogart and Ingrid Bergman . </p > <a href = \" \" id = \" closeLink \" > Close </ a > Figure 6.23: This HTML \ufb01xture mimics the ajax response from the movies controller show action; it goes in spec/javascripts/fixtures/movie_info.html. https://gist.github.com/5bb00dbb9e829d245228982474b8dbca describe ( ' element sanitizer ' , function () { 1 2 3 4 5 6 7 8 it ( ' removes IMG tags from evil HTML ' , function () { setFixtures ( sandbox ({ class : ' myTestClass ' }) ) ; $ ( '. myTestClass ') . text ( \" Evil HTML ! < img src = ' http :// evil . com / xss '>\" ) ; $ ( '. myTestClass ') . sanitize () ; expect ( $ ( '. myTestClass ') . text () ) . not . toContain ( ' < img ') ; }) ; }) ; Figure 6.24: Jasmine-jQuery\u2019s sandbox method creates a new HTML div with the given attributes; its id defaults to sandbox if not given. Lines 4\u20135 use the sandbox-created element. The sandbox can be used to temporarily contain elements constructed in a factory-like way without \u201cpolluting\u201d the test code with HTML markup. ing AJAX and stubbing the Internet for testing code in a Service-Oriented Architecture (Sec- tion 8.4). As you can see, in both scenarios, the decision of where to stub depends on how much of the stack we want to exercise in our tests. Line 19 reads in a \ufb01xture that will take the place of the ajax response from the movies controller show action, see Figure 6.23. In lines 20\u201322 we see the use fo the callFake function to not only intercept an AJAX call, but also to fake a successful response using the \ufb01xture. This and the triggering of the AJAX call (line 23) is repeated for each of the following two tests which check that both the #movieInfo popup is visible (line 26) and that it contains text from the movie description (line 29). This concise introduction, along with the summary tables in this section, should get you started using BDD for your JavaScript code. The best sources of complete documentation for these tools are the Jasmine documentation26 and the Jasmine jQuery add-on27 documentation. Summary of Jasmine BDD for JavaScript: \u2022 Like RSpec, Jasmine specs are anonymous functions accompanied by a descriptive string. They are introduced by the Jasmine function it, can be grouped with (nested) describe blocks that have associated beforeEach and afterEach (test setup and teardown) calls. \u2022 spyOn can be used to stub an existing method by replacing it with a spy. The spy\u2019s behavior can be controlled with functions like and.callThrough, and.returnValue, and so on, as Figure 6.19 shows. \u2022 Jasmine-jQuery\u2019s HTML \ufb01xtures can provide both the \u201cbefore\u201d content for trigger- ing an AJAX request and the \u201cafter\u201d content for testing the results of a successful or failed AJAX request. 190 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT Elaboration: Fixtures or factories? As Section 8.6 explains, in Rails apps it\u2019s often preferable to use a factory to create necessary test doubles \u201cin place\u201d rather than specifying \ufb01xtures. So why do we describe the use of \ufb01xtures rather than factories for AJAX testing? One reason is that the tradeoff is different in JavaScript. In the Rails app, \ufb01xtures are loaded into the database before tests are run, and various ActiveRecord methods such as find may behave differently when different \ufb01xtures are present; therefore \ufb01xtures may break test Independence. Factories are an appealing al- ternative in Rails because gems such as FactoryBot make it easy to instantiate test doubles \u201cjust in time\u201d in each test that needs them. In Jasmine, to substitute an HTML \u201cfactory\u201d for HTML \ufb01xtures, we would use $(\u2019\u2019) to create inline HTML elements, but many developers view this as undesirable because mixing HTML markup with JavaScript test code makes the latter hard to read. Jasmine-jQuery provides some simple support for using factories without excessively polluting your test code with HTML markup, as Figure 6.24 shows, but in general we see that \ufb01xtures for AJAX testing avoid some of the pitfalls of \ufb01xtures for Rails testing. They do, however, introduce a pitfall of their own\u2014the possibility of getting \u201cout of sync\u201d with the app\u2019s views. See Fallacies and Pitfalls for a discussion of this pitfall and its solution. Self-Check 6.8.1. Jasmine-jQuery also supports toContain and toContainText to check if a string of text or HTML occurs within an element. In line 7 of Figure 6.20, why would it be incorrect to substitute .not.toContain(\u2019<div id=\"movieInfo\"></div>\u2019) for toBeHidden()? A hidden element is not visible, but it still contains the text or HTML associated with the element. Hence toContain-style matchers can be used to test the content of an element but not its visibility. In addition, there are many ways for an element to be hidden\u2014its CSS could include display:none, it could have zero width and height, or its ancestor could be hidden\u2014and the toBeHidden() matcher checks all of these. Self-Check 6.8.2. Like RSpec, Jasmine supports and.returnValue() for returning a canned value from a stub. In Figure 6.20, why why did we have to write and.callFake to pass ajaxArgs to a function as the result of stubbing ajax, rather than simply writing and.returnValue(ajaxArgs)? Remember that AJAX calls are asynchronous. It\u2019s not the case that the $.ajax call returns data from the server: normally, it returns immediately, and sometime later, your callback is called with the data from from the server. and.callFake simulates this behavior."
    ]
  },
  {
    "id": "sec_0272",
    "title": "6.9 CHIPS: AJAX Enhancements to RottenPotatoes",
    "pages": [
      202
    ],
    "text_blocks": [
      "CHIPS 6.9: AJAX Enhancements to RottenPotatoes https://github.com/saasbook/hw-javascript-ajax Write and deploy code, unit tests, and integration tests for new AJAX-enabled features in RottenPotatoes, while observing best practices of Unobtrusive JavaScript."
    ]
  },
  {
    "id": "sec_0273",
    "title": "6.10 Single-Page Apps and JSON APIs",
    "pages": [
      202,
      203,
      204,
      205,
      206
    ],
    "text_blocks": [
      "Google Maps was an early example of the emerging category called client-side single-page apps (SPAs). In a SPA, after the initial page load from the server, all interaction appears to the 6.10. SINGLE-PAGE APPS AND JSON APIS 191 user to occur without any page reloads. While we won\u2019t develop a full SPA in this section, we will show the techniques necessary to do so. Even SPAs usually have a signi\ufb01cant server-side component. However, whereas client- side (in-browser) code must use JavaScript, server code can used a variety of languages and frameworks, as best serves the need. You might think that using JavaScript for both client and server code results in signi\ufb01cant simpli\ufb01cation; indeed, you can think of the Node and Express JavaScript libraries Express as analogous to Rack and Rails, respectively. But in fact, the three fundamental challenges of splitting an app between a client and a server bene\ufb01t relatively little by using the same language: 1. The \ufb01rst is the need to identify and carefully manage important application state be- tween the client and server. RESTful design advises us to do this by associating all important state with some type of resource, and de\ufb01ning and exposing a set of REST- ful operations whose semantics are clear and well-circumscribed. 2. The second is the need to communicate data between the client and the server. Since the client and server are completely separate processes, in general such data must be serialized . For the vast majority of SPAs, JSON (JavaScript Object Notation) is used for this purpose. 3. The third is the need to manage dependencies among JavaScript libraries, analogously to what Bundler (Section 2.6) does for Ruby. This challenge only applies once the total amount of JavaScript code (whether on the client or on the server) exceeds a certain level of complexity. This section addresses the second and third challenges, since the approach to the \ufb01rst challenge is not fundamentally different for SPAs than for the server-side apps you\u2019ve been working with. You\u2019ve now seen at least three different ways to represent structured data: XML, YAML (Sections 4.2 and 8.6), and JSON. These three standards, and many others, address the problem of data serialization (also called marshalling or de\ufb02ating)\u2014translating a program\u2019s internal data structures into a representation that can be \u201cresurrected\u201d later. Deserialization (unmarshalling, in\ufb02ating) is often performed by a different program, possibly written in a different language or at the other end of a network connection, so the serialization format must be portable. Early SPAs used XML, but JSON has now eclipsed all other standards for serializing SaaS data between clients and servers. How is JSON used in SPAs? Principally, the client requests some \u201craw\u201d data that the server returns in JSON format, and the client uses that data to construct or modify DOM elements. To do this in Rails, we must solve four problems: 1. Since all requests from client to server use HTTP, how does the client indicate that a particular HTTP request \u201cwants\u201d a JSON response, rather than (for example) rendering an HTML view? 2. How do we get the server to generate JSON in response to such requests? 3. Since JSON objects are just properly-formatted strings, how does the client convert such strings into \u201creal\u201d JavaScript objects once the response is received, so that it can use the data to modify the DOM or take other action? Ruby 1.9 added its alternate hash notation {foo: \u2019bar\u2019}, equivalent to {:foo=>\u2019bar\u2019}, to mimic JSON. 192 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT https://gist.github.com/2a6f7d0f83b3f7ddd42cfc9bbf4ef19e 1 2 3 Review . first . to_json # = > \"{\\\" created_at \\\":\\\"2012 -10 -01 T20 :44:42 Z \\\" , \\\" id \\\":1 , \\\" movie_id \\\":1 , \\ \" moviegoer_id \\\":2 ,\\\" potatoes \\\":3 ,\\\" updated_at \\\":\\\"2013 -07 -28 T18 :01:35 Z \\\"} \" Figure 6.25: Rails\u2019 built-in to_json can serialize simple ActiveRecord objects by calling itself recursively on each attribute of the model. As you can see, it doesn\u2019t traverse associations\u2014the review\u2019s movie_id and moviegoer_id are serialized to integers, not to the Movie and Moviegoer objects to which the integer foreign keys refer. You can effect more sophisticated serialization by overriding to_json in your ActiveRecord models. 4. When testing AJAX requests that expect JSON responses, how can we use \u201cstub out the server\u201d to test these behaviors in isolation, as we did in Section 6.8? jQuery makes the \ufb01rst problem easy. To make an AJAX call that expects a JSON-encoded response, we just ensure that the argument object passed to $.ajax includes a dataType property whose value is the string json, as Figure 6.26 shows. (Recall that $.ajax ulti- mately calls XmlHttpRequest in the browser\u2019s underlying JSAPI, which means that when the HTTP response is received, the browser will not automatically try to re-render the entire page.) Of course, the presence of this property doesn\u2019t by itself cause the server to emit JSON\u2014we address that next. But it does have one important effect: when the server re- turns data, the jQuery callback that receives the response will pass that data to JSON.parse, which converts a string of JSON into the corresponding JavaScript object(s), addressing the third problem above. This function is provided by the JSON object, which is part of the standard built-in collection of JavaScript objects. How do we get the server to emit JSON rather than rendering a view? Rails controller actions can call render :json=>object, which sends a JSON representation of an object back to the client as the single response from the controller action. Like rendering a template, you are only allowed a single call to render per action, so all the response data for a given controller action must be packed into a single JSON object. This is not a limitation in prac- tice, since in general most calls to a RESTful API expect a single JSON object as a result. render :json works by calling to_json on object to create the string to send back to the client. The default implementation of to_json can serialize simple ActiveRecord objects, as Figure 6.25 shows, but you can override it for your own models and other classes. Finally, good unit-testing discipline requires us to be able to test the client-side JavaScript code without calling the server every time. Recall from Section 8.4 how stubbing the Inter- net to isolate tests from external services can be done either \u201cnear the client\u201d or \u201cfar from the client.\u201d In Section 6.8 we stubbed \u201cnear the client\u201d by stubbing $.ajax and forcing it to immediately call the success function rather than allowing it to proceed with the ex- ternal HTTP request. Another way to stub near the client for SPAs is Jasmine-jQuery\u2019s \ufb01xture mechanism, which allows us to specify JSON \ufb01xtures as well as HTML \ufb01xtures, as Figure 6.27 shows. You can make a call to the actual server, capture the response as a JSON \ufb01xture, and use the \ufb01xture as a \u201ccanned\u201d response in Jasmine tests, similar to how we stubbed find_in_tmdb in Section 8.4 to return a value immediately rather than allowing it to make a real HTTP request. An alternative, which would more thoroughly exercise the code that handles the ac- tual AJAX server responses, is to stub at the network level. Just as Webmock lets you provide \u201ccanned\u201d XML or HTML responses based on the arguments of an XHR call, jasmine-ajax28, a Jasmine extension from Pivotal Labs, lets you provide \u201ccanned\u201d XML, HTML or JSON responses to AJAX XHR calls that are used instead of allowing the XHR call 6.10. SINGLE-PAGE APPS AND JSON APIS 193 dataType : ' json ' , url : $ ( this ) . attr ( ' href ') , success : MoviePopupJson . showMovieInfo // ' timeout ' and ' error ' functions omitted for brevity }) ; return ( false ) ; $ . ajax ({ type : ' GET ' , let MovieP opupJson = { // ' setup ' function omitted for brevity getMovieInfo : function () { https://gist.github.com/499c2b3ad7ad5ba067e358462b7266e1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 } // hideMovieInfo omitted for brevity show () ; }; } , showMovieInfo : function ( jsonData , requestStatus , xhrObject ) { // center a floater 1/2 as wide and 1/4 as tall as screen let oneFourth = Math . ceil ( $ ( window ) . width () / 4) ; $ ( '# movieInfo ') . css ({ ' left ': oneFourth , html ( $ ( ' <p > ' + jsonData . description + ' </p > ') , ' width ': 2* oneFourth , ' top ': 250}) . $ ( ' <a id =\" closeLink \" href =\"#\" > </ a > ') ) . // make the Close link in the hidden element work $ ( '# closeLink ') . click ( MoviePopupJson . hideMovieInfo ) ; return ( false ) ; // prevent default link action Figure 6.26: This version of MoviePopup expects a JSON rather than HTML response (line 5), so the success function uses the returned JSON data structure to create new HTML elements inside the popup div (lines 17\u201319; observe that jQuery DOM-manipulation functions such as append can take multiple arguments of distinct pieces of HTML to create). The functions omitted for brevity are the same as in Figure 6.14. loadFixtures ( ' movie_row . html ') ; let jsonResponse = getJSONFixture ( ' movie_info . json ') ; spyOn ($ , ' ajax ') . and . callFake ( function ( ajaxArgs ) { ajaxArgs . success ( jsonResponse , ' 200 ') ; describe ( ' successful AJAX call ' , function () { beforeEach ( function () { https://gist.github.com/4a3fdcdd704492c52eb5a3714bf284c5 describe ( ' MoviePopupJson ' , function () { 1 2 3 4 5 6 7 8 9 10 11 12 13 }) ; $ ( '# movies a ') . trigger ( ' click ') ; }) ; }) ; }) ; // ' it ' clauses are same as in movie_popup_spec . js Figure 6.27: Jasmine-jQuery expects to \ufb01nd \ufb01xture \ufb01les containing .json data in spec/javascripts/fixtures/json. After executing line 5, jsonResponse will contain the actual JavaScript object (not the raw JSON string!) that will get passed to the success handler. 194 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT to proceed. You can then spy on the handler functions success, failure, timeout, and so on passed to $.ajax to make sure the correct handler is called depending on the server\u2019s response. Summary of Single-Page Apps: \u2022 Whereas JavaScript-enhanced traditional SaaS apps will typically render complete chunks of HTML (for example, using partials) that the client will simply \u201cplug into\u201d the current HTML page, SPAs will usually receive structured data from one or more services and use that data to synthesize new content or modify existing content on the page. \u2022 JSON\u2019s simplicity and its natural \ufb01t with JavaScript are rapidly making it the pre- ferred format for interchanging structured data in SPAs. Rails can serialize simple ActiveRecord models to JSON with render :json=> object, but you can override ActiveRecord\u2019s to_json method to serialize arbitrarily complex data structures. \u2022 Setting the dataType property to \"json\" in an $.ajax call tells jQuery to auto- matically deserialize the server\u2019s response data into a JSON object. \u2022 A spy that returns a JSON \ufb01xture can be used to simulate a server\u2019s response in testing a SPA, allowing Jasmine tests to be isolated from the remote server(s) the SPA relies on. Elaboration: Managing JavaScript dependencies Early in the book we emphasized the importance of managing library versions in complex apps. For Ruby, the gem tool installs or uninstalls speci\ufb01c versions of Gems (libraries), and Bundler tracks and resolves dependencies among the set of gems needed by your app. The Node package manager npm is analogous to gem, and various tools are vying for the function of Bundler. Yarn, itself an npm package, manages npm-installed JavaScript libraries and tracks versions and dependencies just as Bundler does for Ruby gems. Webpack not only manages JavaScript libraries but also manages CSS stylesheets and does much of the work of the Rails asset pipeline (Section 6.2). Part of the motivation for Webpack is that ECMAScript version"
    ]
  },
  {
    "id": "sec_0274",
    "title": "6 (\u201cES6\u201d) de\ufb01nes modules as a new JavaScript abstraction: a module is a namespace that can",
    "pages": [
      206,
      207
    ],
    "text_blocks": [
      "export speci\ufb01c symbols for use by other namespaces, with live bindings that ensure that when a module changes the value of such an exported symbol, the change is immediately visible in other modules that imported the symbol. Webpack attempts to construct a dependency graph of JavaScript modules that respects live bindings. Our view in early 2021 is that unless your client-side SPA code becomes comparable in complexity to your server code, Webpack (and the gem webpacker, which integrates it with Rails apps) may introduce complexity that does not pay back its own cost. But as these tools become more streamlined, expect to see JavaScript library management become a standard part of multi-langauge SaaS frameworks. Self-Check 6.10.1. In Figure 6.27 showing the use of a JSON \ufb01xture, why do we also still need the HTML \ufb01xture to be loaded in line 4? Line 9 tries to trigger the click handler for an element matching #movies a, and if we don\u2019t load the HTML \ufb01xture representing a row of the movies table, no such element will exist. (Indeed, the MoviePopupJson.setup function tries to bind a click handler on this element, 6.11. FALLACIES AND PITFALLS 195 Figure 6.28: Architecture of in-browser SPAs that retrieve assets from multiple distinct services. Left: If the JavaScript code was served from RottenPotatoes.com, the default same-origin policy that browsers implement for JavaScript will forbid the code from making AJAX calls to servers in other domains. The cross-origin resource sharing (CORS) speci\ufb01cation relaxes this restriction but is only supported by very recent browsers. Right: in the traditional SPA architecture, a single server serves the JavaScript code and interacts with other remote services. This arrangement respects the same-origin policy and also allows the main server to do additional work on behalf of the client if needed. so that would also fail.) This is an example of using both an HTML \ufb01xture to simulate the user clicking on a page element and a JSON \ufb01xture to simulate a successful response from the server in response to that click. Elaboration: Same-origin policy You can also arrange for your SPA to communicate with a RESTful server fa\u00e7ade (Sec- tion 11.6), as Figure 6.28 shows. You might do this if your SPA relies on content from mul- tiple sites: for security, JavaScript browser apps are bound by a same origin policy , which says that a JavaScript app can only make AJAX requests to the same origin (scheme, host name, and port number, as described in Section 3.2) from which the app itself was served."
    ]
  },
  {
    "id": "sec_0275",
    "title": "6.11 Fallacies and Pitfalls",
    "pages": [
      207,
      208,
      209,
      210,
      211
    ],
    "text_blocks": [
      "Fallacy: AJAX will surely improve my app\u2019s responsiveness because more action happens right in the browser. In a carefully-engineered app, judicious use of JavaScript and AJAX have the poten- tial to improve responsiveness and usability. However, many factors also work against this goal. Your JavaScript code must be loaded from the server; Internet connection speeds to- day range from less than 1 Mbps (mobile phones in poorly-connected areas) to 1000 Mbps (high-speed wired networks). The JavaScript code must then be parsed and executed, and be- cause JavaScript is single-threaded, JavaScript performance bene\ufb01ts from faster CPUs but not more CPUs. For both laptops and smartphones, this leads to order-of-magnitude differences in JavaScript performance between \u201cpremium\u201d models (recent Apple iPhones, full-featured laptops) and \u201ceconomy\u201d models (US$20 smartphones common in developing areas, older premium phones, entry-level Chromebooks) (Osmani 2019). That cute JavaScript animation may simply make your site frustratingly sluggish on less powerful or less well-connected devices. The true test of usability is not how the site behaves on your computer, but how it behaves on the devices used by the majority of your customers. The variation among those devices should make you cautious about the gratuitous overuse of JavaScript. Pitfall: Disregarding the credibility of a source of information about JavaScript. 196 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT When JavaScript was embedded into browsers, it immediately became the one program- ming language that literally anyone with a browser could code in, and their creations could be deployed on the Web to boot. One unfortunate side effect of this rapid explosion in use is that there is a lot of bad JavaScript code out there, and trying to \ufb01nd good, sound advice online for \u201chow to do X in JavaScript\u201d can be like wading through a cesspit. Carefully vet the sources of such advice! The Mozilla Developer Network\u2019s JavaScript documentation29 is an excellent comprehensive reference for the language itself. JavaScript The Right Way30 is primarily a curated set of links to descriptions of JavaScript best practices. And as always, don\u2019t copy-paste code into your app if you don\u2019t know where it\u2019s been! Pitfall: Creating a site that fails without JavaScript rather than being en- hanced by it. For reasons of accessibility by people with disabilities, security, and cross-browser com- patibility, a well-designed site should work better if JavaScript is available, but accept- ably otherwise. For example, GitHub\u2019s pages for browsing code repos work well without JavaScript but work more smoothly and quickly with JavaScript. Try the site both ways for a great example of progressive enhancement. Tests also run faster without JavaScript: having a site for which JavaScript is optional means you can do the majority of your integration testing in the faster \u201cheadless browser\u201d mode of Cucumber and Capybara. Pitfall: Silent JavaScript failures in production code. When an unexpected exception occurs in your Rails code, you know it right away, as we\u2019ve already seen: your app displays an ugly error page, or if you\u2019ve been care- ful, a service like Hoptoad immediately contacts you to report the error, as we describe in Chapter 12). But JavaScript problems manifest as silent failures\u2014the user clicks a control or loads a page, and nothing happens. These problems are especially perni- cious because if they occur while an AJAX request is in progress, the success call- back will never get called. So be warned: jQuery provides shortcuts for common uses of $.ajax() such as $.get(url,data,callback), $.post(url,data,callback), $.load(url_and_selector), and $.getJSON(url,data,callback), but all of these fail silently if anything goes wrong, whereas $.ajax() allows you to specify additional callbacks to be called in case of errors. Pitfall: Silent JavaScript failures in tests. The \u201csilent failure\u201d pitfall also arises when using Jasmine: if there are syntax errors in any of your JavaScript \ufb01les or specs, when you reload the browser page that runs your Jasmine specs, you may see a blank page with no hint as to where the errors are. We suggest using Doug Crockford\u2019s JSLint31 tool, which not only \ufb01nds syntax errors but also points out bad habits and the use of JavaScript mechanisms that Crockford and others consider misfeatures. Similarly, you may accidentally load HTML \ufb01xtures that result in illegal HTML. For example, you might accidentally create a \ufb01xture containing an element whose ID duplicates an existing element, or a \ufb01xture containing improperly-nested elements or HTML syntax errors. Since \ufb01xtures are loaded into an actual page when tests are run, the results of an ill-formed page may be unpredictable or result in silent failures. Pitfall: Providing only expensive server operations and relying on JavaScript to do the rest. 6.11. FALLACIES AND PITFALLS 197 If JavaScript is so powerful, why not write substantially all of the app logic in it, using the server as just a thin API to a database? For one thing, as we\u2019ll see in Chapter 12, successful scaling requires reducing the load on the database, and unless the APIs exposed to your JavaScript client code are carefully thought out, there\u2019s a risk of making needlessly complex database queries so that client-side JavaScript code can pick out the data it needs for each view. Second, whereas you have nearly complete control of performance (and therefore of the user experience) on the server side, you have nearly none on the client side. Because of wide variation in browser types, Internet connection speeds, and other factors beyond your control, JavaScript performance on each user\u2019s browser is largely out of your hands, making it dif\ufb01cult to provide consistent performance for the user experience. Pitfall: Incorrect use of this in JavaScript functions. The value of this in the body of a JavaScript function is the source of much grief and confusion for programmers new to the language. In particular, after seeing a couple of ex- amples, new programmers don\u2019t realize that the value of this for a particular function is not dependent on how that function is written, but on how it is called, so different calls to the same function can result in different bindings for this. A complete discussion of why this works as it does is beyond the scope of this introduction, but the To Learn More section offers some pointers for those interested in delving deeper, which will take you into the realm of how JavaScript is in\ufb02uenced by its ancestors Scheme and Self. Until you understand the issue more deeply, you can make your own code safe by follow- ing the common cases we outlined, which Figure 6.11 summarizes. Pitfall: JavaScript\u2014the bad parts. The ++ operator was invented by [Ken] Thompson for pointer arithmetic. We now know that pointer arithmetic is bad, and we don\u2019t do it anymore; it\u2019s been implicated in buffer- overrun attacks and other evil stuff. The last popular language to include the ++ operator is C++, a language so bad it was named after this operator. \u2014Douglas Crockford, Programming and Your Brain, keynote at USENIX WebApps\u201912 conference The entrepreneurial boom in which JavaScript was born was a time of ridiculous sched- ule pressures: LiveScript was designed, implemented, and released in a product in 10 days. As a result, the language has some widely-regarded misfeatures and pitfalls that some have compared to \u201cgotchas\u201d in the C language, so we urge you to use Doug Crockford\u2019s JSLint32 tool to warn you of both potential pitfalls and opportunities to beautify your JavaScript code. Some speci\ufb01c pitfalls to avoid include the following: 1. The interpreter helpfully tries to insert semicolons it believes you forgot, but sometimes its guesses are wrong and result in drastic and unexpected changes in code behavior, such as the following example: 198 CHAPTER 6. SAAS CLIENTS: JAVASCRIPT ok : true ; // good : returns new object return { https://gist.github.com/4491c97822d4b7bec7c886905b4e64d5 1 2 3 4 5 6 7 8 9 10 }; // bad : returns undefined , because JavaScript // return { inserts \" missing semicolon \" after return ok : true ; }; One good workaround is to adopt a consistent coding style designed to make \u201cpunctua- tion errors\u201d quickly visible, such as the coding style recommended for Node.js package developers33. 2. Despite a syntax that suggests block scope\u2014for example, the body of a for-loop inside a function gets its own set of curly braces inside which additional var declarations can appear\u2014all variables declared with var in a function are visible everywhere through- out that function, including to any nested functions. Hence, in a common construction such as for (var m in movieList), the scope of m is the entire function in which the for-loop appears, not just the body of the for-loop itself. The same is true for vari- ables declared with var inside the loop body. This behavior, called function scope, was invented in Algol 60. Keeping functions short (remember SOFA from Section 9.5?) helps avoid the pitfall of block vs. function scope. 3. An Array is really just a object whose keys are nonnegative integers. In some JavaScript implementations, retrieving an item from a linear array is marginally faster than retrieving an item from a hash, but not enough to matter in most cases. The pitfall is that if you try to index an array with a number that is negative or not an integer, a string-valued key will be created. That is, a[2.1] becomes a[\"2.1\"]. 4. The comparison operators == and != perform type conversions automatically, so \u20195\u2019==5.0 is true. The operators === and !== perform comparisons without doing any conversions. This is potentially confusing because Ruby also has a === (\u201cthree- qual\u201d) operator that does something quite different. 5. Equality for arrays and hashes so in which the Array class can de- [1,2,3]==[1,2,3] is false. Unlike Ruby, \ufb01ne its own == operator, in JavaScript you must work around these built-in behaviors, because == is part of the language. is based on identity and not value, 6. Strings are immutable, so methods like toUpperCase() always return a new object. Hence write s=s.toUpperCase() if you want to replace the value of an existing variable. 7. If you call a function with more arguments than its de\ufb01nition speci\ufb01es, the extra argu- ments are ignored; if you call it with fewer, the unassigned arguments are undefined. In either case, the array arguments[] (within the function\u2019s scope) gives access to all arguments that were actually passed. 8. String literals behave differently from strings created with new String if you try to create new properties on them, as the code excerpt below shows. The reason 6.12. CONCLUDING REMARKS: JAVASCRIPT PAST, PRESENT AND FUTURE 199 is that JavaScript creates a temporary \u201cwrapper object\u201d around fake to respond to fake.newprop=1, performs the assignment, then immediately destroys the wrapper object, leaving the \u201creal\u201d fake without any newprop property. You can set extra prop- erties on strings if you create them explicitly with new. But better yet, don\u2019t set prop- erties on built-in types: de\ufb01ne your own prototype object and use composition rather than inheritance (Chapter 11) to make a string one of its properties, then set the other properties as you see \ufb01t. (This restriction applies equally to numbers and Booleans for the same reasons, but it doesn\u2019t apply to arrays because, as we mentioned earlier, they are just a special case of hashes.) https://gist.github.com/0458f7f6c0921e7002342ce5f0d177d9 1 2 3 4 5 6 real = new String ( \" foo \" ) ; fake = \" foo \" ; real . newprop = 1; real . newprop fake . newprop = 1; // BAD : silently fails since ' fake ' isn 't true object fake . newprop // = > undefined // = > 1"
    ]
  },
  {
    "id": "sec_0276",
    "title": "6.12 Concluding Remarks: JavaScript Past, Present and Future",
    "pages": [
      211,
      212,
      213,
      214,
      215,
      216
    ],
    "text_blocks": [
      "JavaScript\u2019s privileged position as the client-side language of the Web has focused a lot of energy on it. Just-in-time compilation (JIT) techniques and other advanced language engi- neering features are being brought to bear on the language, closing the performance gap with other interpreted and even some compiled languages. Over half a dozen JavaScript engine implementations and one compiler (Google\u2019s Closure) are available as of this writing, most of them open source, and vendors such as Microsoft, Apple, Google, and others compete on the performance of their browsers\u2019 JavaScript interpreters. As early as 2011, JavaScript was fast enough to use to rewrite large parts of the Palm webOS operating system. We can expect this trend to continue, because JavaScript is one of the \ufb01rst languages to receive attention when new hardware becomes available that could be useful for user-facing apps. We saw over and over again in studying Ruby and Rails that productivity often goes hand in hand with conciseness. JavaScript\u2019s syntax is sometimes awkward, in part be- cause JavaScript was always functional at heart (recall that its creator originally wanted to use Scheme as the browser scripting language) and in part because its large community of developers accustomed to class-oriented languages sometimes had dif\ufb01culty embracing JavaScript\u2019s alternative model of prototype-based inheritance. ECMAScript version 6 (ES6) attempts to address this by providing new keywords such as class that look more familiar to such developers, but it\u2019s important to remember that no new mechanisms or abilities were added to the language in this case. The new keywords are syntactic sugar that make prototype-based inheritance look and behave more like tradi- tional classes. Indeed, it is possible to create a Source-to-source compiler , sometimes called a transpiler, that consumes ES6 and emits pure JavaScript, as some early browsers\u2019 implementations of ES6 did. JavaScript\u2019s single-threaded execution model, which some feel hampers productivity be- cause it requires event-driven programming, seems unlikely to change anytime soon. Some bemoan the adoption of JavaScript-based server-side frameworks such as Node, a JavaScript library that provides event-driven versions of the same POSIX (Unix-like) operating system 200 REFERENCES facilities used by task-parallel code. Rails core committer Yehuda Katz summarized the opin- ions of many experienced programmers: when things happen in a deterministic order, such as server-side code handling a controller action in a SaaS app, a sequential and blocking model is easier to program; when things happen in an unpredictable order, such as reacting to user-initiated user interface events, the asynchronous model makes more sense. Your authors \ufb01rmly believe that the future of software is \u201ccloud+client\u201d apps, and our view is that it\u2019s more important to choose the right language or framework for each job than to obsess about whether a single language or framework will become dominant for both the client and cloud parts of the app. We covered only a small part of the language-independent DOM representation using its JavaScript API. The DOM representation itself has a rich set of data structures and traversal methods, and APIs are available for all major languages, such as the dom4j34 library for Java and the Nokogiri35 gem for Ruby. Here are additional useful resources for mastering JavaScript and jQuery: \u2022 A great presentation by Google JavaScript guru Mi\u0161ko Hevery: How JavaScript works: introduction to JavaScript and Browser DOM36 \u2022 Yehuda Katz37 is an active core committer to both Rails and jQuery, among other high- pro\ufb01le projects. His programmer-oriented blog posts discuss tips and techniques rang- ing from the practical to the esoteric for both Ruby and JavaScript. In particular, he has a nice post on the subtle difference between Ruby blocks and JavaScript anonymous functions38 and another on why this works the way it does in JavaScript functions39. \u2022 jQuery is an extremely powerful library whose potential we barely tapped. Combined with Bootstrap, it may provide the facilities needed to enhance server-centric apps whose client-side part is not complex enough to justify the use of a full client-side framework such as React. jQuery: Novice to Ninja (Castledine and Sharkie 2012) is an excellent reference with many examples that go far beyond our introduction. \u2022 JavaScript: The Good Parts (Crockford 2008), by the creator of the JSLint40 tool, is a highly opinionated, intellectually rigorous exposition of JavaScript, focusing uncom- promisingly on the disciplined use of its good features while candidly exposing the pitfalls of its design \ufb02aws. This book is \u201cmust\u201d reading if you plan to write entire JavaScript apps comparable to Google Docs. \u2022 The ProgrammableWeb41 site lists hundreds of service APIs, both RESTful and non- RESTful and serving both XML and JSON data, that you may \ufb01nd useful for SPAs and mashups. Some are completely open and require no authentication; others require a developer key which may be free or non-free. E. Castledine and C. Sharkie. jQuery: Novice to Ninja, 2nd Edition - New Kicks and Tricks. SitePoint Books, 2012. D. Crockford. JavaScript: The Good Parts. O\u2019Reilly Media, 2008. A. Osmani. The Cost of JavaScript in 2019. In PerfMatters Conference 2019, June 2019. URL https://v8.dev/blog/cost-of-javascript-2019. P. Seibel. Coders at Work: Re\ufb02ections on the Craft of Programming. Apress, 2009. ISBN 1430219483. NOTES Notes 201 1http://github.com/jasmine/jasmine 2https://vuejs.org/v2/guide/comparison.html 3http://jquery.org 4https://developer.mozilla.org/en-US/docs/Web/JavaScript 5http://developers.google.com/closure 6http://yui.github.io/yuicompressor 7http://jsonlint.com 8http://guides.rubyonrails.org/asset_pipeline.html 9https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes 10http://www.w3.org/DOM 11http://api.jquery.com 12http://api.jquery.com 13https://www.w3.org/TR/html52/ 14https://html.spec.whatwg.org/multipage/input.html#the-input-element 15https://www.w3.org/TR/html-aria/ 16https://www.w3.org/TR/wai-aria-1.1/#roles_categorization 17https://www.w3.org/TR/WCAG21/ 18https://www.deque.com/axe/axe-for-web/ 19https://www.w3.org/TR/wai-aria-practices-1.1/#aria_ex 20http://en.wikipedia.org/wiki/Web_Workers 21http://johnbintz.github.com/jasmine-headless-webkit/ 22http://github.com/jasmine/jasmine 23http://github.com/velesin/jasmine-jquery 24http://github.com/jasmine/jasmine 25http://github.com/velesin/jasmine-jquery 26http://github.com/jasmine/jasmine 27http://github.com/velesin/jasmine-jquery 28https://github.com/jasmine/jasmine-ajax 29https://developer.mozilla.org/en-US/docs/Web/JavaScript 30https://jstherightway.org/ 31http://jslint.com 32http://jslint.com 33https://www.npmjs.com/package/node-style-guide 34http://dom4j.sourceforge.net 35http://nokogiri.org 36http://misko.hevery.com/2010/07/14/how-javascript-works/ 37http://yehudakatz.com 38http://yehudakatz.com/2012/01/10/javascript-needs-blocks/ 39http://yehudakatz.com/2011/08/11/understanding-javascript-function-invocation-and- this 40http://jslint.com 41http://programmableweb.com 202 NOTES Part II Agile Software Development 7 Requirements: Behavior-Driven Design and User Stories Niklaus Wirth (1934\u2013) received the Turing Award in"
    ]
  },
  {
    "id": "sec_0277",
    "title": "1984 for his pioneering",
    "pages": [
      216
    ],
    "text_blocks": [
      "contributions to structured programming, in which structured control \ufb02ow constructs (if/then/else) and loops (while and for) improve the clarity and quality of code. Wirth also developed a sequence of innovative programming languages that embodied these concepts, including Algol-W, Euler, Modula, and Pascal. Clearly, programming courses should teach methods of design and construction, and the selected examples should be such that a gradual development can be nicely demonstrated. \u2014Niklaus Wirth, \u201cProgram Development by Stepwise Re\ufb01nement,\u201d CACM 14(5), May 1971 . . . . . . . . . . . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0278",
    "title": "7.1 Behavior-Driven Design and User Stories .",
    "pages": [
      216
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0279",
    "title": "7.2 SMART User Stories .",
    "pages": [
      216
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0280",
    "title": "7.3 Lo-Fi User Interface Sketches and Storyboards .",
    "pages": [
      216
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0281",
    "title": "7.4 Points and Velocity .",
    "pages": [
      216
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0282",
    "title": "7.5 Agile Cost Estimation .",
    "pages": [
      216
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0283",
    "title": "7.6 Cucumber: From User Stories to Acceptance Tests",
    "pages": [
      216
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0284",
    "title": "7.7 CHIPS: Intro to BDD and Cucumber .",
    "pages": [
      216
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0285",
    "title": "7.8 Explicit vs. Implicit and Imperative vs. Declarative Scenarios",
    "pages": [
      216
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0286",
    "title": "7.9 The Plan-And-Document Perspective on Documentation .",
    "pages": [
      216
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0287",
    "title": "7.10 Fallacies and Pitfalls .",
    "pages": [
      216
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0288",
    "title": "7.11 Concluding Remarks: Pros and Cons of BDD .",
    "pages": [
      216,
      217,
      218
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206 . 209 . 211 . 213 . 216 . 217 . 220 . 220 . 223 . 230 . 233 205 Prerequisites and Concepts Concepts: The big concepts of this chapter are requirements elicitation, cost estimation, project scheduling, and monitoring progress. The embodiment of these concepts for the Agile lifecycle, which follows Behavior- Driven Development (BDD), are: \u2022 User stories to elicit functional requirements. \u2022 Low-\ufb01delity (Lo-Fi) user interfaces and storyboards to elicit UI requirements. \u2022 Points to turn user stories into cost estimates. \u2022 Velocity to measure and estimate schedule. \u2022 Using the tool Cucumber to transform user stories into acceptance tests. \u2022 Using the tool Pivotal Tracker to track project progress, to calculate velocity, and to estimate time to milestones. For the Plan-and-Document lifecycle, you will become familiar with the same concepts in a quite different format: \u2022 Requirements elicitation via interviewing, scenarios, and use cases, requirements documentation via a Software Requirements Speci\ufb01cation (SRS), and require- ments fulllment using requirements traceability . \u2022 Cost estimation based on project manager experience or formulas such as CO- COMO, scheduling and monitoring progress using PERT charts, and change management using version control systems for documentation and schedule as well as the code. \u2022 Risk analysis and management to increase chances of project being successful. Both lifecycles illustrate the difference between functional versus non-functional requirements and explicit versus implicit requirements. 206 CHAPTER 7. BDD AND USER STORIES Figure 7.1: An iteration of the Agile software lifecycle and its relationship to the chapters in this book. This chapter emphasizes talking to customers as part of Behavior-Driven Design."
    ]
  },
  {
    "id": "sec_0289",
    "title": "7.1 Behavior-Driven Design and User Stories",
    "pages": [
      218,
      219,
      220,
      221
    ],
    "text_blocks": [
      "Behavior-Driven Design is Test-Driven Development done correctly. \u2014Anonymous Software projects fail because they don\u2019t do what customers want; or because they are late; or because they are over budget; or because they are hard to maintain and evolve; or all of the above. The Agile lifecycle was invented to attack these problems for many common types of software. Figure 7.1 shows one iteration of the Agile lifecycle from Chapter 1, highlighting the portion covered in this chapter. As we saw in Chapter 1, the Agile lifecycle involves: \u2022 Working closely and continuously with stakeholders to develop requirements and tests. \u2022 Maintaining a working prototype while deploying new features typically every two weeks\u2014called an iteration\u2014and checking in with stakeholders to decide what to add next and to validate that the current system is what they really want. Having a working prototype and prioritizing features reduces the chances of a project being late or over budget, or perhaps increasing the likelihood that the stakeholders are satis\ufb01ed with the current system once the budget is exhausted! Unlike a plan-and-document lifecycle in Chapter 1, Agile development does not switch phases (and people) over time from development mode to maintenance mode. With Agile, you are basically in maintenance mode as soon as you\u2019ve implemented the \ufb01rst set of features. This approach helps make the project easier to maintain and evolve. Agile stakeholders include users, customers, developers, maintenance programmers, operators, project management, . . . . 7.1. BEHAVIOR-DRIVEN DESIGN AND USER STORIES 207 We start the Agile lifecycle with Behavior-Driven Design (BDD). BDD asks questions about the behavior of an application before and during development so that the stakeholders are less likely to miscommunicate. Requirements are written down as in plan-and-document, but unlike plan-and-document, requirements are continuously re\ufb01ned to ensure the resulting software meets the stakeholders\u2019 desires. That is, using the terms from Chapter 1, the goal of BDD requirements is validation (build the right thing), not just veri\ufb01cation (build the thing right). The BDD version of requirements is user stories, which describe how the application is expected to be used. They are lightweight versions of requirements that are better suited to Agile. User stories help stakeholders plan and prioritize development. Thus, like plan- and-document, you start with requirements, but in BDD user stories take the place of design documents in plan-and-document. By concentrating on the behavior of the application versus its implementation, it is easier to reduce misunderstandings between stakeholders. As we shall see in the next chapter, BDD is closely tied to Test-Driven Development (TDD), which does test implementation. In practice they work together hand-in-hand, but for pedagogical reasons we introduce them sequentially. User stories came from the Human Computer Interface (HCI) community. They devel- oped them using 3-inch by 5-inch index cards or \u201c3-by-5 cards,\u201d or in countries where metric paper sizes are used, A7 cards of 74 mm by 105 mm. (We\u2019ll see other examples of paper and pencil technology from the HCI community shortly.) These cards contain one to three sentences in everyday nontechnical language written jointly by the customers and developers. The rationale is that paper cards are nonthreatening and easy to rearrange, thereby enhancing brainstorming and prioritizing. The general guidelines for the user stories themselves is that they must be testable, be small enough to implement in one iteration, and have business value. Section 7.2 gives more detailed guidance for good user stories. Note that individual developers working by themselves without customer interaction don\u2019t need these 3-by-5 cards, but this \u201clone wolf\u201d developer doesn\u2019t match the Agile philos- ophy of working closely and continuously with the customer. We will use the RottenPotatoes app from Chapters 3 and 4 as the running example in this chapter and the next one. We start with the stakeholders for this simple app: \u2022 The operators of RottenPotatoes, and \u2022 The movie fans who are end-users of RottenPotatoes. introduce a new feature in Section 7.6, but We\u2019ll the mov- ing parts, we\u2019ll start with a user story for an existing feature of RottenPotatoes the components in a simpler set- so that we can understand the relationship of all The user story we picked is to add movies to the RottenPotatoes database: ting. to help understand all 208 CHAPTER 7. BDD AND USER STORIES Scenario : Add a movie As a movie fan So that I can share a movie with other movie fans I want to add a movie to RottenPotatoes database https://gist.github.com/1b759799a29f3b3e56686b32c6509ec1 Feature : Add a movie to RottenPotatoes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Given I am on the RottenPotatoes home page When I follow \" Add new movie \" Then I should be on the Create New Movie page When I fill in \" Title \" with \" Hamilton \" And I select \" PG -13 \" from \" Rating \" And I select \" July 4 , 2020 \" as the \" Released On \" date And I press \" Save Changes \" Then I should be on the RottenPotatoes home page And I should see \" Hamilton \" This user story format was developed by the startup company Connextra and is named after them; sadly, this startup is no longer with us. The format is: https://gist.github.com/f2be5cdde6a9d6c116a9877fb93aa0b9 1 2 3 4 As a [ kind of stakeholder ] , So that [ I can achieve some goal ] , I want to [ do some task ] Feature name This format identi\ufb01es the stakeholder since different stakeholders may describe the de- sired behavior differently. For example, users may want links to information sources to make it easier to \ufb01nd the information, while operators may want links to trailers so that they can get an income stream from the advertisers. All three clauses have to be present in the Connextra format, but they do not have to be in this order. Summary of BDD and User Stories \u2022 BDD emphasizes working with stakeholders to de\ufb01ne the behavior of the system be- ing developed. Stakeholders include nearly everyone: customers, developers, man- agers, operators, . . . . \u2022 User stories, a device borrowed from the HCI community, make it easy for non- technical stakeholders to help create requirements. \u2022 3 \u00d7 5 cards (or A7-size cards), each with a user story of one to three sentences, are a simple and nonthreatening technology that lets all stakeholders brainstorm and prioritize features. \u2022 The Connextra format of user stories captures the stakeholder, the stakeholder\u2019s goal for the user story, and the task at hand. 7.2. SMART USER STORIES 209 Elaboration: User Stories and Case Analysis User stories represent a lightweight approach to use-case analysis, a term traditionally used in software engineering to describe a similar process. A full use case analysis would include the use case name; actor(s); goals of the action; summary of the use case; preconditions (state of the world before the action); steps occurring in the scenario (both the actions performed by the user and the system\u2019s responses); related use cases; and postconditions (state of the world after the action). A use case diagram is a type of UML diagram (see Chapter 11) with stick \ufb01gures standing in for the actors, and can be used to generalize or extend use cases or to include a use case by reference. For example, if we have a use case for \u201cuser logs in\u201d and another use case for \u201clogged-in user views her account summary\u201d, the latter could include the former by reference, since a precondition to the second use case is that the user has logged in. Self-Check 7.1.1. True or False: User stories on 3x5 cards in BDD play the same role as design requirements in plan-and-document. True."
    ]
  },
  {
    "id": "sec_0290",
    "title": "7.2 SMART User Stories",
    "pages": [
      221,
      222,
      223
    ],
    "text_blocks": [
      "What makes a good user story versus a bad one? The SMART acronym offers concrete and (hopefully) memorable guidelines: Speci\ufb01c, Measurable, Achievable, Relevant, and Time- boxed. \u2022 Speci\ufb01c. Here is an example of a vague feature paired with a speci\ufb01c version: https://gist.github.com/c1d72e393df67e390453bc030d2caa37 1 2 Feature : User can search for a movie ( vague ) Feature : User can search for a movie by title ( specific ) \u2022 Measurable. Adding Measurable to Speci\ufb01c means that each story should be testable, which implies that there are known expected results for some good inputs. Here is an example of an unmeasurable feature versus its measurable counterpart: https://gist.github.com/ae608d98061eebb1348f988b67ae5563 1 2 3 RottenPotatoes should have good response time ( unmeasurable ) When adding a movie , 99% of Add Movie pages should appear within 3 seconds ( measurable ) Feature : Feature : Only the second case can be tested to see if the system ful\ufb01lls the requirement. \u2022 Achievable. Ideally, you implement the user story in one Agile iteration. If you are getting less than one story per iteration, then they are too big and you need to subdi- vide these stories into smaller ones. As mentioned above, the tool Pivotal Tracker measures Velocity , which is the rate of completing stories of varying dif\ufb01culty. \u2022 Relevant. A user story must have business value to one or more stakeholders. To drill down to the real business value, one technique is to keep asking \u201cWhy.\u201d Using as an example a ticket-selling app for a regional theater, suppose the proposal is to add a Facebook linking feature. Here are the \u201cFive Whys\u201d in action with their recursive questions and answers: 210 CHAPTER 7. BDD AND USER STORIES 1. Why add the Facebook feature? As box of\ufb01ce manager, I think more people will go with friends and enjoy the show more. 2. Why does it matter if they enjoy the show more? I think we will sell more tickets. 3. Why do you want to sell more tickets? Because then the theater makes more money. 4. Why does the theater want to make more money? We want to make more money so that we don\u2019t go out of business. 5. Why does it matter that the theater is in business next year? If not, I have no job. (We\u2019re pretty sure the business value is now apparent to at least one stakeholder!) \u2022 Timeboxed. Timeboxing means that you stop developing a story once you\u2019ve exceeded the time budget. Either you give up, divide the user story into smaller ones, or resched- ule what is left according to a new estimate. If dividing looks like it won\u2019t help, then you go back to the customers to \ufb01nd the highest value part of the story that you can do quickly. The reason for a time budget per user story is that it is extremely easy to underestimate the length of a software project. Without careful accounting of each iteration, the whole project could be late, and thus fail. Learning to budget a software project is a critical skill, and exceeding a story budget and then refactoring it is one way to acquire that skill. One important concept expands upon the R of SMART. The minimum viable product (MVP) is a subset of the full set of features that when completed has business value in the real world. Not only are the stories Relevant, but the combination of all of them makes the software product viable in the marketplace. Obviously, you can\u2019t start selling the product if it\u2019s not viable, so it makes sense to give priority to the stories that will let the product be shipped. The Epic or a Release point of Pivotal Tracker can help identify the stories of the MVP. Summary of SMART User Stories \u2022 The SMART acronym captures the desirable features of a good user story: Speci\ufb01c, Measurable, Achievable, Relevant, and Timeboxed. \u2022 The Five Whys are a technique to help you drill down to uncover the real business relevance of a user story. Self-Check 7.2.1. Which SMART guideline(s) does https://gist.github.com/5eee5f0d00ca47c288c854a7a56fa60b 1 Feature : RottenPotatoes should have a good User Interface the feature below violate? It is not Speci\ufb01c, not Measurable, not Achievable (within 1 iteration), and not",
      "Timeboxed. While business Relevant, this feature goes just one for \ufb01ve. Self-Check 7.2.2. Rewrite this feature to make it SMART. 7.3. LO-FI USER INTERFACE SKETCHES AND STORYBOARDS 211 https://gist.github.com/f284bab41b84680a27572cb1f6881fee 1 Feature : I want to see a sorted list of movies sold . Here is one SMART revision of this user story: https://gist.github.com/4058581d653f1e429c46e816db6c792c 1 2 Feature : As a customer , I want to see the top 10 movies sold , listed by price , so that I can buy the cheapest ones first . Given user stories as the work product from eliciting requirements of customers, we can introduce a metric and tool to measure productivity."
    ]
  },
  {
    "id": "sec_0291",
    "title": "7.3 Lo-Fi User Interface Sketches and Storyboards",
    "pages": [
      223,
      224,
      225
    ],
    "text_blocks": [
      "We usually need to specify a user interface (UI) when adding a new feature since many SaaS applications interact with end users. Thus, part of the BDD task is often to propose a UI to match the user stories. If a user story says a user needs to login, then we need a mockup of a page that has the login. Alas, building software prototypes of user interfaces can intimidate stakeholders from suggesting improvements\u2014just the opposite of the effect we need at this early point of the design. What we want is the UI equivalent of 3x5 cards; engaging to the nontechnical stakeholder and encouraging trial and error, which means it must be easy to change or even discard. Just as the HCI community advocates 3x5 cards for user stories, they recommend using kinder- garten tools for UI mockups: crayons, construction paper, and scissors. They call this low- tech approach to user interfaces lo-\ufb01 (low-\ufb01delity) UI and the paper prototypes sketches. Ideally, you make sketches for all the user stories that involve a UI. It may seem tedious, but eventually you are going to have to specify all the UI details when using HTML to make the real UI, and it\u2019s a lot easier to get it right with pencil and paper than with code. A lo-\ufb01 sketch shows what the UI looks like at one instant in time. However, we also need to show how the sketches work together as a user interacts with a page. Filmmakers face a similar challenge with scenes of a movie. Their solution, which they call storyboarding , is to go through the entire \ufb01lm as if it was a comic book, with drawings for every scene. Instead of a linear sequence of images like in a movie, the storyboard for a UI is typically a tree or graph of screens driven by different user choices. To make a storyboard, you must think about all the user interactions with a web app: \u2022 Pages or sections of pages, \u2022 Forms and buttons, and \u2022 Popups. Figure 7.2 shows a storyboard composed of lo-\ufb01 sketches for adding a new movie to RottenPotatoes. The storyboard includes indications of what the user clicks to cause the transitions between sketches. After drawing the sketches and storyboards, you are ready to write HTML. Chapter 3 showed how Erb markup becomes HTML, and how the class and id attributes of HTML elements can be used to attach styling information to them via Cascading Style Sheets (CSS). The key to the lo-\ufb01 approach is to get a good overall structure from your sketches, and do minimal CSS (if any) to get the view to look more or less like 212 CHAPTER 7. BDD AND USER STORIES Figure 7.2: A storyboard illustrating two simple user stories about RottenPotatoes. Top: RottenPotatoes home page, listing all movies; the starting point for both stories. Middle: Screen that should appear when adding a movie to RottenPotatoes. Bottom: Screen that should appear when viewing details of an existing movie. The red-shaded words on each page are clickable links or buttons; the arrows show what screen should be displayed next if that link or button is clicked. 7.4. POINTS AND VELOCITY 213 your sketch. Remember that the common parts of the page layout\u2014banners, structural divs, and so on\u2014can go into views/layouts/application.html.erb. Start the process by looking at the lo-\ufb01 UI sketches and split them into \u201cblocks\u201d of the layout. Use HTML divs for obvious layout sections. There is no need to make it pretty until after you have everything working. Adding CSS styling, images, and so on is the fun part, but make it look good after it works. One reason we have repeatedly advocated for the use of CSS frameworks such as Bootstrap in this book is that they facilitate producing an acceptable-looking prototype quickly. Summary: Borrowing from the HCI community once again, lo-\ufb01 sketches are low cost ways to explore the user interface of a user story. Paper and pencil makes them easy to change or discard, which once again can involve all stakeholders. Storyboards capture the interaction between different pages depending on what the user does. It is much less effort to experiment in this low cost medium before using HTML and CSS to create the pages you want. Self-Check 7.3.1. True or False: The purpose of lo-\ufb01 UI sketches and storyboards is to debug the UI before you program it. True."
    ]
  },
  {
    "id": "sec_0292",
    "title": "7.4 Points and Velocity",
    "pages": [
      225,
      226
    ],
    "text_blocks": [
      "One way to measure the productivity of a team would be simply to count the number of user stories completed per iteration, and then calculate the average. The average would then be used to decide how many stories to try to implement each iteration. The problem with this measure is that some stories are much harder than others, leading to mispredictions. The simple solution is to give each user story an integer number of points re\ufb02ecting its perceived dif\ufb01culty. The \u201cvalue\u201d of a point\u2014the approximate expected number of coding hours it represents\u2014is completely up to the team, and will likely differ across teams, but the point scale should have two important properties. First, everyone on the team should be in rough agreement on how much a \u201cpoint\u201d is worth. Second, more points should represent not only more effort, but more uncertainty. For example, your team might start with a simple 3-point scale in which 1 point represents approximately a 3-hour work session. Your team might be good at estimating the effort required to complete a 1 or 2 point story this way, but can you con\ufb01dently estimate that a 3-point story will really take 9 hours of work? For this reason, your team should also set a threshold above which a story must be broken down into smaller tasks before estimating its dif\ufb01culty, until each task is suf\ufb01ciently well understood that it can be estimated with high con\ufb01dence. Therefore, in our simple suggested introductory scheme, you might decide that any story estimated at higher than 3 points must be subdivided into stories that everyone agrees are 3 points or less. A practical way to estimate points that also builds the team\u2019s collective ownership (knowl- edge of different parts of the project being diffused around the team) is known as planning poker . During an Iteration Planning Meeting at the beginning of an iteration, the team \ufb01rst prioritizes the stories according to the stated desires of the customer (or the Product Owner speaking for the customer). Each story is discussed in turn: the Project Manager reads and reviews the story to ensure everyone understands what the story requires, then each team member places a card face-down marked with the number of points they think that story Fibonacci scale With more experience, the Fibonacci scale is commonly used: 1, 2, 3, 5, and 8. (Each new number is sum of previous two.) However, at places like Pivotal Labs, 8 is extremely rare. Tracker intro Pivotal Labs has produced an excellent 3-minute video intro2 to using Tracker. 214 CHAPTER 7. BDD AND USER STORIES should be worth. An even easier variation is to have everyone simultaneously stick out 1 to 5 \ufb01ngers, in the style of the children\u2019s game Rock\u2013Paper\u2013Scissors. There should be a card (or hand gesture) that means \u201cI don\u2019t know\u201d and another that means \u201cThis story is too compli- cated and should be broken down.\u201d The team then discusses differences in the votes to reach consensus, and they vote again, possibly after subdividing the story. An inability to reach consensus may indicate a story that isn\u2019t SMART. When should a story get more points? Some stories may require information-gathering, such as becoming familiar with other parts of the codebase or doing some scouting to deter- mine which \ufb01les or classes in the app will be affected by the proposed feature. A major source of uncertainty, such as \ufb01guring out how to integrate a new technology or library, should get its own spike: a short investigation into a technique or problem that the team wants explored before sitting down to do serious coding. An example would be a spike on incorporating recommendations into an app, in which a developer or pair investigates different algorithms and different libraries that could be used, possibly using a scratch branch of the code (which we discuss in Section 10.2) to do some basic testing and exploration. After a spike is done, the spike code must be thrown away: The spike\u2019s purpose is to help you determine what approach you want to follow, and now that you know, you should write it correctly. The backlog is the collection of stories that have been prioritized and assigned points in this way, but have not yet been started in this iteration. The team then begins delivering the backlog, that is, working on the stories in priority order during the iteration. (Section 10.4 presents best practices for coordinating this work.) At the end of the iteration, the team computes the total number of points completed, rather than the number of stories. The moving average of this total is called the team\u2019s velocity . Velocity measures work rate based on the team\u2019s self-evaluation. As long as the team rates user stories consistently, it doesn\u2019t matter whether the team is completing 5 points or"
    ]
  },
  {
    "id": "sec_0293",
    "title": "10 points per iteration. The purpose of velocity is to give all stakeholders an idea how many",
    "pages": [
      226,
      227,
      228
    ],
    "text_blocks": [
      "iterations it will take a team to add the desired set of features, which helps set reasonable expectations and reduces chances of disappointment. Points and velocity are often used as the basis of a burn down chart, which shows work to be done (points) on the vertical axis and time along the horizontal axis. The slope of the downward-pointing line is the team\u2019s velocity, and the line\u2019s intersection with the x-axis represents the prediction for when the work will be done. Figure 7.3 shows the UI of Pivotal Tracker1, a Web-based tool that allows a team to enter and prioritize user stories with point values, assign stories to developers, attach design documents such as lo-\ufb01 mockups to stories, and perhaps most importantly, track points and velocity as stories are delivered, optionally generating a variety of analytics including burn down charts. Tracker also provides an Icebox panel, which contains unprioritized stories. They can stay \u201con ice\u201d inde\ufb01nitely, but when you\u2019re ready to start working on them, just drag them to the Current or Backlog panels. Tracker provides a way to enter a spike and prioritize it relative to other stories, so the team knows that certain stories cannot be completed until the spike is done. Similarly, one story can be marked as being blocked by another, indicating a dependency that must be taken into account when arranging the backlog in priority order. Finally, since complex stories representing a single \u201cfeature\u201d should be broken down into smaller stories, Tracker provides Epics as a way of grouping related stories and tracks how many total points are still needed to complete the epic, regardless of how the stories are ordered in the backlog. The idea is to give software engineers the big picture of where the application is in the development process with regard to big features. 7.4. POINTS AND VELOCITY 215 Figure 7.3: Screen image of the UI of the Pivotal Tracker service. Because Tracker calculates velocity based on points completed, it groups the remaining prioritized stories in the backlog into iterations based on the assumption that velocity will remain approximately constant. These estimates can be useful in setting customer expecta- tions as to when a particular feature will be delivered. Tracker even allows the insertion of Release markers, which bound the stories that must all be delivered before a particular fea- ture is completely working and ready to announce to the customer. (We will have more to say about releases in Section 12.4.) This approach is in sharp contrast to management by schedule, in which a manager picks a release date and the team is expected to work hard to meet the deadline. Some teams use GitHub Issues3 to track stories as a to-do list, or a project management tool such as Trello4 to put virtual story cards on a virtual wall. These simpler tools are \ufb01ne to start out with, but they lack the ability to track points and velocity, and therefore to supply estimates of story completion time in more complicated projects. In addition, Tracker is a good place to centralize information about the project\u2014design notes, architecture diagrams, lo-\ufb01 sketches, and so on\u2014because you can associate it with individual user stories and even link out to documents in Google Docs or other places. Every GitHub repository also includes a Wiki, which allows team members to jointly edit a document and add \ufb01les. Whatever tool you choose, the important thing is to keep all documentation about the project accessible from one place that the whole team can agree on, and which will remain stable even as members of the team come and go. 216 CHAPTER 7. BDD AND USER STORIES Summary of points and velocity: \u2022 To help the team manage each iteration and to predict how long the team will take to implement new features, the team assigns points to rate dif\ufb01culty of user stories and tracks the team\u2019s velocity , or average points per iteration. \u2022 Techniques such as planning poker, in which team members simultaneously \u201cvote\u201d on the dif\ufb01culty of a story and then discuss discrepancies, are a quick and practical way to estimate points while diffusing knowledge of the project throughout the team. \u2022 Pivotal Tracker provides a service that helps prioritize and keep track of user stories and their status, calculates velocity, and predicts software development time based on the team\u2019s history. Self-Check 7.4.1. True or False: When comparing two teams, the one with the higher veloc- ity is more productive. False: Since each team assigns points to user stories, you cannot use velocity to compare different teams. However, you could look over time for a given team to see if there were iterations that were signi\ufb01cantly less or more productive. Self-Check 7.4.2. True or False: When you don\u2019t know how to approach a given user story, just give it 3 points. False: A user story should not be so complex that you don\u2019t have an approach to imple- menting it. If they are, you should go back to your stakeholders to refactor the user story into a set of simpler tasks that you do know how to approach."
    ]
  },
  {
    "id": "sec_0294",
    "title": "7.5 Agile Cost Estimation",
    "pages": [
      228,
      229
    ],
    "text_blocks": [
      "Given that the Agile Manifesto values customer collaboration over contract negotiation, it is unsurprising that it does not follow the plan-and-document approach of making a cost estimate and schedule for a given set of features as part of a bid to win a contract, as we shall see in Section 7.9. This section describes the process at Pivotal Labs, which relies upon Agile development (Burkes 2012). Because Pivotal does Agile, Pivotal never commits to delivering features X, Y, and Z by date D. Pivotal commits to providing a certain amount of resources to work in the most ef\ufb01cient way possible up to date D. Along the way, Pivotal needs the client to work with the project team to de\ufb01ne priorities, and let Tracker\u2019s velocity guide the decisions as to which features actually make it into the release on date D. A potential client \ufb01rst gets in contact with the Agile team. If it looks like a good \ufb01t for the Agile team, they do a 30 to 60 minute phone call telling the potential client what an engagement looks like, how it\u2019s different from other \u201coutsourcing\u201d agencies, what type of time commitment it will require on the customer\u2019s part, and so on. This \ufb01rst call makes clear that the Agile team works on a time and materials basis, not on a \ufb01xed bid basis, as is usually the case with plan-and-document processes. The Agile team gets them to describe at a high level what they want developed, what their current development process looks like, what their current staf\ufb01ng is, and so on. Pivotal Labs is a software consultancy that teaches clients the Agile lifecycle while collaborating with them to develop a speci\ufb01c software product. 7.6. CUCUMBER: FROM USER STORIES TO ACCEPTANCE TESTS 217 If the client is comfortable with what they heard, and the Agile team thinks it still sounds like a good \ufb01t, the client visits for what Pivotal calls a \u201cscoping.\u201d A scoping is a roughly 90 minute conversation with a potential client, preferably in person. The Agile team asks the client to bring the person responsible for the product, a lead developer if they have one, a designer if they have one, any existing designs for what they want built, and so on. Basically, the client representatives bring whatever they think can clarify exactly what they want done, and the Agile team brings two engineers to the scoping. During the scoping, the Agile team asks the client to describe what they want done in detail, and they ask a series of questions designed to identify unknowns, risks, external inte- grations, and so forth. Essentially, the Agile team wants to identify anything that would add uncertainty to the estimate that the Agile team will deliver. If the Agile team gets a client with a very clear de\ufb01nition of what they want to build, a \ufb01nished design, no external inte- grations, and so on, the Agile team can produce a fairly tightly-scoped estimate, such as \u201c20 to 22 weeks.\u201d On the other hand, if they don\u2019t have clear product de\ufb01nition, lots of external integrations, or other uncertainty, the Agile team\u2019s estimate will have a greater range, such as \u201c18 to 26 weeks.\u201d If you use pair programming (see Section 2.2), as Pivotal Labs does, the cost estimates would be in \u201cpair weeks.\u201d After the client leaves the scoping, the Pivots (engineers) involved will stay behind for another 15 to 30 minutes, and agree on an estimate in terms of weeks. They deliver their \ufb01ndings, which include the estimate, identi\ufb01cation of risks, and so on, to the sales staff, who then turn that into a proposal email to the client. Because the Agile team does time and materials only, it\u2019s easy to turn estimated weeks into an estimated range of expense. Summary: Following the Agile Manifesto\u2019s emphasis on customer cooperation over con- tracts, an Agile team\u2019s notion of \u201ccost estimation\u201d is therefore more about advising the client on what team size can provide the maximum ef\ufb01ciency, following Brooks\u2019s Law that there is a point of diminishing returns on team size (see Section 7.10). The Agile team\u2019s goal in the scoping process is to identify that point, then ramp the team up to that size over time. Agile companies bid costs for time and materials based on short discussions with external customers. As we shall see in Section 7.9, this approach is in sharp contrast with companies that follow plan-and-document processes, which promise customers a set of features for an agreed upon cost by an agreed upon date. Self-Check 7.5.1. True or False: As practitioners of Agile Development, Pivotal Labs does not use contracts. False. Pivotal certainly offers customers a contract that they sign, but it is primarily a promise to pay Pivotal for its best effort to make the customer happy over a limited range of time. With the already helpful role of user stories for measuring progress behind us, we intro- duce a tool that lets user stories play yet another important role."
    ]
  },
  {
    "id": "sec_0295",
    "title": "7.6 Cucumber: From User Stories to Acceptance Tests",
    "pages": [
      229,
      230,
      231,
      232
    ],
    "text_blocks": [
      "Remarkably enough, the tool Cucumber turns customer-understandable user stories into acceptance tests, which ensure the customer is satis\ufb01ed, and integration tests, which 218 CHAPTER 7. BDD AND USER STORIES Scenario : Add a movie As a movie fan So that I can share a movie with other movie fans I want to add a movie to RottenPotatoes database https://gist.github.com/1b759799a29f3b3e56686b32c6509ec1 Feature : Add a movie to RottenPotatoes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Given I am on the RottenPotatoes home page When I follow \" Add new movie \" Then I should be on the Create New Movie page When I fill in \" Title \" with \" Hamilton \" And I select \" PG -13 \" from \" Rating \" And I select \" July 4 , 2020 \" as the \" Released On \" date And I press \" Save Changes \" Then I should be on the RottenPotatoes home page And I should see \" Hamilton \" Figure 7.4: A Cucumber scenario associated with the adding a movie feature for RottenPotatoes. ensure that the interfaces between modules have consistent assumptions and communicate correctly. (Chapter 1 describes types of testing.) The key is that Cucumber meets halfway between the customer and the developer: user stories don\u2019t look like code, so they are clear to the customer and can be used to reach agreement, but they also aren\u2019t completely free-form. This section explains how Cucumber accomplishes this minor miracle. In the Cucumber context we will use the term user story to refer to a single feature with one or more scenarios that show different ways a feature is used. The keywords Feature and Scenario identify the respective components. Each scenario is in turn composed of a sequence of typically 3 to 8 steps. Expanding a user story into a set of scenarios also helps developers enumerate the various user-visible conditions that will be tested to ensure the feature works. For example, consider a \ufb01ctitious e-commerce site that wants developers to implement the feature Customer can use \u201cguest checkout\u201d to make a purchase without creating an account. This might be broken down into several scenarios: \u2022 Customer can complete a purchase as guest \u2022 Customer cannot do a guest purchase if the order includes a gift \u2022 Multiple guest checkouts associated with same email address group the orders into the same account Notice in particular the third scenario, which might arise from conversation with the cus- tomer while discussing the feature: \u201cWell, what happens if the same email address appears on multiple orders but that user has no account? Should we associate those orders with the same customer internally?\u201d Indeed, such discussions are vital to \ufb02eshing out ambiguities in the customer\u2019s desired features. Figure 7.4 is an example user story, showing a feature with one scenario of adding the movie Hamilton; the scenario has nine steps. (We show just a single scenario in this ex- ample, but features usually have many scenarios.) Although stilted writing, this format that Cucumber can act upon is still easy for the nontechnical customer to understand, providing a common representation of the story on which the customer and team can now collaborate\u2014a founding principle of Agile and BDD. Each step of a scenario starts with its own keyword. Steps that start with Given usually set up some preconditions, such as navigating to a page. Steps that start with When typically Cucumber keywords Given, When, Then, And, and But have different names just for the bene\ufb01t of human readers, but they are all aliases to the same method. 7.6. CUCUMBER: FROM USER STORIES TO ACCEPTANCE TESTS 219 use one of Cucumber\u2019s built-in web steps to simulate the user pressing a button, for example. Steps that start with Then will usually check to see if some condition is true. The conjunction And allows more complicated versions of Given, When, or Then phrases. The only other keyword you see in this format is But. A separate set of \ufb01les de\ufb01nes the Ruby code that tests these steps. These are called step de\ufb01nitions. How does Cucumber match each step of a scenario with the correct step de\ufb01nitions? The trick is that Cucumber uses regular expressions or regexes (Chapter 2) to match the phrases in the scenario steps to the step de\ufb01nitions themselves. For example, below is a string from a step de\ufb01nition in the scenario for RottenPotatoes: https://gist.github.com/8873bc7dc65d123f752e37fdb701ea6e 1 Given /^(?:| I ) am on (.+) $ / This regex can match the text \u201cI am on the RottenPotatoes home page\u201d on line 6 of Figure 7.4. The regex also captures the string after the phrase \u201cam on \u201d until the end of the line (\u201cthe RottenPotatoes home page\u201d). The body of the step de\ufb01nition contains Ruby code that tests the step, likely using captured strings such as the one above. Thus, most step de\ufb01nitions are typically used by many different steps. You can think of step de\ufb01nitions as method de\ufb01nitions, and the steps of the scenarios are analogous to method calls. We then need a tool that will act as a user and pretend to use the feature under different scenarios. In the Rails world, this tool is called Capybara, and Cucumber integrates seam- lessly with it. Capybara \u201cpretends to be a user\u201d by taking actions in a simulated web browser, for example, clicking on a link or button. Capybara can interact with the app to receive pages, parse the HTML, and submit forms as a user would. In the rest of this chapter and its asso- ciated CHIPS, you will write your own steps to describe the app\u2019s behavior, then connect the steps to step de\ufb01nitions that actually stimulate the app to instantiate the behaviors\u2014the core of Behavior-Driven Design. Finally, the simple scenario above only describes one particular happy path of the fea- ture in question, but it is also important to agree with the customer on what should happen when things go wrong. For example, if the user leaves the movie title blank, we would probably want to redisplay the Create New Movie page, but perhaps with an error message informing the user of what went wrong. This \u201csad path\u201d would get its own scenario in the feature \ufb01le and its own storyboard, since describing what happens when things go wrong is part of the overall feature. Summary of Cucumber Introduction \u2022 Cucumber lets you use a stylized, restricted form of English to describe a set of user stories, or scenarios, that collectively describe a feature. \u2022 The steps of a Cucumber scenario use the keyword Given to describe the current state, When to identify user actions, and Then to describe the intended consequences of those actions. \u2022 Each scenario step is matched to a step de\ufb01nition using regular expressions. A typical step de\ufb01nition uses the browser simulator Capybara to simulate a user\u2019s actions corresponding to that step, or interrogates the app to check if the desired consequences of the user\u2019s actions have occurred. 220 CHAPTER 7. BDD AND USER STORIES Elaboration: Stubbing the web The way we use Cucumber and Capybara in this chapter doesn\u2019t allow us to test JavaScript code, which is covered in Chapter 6. With appropriate options, Cucumber can control Web- driver, which actually \ufb01res up a real browser and \u201cremote controls\u201d it to make it do what the stories say, including all JavaScript code. For this chapter, we will use Capybara\u2019s \u201chead- less browser simulator\u201d mode, which is much faster and is appropriate for testing everything except JavaScript. Self-Check 7.6.1. Given that Cucumber step de\ufb01nitions are just Ruby code, in principle we could just write the entire scenario in Ruby, rather than writing steps in stilted English and looking up the step de\ufb01nition for each step. Why do you think Cucumber has remained pop- ular despite this fact? The customer can (probably) read the Cucumber scenario steps and understand the de- scription of what the app is supposed to do, and can determine whether they agree with that description. Most customers would \ufb01nd it much more dif\ufb01cult to read Ruby code. Thus the scenarios provide a common ground on which the technical team and customer can meet."
    ]
  },
  {
    "id": "sec_0296",
    "title": "7.7 CHIPS: Intro to BDD and Cucumber",
    "pages": [
      232
    ],
    "text_blocks": [
      "CHIPS 7.7: BDD With Cucumber https://github.com/saasbook/hw-bdd-cucumber In this exercise you\u2019ll write Cucumber scenarios to both test existing features and drive the creation of new features in the RottenPotatoes app."
    ]
  },
  {
    "id": "sec_0297",
    "title": "7.8 Explicit vs. Implicit and Imperative vs. Declarative Scenarios",
    "pages": [
      232,
      233,
      234,
      235
    ],
    "text_blocks": [
      "Now that we have seen user stories and Cucumber in action, we are ready to cover two important testing topics that involve contrasting perspectives. The \ufb01rst is explicit versus implicit requirements. A large part of the formal speci\ufb01cation in plan-and-document is requirements, which in BDD are user stories developed by the stake- holders. Using the terminology from Chapter 1, they typically correspond to acceptance tests. Implicit requirements are the logical consequence of explicit requirements, and typically cor- respond to what Chapter 1 calls integration tests. An example of an implicit requirement in RottenPotatoes might be that by default movies should be listed in chronological order by release date. The good news is that you can use Cucumber to kill two birds with one stone\u2014create acceptance tests and integration tests\u2014if you write user stories for both explicit and implicit requirements. (The next chapter shows how to use another tool for unit testing.) The second contrasting perspective is imperative versus declarative scenarios. The ex- ample scenario in Figure 7.4 above is imperative, in that you are specifying a logical sequence of user actions: \ufb01lling in a form, clicking on buttons, and so on. Imperative scenarios tend to have complicated When statements with lots of And steps. While such scenarios are useful 7.8. EXPLICIT VS. IMPLICIT AND IMPERATIVE VS. DECLARATIVE SCENARIOS221 in ensuring that the details of the UI match the customer\u2019s expectations, it quickly becomes tedious and non-DRY to write most scenarios this way. To see why, suppose we want to write a feature that speci\ufb01es that movies should appear in alphabetical order on the list of movies page. For example, \u201cZorro\u201d should appear after \u201cApocalypse Now\u201d, even if \u201cZorro\u201d was added \ufb01rst. As Figure 7.5(a) shows, it would be the height of tedium to express this scenario naively, because it mostly repeats lines from our existing \u201cadd movie\u201d scenario\u2014not very DRY. Cucumber is supposed to be about behav- ior rather than implementation\u2014focusing on what is being done\u2014yet in this poorly-written scenario, only line 18 mentions the behavior of interest! An alternative approach is to think of using the step de\ufb01nitions to make a domain lan- guage (which is different from a formal Domain Speci\ufb01c Language (DSL)) for your application. A domain language is informal but uses terms and concepts speci\ufb01c to your application, rather than generic terms and concepts related to the implementation of the user interface. Steps written in a domain language are typically more declarative than imperative in that they describe the state of the world rather than the sequence of steps to get to that state and they are less dependent on the details of the user interface. Figure 7.5(b) shows what a declarative version of the above scenario might look like using a domain language for RottenPotatoes. The declarative version is obviously shorter, easier to maintain, and easier to understand since the text describes the state of the app in a natural form: \u201cI am on the RottenPotatoes home page sorted by title.\u201d The good news is that, as Figure 7.5(c) shows, you can reuse existing imperative steps to implement such scenarios. This is a very powerful form of reuse, and as your app evolves, you will \ufb01nd yourself reusing steps from your \ufb01rst few imperative scenarios to create more concise and descriptive declarative scenarios. Declarative, domain-language-oriented scenarios focus the attention on the feature being described rather than the low-level steps you need to set up and perform the test. Summary: \u2022 We can use Cucumber for both acceptance and integration testing if we write user stories for both explicit and implicit requirements. Declarative scenarios are simpler, less verbose, and more maintainable than imperative scenarios. \u2022 As you get more experienced, the vast majority of your user stories should be in a domain language that you have created for your app via your step de\ufb01nitions, and the stories should worry less about user interface details. The exception is for the speci\ufb01c stories where there is business value (customer need) in expressing the details of the user interface. 222 CHAPTER 7. BDD AND USER STORIES Feature : movies should appear in alphabetical order , not added order Scenario : view movie list after adding 2 movies ( imperative and non - DRY ) https://gist.github.com/2aa894c7bad7c813ecae447b6a97b059 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Given I am on the RottenPotatoes home page When I follow \" Add new movie \" Then I should be on the Create New Movie page When I fill in \" Title \" with \" Zorro \" And I select \" PG \" from \" Rating \" And I press \" Save Changes \" Then I should be on the RottenPotatoes home page When I follow \" Add new movie \" Then I should be on the Create New Movie page When I fill in \" Title \" with \" Apocalypse Now \" And I select \" R \" from \" Rating \" And I press \" Save Changes \" Then I should be on the RottenPotatoes home page Then I should see \" Apocalypse Now \" before \" Zorro \" on the RottenPotatoes home page sorted by title Feature : movies should appear in alphabetical order , not added order Scenario : view movie list after adding movie ( declarative and DRY ) https://gist.github.com/548b8f5a3a62a5d6f2b600d0ae91ae30 1 2 3 4 5 6 7 Given I have added \" Zorro \" with rating \" PG -13 \" And Then home page sorted by title I have added \" Apocalypse Now \" with rating \" R \" I should see \" Apocalypse Now \" before \" Zorro \" on the RottenPotatoes Given / I have added \" (.*) \" with rating \" (.*) \" / do | title , rating | steps % Q { Given I am on the Create New Movie page I fill in \" Title \" with \"#{ title } \" When I select \" # { rating }\" from \" Rating \" And I press \" Save Changes \" And https://gist.github.com/068e25c2428df4dbf731133e444f1926 1 2 3 4 5 6 7 8 9 10 11 12 13 14 steps % Q { Given I am on #{ path } } regexp = / # { string1 }.*#{ string2 }/ m # expect ( page . body ) . to match ( regexp ) } end end Then / I should see \" (.*) \" before \" (.*) \" on (.*) / do | string1 , string2 , path | / m means match across newlines Figure 7.5: Top (a): A repetitive, non-DRY scenario for checking the alphabetical ordering of movies in the list. Middle (b): A DRYer, more declarative expression of the same scenario. Bottom (c): Adding this code to movie_steps.rb creates new step de\ufb01nitions matching lines 5\u20137 of the declarative scenario by reusing existing steps. (Recall from Figure 2.2 that %Q is an alternative syntax for double-quoting a string.) We will learn about expect, which appears in line 13, in the next chapter. 7.9. THE PLAN-AND-DOCUMENT PERSPECTIVE ON DOCUMENTATION 223 Elaboration: The BDD ecosystem There is enormous momentum, especially in the Ruby community where testable, beauti- ful, and self-documenting code is highly valued, to document and promote best practices for BDD. Good scenarios serve as both documentation of the app designers\u2019 intent and exe- cutable acceptance and integration tests; they therefore deserve the same attention to beauty as the code itself. For example, this free screencast from RailsCasts5 describes scenario outlines, a way to DRY out a repetitive set of happy or sad paths whose expected outcomes differ based on how a form is \ufb01lled in, similar to the contrast between our happy and sad paths above. The Cucumber wiki6 is a good place to start, but as with all programming, you\u2019ll learn BDD best by doing it often, making mistakes, and revising and beautifying your code and scenarios as you learn from your mistakes. Self-Check 7.8.1. True or False: Explicit requirements are usually de\ufb01ned with imperative scenarios and implicit requirements are usually de\ufb01ned with declarative scenarios. False. These are two independent classi\ufb01cations; both requirements can use either type of scenario."
    ]
  },
  {
    "id": "sec_0298",
    "title": "7.9 The Plan-And-Document Perspective on Documentation",
    "pages": [
      235,
      236
    ],
    "text_blocks": [
      "As is well known to software engineers (but not to the general public), by far the largest class of [software] problems arises from errors made in the eliciting, recording, and analysis of requirements. \u2014Daniel Jackson, Martyn Thomas, and Lynette Millett (Editors), Software for Dependable Systems: Suf\ufb01cient Evidence?, 2007 Recall that the hope for plan-and-document methods was to make software engineering as predictable in budget and schedule as civil engineering. Remarkably, user stories, points, and velocity correspond to seven major tasks of the plan-and-document methodologies. They include: 1. Requirements Elicitation 2. Requirements Documentation 3. Cost Estimation 4. Scheduling and Monitoring Progress These are done up front for the Waterfall model and at the beginning of each major iteration for the Spiral and RUP models. As requirements change over time, these items above imply other tasks: 5. Change Management for Requirements, Cost, and Schedule 6. Ensuring Implementation Matches Requirement Features Finally, since accuracy of the budget estimate and the schedule is vital to the success of the plan-and-document process, there is another task not found in BDD: It\u2019s worth recalling that novel civil engineering projects, or modi\ufb01cations after the fact, often suffer cost and time overruns as well. Civil engineers tend to have better success predicting project outcomes when the project is similar to others that have been successfully completed in the past. 224 CHAPTER 7. BDD AND USER STORIES 7. Risk Analysis and Management The hope is that by imagining all the risks to the budget and schedule in advance, the project can make plans to avoid or overcome them. As we shall see in Chapter 10, the plan-and-document processes assume that each project has a manager. While the whole team may participate in requirements elicitation and risk analysis and help document them, it is up to the project manager to estimate costs, make and maintain the schedule, and decide which risks to address and how to overcome or avoid them. Advice for project managers comes from all corners, from practitioners who offer guide- lines and rules of thumb based on their experience to researchers who have measured many projects to come up with formulas for estimating budget and schedule. There are also tools to help. Despite this helpful advice and tools, the project statistics from Chapter 1 (Johnson 1995, 2009)\u2014that 40% to 50% of projects exceed the budget and schedule by factors of 1.7 to 3.0, and that 20% to 30% of projects are cancelled or abandoned\u2014document the dif\ufb01culty of making accurate budgets and schedules. We now give quick overviews of these seven tasks so that you can be familiar with what is done in plan-and-document processes to give you a head start if you need to use them in the future. These overviews help explain the inspiration for the Agile Manifesto. If you are unclear on how to successfully perform these tasks, it may be due more to their inherent dif\ufb01culties rather than to brevity. 1. Requirements Elicitation. Like User Stories, requirements elicitation involves partic- ipation by all stakeholders, using one of several techniques. The \ufb01rst is interviewing, where stakeholders answer prede\ufb01ned questions or just have informal discussions. Note that one goal is to understand the social and organization environment to see how tasks are really done versus the of\ufb01cial story. Another technique is to cooperatively create scenarios, which can start with an initial assumption of the state of the system, show the \ufb02ow of the system for a happy case and a sad case, list what else is going on in the system, and then the state of the system at the end of the scenario. Related to scenarios and user stories, a third technique is to create use cases, which are lists of steps between a person and a system to achieve a goal (see the elaboration in Section 7.1). In addition to functional requirements such as those listed above, non-functional requirements include performance goals, dependability goals, and so on. 2. Requirements Documentation. Once elicited, the next step is to document the re- quirements in a Software Requirements Speci\ufb01cation (SRS). Figure 7.6 gives an outline for an SRS based on IEEE Standard 830-1998. A SRS for a patient management system7 is"
    ]
  },
  {
    "id": "sec_0299",
    "title": "14 pages long, but they are often hundreds of pages.",
    "pages": [
      236,
      237
    ],
    "text_blocks": [
      "Part of the process is to check the SRS for: \u2022 Validity\u2013are all these requirements really necessary? \u2022 Consistency\u2013do requirements con\ufb02ict? \u2022 Completeness\u2013are all requirements and constraints included? \u2022 Feasibility\u2013can the requirements really be implemented? Techniques to test for these four characteristics include having stakeholders\u2014developers, customers, testers, and so on\u2014proofread the document, trying to build a prototype that in- cludes the basic features, and generating test cases that check the requirements. 7.9. THE PLAN-AND-DOCUMENT PERSPECTIVE ON DOCUMENTATION 225 Table of Contents 1. Introduction"
    ]
  },
  {
    "id": "sec_0300",
    "title": "1.1 Purpose",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0301",
    "title": "1.2 Scope",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0302",
    "title": "1.3 De\ufb01nitions, acronyms, and abbreviations",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0303",
    "title": "1.4 References",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0304",
    "title": "1.5 Overview",
    "pages": [
      237
    ],
    "text_blocks": [
      "2. Overall description"
    ]
  },
  {
    "id": "sec_0305",
    "title": "2.1 Product perspective",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0306",
    "title": "2.2 Product functions",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0307",
    "title": "2.3 User characteristics",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0308",
    "title": "2.4 Constraints",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0309",
    "title": "2.5 Assumptions and dependencies",
    "pages": [
      237
    ],
    "text_blocks": [
      "3. Speci\ufb01c requirements"
    ]
  },
  {
    "id": "sec_0310",
    "title": "3.1 External interface requirements",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0311",
    "title": "3.1.1 User interfaces",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0312",
    "title": "3.1.2 Hardware interfaces",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0313",
    "title": "3.1.3 Software interfaces",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0314",
    "title": "3.1.4 Communication interfaces",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0315",
    "title": "3.2 System features",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0316",
    "title": "3.2.1 System feature 1",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0317",
    "title": "3.2.1.1 Introduction/purpose of feature",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0318",
    "title": "3.2.1.2 Stimulus/response sequence",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0319",
    "title": "3.2.1.3 Associated function requirements",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0320",
    "title": "3.2.1.3.1 Functional requirement 1",
    "pages": [
      237
    ],
    "text_blocks": [
      ". . . 3.2.1.3.n Functional requirement n"
    ]
  },
  {
    "id": "sec_0321",
    "title": "3.2.2 System feature 2",
    "pages": [
      237
    ],
    "text_blocks": [
      ". . . 3.2.m System feature m"
    ]
  },
  {
    "id": "sec_0322",
    "title": "3.3 Performance requirements",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0323",
    "title": "3.4 Design constraints",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0324",
    "title": "3.5 Software system attributes",
    "pages": [
      237
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0325",
    "title": "3.6 Other requirements",
    "pages": [
      237,
      238,
      239
    ],
    "text_blocks": [
      "Figure 7.6: A table of contents for the IEEE Standard 830-1998 recommended practice for Software Requirements Speci\ufb01cations. We show Section 3 organized by feature, but the standard offers many others ways to organize Section 3: by mode, user class, object, stimulus, functional hierarchy, or even mixing multiple organizations. 226 CHAPTER 7. BDD AND USER STORIES A project may \ufb01nd it useful to have two types of SRS: a high-level SRS that is for man- agement and marketing and a detailed SRS for the project development team. The former is presumably a subset of the latter. For example, the high-level SRS might leave out the functional requirements that correspond to 3.2.1.3 in Figure 7.6. Elaboration: Formal speci\ufb01cation languages Formal speci\ufb01cation languages such as Alloy or Z allow the project manager to write exe- cutable requirements, which makes it easier to validate the implementation. Not surprisingly, the cost is both a more dif\ufb01cult document to write and usually a much longer requirements document to read. The advantage is both precision in the speci\ufb01cation and the potential to automatically generate tests cases or even use formal methods for veri\ufb01cation of correctness (see Section 8.10). 3. Cost Estimation. The project manager then decomposes the SRS into the tasks to implement it, and then estimates the number of weeks to complete each task. The advice is to decompose no \ufb01ner than one week. Just as a user story with more than seven points should be divided into smaller user stories, any task with an estimate of more than eight weeks should be further divided into smaller tasks. The total effort is traditionally measured in person-months, perhaps in homage to Brooks\u2019s classic software engineering book The Mythical Man-Month (Brooks 1995). Man- agers use salaries and overhead rates to convert person-months into an actual budget. The cost estimate is likely done twice: once to bid a contract, and once again after the contract is won. The second estimate is done after the software architecture is designed, so that the tasks as well as the effort per task can be more easily and accurately identi\ufb01ed. The project manager surely wants the second estimate to be no larger than the \ufb01rst, since that is what the customer will pay. One suggestion is to add a safety margin by multiplying your original estimate by 1.3 to 1.5 to try to handle estimation inaccuracy or unforeseen events. Another is to make three estimates: a best case, expected case, and worst case, and then use that information to make your best guess. The two approaches to estimating are experiential or quantitative. The \ufb01rst assumes the project managers have signi\ufb01cant experience either at the company or in the industry, and they rely on that experience to make accurate estimates. It certainly increases con\ufb01dence when the project is similar to tasks that the organization has already successfully completed. The quantitative or algorithmic approach is to estimate the programming effort of the tasks in a technical measure such as lines of code (LOC), and then divide by a productivity measure like LOC per person-month to yield person-months per task. The project manager can get help from others to get estimates on LOC, and like velocity, can look at the historical record of the organization\u2019s productivity to calculate person-months. Since cost estimates for software projects have such a dismal record, there has been con- siderable effort on improving the quantitative approach by collecting information about com- pleted projects and \ufb01nding models that predict the outcomes (Boehm and Valerdi 2008). The next step in sophistication follows this formula: Effort = Organizational Factors \u00d7 Code SizeSize Penalty \u00d7 Product Factors (7.1) where Organizational Factors include practices for this type of product, Code Size is mea- sured as before, Size Penalty re\ufb02ects that effort is not linear in code size, and Product Factors include experience of development team with this type of product, dependability require- ments, platform dif\ufb01culty, and so on. Example constants from real projects are 2.94 for Constructive Cost Model (COCOMO) is the basis of this 1981 formula. Its 1995 successor is called COCOMO II. 7.9. THE PLAN-AND-DOCUMENT PERSPECTIVE ON DOCUMENTATION 227 Organizational Factors; Size Penalty between 1.10 and 1.24; and Product Factors between"
    ]
  },
  {
    "id": "sec_0326",
    "title": "0.9 and 1.4.",
    "pages": [
      239,
      240,
      241,
      242
    ],
    "text_blocks": [
      "While these estimates are quantitative, they certainly depend on the project manager\u2019s subjective picks for Code Size, Size Penalty, and Product Factors. The successor to the COCOMO formula above asks the project manager to pick many more parameters. COCOMO II adds three more formulas to adjust estimates for 1) develop- ing prototypes, 2) accounting for the amount of code reuse, and 3) a post-detailed-architecture estimate. This last formula expands Size Penalty by adding a normalized product of 5 inde- pendent factors and replaces Product Factors by a product of 17 independent factors. The British Computer Society Survey of more than 1000 projects mentioned in Chap- ter 1 found that 92% of project managers made their estimates using experience instead of formulas (Taylor 2000). As no more than 20% to 30% of projects meet their budget and schedule, what happens to the rest? Another 20% to 30% of the projects are indeed cancelled or abandoned, but the remaining 40% to 50% are still valuable to the customer even if late. Customers and providers typically then negotiate a new contract to deliver the product with a more limited set of features by a near-term date. Elaboration: Function points Function points are an alternative measure to LOC that can lead to estimates that are more accurate. They are based on the function inputs, outputs, external queries, input \ufb01les, output \ufb01les, and the complexity of each. The corresponding productivity measure is then function points per person-month. 4. Scheduling and Monitoring Progress. Given the SRS has been broken into tasks whose effort has been estimated, the next step is to use a scheduling tool that shows which tasks can be performed in parallel and which have dependencies so they must be performed sequentially. The format is typically a box and arrow diagram such as a PERT chart, which can identify the critical path or minimum time for project. For example, in Figure 7.7, the shortest possible path from step 1 (the starting state) to step 11 (software release) must traverse the nodes 3, 5, 9, and 10. The project manager places the graph in a table with rows associated with the people on the project, and then assigns people to tasks. Once again, this process is typically done twice, once when bidding the contract, and once after the contract is won and the detailed architecture design is complete. Safety margins are again used to ensure that the \ufb01rst schedule, which is when the customer expects the product to be released, is not longer than the second version. Similar to calculating velocity, the project manager can see if the project is behind by comparing the predicted expenditures and time for tasks to the actual expenditures and progress to date. A way to make project status clear to all stakeholders is to add interme- diate milestones to the schedule, which lets everyone see if the project is on schedule and on budget. 5. Change Management for Requirements, Cost, and Schedule. As stated many times in this book, customers are likely to ask for changes to the requirements as the project evolves for many reasons, including a better understanding of what is wanted after trying a prototype, changing market conditions for the project, and so on. The challenge for the project manager is keeping the requirements documents, the schedule, and cost predictions up-to-date as the project changes. Thus, version control systems are needed for evolving documents as well as for programs, so the norm should be checking in the revised documentation along with the PERT stands for Program Evaluation and Review Technique, which was invented by the US Navy in the 1950s for its nuclear submarine program. Requirements Creep is the term developers use to describe the dreaded increase in requirements over time. 228 CHAPTER 7. BDD AND USER STORIES Figure 7.7: Numbered nodes represent milestones and labeled lines represent tasks, with arrowheads representing dependencies. Diverging lines from a node represent concurrent tasks. The numbers on the other side of lines represent the time allocated for the task. Dotted lines indicate dependencies that need no resources, so they have no time allocated for the task. 7.9. THE PLAN-AND-DOCUMENT PERSPECTIVE ON DOCUMENTATION 229 revised code. 6. Ensuring Implementation Matches Requirement Features. The Agile process con- solidates these many major tasks into three tightly coupled ones: User Stories, acceptance tests in Cucumber, and the code that comes from the BDD/TDD process. Thus, there is little confusion in the relationship between particular stories, tests, and code. However, plan-and-document methodologies involve many more mechanisms without tight integration. Thus, we need tools that allow the project manager to check to see if the implementation matches the requirements. The relationship between features in requirements and what is implemented is called requirements traceability . Tools that implement trace- ability essentially offer cross-references between a portion of the design, the portion of the code that implements the feature, code reviews that checked it, and the tests that validate it. If there is both a high-level SRS and a detailed SRS, forward traceability refers to the traditional path from requirements to implementation, while backwards traceability is the mapping from a detailed requirement back to a high-level requirement. 7. Risk Analysis and Management. In an effort to improve the accuracy of cost estima- tion and scheduling, plan-and-document methodologies have borrowed risk analysis from the business school. The philosophy is that by taking the time up front to identify potential risks to the budget and schedule, a project can either do extra work to reduce the risk of changes, or change the plan to avoid risks. Ideally, risk identi\ufb01cation and management occurs over the \ufb01rst third of a project. It does not bode well if they are identi\ufb01ed late in the development cycle. Risks are classi\ufb01ed as technical, organizational, or business. An example of a technical risk might be that the relational database chosen cannot scale to the workload the project needs. An organizational risk might be that many members of the team are unfamiliar with J2EE, which the project depends upon. A business risk could be that by the time the project is complete, the product is not competitive in the market. Examples of actions to overcome these risks would be to acquire a more scalable database, send team members to a J2EE workshop, and do a competitive survey of existing products, including their current features and plans for improvements. The approach to identify risks is to ask everyone for their worst-case scenarios. The project manager puts them into a \u201crisk table,\u201d in which each risk is assigned a probability of happening between 0% and 100%, and an impact on a numeric scale of 1 to 4, representing negligible, marginal, critical, and catastrophic. One can then sort the risk table by the product of the probability and impact of each risk. There are many more potential risks than projects can afford to address, so the advice is to address the top 20% of the risks, in the hope that they represent 80% of the potential risks to the budget and schedule. Trying to address all potential risks could lead to an effort that is larger than the original software project! Risk reduction is a major reason for iteration in both the Spiral and RUP models. Iterations and prototypes should reduce risks associated with a project. Section 7.5 mentions asking the customers about risks for the project as part of the cost estimation in Agile, but the difference is that this information is used to decide the range of the cost estimate rather than becoming a signi\ufb01cant part of the project itself. 230 Tasks Requirements Documentation Requirements Elicitation Change Management for Requirements, Schedule, and Budget Ensuring Requirements Features Scheduling and Monitoring Cost Estimation Risk Management CHAPTER 7. BDD AND USER STORIES In Plan-and-Document Software Requirements Speci\ufb01cation such as IEEE Standard 830-1998 Interviews, Scenarios, Use Cases Version Control for Documentation and Code In Agile User stories, Cucumber, Points, Velocity Traceability to link features to tests, reviews, and code Early in project, contracted delivery date based on cost estimation, using PERT charts. Milestones to monitor progress Early in project, contracted cost based on manager experience or estimates of task size combined with productivity metrics Early in project, identify risks to budget and schedule, and take actions to overcome or avoid them Evaluate to pick range of effort for time and materials contract Figure 7.8: The relationship between the requirements related tasks of Plan-and-Document versus Agile methodologies. Summary The hope of the original efforts in software engineering was to make software development as predictable in quality, cost, and schedule as building a bridge. Perhaps because less than a sixth of software projects are completed on time and on budget with full functionality, the plan-and-document process has many steps to try to achieve this dif\ufb01cult goal. Agile does not try to predict cost and schedule at the start of the project, instead relying on working with customers on frequent iterations and agreeing on a range of time for the best effort to achieve the customer\u2019s goals. Rating user stories on dif\ufb01culty and recording the points actually completed per iteration increases the chances of more realistic estimates. Figure 7.8 shows the resulting different tasks given the differing perspectives of these two philosophies. Self-Check 7.9.1. Name three plan-and-document techniques that help with requirements elicitation. Interviewing, Scenarios, and Use Cases."
    ]
  },
  {
    "id": "sec_0327",
    "title": "7.10 Fallacies and Pitfalls",
    "pages": [
      242,
      243,
      244,
      245
    ],
    "text_blocks": [
      "Pitfall: Customers who confuse mock-ups with completed features. As a developer, this pitfall may seem ridiculous to you. But nontechnical customers sometimes have dif\ufb01culty distinguishing a highly polished digital mock-up from a working feature! The solution is simple: use paper-and-pencil techniques such as hand-drawn sketches and storyboards to reach agreement with the customer\u2014there can be no doubt that such Lo-Fi mockups represent proposed rather than implemented functionality. Pitfall: Adding cool features that do not make the product more successful. 7.10. FALLACIES AND PITFALLS 231 Agile development was inspired in part by the frustration of software developers building what they thought was cool code that customers dropped. The temptation is strong to add a feature that you think would be great, but it can also be disappointing when your work is discarded. User stories help all stakeholders prioritize development and reduce chances of wasted effort on features that only developers love. Pitfall: Sketches without storyboards. Sketches are static; interactions with a SaaS app occur as a sequence of actions over time. You and the customer must agree not only on the general content of the Lo-Fi UI sketches, but on what happens when they interact with the page. \u201cAnimating\u201d the Lo-Fi sketches\u2014\u201cOK, you clicked on that button, here\u2019s what you see; is that what you expected?\u201d\u2014goes a long way towards ironing out misunderstandings before the stories are turned into tests and code. Pitfall: Tracking tasks rather than stories. A story is the customer\u2019s view of how a feature should work, such as \u201cBox of\ufb01ce manager can generate a report of today\u2019s sales.\u201d Tasks such as \u201cAdd Excel export code in Report model\u201d is a developer-facing task that, while it may be part of implementing a story, is not itself something that results in customer value. Use project management and effort estimation tools to track stories, not tasks. Tracker allows multiple speci\ufb01c tasks to be part of a story, but expressing the task itself as a story also entails the further risk that you\u2019ll use the tool as a to-do list, simply checking off tasks when they\u2019re done, rather than tracking the lifecycle of a story and allowing you to improve your skill at estimating project effort. Pitfall: Using Cucumber solely as a test-automation tool rather than as a common middle ground for all stakeholders. If you look at web_steps.rb, you\u2019ll quickly notice that low-level, imperative Cucumber steps such as \u201cWhen I press Cancel\u201d are merely a thin wrapper around Capybara\u2019s \u201cheadless browser\u201d API, and you might wonder (as some of the authors\u2019 students have) why you should use Cucumber at all. But Cucumber\u2019s real value is in creating documentation that nontech- nical stakeholders and developers can agree on and that serves as the basis for automating acceptance and integration tests, which is why the Cucumber features and steps for a ma- ture app should evolve towards a \u201cmini-language\u201d appropriate for that app. For example, an app for scheduling vacations for hospital nurses would have scenarios that make heavy use of domain-speci\ufb01c terms such as shift, seniority, holiday, overtime, and so on, rather than focusing on the low-level interactions between the user and each view. Pitfall: Relying too heavily on integration-level scenarios for your tests. Scenarios are comforting to write and satisfying to run (when they pass) because they closely mimic what a real user would do. Indeed, that is why Cucumber tests have value both as validation\u2014you built the right thing, because the test instantiates a user story cre- ated in collaboration with the customer\u2014and veri\ufb01cation\u2014you built the thing right, because the test passes. However, one thing such tests don\u2019t reveal is whether your code is well factored\u2014whether the different subsystems exercised in the scenario are easily testable, let alone whether each has been thoroughly tested. Unit and module level tests, which are the subject of Chapter 8, are more likely to tell you about the design of your code. Of course, over-reliance on unit and module level tests is just as bad, as the corresponding Pitfall at the 232 CHAPTER 7. BDD AND USER STORIES end of Chapter 8 reminds us! Fallacy: The feature is \u201cdone\u201d if it works correctly in production, even if the scenario doesn\u2019t pass. When a test fails, it\u2019s trying to tell you something. Sometimes it\u2019s straightforward\u2014 there\u2019s a bug in your code. Other times it\u2019s more subtle: your code ful\ufb01lls the requirements of the user story, but for some reason, it is unusually dif\ufb01cult to test. Either way, the outcome bears investigation. Without an integration test you can trust, it will be hard to detect if future changes cause your existing code to break. Pitfall: Trying to predict what you need before you need it. Part of the magic of Behavior-Driven Design (and Test-Driven Development in the next chapter) is that you write the tests before you write the code you need, and then you write code needed to pass the tests. This top-down approach again makes it more likely for your efforts to be useful, which is harder to do when you\u2019re predicting what you think you\u2019ll need. This observation has also been called the YAGNI principle\u2014You Ain\u2019t Gonna Need It. Pitfall: Careless use of negative expectations. Beware of overusing Then I should not see. . . . Because it tests a negative condition, you might not be able to tell if the output is what you intended\u2014you can only tell what the output isn\u2019t. Many, many outputs don\u2019t match, so that is not likely to be a good test. For example, if you were testing for the absence of \u201cWelcome, Dave!\u201d but you accidentally wrote Then I should not see \u201cGreetings, Dave!\u201d, the scenario will pass even if the app incorrectly emits \u201cWelcome, Dave!\u201d. Always include positive expectations such as Then I should see. . . to check results. Pitfall: Careless use of positive expectations. Even if you use positive expectations such as Then I should see. . . , what if the string you\u2019re looking for occurs multiple times on the page? For example, if the logged-in user\u2019s name is Emma and your scenario is checking whether Jane Austen\u2019s book Emma was cor- rectly added to the shopping cart, a scenario step Then I should see \u201cEmma\u201d might pass even if the cart isn\u2019t working. To avoid this pitfall, use Capybara\u2019s within helper, which constrains the scope of matchers such as I should see to the element(s) matching a given CSS selector, as in Then I should see \u201dEmma\u201d within \u201ddiv#shopping_cart\u201d, and use unambiguous HTML id or class attributes for page elements you want to name in your scenarios. The Capybara documentation8 lists all the matchers and helpers. Pitfall: Delivering a story as \u201cdone\u201d when only the happy path is tested. As should be clear by now, a story is only a candidate for delivery when both the happy path and the most important sad paths have been tested. Of course, as Chapter 8 describes, there are many more ways for something to work incorrectly than to work correctly, and sad- path tests are not intended to be a substitute for \ufb01ner-grained test coverage. But from the user\u2019s point of view, correct app behavior when the user accidentally does the wrong thing is just as important as correct behavior when they do the right thing. Google places these posters inside restrooms to remind developers of the importance of testing. Used with permission. 7.11. CONCLUDING REMARKS: PROS AND CONS OF BDD 233"
    ]
  },
  {
    "id": "sec_0328",
    "title": "7.11 Concluding Remarks: Pros and Cons of BDD",
    "pages": [
      245,
      246,
      247,
      248
    ],
    "text_blocks": [
      "In software, we rarely have meaningful requirements. Even if we do, the only measure of success that matters is whether our solution solves the customer\u2019s shifting idea of what their problem is. \u2014Jeff Atwood, Is Software Development Like Manufacturing?, 2006 The advantage of user stories and BDD is creating a common language shared by all stakeholders, especially the nontechnical customers. BDD is perfect for projects where the requirements are poorly understood or rapidly changing, which is often the case. User stories also make it easy to break projects into small increments or iterations, which makes it easier to estimate how much work remains. The use of 3x5 cards and paper mockups of user inter- faces keeps the nontechnical customers involved in the design and prioritization of features, which increases the chances of the software meeting the customer\u2019s needs. Iterations drive the re\ufb01nement of this software development process. Moreover, BDD and Cucumber natu- rally leads to writing tests before coding, shifting the validation and development effort from debugging to testing. Comparing user stories, Cucumber, points, and velocity to the plan-and-document pro- cesses makes it clear that BDD plays many important roles in the Agile process: 1. Requirements elicitation 2. Requirements documentation 3. Acceptance tests 4. Traceability between features and implementation 5. Scheduling and monitoring of project progress The downside of user stories and BDD is that it may be dif\ufb01cult or too expensive to have continuous contact with the customer throughout the development process, as some customers may not want to participate. This approach may also not scale to very large soft- ware development projects or to safety critical applications. Perhaps plan-and-document is a better match in both situations. Another potential downside of BDD is that the project could satisfy customers but not result in a good software architecture, which is an important foundation for maintaining the code. Chapter 11 discusses design patterns, which should be part of your software devel- opment toolkit. Recognizing which pattern matches the circumstances and refactoring code when necessary (see Chapter 9) reduces the chances of BDD producing poor software archi- tectures. All this being said, there is enormous momentum in the Ruby community (which places high value on testable, beautiful and self-documenting code) to document and promote best practices for specifying behavior both as a way to document the intent of the app\u2019s developers and to provide executable acceptance tests. The Cucumber wiki9 is a good place to start. BDD may not seem initially the natural way to develop software; the strong temptation is to just start hacking code. However, once you have learned BDD and had success at it, for most developers there is no going back. Your authors remind you that good tools, while 234 NOTES sometimes intimidating to learn, repay the effort many times over in the long run. Whenever possible in the future, we believe you\u2019ll follow the BDD path to writing beautiful code. You may \ufb01nd the following resources useful for more depth on the topics in this chapter: \u2022 Want to see paper prototyping and storyboards in action? First read this excellent article with examples10 of paper prototyping, then watch this video of paper storyboarding11 for a web-based email app. \u2022 The Cucumber wiki12 has links to documentation, tutorials, examples, screencasts, best practices, and lots more on Cucumber. \u2022 The Cucumber Book (Wynne and Helles\u00f8y 2012), co-authored by the tool\u2019s creator and one of its earliest adopters, includes detailed information and examples using Cucum- ber, excellent discussions of best practices for BDD, and additional Cucumber uses such as testing RESTful service automation. B. W. Boehm and R. Valerdi. Achievements and challenges in COCOMO-based software resource estimation. IEEE Software, 25(5):74\u201383, Sept 2008. F. P. Brooks. The Mythical Man-Month. Addison-Wesley, Reading, MA, Anniversary edi- tion, 1995. ISBN 0201835959. D. Burkes. Personal communication, December 2012. J. Johnson. The CHAOS report. Technical report, The Standish Group, Boston, Mas- sachusetts, 1995. URL http://blog.standishgroup.com/. J. Johnson. The CHAOS report. Technical report, The Standish Group, Boston, Mas- sachusetts, 2009. URL http://blog.standishgroup.com/. A. Taylor. IT projects sink or swim. BCS Review, Jan. 2000. URL http://archive.bcs. org/bulletin/jan00/article1.htm. M. Wynne and A. Helles\u00f8y. The Cucumber Book: Behaviour-Driven Development for Testers and Developers. Pragmatic Bookshelf, 2012. ISBN 1934356808. Notes 1https://pivotaltracker.com 2http://www.youtube.com/watch?v=mTYcHg51sWY 3https://github.com 4https://trello.com 5http://railscasts.com/episodes/159-more-on-cucumber 6http://cukes.info 7http://www.cs.st-andrews.ac.uk/~ifs/Books/SE9/CaseStudies/MHCPMS/SupportingDocs/ MHCPMSCaseStudy.pdf 8http://rubydoc.info/github/jnicklas/capybara/ 9http://cukes.info 10https://alistapart.com/article/paperprototyping/ 11http://www.youtube.com/watch?v=GrV2SZuRPv0 12http://cukes.info NOTES 235 8 Software Testing: Test-Driven Development Sir Maurice Wilkes (1913\u20132010) received the"
    ]
  },
  {
    "id": "sec_0329",
    "title": "1967 Turing Award for",
    "pages": [
      248
    ],
    "text_blocks": [
      "designing and building EDSAC in 1949, one of the \ufb01rst stored-program computers. It was on one of my journeys between the EDSAC room and the punching equipment that \u201chesitating at the angles of stairs\u201d the realization came over me with full force that a good part of the remainder of my life was going to be spent \ufb01nding errors in my own programs. \u2014Maurice Wilkes, Memoirs of a Computer Pioneer, 1985 . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0330",
    "title": "8.1 FIRST, TDD, and Red\u2013Green\u2013Refactor",
    "pages": [
      248
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0331",
    "title": "8.2 Anatomy of a Test Case: Arrange, Act, Assert .",
    "pages": [
      248
    ],
    "text_blocks": [
      ". . . Isolating Code: Doubles and Seams . . 8.3 . . . . ."
    ]
  },
  {
    "id": "sec_0332",
    "title": "8.4 Stubbing the Internet",
    "pages": [
      248
    ],
    "text_blocks": [
      ". . . . . ."
    ]
  },
  {
    "id": "sec_0333",
    "title": "8.5 CHIPS: Intro to RSpec on Rails .",
    "pages": [
      248
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0334",
    "title": "8.6 Fixtures and Factories .",
    "pages": [
      248
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0335",
    "title": "8.7 Coverage Concepts and Types of Tests",
    "pages": [
      248
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0336",
    "title": "8.8 Other Testing Approaches and Terminology .",
    "pages": [
      248
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0337",
    "title": "8.9 CHIPS: The Acceptance Test/Unit Test Cycle",
    "pages": [
      248
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0338",
    "title": "8.10 The Plan-And-Document Perspective on Testing .",
    "pages": [
      248
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0339",
    "title": "8.11 Fallacies and Pitfalls .",
    "pages": [
      248
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0340",
    "title": "8.12 Concluding Remarks: TDD vs. Conventional Debugging .",
    "pages": [
      248,
      249,
      250
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238 . 240 . 243 . 248 . 249 . 249 . 255 . 258 . 260 . 260 . 264 . 266 237 Prerequisites and Concepts The big concepts of this chapter are test creation, test coverage, and levels of testing. Concepts: Agile and Plan-and-Document differ sharply in their approaches to testing: when test writing starts, the order in which different kinds of tests are written, and even who does the testing. Testing in the Agile lifecycle, which follows Test-Driven Development (TDD), is largely the responsibility of the developers rather than a separate Quality Assurance team. Agile testing follows these steps: \u2022 Starting from the acceptance and integration tests derived from User stories, write failing unit tests that test the nonexistent code you wish you had. \u2022 Write just enough code to pass one such unit test and look for opportunities to refactor the code before continuing with the next test. Since many test frameworks display failing test output in red and passing test output in green, the iterative sequence of this step and the previous one is called RedGreenRefactor. \u2022 To isolate the behavior of the code you\u2019re testing from the behavior of other classes or methods on which it depends, use test doubles: stunt doubles that stand in for real objects in tests, but whose behavior you can closely control. Test doubles are examples of seams, or places where you can change program behavior during testing without changing the source code itself. \u2022 Construct your tests so that they are Fast, Independent, Repeatable, Self-checking, and Timely (FIRST). \u2022 Capture and inspect code coverage metrics to help determine which parts of your code need more testing. For the Plan-and-Document lifecycle, you use some of the same concepts in a quite different order and even with different people: \u2022 The program manager assigns programming tasks based on the SRS, so unit testing starts after coding. Quality-Assurance (QA) testers take over from the developers to perform the higher level tests. \u2022 Top-down, Bottom-up, and Sandwich are options on how to combine the resulting code to perform integration testing . The testing plan and results are documented, such as by following IEEE Standard 829-2008. \u2022 After integration testing, the QA team performs a system test before releasing it to the customer. Testing stops when a specied level of coverage is reached, such as 95% statement coverage. \u2022 An alternative to testing, used for small critical software, is formal methods. They use formal specications of correct program behavior that are automatically veried by theorem provers or by exhaustive state search, both of which can go beyond what conventional testing can do. 238 CHAPTER 8. TEST-DRIVEN DEVELOPMENT Figure 8.1: The Agile software lifecycle and its relationship to the chapters in this book. This chapter emphasizes unit testing as part of Test-Driven Development."
    ]
  },
  {
    "id": "sec_0341",
    "title": "8.1 FIRST, TDD, and RedGreenRefactor",
    "pages": [
      250,
      251,
      252
    ],
    "text_blocks": [
      "Chapter 1 introduced the Agile lifecycle and distinguished two aspects of software assur- ance: validation (\u201cDid you build the right thing?\u201d) and veri\ufb01cation (\u201cDid you build the thing right?\u201d). In this chapter, we focus on veri\ufb01cation\u2014building the thing right\u2014via software testing as part of the Agile lifecycle. Figure 8.1 highlights the portion of the Agile lifecycle covered in this chapter. Although testing is only one technique used for veri\ufb01cation, we focus on it because its role is often misunderstood, and as a result it doesn\u2019t get as much attention as other parts of the software lifecycle. In addition, as we will see, approaching software construction from a test-centric perspective often improves the software\u2019s readability and maintainability. In other words, testable code tends to be clear code, and vice versa. This insight may take a while to sink in if you are new to TDD, because practicing TDD may feel alien to you. We ask you again to be patient and have faith in the process! In Agile development, developers do not \u201ctoss their code over the wall\u201d to the Quality Assurance (QA) team, nor do QA engineers extensively exercise the software manually and \ufb01le bug reports. Instead, Agile developers bear far more responsibility for testing their own code and participating in reviews, while Agile QA responsibilities focus on improving the testing tools infrastructure, helping developers make their code more testable, and verifying that customer-reported bugs are reproducible, as we\u2019ll discuss further in Chapter 10. Further- more, in the vast majority of tests you will write, the test code itself can determine whether the code being tested works or not, without requiring a human to manually check test output or interact with the software. Even though Agile developers are expected to write their own tests, and those tests are When TDD is used to extend or modify legacy code, as in Chapter 9, new tests may be created for code that already exists. 8.1. FIRST, TDD, AND RED\u2013GREEN\u2013REFACTOR 239 expected to be automated, there is often a role for some manual testing. For example, user acceptance testing observes actual users (or QA engineers acting as \u201ctypical\u201d users) using the product to determine whether you \u201cbuilt the right thing,\u201d and operational acceptance testing may manually try additional scenarios to ensure you \u201cbuilt the thing right.\u201d Both can uncover bugs that were previously undetected, some of which can then have automated tests created for them. And some visual aspects of the design, such as whether particular elements on the page render in a visually appealing way, require manual inspection. But in general, modern software quality assurance is the shared responsibility of a whole team following good processes, rather than compartmentalized in a separate group. In this section we introduce two key ideas that underpin Test-driven development (TDD): Red\u2013Green\u2013Refactor and making tests FIRST. TDD advocates the use of tests to drive the development of code. When TDD is used to create new code, as in this chapter, it is sometimes referred to as test-\ufb01rst development. The basic TDD work\ufb02ow, repeated for each created test, is known as Red\u2013Green\u2013Refactor and proceeds as follows. 1. Before you write any code, write a test for one aspect of the behavior you expect the new code will have. Since the code being tested doesn\u2019t exist yet, writing the test forces you to think about how you wish the code would behave and interact with its collaborators if it did exist. We call this \u201cexercising the code you wish you had.\u201d 2. Red step: Run the test, and verify that it fails because you haven\u2019t yet implemented the code necessary to make it pass (that is, the code you wish you had). 3. Green step: Write the simplest possible code that causes this test to pass without break- ing any existing tests. 4. Refactor step: Look for opportunities to refactor either your code or your tests\u2014 changing the code\u2019s structure to eliminate redundancy or repetition that may have arisen as a result of adding the new code. The tests ensure that your refactoring doesn\u2019t introduce bugs. How do you know when you have completed all necessary tests? If you are using BDD (Chapter 7) to drive your application development, the new code being written is presumably necessary to make one or more Cucumber scenario steps pass. When all steps in a scenario pass, you\u2019re done. Although TDD may feel strange at \ufb01rst, it tends to result in code that is not only well tested, but also more modular and easier to read than code developed separately from tests. While TDD is certainly not the only way to achieve those goals, it is dif\ufb01cult to end up with seriously de\ufb01cient code if TDD is used correctly. What about the tests themselves? Five principles for creating good tests are summarized by the acronym FIRST: Fast, Independent, Repeatable, Self-checking, and Timely. \u2022 Fast: it should be easy and quick to run the subset of test cases relevant to your current coding task, to avoid interfering with your train of thought. \u2022 Independent: The order in which tests run shouldn\u2019t matter. More precisely, if no test relies on preconditions created by other tests, we can prioritize running only a subset of tests that cover recent code changes. Y2K bug in action This photo was taken on Jan. 3, 2000. (Wikimedia Commons) 240 CHAPTER 8. TEST-DRIVEN DEVELOPMENT \u2022 Repeatable: test behavior should not depend on external factors such as today\u2019s date or on \u201cmagic constants\u201d that will break the tests if their values change, as occurred with many 1960s programs when the year 2000 arrived due to the Y2K problem. \u2022 Self-checking: each test should be able to determine on its own whether it passed or failed, rather than relying on humans to check its output. \u2022 Timely: tests should be created or updated at the same time as the code being tested. As we\u2019ll see, with test-driven development the tests are written immediately before the code. Summary \u2022 Besides ensuring software correctness, another reason to use test-centric software construction is that it often improves readability and maintainability: testable code tends to be clear code, and vice versa. \u2022 Software QA is a shared responsibility of the whole team: developers write most of their own tests, with QA staff improving the testing environment and handling some kinds of testing that are hard to automate. \u2022 The TDD cycle of Red\u2013Green\u2013Refactor begins with writing a test that fails because the subject code being tested doesn\u2019t exist yet (Red), then adding the minimum code necessary to pass just that one example (Green), and \ufb01nally DRYing out and cleaning up the test code (Refactor). \u2022 Tests should be Fast to run, with results Independent of the order in which they are run, thus Repeatably giving the same result. Each test should be Self-checking (the test code itself knows whether the test passed or failed), and should be developed in a Timely way with respect to the code it tests. Indeed, TDD suggests developing the tests before writing the code. Self-Check 8.1.1. Suppose step 1 in your Cucumber scenario is passing, but step 2 is failing because the code needed is not yet written. If you are practicing strict BDD and TDD, explain why you will necessarily go through one or more cycles of Red\u2013Green\u2013Refactor before step"
    ]
  },
  {
    "id": "sec_0342",
    "title": "2 passes.",
    "pages": [
      252
    ],
    "text_blocks": [
      "If the code for step 2 does not yet exist, strict TDD says you should develop that code by \ufb01rst writing a focused test for one aspect of the code\u2019s behavior, watching that test fail, then writing the code to make it pass."
    ]
  },
  {
    "id": "sec_0343",
    "title": "8.2 Anatomy of a Test Case: Arrange, Act, Assert",
    "pages": [
      252,
      253,
      254,
      255
    ],
    "text_blocks": [
      "We begin with a few de\ufb01nitions. Following the terminology in the fairly widely used xUnit Test Patterns1 (Meszaros 2007), we refer to the object being tested as the system under test (SUT), whether that \u201cobject\u201d is a single method, a group of methods, or even the entire appli- cation. That is, SUT is de\ufb01ned from the point of view of the test. The goal of a single test case for some SUT is to check that some speci\ufb01c behavior happens (for example, the return value from a function matches an expected result) or doesn\u2019t happen (for example, passing The ISTQB (International Software Testing Quali\ufb01cations Board) de\ufb01nes2 test object as the thing being tested and SUT as a test object that is a system, but the xUnit terminology is more widely used among Agile developers. 8.2. ANATOMY OF A TEST CASE: ARRANGE, ACT, ASSERT 241 On a value Value equality Boolean Regular expression Object properties On a block Exception Side effect Example in RSpec expect(x).to eq(\u2019Ruby\u2019); expect(x).not_to eq(\u2019Ruby\u2019) expect(x).to be_truthy # i.e., non-false/non-nil expect(s).to match(/YourRegexpHere/) expect(a).to be_a_kind_of(Array) expect(a).to respond_to(:[]) Example in RSpec expect { Math.sqrt(-1) }.to raise_error(Math::DomainError) expect { Review.first.destroy }.to change { Review.count }.by(-1) Figure 8.2: A few examples of the kinds of assertions allowed by RSpec. One can invert the sense of any assertion (\u201cExpect x not to equal 50\u201d), as in the \ufb01rst line of the table, but as Chapter 7 warned, negative assertions should be used with caution, since there are many ways for a program not to satisfy a particular condition while still not behaving correctly. The use of braces rather than parentheses for the Exception example shows that expect can take either an expression, like x, or a callable block. an empty string to a string comparison function doesn\u2019t result in an error or exception). A collection of test cases is called a test suite. A code base usually has several test suites, corresponding to different kinds of tests, as we describe later in Section 8.7. In this section we focus on unit tests, the \ufb01nest-grained test cases, for which the SUT is a single method. In particular, if the method being tested does not call any other methods to help do its job, we say it is a leaf method . Since even a leaf method may have multiple testable behaviors, a single method may be the subject of multiple test cases. A unit test is conceptually simple: call a method, and verify some aspect of its behavior. But even leaf methods usually require establishing some preconditions before exercising the code. For example, when testing a method that combines two lists into a single sorted list, we need to create the two lists that will be provided as input. We then exercise the SUT, and \ufb01nally check whether the particular behavior we were looking for was correctly exhibited. In general, then, every test case in a suite follows the same structure of Arrange, Act, Assert: 1. Arrange: create any necessary preconditions for the test case, such as setting values of variables that affect the behavior of the SUT. 2. Act: exercise the SUT. 3. Assert: verify that the result or behavior matches what was expected. The general form of an assertion or expectation is \u201cExpect expression to satisfy predicate\u201d. An example of a simple predicate is an equality check: \u201cExpect the return value of Math.sqrt(49) to equal 7\u201d. As Figure 8.2 shows, other kinds of assertions deal with both inspecting output values and checking non-output-value-related behaviors. The easiest unit tests to write are those for which the SUT is a method that is a pure function\u2014one that has no side effects and whose return value is always the same for the same arguments. The only thing a test case needs to do is choose some inputs, call the method, and check the returned value. For example, consider a hypothetical method leap? that accepts an integer and returns a truthy value if and only if that integer corresponds to a leap year (that is, it is either a multiple of 400, or a multiple of 4 but not 100). So, for example, 2000 and 2004 are leap years, but 1900 is not. Since exhaustive testing (trying every possible input) is clearly infeasible, how do we choose which input values to use for our test cases? 242 CHAPTER 8. TEST-DRIVEN DEVELOPMENT Category 1. A number that is not a multiple of 4 or 100 (and therefore not a multiple of 400) 2. A number that is a multiple of 4, but not of 100 (and therefore not a multiple of 400) 3. A number that is not a multiple of 400, but is a multiple of 100 4. A number that is a multiple of 400 Test value 1973 2008 1900 2000 Figure 8.3: A set of categories that completely covers the space of possible nonnegative numeric inputs for a leap year detector, and a possible test value representative of each category. The calculation of a leap year depends only on which category a value is in, not the value itself. Chapter 9 considers how to write tests after the fact for code you didn\u2019t write or can\u2019t easily inspect. A good guideline in such cases is to use input values that would cause the calculation performed in the method to follow different code paths. Given the above rule for leap years, by inspection we can deduce four categories, as Figure 8.3 shows. A \u201cpure\u201d TDD work\ufb02ow for developing a function that detects leap years might therefore proceed as follows. Choose any value in category 1 above, and write a test case that asserts that the return value of leap? is falsy when called with that value. The test fails because leap? doesn\u2019t yet exist, so write just enough of leap? to make that case pass. Next, choose a value in category 2, write the corresponding test, and when it fails, modify leap? so that now both tests pass. Continue until all categories are covered. You might object that leap? is such a simple leaf method, and its functionality so well- circumscribed, that you might as well write the entire method at once along with the four test cases, rather than going through the motions of developing each test case incrementally. That\u2019s not an unreasonable objection, and as with other Agile practices, \u201cpure\u201d TDD is an ideal to strive for even if you do not always follow it to the letter. But with methods that have more complex behaviors, TDD is a valuable way to proceed methodically. 8.3. ISOLATING CODE: DOUBLES AND SEAMS 243 Summary: \u2022 The system under test (SUT), which may be as small as a single method or as large as the whole app, is the subject of a particular test case. A test suite is a full set of tests, which usually includes unit, integration, and perhaps other types of tests. \u2022 The \ufb01nest-grained tests are unit tests, which test the code in a single method. The simplest unit tests are those for pure leaf functions: deterministic, no side effects, no collaborators or helper methods called. Hence, it is worth structuring your code to expose as much functionality as possible in pure leaf functions. \u2022 One way to select input values for unit tests is to test critical points (values that may in\ufb02uence the code path in the SUT) and values from each noncritical set (set within which the choice of any particular value does not affect control \ufb02ow). \u2022 Each unit test checks just one behavior, so, for example, each category of input values would get its own test case. Most testing frameworks provide some way to group together examples that test related behaviors and share common setup or teardown phases. \u2022 Each test case follows the same structure: arrange (set up preconditions), act (stimu- late the SUT), assert (verify the expected results). The assertion step makes each test Self-checking, eliminating the need for a human programmer to inspect test results. \u2022 Common assertions are checks on values (equality, betweenness, and so on) and checks on behavior (is an exception raised or not)."
    ]
  },
  {
    "id": "sec_0344",
    "title": "8.3 Isolating Code: Doubles and Seams",
    "pages": [
      255,
      256,
      257,
      258,
      259,
      260
    ],
    "text_blocks": [
      "We can distinguish three characteristics (which may occur individually or together) that com- plicate unit tests: \u2022 The SUT has one or more dependencies, such as other methods it calls to help do its work. Test cases should isolate the SUT from those dependencies. \u2022 The SUT has side effects when executed; that is, it causes a change in application state visible outside the test code itself. Test cases should verify that the correct side effect occurred, which involves inspecting application state outside the SUT. \u2022 The SUT is not a pure function, because its output depends not only on its input but other implicit factors, such as the time of day or a random event. Test cases should control the values of these factors to force the SUT to traverse predictable code paths. As an example, consider testing a controller action. By design, as we have seen, con- troller actions shouldn\u2019t contain \u201cbusiness logic\u201d\u2014instead they manage communication with the model, calling model methods to do the real work and setting up variables to display in- formation in the view. To make our example relevant to SaaS, consider a hypothetical SaaS app that allows the user to look up a movie in another service\u2019s movie database, and display the movie info so the user can write a review. Here is how our hypothetical app works: 244 CHAPTER 8. TEST-DRIVEN DEVELOPMENT matches = Movie . find_in_tmdb ( search_string ) if matches . empty ? # nothing was found redirect_to review_movie_path , : alert = > \" No matches . \" class MoviesController < A p p l i c a t i o n C o n t r o l l e r def review_movie search_string = params [: search ] begin https://gist.github.com/ae42df0d8365b35af8b67f2698d74c3c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @movie = matches [0] render ' review_movie ' else # more than 1 match @movies = matches render ' select_movie ' rescue Movie :: ConnectionError = > err elsif matches . length == 1 end message } \" redirect_to review_movie_path , : alert = > \" Error contacting TMDb : #{ err . 17 18 19 end end end Figure 8.4: A simple controller method that tries to search a remote database for one or more matches to a movie title. The call to the remote service happens from within the find_in_tmdb class method. 1. The Movie model has a class (static) method find_in_tmdb that makes a call to the API of the external service The Movie Database (TMDb)3 and returns an array of Movie objects, which may be empty if there were no matches. 2. If there are no matches, the controller action should redirect the user back to the search page with an appropriate message. 3. If there is exactly one match, the controller should render a view that allows the user to enter a review for that movie. 4. If there is more than one match, the controller should render a different view that allows the user to specify which movie they want to review. 5. Because the model method relies on calling an external service, fail if the service doesn\u2019t respond for some reason. Movie.find_in_tmdb will raise the exception Movie::ConnectionError. the call might In that case, we assume Figure 8.4 shows what the above controller action might look like. How would we unit-test this controller action? The Arrange step consists of preparing params to hold some search string. The Act step consists of calling the controller action with that search string. But the Assert step depends on whether the call to find_in_tmdb returns an empty array, an array of exactly one match, an array containing more than one match, or raises an exception because of an error communicating with The Movie Database. Indeed, as items 2\u20135 in the list above show, there are really four test cases required here, and to test each of them, we essentially need to be able to control the behavior of the call to find_in_tmdb. Michael Feathers (Feathers 2004) de\ufb01nes a seam as \u201ca place where you can alter behavior in your program without editing in that place.\u201d In our case, we want to alter (control) the behavior of find_in_tmdb but without changing the source code of the controller action. Recall that one ability afforded by metaprogramming is being able to modify code while a 8.3. ISOLATING CODE: DOUBLES AND SEAMS 245 describe M oviesController do describe ' looking up movie ' do https://gist.github.com/94f973152cfb2080ed5875ab1685acaf 1 2 3 4 5 6 7 8 9 end end end it ' redirects to search page if no match ' do allow ( Movie ) . to receive (: find_in_tmdb ) . and_return ( [] ) post ' review_movie ' , { ' search_string ' = > 'I Am Big Bird '} expect ( response ) . to redirect_to ( r evi ew_ mo vie _pa th ) Figure 8.5: This RSpec example (test case) stubs Movie.find_in_tmdb to isolate the controller action from its collaborators for the purposes of unit testing. program is running. In this case, the strategy would be to temporarily modify find_in_tmdb so that instead of calling the real method, it calls a \u201cfake\u201d method whose behavior we control and can change for each test case. Such a construction is called a method stub, and is easy to implement in languages that support metaprogramming. The RSpec testing framework provides direct support for this, as Figure 8.5 shows: the Arrange part of a test now includes setting up a stub for the method, and specifying that when the stub is called, it should return an empty array, ensuring that matches.empty? in line 6 of Figure 8.4 will be true, causing line 7 to be executed next. As is typical for a testing framework, RSpec \u201cun-registers\u201d any stubs after each example (test case) is run, making the stub visible only to that test case and thereby keeping tests Independent. Later we will show how to group together sets of examples that rely on the same precondition setup, so that tests can be DRY as well. Keeping in mind that every Ruby function call is a method call on an object, line 4 of Figure 8.5 can be read as follows: \u201cAllow the Movie class (which is itself an object) to re- ceive a call to its (class) method find_in_tmdb, and return an empty array as the return value of that call.\u201d Note that it is not an error for find_in_tmdb not to be called: the stub setup only speci\ufb01es what should happen if that method is called. If we wanted to express the test condition that the method must be called, we would replace allow with expect. In that case, line 4 would be both an Arrange step de\ufb01ning a stub and an Assert step spec- ifying that the test should fail if the stub isn\u2019t actually called. RSpec automatically veri\ufb01es expect...to receive assertions at the end of each example, so the test wouldn\u2019t need an extra line to check if the stub was called\u2014simply using expect rather than allow to set up the stub distinguishes the two cases. In this case, receive() creates a seam by overriding a method in place, without us having to edit the \ufb01le containing the original method (although in this case, the original method doesn\u2019t even exist yet). Seams are also important when it comes to adding new code to your application, but in the rest of this chapter we will see many more examples of seams in testing. Seams are useful in testing because they let us break dependencies between a piece of code we want to test and its collaborators, allowing the collaborators to behave differently under test than they would in real life. The kind of seam we just described is called a method stub or simply stub, because it is a piece of code that replaces the real method\u2019s code with a controllable or \ufb01xed behavior for testing purposes. A mock object or simply mock is a simpli\ufb01ed \u201cstunt double\u201d of an object that can only mimic a few \ufb01xed behaviors of the object, such as returning \ufb01xed values for speci\ufb01c attributes. Mocks are useful when a real object would be complex to instantiate because it has other dependencies, yet only a few speci\ufb01c properties of the object Spies are similar to stubs, but they allow a call to the real method to proceed while \u201crecording\u201d the arguments and return values for later inspection. 246 CHAPTER 8. TEST-DRIVEN DEVELOPMENT System under test (SUT) Pure leaf function\u2014no side effects, no collaborator methods or classes, same inputs yield same outputs Relies on results from calling collaborator methods or invoking behaviors on collaborator objects Nondeterministic or time-dependent behavior Has side effects Testing strategy Assert correct output results for critical values and for arbitrary values in noncritical regions In Arrange phase, create doubles that \u201cforce\u201d the de- sired behavior by returning prearranged values, raising an exception, and so on In code under test, isolate the nondeterminism in a method call that can be stubbed using a double in the Arrange phase In Arrange phase, observe the relevant state before ex- ecuting test code; in Assert phase, observe it again and check for side effect Figure 8.6: Strategy to properly isolate the SUT when it is not a pure function, not a leaf method, or both. are necessary for the SUT to work properly. The term test double generically covers these and a few other types of seams. Figure 8.6 summarizes typical strategies for using these doubles in various unit-testing scenarios, and Figure 8.7 shows examples of each strategy using RSpec. Summary \u2022 When testing a method that has external dependencies, for example calling other methods or consuming other objects, we use test doubles to \u201cstand in\u201d for the real methods or objects and allow the test to tightly control the SUT\u2019s behavior. \u2022 Test doubles are set up in the Arrange phase of a test case. Stubs are set up to control the return values from collaborator methods, while mocks are set up to mimic just those behaviors of the collaborator object used by the SUT. \u2022 Depending on what behavior is being tested, a test case can specify whether a par- ticular stub must be called, that is, if the stub not being called signals a bug. 8.3. ISOLATING CODE: DOUBLES AND SEAMS 247 # 1. Pure leaf function : test critical values and noncritical regions it ' occurs when multiple of 4 but not 100 ' do # 2. Using doubles for explicit dependencies such as collaborators # it ' colors the UI red if Defcon is 2 or lower ' do UI . background () calls Defcon . level () to determine display color # Arrange : stub Defcon to return 2 allow ( Defcon ) . to receive (: level ) . and_return (2) expect ( UI . background ) . to eq ( ' red ') # Act and Assert end end expect ( leap ?(2000) ) . to be_falsy expect ( leap ?(2008) ) . to be_truthy end it ' does not occur when multiple of 400 ' do # 3. Has implicit dependencies such as time it ' runs backups on Tuesdays ' do https://gist.github.com/7ba2377b49261a1d97c3109b99a4dbf0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 4. Has side effects ( verbose version ) it ' lowers Defcon level by 1 ' do to change { Defcon . level () }. by ( -1) end end end # Arrange : check previous value of state before = Defcon . level () post_alert ( \" Hostile craft detected \" ) expect ( Defcon . level () ) . to eq ( before - 1) # Asset # Act # Shortcut version passing a callable to ` expect ` it ' lowers Defcon level by 1 ' do expect { post_alert ( \" Hostile craft detected \" ) }. # Arrange : stub Date . today to return Tues 2020 -02 -04 allow ( Date ) . to receive (: today ) . and_return ( Time . local (2020 ,2 ,4) ) expect ( ru n _b ack ups _t oda y ?() ) . to be_truthy # Act and Assert Figure 8.7: RSpec examples corresponding to Figure 8.6. 248 CHAPTER 8. TEST-DRIVEN DEVELOPMENT Elaboration: Seams in other languages In non-object-oriented languages such as C, seams are hard to create. Since all method calls are resolved at link time, usually the developer creates a library containing the \u201cfake\u201d (test double) version of a desired method, and carefully controls library link order to ensure the test-double version is used. Similarly, since C data structures are accessed by reading directly from memory rather than calling accessor methods, data structure seams (mocks) are usually created by using preprocessor directives such as #ifdef TESTING to compile the code differently for testing vs. production use. In statically-typed OO languages like Java, since method calls are resolved at runtime, one way to create seams is to create a subclass of the class under test and override certain methods when compiling against the test harness. Mocking objects is also possible, though the mock object must satisfy the compiler\u2019s expectations for a fully-implemented \u201creal\u201d object, even if the mock is doing only a small part of the work that a real object would. The JMock website4 shows some examples of inserting testing seams in Java. In dynamic OO languages like Ruby that let you modify classes at runtime, we can create a seam almost anywhere and anytime. RSpec exploits this ability in allowing us to create just the speci\ufb01c mocks and stubs needed by each test, which makes tests easy to write. Self-Check 8.3.1. Name two likely violations of FIRST that arise when unit tests actually call an external service as part of testing. The test may no longer be Fast, since it takes much longer to call an external service than to compute locally. The test may no longer be Repeatable, since circumstances beyond our control could affect its outcome, such as the temporary unavailability of the external service."
    ]
  },
  {
    "id": "sec_0345",
    "title": "8.4 Stubbing the Internet",
    "pages": [
      260
    ],
    "text_blocks": [
      "When testing a method that makes a call to an external service via an API, there are many reasons we almost certainly don\u2019t want to make a real call to that API. One reason is abuse of the service\u2019s terms. Several years ago, the CS department head at a major US university re- ceived a complaint from a web site that hosted academic papers, because a group of students had been working on a student project that repeatedly made \u201ctest\u201d API calls against the real site. The site threatened to cut off the university\u2019s access if the students continued this be- havior. Another reason is that making real calls might prevent the test from being Repeatable depending on how the remote service responds, and would almost certainly prevent the test from being Fast. In fact, when testing our own app, all that we really care about is whether the API calls it would make are correctly formed\u2014analogous to checking a call to a method stub to make sure the arguments are correct. So the more general question is: Where should we stub ex- ternal methods when testing an app that makes calls to an external service? In Figure 8.5 we chose to stub the model and mimic the results of the gem\u2019s calls to TMDb, but a more robust integration testing approach would instead place the stub \u201ccloser\u201d to the remote ser- vice. In particular, we could create \ufb01xtures\u2014\ufb01les containing the JSON content returned by actual calls to the service\u2014and arrange to intercept calls to the remote service and return the"
    ]
  },
  {
    "id": "sec_0346",
    "title": "contents of those \ufb01xture \ufb01les instead. The Webmock5 gem does exactly this: it stubs out the",
    "pages": [
      260,
      261
    ],
    "text_blocks": [
      "entire Web except for particular URIs that return a canned response when accessed from a 8.5. CHIPS: INTRO TO RSPEC ON RAILS 249 Ruby program. (You can think of Webmock as allow(...).to receive(...).and_- return for the whole Web.) There\u2019s even a companion gem VCR6 that automates getting a response from the real service, saving the response data in a \ufb01xture \ufb01le, and then \u201creplaying\u201d the \ufb01xture when your tests cause the remote service to be \u201ccalled\u201d by intercepting low-level calls in the Ruby HTTP library. From an integration-testing standpoint, Webmock is the most realistic way to test interac- tions with a remote service, because the stubbed behavior is \u201cfarthest away\u201d\u2014we are stubbing as late as possible in the \ufb02ow of the request. Therefore, when creating Cucumber scenarios to test external service integration, Webmock is usually the appropriate choice. From a unit testing point of view (as we\u2019ve adopted in this chapter) it\u2019s less compelling, since we are concerned with the correct behavior of speci\ufb01c class methods, and we don\u2019t mind stubbing \u201cclose by\u201d in order to observe those behaviors in a controlled environment. VCR (for Videocassette Recorder ) was an analog-tape video-recording device popular in the 1980s but made obsolete by DVDs in the early 2000s. The vcr gem even uses the term cassette to refer to the stored server responses that are replayed during tests. Summary: \u2022 To create Fast and Repeatable test cases for code that communicates with an external service, we use stubs to mimic the service\u2019s behavior. context blocks can group specs that test different behaviors of the remote service, using before blocks to set up necessary stubs or other preconditions to simulate each behavior. \u2022 The question of \u201cwhere to stub\u201d an external service depends on the purpose of the test. Stubbing \u201cfar away\u201d using Webmock is more realistic and appropriate for func- tional or integration tests; stubbing \u201cclose by\u201d in a gem or library that communicates with the remote service is often adequate for low-level unit tests. Self-Check 8.4.1. Is \u201cstubbing the Internet\u201d in con\ufb02ict with the advice of Chapter 7 that one should avoid mocks or stubs in full-system Cucumber scenarios? Full-system testing should avoid \u201cfaking\u201d certain parts of it as we have done using seams in most of this chapter. However, if the \u201cfull system\u201d includes interacting with outside services we don\u2019t control, such as the interaction with TMDb in this example, we do need a way to \u201cfake\u201d their behavior for testing."
    ]
  },
  {
    "id": "sec_0347",
    "title": "8.5 CHIPS: Intro to RSpec on Rails",
    "pages": [
      261
    ],
    "text_blocks": [
      "CHIPS 8.5: Intro to RSpec on Rails https://github.com/saasbook/hw-tdd-rspec In this assignment, you\u2019ll learn to use RSpec and other tools to support test-driven develop- ment."
    ]
  },
  {
    "id": "sec_0348",
    "title": "8.6 Fixtures and Factories",
    "pages": [
      261,
      262,
      263,
      264,
      265,
      266,
      267
    ],
    "text_blocks": [
      "Doubles are appropriate when you need a stand-in with a small amount of functionality to isolate the code under test from its dependencies. But suppose you were testing a new in- stance method of class Movie called name_with_rating that returns a nicely formatted string showing a movie\u2019s title and rating. Clearly, such a method would have to access the Don\u2019t confuse this use of the term \u201cfactory\u201d with the Abstract Factory Pattern discussed in Chapter 11. 250 CHAPTER 8. TEST-DRIVEN DEVELOPMENT title and rating attributes of a Movie instance. You could create a double that knows all that information, and pass that double: https://gist.github.com/040ab61ab111ebfe71e9c42\ufb009dc726b 1 2 3 4 fake_movie = double ( ' Movie ') allow ( fake_movie ) . to receive (: title ) . and_return ( ' Casablanca ') allow ( fake_movie ) . to receive (: rating ) . and_return ( ' PG ') expect ( fake_movie . name_with_rating ) . to eq ' Casablanca ( PG ) ' But since the instance method being tested is part of the Movie class itself, it makes sense to use a real object here, since this isn\u2019t a case of isolating the test code from collaborator classes. Where can we get a real Movie instance to use in such a test? Most testing frameworks for object-oriented languages support the use of factories\u2014bits of code or declarative descrip- tions of objects designed to allow rapid creation of full-featured objects (rather than mocks) at testing time. The goal of a factory is to quickly create valid instances of a class using some default attributes that you can selectively override for testing. For example, if you were test- ing some code that allows a user to write a review for a movie, you might need a valid movie instance to pass to that code. In the above scenario of testing a title-and-rating formatter, you don\u2019t care what the movie\u2019s release date is, or who directed it; you just need a movie object that is valid and whose title and rating you do know. So you would ask the factory to produce a movie instance whose title and rating you specify, but whose other attributes you don\u2019t care about as long as they are valid values. You might think this seems like more work than just creating a movie instance directly by calling its constructor. In our simple example, that may be true. But there are two cases in which factories really shine. The \ufb01rst is when the object to be created has many attributes that must be initialized at creation time, even though any particular test case may only care about the speci\ufb01c values of a few of them. For example, the app that manipulates Movie objects may have validations requiring a movie to have a valid release date or other \ufb01elds meeting speci\ufb01c criteria, yet the test above doesn\u2019t care about the values of those other \ufb01elds. In such cases, you can ask the factory to create an object in which certain attribute values are speci\ufb01ed but others are \ufb01lled in with valid defaults. The second case is when objects you need to create have has-many or belongs-to relationships with other objects, as Chapter 5 describes. For example, if a Review belongs to a Movie, and you are creating a set of tests to check various behaviors of a Review, you literally cannot create a valid Review instance without creating a Movie instance for it to belong to, even if the tests you are writing don\u2019t care about the movie itself. In this case, the Review factory can be con\ufb01gured so that creating a Review also creates a valid Movie to which it belongs. Again, you can either specify a particular Movie object you\u2019ve created, or let the factory create one with valid default values. Then in your test you can simply ask for a Review object to be created, without having the details of the parent relationship clutter your test code. The Ruby gem FactoryBot7 lets you de\ufb01ne a factory for any kind of model in your app and create just the objects you need quickly for each test, selectively overriding only certain attributes, as Figure 8.8 shows. In database-backed MVC apps, one other source of \u201creal\u201d objects for use in tests is \ufb01x- tures\u2014a set of objects whose existence is guaranteed and \ufb01xed, and can be assumed by all test cases. The term \ufb01xture comes from the manufacturing world: a test \ufb01xture is a device that holds or supports the item under test. Since all state in Rails SaaS apps is kept in the database, a \ufb01xture \ufb01le de\ufb01nes a set of objects that is automatically loaded into the test database before tests are run, so you can use those objects in your tests without \ufb01rst setting them up. Rails 8.6. FIXTURES AND FACTORIES 251 # spec / factories / movie . rb FactoryBot . define do factory : movie do https://gist.github.com/81860a06858f0233566e76324228b185 1 2 3 4 5 6 7 8 9 title 'A Fake Title ' # default values rating ' PG ' release_date { 10. years . ago } end end # in spec / models / movie_spec . rb describe Movie do https://gist.github.com/b12c0c67a9859877324ec85dc7dee37a 1 2 3 4 5 6 7 8 end end it ' should include rating and year in full name ' do # ' build ' creates but doesn 't save object ; ' create ' also saves it movie = FactoryBot . build (: movie , : title = > ' Milk ' , : rating = > 'R ') expect ( movie . name_with_rating ) . to eq ' Milk ( R ) ' Figure 8.8: Using factories rather than \ufb01xtures preserves Independence among tests. Frameworks such as FactoryBot (gem \u2019factory_bot_rails\u2019 in Gem\ufb01le) make factory creation easy. looks for \ufb01xtures in a \ufb01le containing objects expressed in YAML (a recursive acronym for YAML Ain\u2019t Markup Language), as Figure 8.9 shows. Following convention over con\ufb01gura- tion, the \ufb01xtures for the Movie model are loaded from spec/fixtures/movies.yml, and are available to your specs via their symbolic names, as Figure 8.9 shows. But unless used carefully, \ufb01xtures can interfere with tests being Independent, as every test now depends implicitly on the \ufb01xture state, so changing the \ufb01xtures might change the behavior of tests. In addition, although any given test probably relies on only one or two \ufb01xtures, the union of \ufb01xtures required by all tests can become unwieldy. Therefore, \ufb01xtures should be used very sparingly if at all, and primarily for truly \ufb01xed data that, in production, would not be expected to change while the app is running but needs to be present in order for it to work. For example, at deployment time the app might allow setting the timezone or language in which it operates and storing the preferences in the database, and many aspects of the app might rely on these values being set to a legal value. Having a \ufb01xture that \u201chardwires\u201d some values suitable for testing is reasonable in this case. As a rule of thumb, use factories for kinds of data that normally change while the app is running, and consider \ufb01xtures for data that doesn\u2019t change but must be present for the app to work at all. Whether you use factories or \ufb01xtures, the test framework itself (in our case, RSpec) is responsible for restoring the state of the world to look \u201cpristine\u201d before the next test case runs, just as with doubles. Speci\ufb01cally, the database is completely erased, and any \ufb01xtures are then reloaded. Doing this test teardown before every single example keeps tests Independent. 252 CHAPTER 8. TEST-DRIVEN DEVELOPMENT # spec / fixtures / movies . yml milk_movie : id : 1 title : Milk rating : R release_date : 2008 -11 -26 https://gist.github.com/ab3223cfdfc9270c8391ea63f5f66571 1 2 3 4 5 6 7 8 9 10 11 id : 2 title : Food , Inc . release_date : 2008 -09 -07 do cum ent ar y_m ovi e : describe Movie do require ' rails_helper . rb ' # spec / models / movie_spec . rb : https://gist.github.com/697fb4ec76a1f1845a72bf1d2341b972 1 2 3 4 5 6 7 8 9 10 11 fixtures : movies it ' includes rating and year in full name ' do movie = movies (: milk_movie ) expect ( movie . name_with_rating ) . to eq ( ' Milk ( R ) ') end end Figure 8.9: Fixtures declared in YAML \ufb01les (top) are automatically loaded into the test database before each spec is executed (bottom). After each example runs, the database is cleared out and the \ufb01xtures reloaded. Summary \u2022 When a test needs to operate on a real object rather than a mock, the real object can be created on the \ufb02y by a factory or preloaded as a \ufb01xture. But beware that \ufb01xtures can create subtle interdependencies between tests, breaking Independence, so best practice is to avoid them except for \ufb01xed data that must be present for the app to run at all. \u2022 Tests are a form of internal documentation. RSpec exploits Ruby language features to let you write exceptionally readable test code. Like application code, test code is there for humans, not for the computer, so taking the time to make your tests readable not only deepens your understanding of them but also documents your thoughts more effectively for those who will work with the code after you\u2019ve moved on. Self-Check 8.6.1. Suppose a test suite contains a test that adds a model object to a table and then expects to \ufb01nd a certain number of model objects in the table as a result. Explain how the use of \ufb01xtures may affect the Independence of the tests in this suite, and how the use of factories can remedy this problem. If the \ufb01xtures \ufb01le is ever changed so that the number of items initially populating that table changes, this test may suddenly start failing because its assumptions about the initial state of the table no longer hold. In contrast, a factory can be used to quickly create only those objects needed for each test or example group on demand, so no test needs to depend on any global \u201cinitial state\u201d of the database. 8.6. FIXTURES AND FACTORIES 253 Structure of test cases: \u2022 before(:each) do...end Set up preconditions executed before each spec (use before(:all) to do just once, at your own risk) \u2022 it \u2019does something\u2019 do...end A single example (test case) for one behavior \u2022 describe \u2019collection of behaviors\u2019 do...end Groups a set of related examples Mocks and stubs: \u2022 m=double(\u2019movie\u2019) Creates a mock object with no prede\ufb01ned methods \u2022 allow(m).to receive(:rating).and_return(\u2019R\u2019) Replaces the existing rating method on m, or de\ufb01nes a new rating method if none exists, that returns the canned response \u2019R\u2019 \u2022 m=double(\u2019movie\u2019, :rating=>\u2019R\u2019) Shortcut that combines the 2 previous examples \u2022 allow(Movie).to receive(:find).and_return(@fake_movie) If Movie.find is called, @fake_movie will be returned; if not called, no error Useful methods and objects for controller specs: Your specs must be in the spec/controllers subdirectory for these methods to be available. \u2022 post \u2019/movies/create\u2019, {title: \u2019Milk\u2019, rating: \u2019R\u2019} Causes a POST request to /movies/create and passes the given hash as the value of params. get, put, delete also available. \u2022 expect(response).to render_template(\u2019show\u2019) Checks that the controller action renders the show template for this controller\u2019s model \u2022 expect(response).to redirect_to(controller: \u2019movies\u2019, action: \u2019new\u2019) Checks that the controller action redirects to MoviesController#new rather than rendering a view Figure 8.10: Some of the most useful RSpec methods introduced in this chapter. See the rspec.info documentation site for details and additional methods not listed here. 254 CHAPTER 8. TEST-DRIVEN DEVELOPMENT Assertions on method calls: can also negate by using either to_not or not_to (whichever reads better) in place of to \u2022 expect(Movie).to receive(:find).exactly(2).times Stubs Movie.find and ensures it\u2019s called exactly twice. Omit exactly if you don\u2019t care how many calls; at_least() and at_most() also available \u2022 expect(Movie).to receive(:find).with(\u2019Milk\u2019,\u2019R\u2019) Checks that Movie.find is called with exactly 2 arguments having these values \u2022 expect(Movie).to receive(:find).with(anything(),anything()) Checks that Movie.find is called with 2 arguments whose values aren\u2019t checked \u2022 expect(Movie).to receive(:find).with(hash_including title: \u2019Milk\u2019) Checks that Movie.find is called with 1 argument that must be a hash (or something that quacks like one) that includes the key :title with the value \u2019Milk\u2019 \u2022 expect(Movie).to receive(:find).with(no_args()) Checks that Movie.find is called with zero arguments Matchers: \u2022 expect(greeting).to eq \u2019bonjour\u2019 Compares its argument for equality with receiver of assertion \u2022 expect(value).to be >= 7 its Compares expect(value).to(be.>=(7)) argument with the given value; syntactic sugar for \u2022 expect(num).to be_within(delta).of(value) Test whether a numeric expression is within a threshold of some numeric value (useful for \ufb02oating-point calculations) \u2022 expect(str).to match(/regexp/) Assert that the string matches the given regexp \u2022 expect(result).to be_remarkable Asserts that calling remarkable? (note question mark) on result returns a non-nil value Figure 8.11: Continuation of summary of useful RSpec methods introduced in this chapter. 8.7. COVERAGE CONCEPTS AND TYPES OF TESTS 255 if x class MyClass def foo (x ,y , z ) if ( y && z ) then bar (0) end https://gist.github.com/811c0b0c8f91fbbb8a4233898450267a 1 2 3 4 5 6 7 8 9 10 end def bar ( x ) ; @w = x ; end bar (1) else end end Figure 8.12: A simple code example to illustrate basic coverage concepts."
    ]
  },
  {
    "id": "sec_0349",
    "title": "8.7 Coverage Concepts and Types of Tests",
    "pages": [
      267,
      268,
      269,
      270
    ],
    "text_blocks": [
      "How much testing is enough? A poor but unfortunately widely-given answer is \u201cAs much as you can before the release deadline.\u201d A very coarse-grained alternative is the code-to-test ratio, the number of non-comment lines of code divided by number of lines of tests of all types. In production systems, this ratio is usually less than 1, that is, there are more lines of test than lines of app code. The command rake stats issued in the root directory of a Rails app computes this ratio based on the number of lines of RSpec tests and Cucumber scenarios. Another widely-used metric that is more conservative is \u201cwhen the rate of new bug reports falls below some threshold.\u201d This formulation acknowledges that while code can never be proven bug-free, bugs are getting harder to \ufb01nd. But a more precise way to approach the question is to combine such metrics with code coverage. Since the goal of testing is to exercise the subject code in at least the same ways it would be exercised in production, what fraction of those possibilities is actually exercised by the test suite? Surprisingly, measuring coverage is not as straightforward as you might suspect. Figure 8.12 shows a simple fragment of code that we will use to illustrate the de\ufb01nitions of several commonly-used coverage terms. \u2022 S0 or Method coverage: Is every method executed at least once by the test suite? Satisfying S0 requires calling foo and bar at least once each. \u2022 S1 or Call coverage or Entry/Exit coverage: Has each method been called from every place it could be called? Satisfying S1 requires calling bar from both line 4 and line 6. Sometimes written with a subscript, S0. \u2022 C0 or Statement coverage: Is every statement of the source code executed at least once by the test suite, counting both branches of a conditional as a single statement? In addition to calling bar, satisfying C0 would require calling foo at least once with x true (otherwise the statement in line 4 will never be executed), and at least once with y false. \u2022 C1 or Branch coverage: Has each branch been taken in each direction at least once? Satisfying C1 would require calling foo with both false and true values of x and with values of y and z such that y && z in line 4 evaluates once to true and once to false. A more stringent condition, decision coverage, requires that each subexpression that independently affects a conditional expression be evaluated to true and false. In this example, a test would additionally have to separately set y and z so that the condition y && z fails once for y being false and once for z being false. 256 CHAPTER 8. TEST-DRIVEN DEVELOPMENT \u2022 C2 or Path coverage: Has every possible route through the code been executed? In this simple example, where x,y,z are treated as booleans, there are 8 possible paths. \u2022 Modi\ufb01ed Condition/Decision Coverage (MCDC) combines a subset of the above lev- els: Every point of entry and exit in the program has been invoked at least once, every decision in the program has taken all possible outcomes at least once, and each condi- tion in a decision has been shown to independently affect that decision\u2019s outcome. Achieving C0 coverage is relatively straightforward, and a goal of 100% C0 coverage is not unreasonable. Achieving C1 coverage is more dif\ufb01cult since test cases must be con- structed more carefully to ensure each branch is taken at least once in each direction. C2 coverage is most dif\ufb01cult of all, and not all testing experts agree on the additional value of achieving 100% path coverage. Therefore, code coverage statistics are most valuable to the extent that they highlight undertested or untested parts of the code and show the overall com- prehensiveness of your test suite. The SimpleCov gem8 is easy to con\ufb01gure and measures and displays the C0 and C1 coverage of your specs, allowing you to browse \ufb01le-by-\ufb01le to see which lines of your app were exercised by your test suites. If you have multiple suites, such as a set of Cucumber features as well as a set of specs, you must decide whether you need to know only whether a particular line of your app is exercised by some test, which may be either a Cucumber scenario or an RSpec example, or whether you need to know which type of test exercised it. SimpleCov does the former by default, but its instructions tell you how to do the latter. This chapter, and the above discussion of coverage, have focused on unit tests. Chapter 7 explained how user stories could become automated acceptance tests; we can think of a Cu- cumber scenario as both a system test, because it exercises code in many different parts of the application in the same ways a user would, as well as an acceptance test, because a properly-written scenario re\ufb02ects and veri\ufb01es the behavior the user said they wanted. In SaaS, such tests may also be called full-stack tests, since a typical scenario exercises every part of the app from the browser-based UI to the database. Unlike unit tests, system tests rarely rely on test doubles to isolate behavior; on the contrary, the goal is to simulate real users as closely as possible. Any test that covers more than one method but is not a full-stack test is generically an integration test. For example, an RSpec test of a controller action would probably stub out calls to the database and bypass the routing mechanism, neither of which is central to testing the controller action itself, but would probably include interactions with mechanisms such as parsing form input, which clearly are outside the controller action. System and integration tests are important, but insuf\ufb01cient. Their resolution is poor: if an integration test fails, it is harder to pinpoint the cause since the test touches many parts of the code. Especially for system tests, coverage also tends to be poor because even though a single scenario touches many classes, it executes only a few code paths in each class. For the same reason, system and integration tests also tend to take longer to run. On the other hand, while unit tests run quickly and can isolate the subject code with great precision (improving both coverage resolution and error localization), because they rely on fake objects to isolate the subject code, they may mask problems that would only arise in integration tests. In other words, high assurance requires both good coverage and a mix of all three kinds of tests. Figure 8.13 summarizes the relative strengths and weaknesses of different types of tests. We have focused on testing for correctness (\u201cdid you build the thing right\u201d), but in prac- tice, other \ufb02avors of tests are part of any comprehensive test suite: 8.7. COVERAGE CONCEPTS AND TYPES OF TESTS 257 What is tested Running time Error localization Coverage Use of doubles Unit One method/class Very fast Excellent Excellent Frequently Functional Several methods/classes Fairly fast Moderate Moderate Occasionally System/Integration Large chunks of system Slow Poor Poor Rarely/never Figure 8.13: Summary of the differences among unit tests, functional tests, and integration or whole-system tests. \u2022 A smoke test consists of a minimal attempt to operate the software, to see whether anything is obviously wrong before running the rest of the test suite. For example, if a low-level coding error prevents a SaaS app from displaying its home page or accepting logins, there is no point in running further tests. \u2022 Compatibility testing is less prominent in SaaS since the app developers control the server environment, but may still be important for testing the app\u2019s UI in differ- ent browsers. For example, Sauce Labs9 supports running SaaS integration tests on a variety of browsers and operating systems to check correct client behavior, and even captures a screencast of each run so you can visually check behaviors such as whether the same fonts look good in different browsers. \u2022 Regression testing ensures that previously-\ufb01xed bugs do not reappear. We return to regression tests in Section 10.6. \u2022 Performance, stress, and security testing are types of non-functional testing that ensure the software meets these operational criteria, which are particularly important for SaaS. We return to these in Chapter 12. \u2022 Accessibility testing ensures that the software is usable by persons with disabilities. In SaaS, accessibility testing focuses primarily on the client-side user experience. Summary \u2022 Static and dynamic measures of coverage, including code-to-test ratio (reported by rake stats), C0 or C1 coverage (reported by SimpleCov), and C2 coverage, mea- sure the extent to which your test suite exercises different paths in your code. Sim- pleCov provides one way to measure coverage for Ruby code, including Rails apps. \u2022 Rather than setting \u201chard targets\u201d for coverage levels, use coverage reports to iden- tify under-tested parts of your app so you can enhance the test suite accordingly. \u2022 Unit, integration, and system/acceptance tests differ in terms of their running time, resolution (ability to localize errors), ability to exercise a variety of code paths, and ability to perform a \u201creasonableness check\u201d or so-called smoke test on the whole application. All three are vital to software assurance. \u2022 In addition to functional tests that check correctness, we also need non- functional tests for accessibility, compatibility, security, and performance. 258 CHAPTER 8. TEST-DRIVEN DEVELOPMENT Self-Check 8.7.1. Why does high test coverage not necessarily imply a well-tested applica- tion? Coverage says nothing about the quality of the tests. However, low coverage certainly implies a poorly-tested application. Self-Check 8.7.2. What is the difference between C0 code coverage and code-to-test ratio? C0 coverage is a dynamic measurement of what fraction of all statements are executed by a test suite. Code-to-test ratio is a static measurement comparing the total number of lines of code to the total number of lines of tests."
    ]
  },
  {
    "id": "sec_0350",
    "title": "8.8 Other Testing Approaches and Terminology",
    "pages": [
      270,
      271,
      272
    ],
    "text_blocks": [
      "The \ufb01eld of software testing is as broad and long-lived as software engineering and has its own literature. Its range of techniques includes formalisms for proving things about cover- age, empirical techniques for selecting which tests to create, and directed-random testing. Depending on an organization\u2019s \u201ctesting culture,\u201d you may hear different terminology than we\u2019ve used in this chapter. Ammann and Offutt\u2019s Introduction to Software Testing (Ammann and Offutt 2008) is one of the best comprehensive references on the subject. Their approach is to divide a piece of code into basic blocks, each of which executes from the beginning to the end with no possibility of branching, and then join these basic blocks into a graph in which conditionals in the code result in graph nodes with multiple out-edges. We can then think of testing as \u201ccovering the graph\u201d: each test case tracks which nodes in the graph it visits, and the fraction of all nodes visited at the end of the test suite is the test coverage. Ammann and Offutt go on to analyze various structural aspects of software from which such graphs can be extracted, and present systematic automated techniques for achieving and measuring coverage of those graphs. One insight that emerges from this approach is that the levels of testing described in the previous section refer to control \ufb02ow coverage, since they are only concerned with whether speci\ufb01c parts of the code are executed or not. Another important coverage criterion is de\ufb01ne\u2013 use coverage or DU-coverage: given a variable x in some program, if we consider every place that x is assigned a value and every place that the value of x is used, DU-coverage asks what fraction of all pairs of de\ufb01ne and use sites are exercised by a test suite. This condition is weaker than all-paths coverage but can \ufb01nd errors that control-\ufb02ow coverage alone would miss. Another testing term distinguishes black-box tests, whose design is based solely on the software\u2019s external speci\ufb01cations, from white-box tests (also called glass-box tests), whose design re\ufb02ects knowledge about the software\u2019s implementation that is not implied by external speci\ufb01cations. For example, the external speci\ufb01cation of a hash table might just state that when we store a key/value pair and later read that key, we should get back the stored value. A black-box test would specify a random set of key/value pairs to test this behavior, whereas a white-box test might exploit knowledge about the hash function to construct worst- case test data that results in many hash collisions. Similarly, white-box tests might focus on boundary values\u2014parameter values likely to exercise different parts of the code. Mutation testing , invented by Ammann and Offutt, is a test-automation technique in which small but syntactically legal changes are automatically made to the program\u2019s source code, such as replacing a+b with a-b or replacing if (c) with if (!c). Most such changes should cause at least one test to fail, so a mutation that causes no test to fail in- dicates either a lack of test coverage or a very strange program. 8.8. OTHER TESTING APPROACHES AND TERMINOLOGY 259 Fuzz testing consists of throwing random data at your application and seeing what In 2014, Google engineers reported10 that over a 2-year period, fuzz testing had breaks. helped \ufb01nd over 1,000 bugs in the open source video-processing utility ffmpeg. Fuzz testing has been particularly useful for \ufb01nding security vulnerabilities that are missed by both man- ual code inspection and formal analysis, including stack and buffer over\ufb02ows and unchecked null pointers. While such memory bugs do not arise in interpreted languages like Ruby and Python or in type-safe and memory-safe compiled languages such as Rust, fuzz testing can still \ufb01nd interesting bugs in SaaS apps. Random or black box fuzzing either generates com- pletely random data or randomly mutates valid input data, such as changing certain bytes of metadata in a JPEG image to test the robustness of the image decoder. Smart fuzzing incor- porates knowledge about the app\u2019s structure and possibly a way to specify how to construct \u201crealistic but fake\u201d fuzz data. For example, smart-fuzzing SaaS might include randomizing the variables and values occurring in form postings or URIs, or attempting various cross-site scripting or SQL injection attacks, which we\u2019ll discuss in Chapter 12. Finally, white-box fuzzing uses symbolic execution, which simulates execution of a program observing the conditions under which each branch is taken or not, then generates fuzzed inputs to exercise the branch paths not taken during the simulated execution. White-box fuzzing requires no explicit knowledge of the app\u2019s structure and can theoretically provide C2 (all paths) cover- age, but in practice the size of the search space is huge, and white-box fuzzing relies on a diverse set of \u201cseed inputs\u201d to be effective. This combination of formal analysis and random directed testing is representative of the current state of the art in thorough software testing. For a short contemporary survey of fuzz testing, see Godefroid\u2019s article in Communications of the ACM (Godefroid 2020). Summary of other testing approaches: We can think of testing as \u201ccovering a graph\u201d of possible software behaviors. The graph can represent control \ufb02ow (basic block coverage), variable assignment and usage (DU-coverage), a space of random inputs (fuzz testing), or a space of possible tests with respect to speci\ufb01c errors in the code (mutation testing). The different approaches are complementary and tend to catch different types of bugs. Self-Check 8.8.1. The Microsoft Zune music player had an infamous bug that caused all Zunes to \u201clock up\u201d on December 31, 2008. Later analysis showed that the bug would be triggered on the last day of any leap year. What kinds of tests\u2014black-box, glass-box, muta- tion, or fuzz\u2014would have been likely to catch this bug? A glass-box test for the special code paths used for leap years would have been effective. Fuzz testing might have been effective: since the bug occurs roughly once in every 1460 days, a few thousand fuzz tests would likely have found it. 260 CHAPTER 8. TEST-DRIVEN DEVELOPMENT"
    ]
  },
  {
    "id": "sec_0351",
    "title": "8.9 CHIPS: The Acceptance Test/Unit Test Cycle",
    "pages": [
      272
    ],
    "text_blocks": [
      "CHIPS 8.9: The Acceptance Test/Unit Test Cycle https://github.com/saasbook/hw-acceptance-unit-test-cycle In this assignment you will use a combination of Acceptance and Unit tests with the Cucum- ber and RSpec tools to add a \u201c\ufb01nd movies with same director\u201d feature to RottenPotatoes. You will alternate between BDD, in which you write one step of a Cucumber scenario, and TDD, in which you write tests and code to get that one step to pass, repeating until all steps in the scenario are complete. Along the way you\u2019ll measure code coverage to make sure you are thoroughly testing your code."
    ]
  },
  {
    "id": "sec_0352",
    "title": "8.10 The Plan-And-Document Perspective on Testing",
    "pages": [
      272,
      273
    ],
    "text_blocks": [
      "The project manager takes the Software Requirements Speci\ufb01cation from the requirements planning phase and divides it into the individual program units. Developers then write the code for each unit, and then perform unit tests to make sure they work. In many organizations, quality assurance staff performs the rest of the higher-level tests, such as module, integration, system, and acceptance tests. There are three options on how to integrate the units and perform integration tests: 1. Top-down integration starts with the top of the tree structure showing the dependency among all the units. The advantage of top-down is that you quickly get some of the high level functions working, such as the user interface, which allows stakeholders to offer feedback for the app in time to make changes. The downside is that you have to create many stubs to get the app to limp along in this nascent form. 2. Bottom-up integration starts at the bottom of the dependency tree and works up. There is no need for stubs, as you can integrate all the pieces you need for a module. Alas, you don\u2019t get an idea how the app will look until you get all the code written and integrated. 3. Sandwich integration, not surprisingly, tries to get the best of both worlds by integrat- ing from both ends simultaneously. Thus, you try to reduce the number of stubs by selectively integrating some units bottom-up and try to get the user interface opera- tional sooner by selectively integrating some units top-down. The next step for the QA testers after integration tests is the system test, as the full app should work. This is the last step before showing it to customers for them to try out. Note that system tests cover both non-functional requirements, such as performance, and functional requirements of features found in the SRS. One question for plan-and-document is how to decide when testing is complete. Typi- cally, an organization will enforce a standard level of testing coverage before a product is ready for the customer. Examples might be statement coverage (all statements executed at least once), or all user input opportunities are tested with both good input and problematic input. 8.10. THE PLAN-AND-DOCUMENT PERSPECTIVE ON TESTING 261 In the plan and document process, the \ufb01nal test is for the customers to try the product in their environment to decide whether they will accept the product or not. That is, the aim is validation, not just veri\ufb01cation. In Agile development, the customer is involved in trying prototypes of the app early in the process, so there is no separate system test before running the acceptance tests. As you should expect from the plan-and-document process, documentation plays an im- portant role in testing. Figure 8.14 gives an outline for a test plan based on IEEE Standard 829-2008. While testing is fundamental to software engineering, quoting another Turing Award win- ner: Program testing can be used to show the presence of bugs, but never to show their ab- sence! \u2014Edsger W. Dijkstra Thus, there has been a great deal of research investigating approaches to veri\ufb01cation beyond testing. Collectively, these techniques are known as formal methods. The general strategy is to start with a formal speci\ufb01cation and prove that the behavior of the code follows the behavior of that spec. These are mathematical proofs, either done by a person or done by a computer. The two options are automatic theorem proving or model checking . Theorem proving uses a set of inference rules and a set of logical axioms to produce proofs from scratch. Model checking veri\ufb01es selected properties by exhaustive search of all possible states that a system could enter during execution. Because formal methods are so computationally intensive, they tend to be used only when the cost to repair errors is very high, the features are very hard to test, and the item being veri\ufb01ed is not too large. Examples include vital parts of hardware like network protocols or safety critical software systems like medical equipment. For formal methods to actually work, the size of the design must be limited: the largest formally veri\ufb01ed software to date is an operating system kernel that is less than 10,000 lines of code, and its veri\ufb01cation cost about $500 per line of code (Klein et al. 2010). Hence, formal methods are not good matches to high-function software that changes fre- quently, as is generally the case for Software as a Service. Edsger W. Dijkstra (1930\u20132002) received the"
    ]
  },
  {
    "id": "sec_0353",
    "title": "1972 Turing Award for",
    "pages": [
      273,
      274
    ],
    "text_blocks": [
      "fundamental contributions to developing programming languages. To put the cost of formal methods in perspective, NASA spent $35M per year to maintain 420,000 lines of code11 for the space shuttle, or about $80 per line of code per year. 262 CHAPTER 8. TEST-DRIVEN DEVELOPMENT Top-Level Test Plan Outline 1. Introduction 1.1. Document identi\ufb01er 1.2. Scope 1.3. References 1.4. System overview and key features 1.5. Test overview"
    ]
  },
  {
    "id": "sec_0354",
    "title": "1.5.1 Organization",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0355",
    "title": "1.5.2 Overall test schedule",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0356",
    "title": "1.5.3 Integrity level schema",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0357",
    "title": "1.5.4 Resources summary",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0358",
    "title": "1.5.5 Responsibilities",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0359",
    "title": "1.5.6 Tools, techniques, methods, and metrics",
    "pages": [
      274
    ],
    "text_blocks": [
      "2. Details of the Top-Level Test Plan 2.1. Test processes including de\ufb01nition of test levels"
    ]
  },
  {
    "id": "sec_0360",
    "title": "2.1.1 Process: Management",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0361",
    "title": "2.1.1.1 Activity: Management of test effort",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0362",
    "title": "2.1.2 Process: Acquisition",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0363",
    "title": "2.1.2.1 Activity: Acquisition support test",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0364",
    "title": "2.1.3 Process: Supply",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0365",
    "title": "2.1.3.1 Activity: Planning test",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0366",
    "title": "2.1.4 Process: Development",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0367",
    "title": "2.1.4.1 Activity: Concept",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0368",
    "title": "2.1.4.2 Activity: Requirements",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0369",
    "title": "2.1.4.3 Activity: Design",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0370",
    "title": "2.1.4.4 Activity: Implementation",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0371",
    "title": "2.1.4.5 Activity: Test",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0372",
    "title": "2.1.4.6 Activity: Installation/checkout",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0373",
    "title": "2.1.5 Process: Operation",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0374",
    "title": "2.1.5.1 Activity: Operational test",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0375",
    "title": "2.1.6 Process: Maintenance",
    "pages": [
      274
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0376",
    "title": "2.1.6.1 Activity: Maintenance test",
    "pages": [
      274,
      275,
      276
    ],
    "text_blocks": [
      "2.2. Test documentation requirements 2.3. Test administration requirements 2.4. Test reporting requirements 3. General 3.1. Glossary 3.2. Document change procedures and history Figure 8.14: Outline of Top-Level Test Plan Documentation that follows the IEEE Standard 829-2008. 8.10. THE PLAN-AND-DOCUMENT PERSPECTIVE ON TESTING 263 Tasks Test Plan and Documentation Order of Coding and Testing Testers When Testing Stops In Plan-and-Document Software Test Documentation such as IEEE Standard 829-2008 1. Code units 2. Unit test 3. Module test 4. Integration test 5. System test 6. Acceptance test Developers for unit tests; QA testers for mod- ule, integration, system, and acceptance tests Company policy (e.g., statement coverage, happy and sad user inputs) In Agile User stories 1. Acceptance test 2. Integration test 3. Module test 4. Unit test 5. Code units Developers All tests pass (green) Figure 8.15: The relationship between the testing tasks of Plan-and-Document versus Agile methodologies. Summary: Testing and formal methods reduce the risks of errors in designs. \u2022 Unlike BDD/TDD, the plan-and-document process starts with writing code before you write the tests. \u2022 Developers then perform unit tests. \u2022 Especially in large projects, different people perform the higher-level tests. The integration tests options of putting the units together are top-down, bottom-up, or sandwich. \u2022 Testers do a separate system test to ensure the product passes both functional and non-functional requirements before exposing it to customers for the \ufb01nal acceptance test. \u2022 Formal methods rely on formal speci\ufb01cations and automated proofs or exhaus- tive state search to verify more than what testing can do, but they are so expensive to perform that today they are only applicable to small, stable, critical portions of hardware or software. \u2022 Figure 8.15 shows the different test tasks for plan-and-document versus Agile pro- cesses. Self-Check 8.10.1. Compare and contrast integration strategies including top-down, bottom- up, and sandwich integration. Top-down needs stubs to perform the tests, but it lets stakeholders get a feeling for how the app works. Bottom-up does not need stubs, but needs potentially everything written before stakeholders see it work. Sandwich integration works from both ends to try to get both bene\ufb01ts. 264 CHAPTER 8. TEST-DRIVEN DEVELOPMENT"
    ]
  },
  {
    "id": "sec_0377",
    "title": "8.11 Fallacies and Pitfalls",
    "pages": [
      276,
      277,
      278
    ],
    "text_blocks": [
      "Fallacy: 100% test coverage with all tests passing means no bugs. There are many reasons this statement can be false. Complete test coverage says nothing about the quality of the individual tests. As well, some bugs may require passing a certain value as a method argument (for example, to trigger a divide-by-zero error), and control \ufb02ow testing often cannot reveal such a bug. There may be bugs in the interaction between your app and an external service such as TMDb; stubbing out the service so you can perform local testing might mask such bugs. Pitfall: Dogmatically insisting on 100% test coverage all passing (green) be- fore you ship. As we saw above, 100% test coverage is not only dif\ufb01cult to achieve at levels higher than C1, but gives no guarantees of bug-freedom even if you do achieve it. Test coverage is a useful tool for estimating the overall comprehensiveness of your test suite, but high con\ufb01dence requires a variety of testing methods\u2014integration as well as unit, fuzzing as well as hand- constructing test cases, de\ufb01ne-use coverage as well as control-\ufb02ow coverage, mutation testing to expose additional holes in the test strategy, and so on. Indeed, in Chapter 12 we will discuss operational issues such as security and performance, which call for additional testing strategies beyond the correctness-oriented ones described in this chapter. Fallacy: You don\u2019t need much test code to be con\ufb01dent in the application. While insisting on 100% coverage may be counterproductive, so is going to the other extreme. The code-to-test ratio in production systems (lines of noncomment code divided by lines of tests of all types) is usually less than 1, that is, there are more lines of test than lines of app code. As an extreme example, the SQLite database included with Rails contains over 1200 times as much test code as application code12 because of the wide variety of ways in which it can be used and the wide variety of different kinds of systems on which it must work properly! While there is controversy over how useful a measure the code-to-test ratio is, given the high productivity of Ruby and its superior facilities for DRYing out your test code, a rake stats ratio between 0.2 and 0.5 is a reasonable target. Pitfall: Relying too heavily on just one kind of test (unit, functional, integra- tion). Unit and functional tests are useful for covering rare corner cases and code paths. They also tell you how well-factored or modular your code is: a module or method that is easy to test has well-circumscribed external dependencies, which in turn reinforces that it can be well tested in isolation. On the other hand, because of that very isolation, even 100% unit test coverage tells you nothing about interactions among classes or modules. That\u2019s where integration-level tests such as the Cucumber scenarios of Chapter 7 are useful. Such tests touch only a tiny fraction of all possible application paths and exercise only a few behaviors in each method, but they do test the interfaces and interactions among modules. One rule of thumb used at Google and elsewhere (Whittaker et al. 2012) is \u201c70\u201320\u201310\u201d: 70% short and focused unit tests, 20% functional tests that touch multiple classes, 10% full-stack or integration tests. See Chapter 7 for the complementary pitfall of over-reliance on integration 8.11. FALLACIES AND PITFALLS 265 tests. Pitfall: Undertested integration points due to over-stubbing. Mocking and stubbing confer many bene\ufb01ts, but they can also hide potential problems at integration points\u2014places where one class or module interacts with another. Suppose Movie has some interactions with another class Moviegoer, but for the purposes of unit testing Movie, all calls to Moviegoer methods are stubbed out, and vice versa. Because stubs are written to \u201cfake\u201d the behavior of the collaborating class(es), we no longer know if Movie \u201cknows how to talk to\u201d Moviegoer correctly. Good coverage with functional and integration tests, which don\u2019t stub out all calls across class boundaries, avoids this pitfall. Pitfall: Writing tests after the code rather than before. Thinking about \u201cthe code we wish we had\u201d from the perspective of a test for that code tends to result in code that is testable. This seems like an obvious tautology until you try writing the code \ufb01rst without testability in mind, only to discover that surprisingly often you end up with mock trainwrecks (see next pitfall) when you do try to write the test. In addition, in the traditional Waterfall lifecycle described in Chapter 1, testing comes after code development, but with SaaS that can be in \u201cpublic beta\u201d for months, no one would suggest that testing should only begin after the beta period. Writing the tests \ufb01rst, whether for \ufb01xing bugs or creating new features, eliminates this pitfall. Pitfall: Mock Trainwrecks. Mocks exist to help isolate your tests from their collaborators, but what about the col- laborators\u2019 collaborators? Suppose our Movie object has a pics attribute that returns a list of images associated with the movie, each of which is a Picture object that has a format attribute. You\u2019re trying to mock a Movie object for use in a test, but you realize that the method to which you\u2019re passing the Movie object is going to expect to call methods on its pics, so you \ufb01nd yourself doing something like this: https://gist.github.com/87f04dad610b1da187de8da024bf02af 1 2 movie = double ( ' Movie ' , : pics = > [ double ( ' Picture ' , : format = > ' gif ') ]) expect ( Movie . count_pics ( movie ) ) . to eq 1 This is called a mock trainwreck, and it\u2019s a sign that the method under test (count_pics) has excessive knowledge of the innards of a Picture. In Chapters 9 and 11 we\u2019ll encounter a set of additional guidelines to help you detect and resolve such code smells. Pitfall: Inadvertently creating dependencies regarding the order in which specs are run, for example by using before(:all). If you specify actions to be performed only once for a whole group of test cases, you may introduce dependencies among those test cases without noticing. For example, if a before :all block sets a variable and test example A changes the variable\u2019s value, test example B could come to rely on that change if A is usually run before B. Then B\u2019s behav- ior in the future might suddenly be different if B is run \ufb01rst, which might happen because guard prioritizes running tests related to recently-changed code. Therefore it\u2019s best to use before :each and after :each whenever possible. Pitfall: Forgetting to re-prep the test database when the schema changes. 266 REFERENCES Remember that tests run against a separate copy of the database, not the database used in development (Section 4.2). Therefore, whenever you modify the schema by applying a migration, you must also run rake db:test:prepare to apply those changes to the test database; otherwise your tests may fail because the test code doesn\u2019t match the schema."
    ]
  },
  {
    "id": "sec_0378",
    "title": "8.12 Concluding Remarks: TDD vs. Conventional Debugging",
    "pages": [
      278,
      279,
      280
    ],
    "text_blocks": [
      "In this chapter we\u2019ve used RSpec to develop a method using TDD with unit tests. Although TDD may feel strange at \ufb01rst, most people who try it quickly realize that they already use the unit-testing techniques it calls for, but in a different work\ufb02ow. Often, a typical developer will write some code, assume it probably works, test it by running the whole application, and hit a bug. As an MIT programmer lamented at the \ufb01rst software engineering conference in 1968: \u201cWe build systems like the Wright brothers built airplanes\u2014build the whole thing, push it off a cliff, let it crash, and start over again.\u201d Once a bug has been hit, if inspecting the code doesn\u2019t reveal the problem, the typical developer would next try inserting print statements around the suspect area to print out the values of relevant variables or indicate which path of a conditional was followed. The TDD developer would instead write assertions using expect. If the bug still can\u2019t be found, the typical developer might isolate part of the code by carefully setting up conditions to skip over method calls they don\u2019t care about or change vari- able values to force the code to go down the suspected buggy path. For example, they might do this by setting a breakpoint using a debugger and manually inspecting or manipulating variable values before continuing past the breakpoint. In contrast, the TDD developer would isolate the suspect code path using stubs and mocks to control what happens when certain methods are called and which direction conditionals will go. By now, the typical developer is absolutely convinced that he\u2019ll certainly \ufb01nd the bug and won\u2019t have to repeat this tedious manual process, though this usually turns out to be wrong. The TDD developer has isolated each behavior in its own spec, so repeating the process just means re-running the spec. In other words: If we write the code \ufb01rst and have to \ufb01x bugs, we end up using the same techniques required in TDD, but less ef\ufb01ciently and more manually, hence less productively. But if we use TDD, bugs can be spotted immediately as the code is written. If our code works the \ufb01rst time, using TDD still gives us a regression test to catch bugs that might creep into this part of the code in the future. \u2022 How Google Tests Software (Whittaker et al. 2012) is a rare glimpse into how Google has scaled up and adapted the techniques described in this chapter to instill a culture of testing that is widely admired by its competitors. \u2022 The online RSpec documentation13 gives complete details and additional features used in advanced testing scenarios. \u2022 The RSpec Book (Chelimsky et al. 2010) is the de\ufb01nitive published reference to RSpec and includes examples of features, mechanisms and best practices that go far beyond this introduction. P. Ammann and J. Offutt. Introduction to Software Testing. Cambridge University Press, 2008. ISBN 0521880386. NOTES 267 D. Chelimsky, D. Astels, B. Helmkamp, D. North, Z. Dennis, and A. Helles\u00f8y. The RSpec Book: Behaviour Driven Development with Rspec, Cucumber, and Friends (The Facets of Ruby Series). Pragmatic Bookshelf, 2010. ISBN 1934356379. M. Feathers. Working Effectively with Legacy Code. 9780131177055. Prentice Hall, 2004. ISBN P. Godefroid. Fuzzing: Hack, art, and science. Communications of the ACM, 63(2):70\u201376, Feb 2020. doi: 10.1145/3363824. G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin, D. Elkaduwe, K. En- gelhardt, R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and S. Winwood. seL4: Formal veri\ufb01cation of an OS kernel. Communications of the ACM (CACM), 53(6):107\u2013115, June 2010. xUnit Test Patterns: ISBN 0131495054. G. Meszaros. Wesley, 2007. Test-Patterns-Refactoring-Code/dp/0131495054?SubscriptionId= AKIAIOBINVZYXZQZ2U3A&tag=chimbori05-20&linkCode=xm2&camp=2025& creative=165953&creativeASIN=0131495054. Addison- URL https://www.amazon.com/xUnit- Refactoring Test Code. J. A. Whittaker, J. Arbon, and J. Carollo. How Google Tests Software. Addison-Wesley Professional, 2012. ISBN 0321803027. Notes 1https://xunitpatterns.com 2https://glossary.istqb.org/en/search 3https://themoviedb.org 4http://jmock.org/getting-started.html 5https://github.com/bblimke/webmock 6http://github.com/vcr 7https://github.com/thoughtbot/factory_bot_rails 8https://github.com/colszowka/simplecov 9https://saucelabs.com 10https://security.googleblog.com/2014/01/ffmpeg-and-thousand-fixes.html 11http://www.fastcompany.com/magazine/06/writestuff.html 12http://www.sqlite.org/testing.html 13http://rspec.info 9 Software Maintenance: Enhancing Legacy Software Using Refactoring and Agile Methods There probably isn\u2019t a \u201cbest\u201d way to build the system, or even any major part of it; much more important is to avoid choosing a terrible way, and to have clear division of responsibilities among the parts. \u2014Butler Lampson, Hints for Computer System Design, 1983 . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0379",
    "title": "9.1 What Makes Code \u201cLegacy\u201d and How Can Agile Help? .",
    "pages": [
      280
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0380",
    "title": "9.2 Exploring a Legacy Codebase .",
    "pages": [
      280
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0381",
    "title": "9.3 Establishing Ground Truth With Characterization Tests",
    "pages": [
      280
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0382",
    "title": "9.4 Comments and Commits: Documenting Code .",
    "pages": [
      280
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0383",
    "title": "9.5 Metrics, Code Smells, and SOFA .",
    "pages": [
      280
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0384",
    "title": "9.6 Method-Level Refactoring: Replacing Dependencies With Seams",
    "pages": [
      280
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0385",
    "title": "9.7 The Plan-And-Document Perspective on Working With Legacy Code",
    "pages": [
      280
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0386",
    "title": "9.8 Fallacies and Pitfalls .",
    "pages": [
      280
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0387",
    "title": "9.9 Concluding Remarks: Continuous Refactoring .",
    "pages": [
      280,
      281,
      282
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270 . 273 . 277 . 279 . 281 . 286 292 . 297 . 298 . . . . . . . . . . . . . . . . . . . Butler Lampson (1943\u2013) was the intellectual leader of the legendary Xerox Palo Alto Research Center (Xerox PARC), which during its heyday in the 1970s invented graphical user interfaces, object-oriented programming, laser printing, and Ethernet. Three PARC researchers eventually won Turing Awards for their work there. Lampson received the 1994 Turing Award for contributions to the development and implementation of distributed personal computing environments: workstations, networks, operating systems, programming systems, displays, security, and document publishing. 269 Prerequisites and Concepts Like a shark that must keep moving to live, software must change to remain viable. The big concepts in this chapter are that Agile development is a good approach to both maintain software and to enhance legacy code, and that refactoring is necessary on all development processes to keep code maintainable. Concepts: When writing code, software metrics and code smells can identify code that is hard to read. Transforming the code by refactoring should improve software metrics and eliminate code smells. Methods should be Short, do One thing, have Few arguments, and maintain a single level of Abstraction (SOFA). To enhance legacy code using the Agile lifecycle: \u2022 Understand the code at the change points, where you can plausibly make changes. Reading and enhancing comments is one way to understand the code. \u2022 Explore how it works from all stakeholders\u2019 perspectives, which involves reading tests, design documents, and inspecting code. \u2022 Write characterization tests to beef up test coverage before making changes to the code. For the Plan-and-Document lifecycle: \u2022 A maintenance manager runs the project during maintenance and estimates cost of change requests. \u2022 Using cost-benet analysis, a Change Control Committee triages change requests. \u2022 Like Agile, maintenance relies on regression testing to ensure new releases work well and refactoring to make the code easier to maintain. Surprisingly, the Agile process matches many needs of the maintenance phase of Plan- and-Development lifecycle. Agile and Plan-and-Document processes have the same maintenance goals and many of the same techniques, but Agile suggests getting there by constant incremental refactor- ing rather than recoding all up front. 270 CHAPTER 9. LEGACY, REFACTORING, AND AGILE Figure 9.1: The Agile software lifecycle and its relationship to the chapters in this book. This chapter covers how Agile techniques can be helpful when enhancing legacy apps."
    ]
  },
  {
    "id": "sec_0388",
    "title": "9.1 What Makes Code Legacy and How Can Agile Help?",
    "pages": [
      282,
      283,
      284,
      285
    ],
    "text_blocks": [
      "1. Continuing Change: [software] systems must be continually adapted or they become progressively less satisfactory \u2014Lehman\u2019s \ufb01rst law of software evolution. As Chapter 1 explained, legacy code stays in use because it still meets a customer need, even though its design or implementation may be outdated or poorly understood. In this chapter we will show not only how to explore and come to understand a legacy codebase, but also how to apply Agile techniques to enhance and modify legacy code. Figure 9.1 highlights this topic in the context of the overall Agile lifecycle. Maintainability is the ease with which a product can be improved. In software engineer- ing, maintenance consists of four categories (Lientz et al. 1978): \u2022 Corrective maintenance: repairing defects and bugs \u2022 Perfective maintenance: expanding the software\u2019s functionality to meet new customer requirements \u2022 Adaptive maintenance: coping with a changing operational environment even if no new functionality is added; for example, adapting to changes in the production hosting environment \u2022 Preventive maintenance: improving the software\u2019s structure to increase future main- tainability 9.1. WHAT MAKES CODE \u201cLEGACY\u201d AND HOW CAN AGILE HELP? 271 Highly-readable unit, functional and integration tests (Chapter 8) Lo-\ufb01 UI mockups and Cucumber-style user stories (Chapter 7) Photos of whiteboard sketches about the application architecture, class relationships, etc. (Section 9.2) Git commit log messages (Chapter 10) Comments and RDoc-style documentation embedded in the code (Section 9.4) Archived email, wiki/blog, notes, or video recordings of code and design reviews, for example in Camp\ufb01re1 or Basecamp2 (Chapter 10) Figure 9.2: While up-to-date formal design documents are valuable, Agile suggests we should place relatively more value on documentation that is \u201ccloser to\u201d the working code. Practicing these kinds of maintenance on legacy code is a skill learned by doing: we will provide a variety of techniques you can use, but there is no substitute for mileage. That said, a key component of all these maintenance activities is refactoring , a process that changes the structure of code (hopefully improving it) without changing the code\u2019s functionality. The message of this chapter is that continuous refactoring improves maintainability. Therefore, a large part of this chapter will focus on refactoring. Any piece of software, however well-designed, can eventually evolve beyond what its original design can accommodate. This process leads to maintainability challenges, one of which is the challenge of working with legacy code. Some developers use the term \u201clegacy\u201d when the resulting code is poorly understood because the original designers are long gone and the software has accumulated many patches not explained by any current design doc- uments. A more jaded view, shared by some experienced practitioners (Glass 2002), is that such documents wouldn\u2019t be very useful anyway. Once development starts, necessary design changes cause the system to drift away from the original design documents, which don\u2019t get updated. In such cases developers must rely on informal design documents such as those that Figure 9.2 lists. How can we enhance legacy software without good documentation? As Michael Feathers writes in Working Effectively With Legacy Code (Feathers 2004), there are two ways to make changes to existing software: Edit and Pray or Cover and Modify. The \ufb01rst method is sadly all too common: familiarize yourself with some small part of the software where you have to make your changes, edit the code, poke around manually to see if you broke anything (though it\u2019s hard to be certain), then deploy and pray for the best. In contrast, Cover and Modify calls for creating tests (if they don\u2019t already exist) that cover the code you\u2019re going to modify and using them as a \u201csafety net\u201d to detect unintended behavioral changes caused by your modi\ufb01cations, just as regression tests detect failures in code that used to work. The cover and modify point of view leads to Feathers\u2019s more precise de\ufb01nition of \u201clegacy code\u201d, which we will use: code that lacks suf\ufb01cient tests to modify with con\ufb01dence, regardless of who wrote it and when. In other words, code that you wrote three months ago on a different project and must now revisit and modify might as well be legacy code. Happily, the Agile techniques we\u2019ve already learned for developing new software can also help with legacy code. Indeed, the task of understanding and evolving legacy software can be seen as an example of \u201cembracing change\u201d over longer timescales. If we inherit well-structured software with thorough tests, we can use BDD and TDD to drive addition of functionality in small but con\ufb01dent steps. If we inherit poorly-structured or undertested code, we need to \u201cbootstrap\u201d ourselves into the desired situation in four steps: 272 CHAPTER 9. LEGACY, REFACTORING, AND AGILE 1. Identify the change points, or places where you will need to make changes in the legacy system. Section 9.2 describes some exploration techniques that can help, and intro- duces one type of Uni\ufb01ed Modeling Language (UML) diagram for representing the relationships among the main classes in an application. 2. If necessary, add characterization tests that capture how the code works now, to establish a baseline \u201cground truth\u201d before making any changes. Section 9.3 explains what these tests are and how to create them using tools you\u2019re already familiar with. 3. Determine whether the change points require refactoring to make the existing code more testable or to accommodate the required changes, for example, by breaking de- pendencies that make the code hard to test. Section 9.6 introduces a few of the most widely-used techniques from the many catalogs of refactorings that have evolved as part of the Agile movement. 4. Once the code around the change points is well factored and well covered by tests, make the required changes, using your newly-created tests as regressions and adding tests for your new code as in Chapters 7 and 8. Summary of how Agile can help legacy code: \u2022 Maintainability is the ease with which software can be enhanced, adapted to a chang- ing operating environment, repaired, or improved to facilitate future maintenance. A key part of software maintenance is refactoring, a central part of the Agile process that improves the structure of software to make it more maintainable. Continuous refactoring therefore improves software maintainability. \u2022 Working with legacy code begins with exploration to understand the code base, and in particular to understand the code at the change points where we expect to make changes. \u2022 Without good test coverage, we lack con\ufb01dence that refactoring or enhancing the code will preserve its existing behavior. Therefore, we adopt Feathers\u2019s de\ufb01nition\u2014 \u201cLegacy code is code without tests\u201d\u2014and create characterization tests where neces- sary to beef up test coverage before refactoring or enhancing legacy code. Elaboration: Embedded documentation RDoc is a documentation system that looks for specially formatted comments in Ruby code and generates programmer documentation from them. It is similar to and inspired by JavaDoc. RDoc syntax is easily learned by example and from the Ruby Programming wikibook3. The default HTML output from RDoc can be seen, for example, in the Rails doc- umentation4. Consider adding RDoc documentation as you explore and understand legacy code; running rdoc . (that\u2019s a dot) in the root directory of a Rails app generates RDoc doc- umentation from every .rb \ufb01le in the current directory, rdoc \u2013help shows other options, and rake -T doc in a Rails app directory lists other documentation-related Rake tasks. Self-Check 9.1.1. Why do many software engineers believe that when modifying legacy code, good test coverage is more important than detailed design documents or well-structured 9.2. EXPLORING A LEGACY CODEBASE 273 code? Without tests, you cannot be con\ufb01dent that your changes to the legacy code preserve its existing behaviors."
    ]
  },
  {
    "id": "sec_0389",
    "title": "9.2 Exploring a Legacy Codebase",
    "pages": [
      285,
      286,
      287,
      288,
      289
    ],
    "text_blocks": [
      "If you\u2019ve chosen the right data structures and organized things well, the algorithms will almost always be self-evident. Data structures, not algorithms, are central to program- ming. \u2014Rob Pike The goal of exploration is to understand the app from both the customers\u2019 and the de- velopers\u2019 point of view. The speci\ufb01c techniques you use may depend on your immediate aims: \u2022 You\u2019re brand new to the project and need to understand the app\u2019s overall architecture, documenting as you go so others don\u2019t have to repeat your discovery process. \u2022 You need to understand just the moving parts that would be affected by a speci\ufb01c change you\u2019ve been asked to make. \u2022 You\u2019re looking for areas that need beauti\ufb01cation because you\u2019re in the process of port- ing or otherwise updating a legacy codebase. We can follow some \u201coutside-in\u201d steps to understand the structure of a legacy app at various levels: 1. Check out a scratch branch to run the app in a development environment 2. Learn and replicate the user stories, working with other stakeholders if necessary 3. Examine the database schema and the relationships among the most important classes 4. Skim all the code to quantify code quality and test coverage Since operating on the live app could endanger customer data or the user experience, the \ufb01rst step is to get the application running in a development or staging environment in which perturbing its operation causes no inconvenience to users. Create a scratch branch of the repo that will never be merged with the mainline code and can therefore be used for experimentation. Create a development database if there isn\u2019t an existing one used for development. An easy way to do this is to clone the production database if it isn\u2019t too large, thereby sidestepping numerous pitfalls: \u2022 The app may have relationships such as has-many or belongs-to that are re\ufb02ected in the table rows. Without knowing the details of these relationships, you might create an in- valid subset of data. Using RottenPotatoes as an example, you might inadvertently end up with a review whose movie_id and moviegoer_id refer to nonexistent movies or moviegoers. 274 CHAPTER 9. LEGACY, REFACTORING, AND AGILE https://gist.github.com/617ca988e1425a36dc84e6e973554d1c 1 2 3 4 5 6 7 8 # on production computer : RAILS_ENV = production rake db : schema : dump RAILS_ENV = production rake db : fixtures : extract # copy db / schema . rb and test / fixtures /*. yml to development computer # then , on development computer : rake db : create rake db : schema : load rake db : fixtures : load # uses RAILS_ENV = development by default Figure 9.3: You can create an empty development database that has the same schema as the production database and then populate it with \ufb01xtures. Although Chapter 8 cautions against the abuse of \ufb01xtures, in this case we are using them to replicate known behavior from the production environment in your development environment. \u2022 Cloning the database eliminates possible differences in behavior between production and development resulting from differences in database implementations, differences in how certain data types such as dates are represented in different databases, and so on. \u2022 Cloning gives you realistic valid data to work with in development. If you can\u2019t clone the production database, or you have successfully cloned it but it\u2019s too unwieldy to use in development all the time, you can create a development database by extracting \ufb01xture data from the real database5 using the steps in Figure 9.3. Once the app is running in development, have one or two experienced customers demon- strate how they use the app, indicating during the demo what changes they have in mind (Nierstrasz et al. 2009). Ask them to talk through the demo as they go; although their com- ments will often be in terms of the user experience (\u201cNow I\u2019m adding Mona as an admin user\u201d), if the app was created using BDD, the comments may re\ufb02ect examples of the original user stories and therefore the app\u2019s architecture. Ask frequent questions during the demo, and if the maintainers of the app are available, have them observe the demo as well. In Sec- tion 9.3 we will see how these demos can form the basis of \u201cground truth\u201d tests to underpin your changes. Once you have an idea of how the app works, take a look at the database schema; Fred Brooks, Rob Pike, and others have all acknowledged the importance of understanding the data structures as a key to understanding the app logic. You can use an interactive database GUI to explore the schema, but you might \ufb01nd it more ef\ufb01cient to run rake db:schema:dump, which creates a \ufb01le db/schema.rb containing the database schema in the migrations DSL introduced in Section 4.2. The goal is to match up the schema with the app\u2019s overall archi- tecture. Figure 9.4 shows a simpli\ufb01ed Uni\ufb01ed Modeling Language (UML) class diagram gener- ated by the railroady gem that captures the relationships among the most important classes and the most important attributes of those classes. While the diagram may look overwhelm- ing initially, since not all classes play an equally important structural role, you can identify \u201chighly connected\u201d classes that are probably central to the application\u2019s functions. For ex- ample, in Figure 9.4, the Customer and Voucher classes are connected to each other and to many other classes. You can then identify the tables corresponding to these classes in the database schema. Having familiarized yourself with the app\u2019s architecture, most important data structures, and major classes, you are ready to look at the code. The goal of inspecting the code is to get a sense of its overall quality, test coverage, and other statistics that serve as a proxy for 9.2. EXPLORING A LEGACY CODEBASE 275 Figure 9.4: This simpli\ufb01ed Uni\ufb01ed Modeling Language (UML) class diagram, produced automatically by the railroady gem, shows the models in a Rails app that manages ticket sales, donations, and performance attendance for a small theater. Edges with arrowheads or circles show relationships between classes: a Customer has many Visits and Vouchers (open circle to arrowhead), has one most_recent_visit (solid circle to arrowhead), and has and belongs to many Labels (arrowhead to arrowhead). Plain edges show inheritance: Donation and Voucher are subclasses of Item. (All of the important classes here inherit from ActiveRecord::Base, but railroady draws only the app\u2019s classes.) We will see other types of UML diagrams in Chapter 11. how painful it may be to understand and modify. Therefore, before diving into any speci\ufb01c \ufb01le, run rake stats to get the total number of lines of code and lines of tests for each \ufb01le; this information can tell you which classes are most complex and therefore probably most important (highest LOC), best tested (best code-to-test ratio), simple \u201chelper\u201d classes (low LOC), and so on, deepening the understanding you bootstrapped from the class diagram and database schema. (Later in this chapter we\u2019ll show how to evaluate code with some additional quality metrics to give you a heads up of where the hairiest efforts might be.) If test suites exist, run them; assuming most tests pass, read the tests to help understand the original developers\u2019 intentions. Then spend one hour (Nierstrasz et al. 2009) inspecting the code in the most important classes as well as those you believe you\u2019ll need to modify (the change points), which by now you should be getting a good sense of. Summary of legacy code exploration: \u2022 The goal of exploration is to understand how the app works from multiple stakehold- ers\u2019 points of view, including the customer requesting the changes and the designers and developers who created the original code. \u2022 Exploration can be aided by reading tests, reading design documents if available, inspecting the code, and drawing or generating UML class diagrams to identify relationships among important entities (classes) in the app. \u2022 Once you have successfully seen the app demonstrated in production, the next steps are to get it running in development by either cloning or \ufb01xturing the database and to get the test suite running in development. 276 CHAPTER 9. LEGACY, REFACTORING, AND AGILE Figure 9.5: A 3-by-5 inch (or A7 size) Class\u2013Responsibility\u2013Collaborator (CRC) card representing the Voucher class from Figure 9.4. The left column represents Voucher\u2019s responsibilities\u2014things it knows (instance variables) or does (instance methods). Since Ruby instance variables are always accessed through instance methods, we can determine responsibilities by searching the class \ufb01le voucher.rb for instance methods and calls to attr_accessor. The right column represents Voucher\u2019s collaborator classes; for Rails apps we can determine many of these by looking for has_many and belongs_to in voucher.rb. 9.3. ESTABLISHING GROUND TRUTH WITH CHARACTERIZATION TESTS 277 Elaboration: Class\u2013Responsibility\u2013Collaborator (CRC) cards CRC cards (Figure 9.5) were proposed in 19896 as a way to help with object-oriented design. Each card identi\ufb01es one class, its responsibilities, and collaborator classes with which it interacts to complete tasks. As this external screencast7 shows, a team designing new code selects a user story (Section 7.1). For each story step, the team identi\ufb01es or creates the CRC card(s) for the classes that participate in that step and con\ufb01rms that the classes have the necessary Responsibilities and Collaborators to complete the step. If not, the collection of classes or responsibilities may be incomplete, or the division of responsibilities among classes may need to be changed. When exploring legacy code, you can create CRC cards to document the classes you \ufb01nd while following the \ufb02ow from the controller action that handles a user story step through the models and views involved in the other story steps. Self-Check 9.2.1. What are some reasons it is important to get the app running in develop- ment even if you don\u2019t plan to make any code changes right away? A few reasons include: 1. For SaaS, the existing tests may need access to a test database, which may not be accessible in production. 2. Part of your exploration might involve the use of an interactive debugger or other tools that could slow down execution, which would be disruptive on the live site. 3. For part of your exploration you might want to modify data in the database, which you can\u2019t do with live customer data."
    ]
  },
  {
    "id": "sec_0390",
    "title": "9.3 Establishing Ground Truth With Characterization Tests",
    "pages": [
      289,
      290,
      291
    ],
    "text_blocks": [
      "If there are no tests (or too few tests) covering the parts of the code affected by your planned changes, you\u2019ll need to create some tests. How do you do this given limited understanding of how the code works now? One way to start is to establish a baseline for \u201cground truth\u201d by creating characterization tests: tests written after the fact that capture and describe the actual, current behavior of a piece of software, even if that behavior has bugs. By creating a Repeatable automatic test (see Section 8.1) that mimics what the code does right now, you can ensure that those behaviors stay the same as you modify and enhance the code, like a high-level regression test. It\u2019s often easiest to start with an integration-level characterization test such as a Cucumber scenario, since these make the fewest assumptions about how the app works and focus only on the user experience. Indeed, while good scenarios ultimately make use of a \u201cdomain language\u201d rather than describing detailed user interactions in imperative steps (Section 7.8), at this point it\u2019s \ufb01ne to start with imperative scenarios, since the goal is to increase coverage and provide ground truth from which to create more detailed tests. Once you have some green integration tests, you can turn your attention to unit- or functional-level tests, just as TDD follows BDD in the outside-in Agile cycle. Whereas integration-level characterization tests just capture behaviors that we observe without requiring us to understand how those behaviors happen, a unit-level characterization 278 CHAPTER 9. LEGACY, REFACTORING, AND AGILE if ( y % 400 == 0 || def self . convert ( d ) ( y % 4 == 0 && y % 100 != 0) ) y = 1980 while ( d > 365) do # WARNING ! This code has a bug ! See text ! class TimeSetter https://gist.github.com/b44d2059ebcccd4a1d45111884ba350b 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 if ( d > 366) d -= 366 y += 1 end return y d -= 365 y += 1 else end end end end Figure 9.6: This method is hard to understand, hard to test, and therefore, by Feathers\u2019s de\ufb01nition of legacy code, hard to modify. In fact, it contains a bug\u2014this example is a simpli\ufb01ed version of a bug in the Microsoft Zune music player that caused any Zune booted on December 31, 2008, to freeze permanently, and for which the only resolution was to wait until the \ufb01rst minute of January 1, 2009, before rebooting. require ' simplecov ' SimpleCov . start require ' ./ time_setter ' describe TimeSetter do https://gist.github.com/ca621c822bd39c51e7d6aa27f783bbbe 1 2 3 4 5 6 7 8 9 10 it \" #{ arg } days puts us in #{ result } \" do end end end expect ( TimeSetter . convert ( arg ) ) . to eq ( result ) { 365 = > 1980 , 366 = > 1981 , 900 = > 1982 }. each_pair do | arg , result | Figure 9.7: This simple spec, resulting from the reverse-engineering technique of creating characterization tests achieves 100% C0 coverage and helps us \ufb01nd a bug in Figure 9.6. test seems to require us to understand the implementation. For example, consider the code in Figure 9.6. As we\u2019ll discuss in detail in the next section, it has many problems, not least of which is that it contains a bug. The method convert calculates the current year given a starting year (in this case 1980) and the number of days elapsed since January 1 of that year. If 0 days have elapsed, then it is January 1, 1980; if 365 days have elapsed, it is December 31, 1980, since 1980 was a leap year; if 366 days have elapsed, it is January 1, 1981; and so on. How would we create unit tests for convert without understanding the method\u2019s logic in detail? Feathers describes a useful technique for \u201creverse engineering\u201d specs from a piece of code we don\u2019t yet understand: create a spec with an assertion that we know will probably fail, run the spec, and use the information in the error message to change the spec to match actual behavior. Essentially, we create specs that assert incorrect results, then \ufb01x the specs based on the actual test behavior. Our goal is to capture the current behavior as completely as possible so that we\u2019ll immediately know if code changes break the current behavior, so we aim for 100% C0 coverage (even though that\u2019s no guarantee of bug-freedom!), which is challenging because the code as presented has no seams. Doing this for convert results in 9.4. COMMENTS AND COMMITS: DOCUMENTING CODE 279 the specs in Figure 9.7 and even \ufb01nds a bug in the process! Screencast 9.3.1: Creating characterization specs for TimeSetter. http://youtu.be/8QwvqtMp5QM We create specs that assert incorrect results, then \ufb01x them based on the actual test behavior. Our goal is to capture the current behavior as completely as possible so that we\u2019ll immedi- ately know if code changes break the current behavior, so we aim for 100% C0 coverage (even though that\u2019s no guarantee of bug-freedom!), which is challenging because the code as presented has no seams. Our effort results in \ufb01nding a bug that crippled thousands of Microsoft Zune players on December 31, 2008. Summary of characterization tests: \u2022 To Cover and Modify when we lack tests, we \ufb01rst create characterization tests that capture how the code works now. \u2022 Integration-level characterization tests, such as Cucumber scenarios, are often easier to start with since they only capture externally visible app behavior. \u2022 To create unit- and functional-level characterization tests for code we don\u2019t fully understand, we can write a spec that asserts an incorrect result, \ufb01x the assertion based on the error message, and repeat until we have suf\ufb01cient coverage. Elaboration: What about specs that should pass, but don\u2019t? If the test suite is out-of-date, some tests may be failing red. Rather than trying to \ufb01x the tests before you understand the code, mark them as \u201cpending\u201d (for example, using RSpec\u2019s pending method) with a comment that reminds you to come back to them later to \ufb01nd out why they fail. Stick to the current task of preserving existing functionality while improving coverage, and don\u2019t get distracted trying to \ufb01x bugs along the way. Self-Check 9.3.1. State whether each of the following is a goal of unit and functional testing, a goal of characterization testing, or both: i Improve coverage ii Test boundary conditions and corner cases iii Document intent and behavior of app code iv Prevent regressions (reintroduction of earlier bugs) (i) and (iii) are goals of unit, functional, and characterization testing. (ii) and (iv) are goals of unit and functional testing, but non-goals of characterization testing."
    ]
  },
  {
    "id": "sec_0391",
    "title": "9.4 Comments and Commits: Documenting Code",
    "pages": [
      291,
      292,
      293
    ],
    "text_blocks": [
      "Not only does legacy code often lack tests and good documentation, but its comments are often missing or inconsistent with the code. We now offer a brief sermon on comments, so 280 CHAPTER 9. LEGACY, REFACTORING, AND AGILE # Add one to i . i += 1 # Lock to protect against concurrent access . mutex = SpinLock . new https://gist.github.com/c350c1632f0e9fa7ca47c0c208cc9e8f 1 2 3 4 5 6 7 8 9 10 # This method swaps the panels . def swap_panels ( panel_1 , panel_2 ) # ... end Figure 9.8: Examples of bad comments, which state the obvious. You\u2019d be surprised how often comments just mimic code even in otherwise well-written apps. (Thanks to John Ousterhout for these examples and some of this advice on comments.) # Good Comment : # Scan the array to see if the symbol exists https://gist.github.com/f537017d1909733bbde757ea3abe951a 1 2 3 4 5 6 7 8 9 # Much better than : # Loop through every array index , get the # third value of the list in the content to # determine if it has the symbol we are looking # for . Set the result to the symbol if we # find it . Figure 9.9: Example of comments that raises the level of abstraction compared to comments that describe how you implement it. that once you write successful characterization tests you can capture what you\u2019ve learned by adding comments to the legacy code. Good comments have two properties: 1. They document things that aren\u2019t obvious from the code. 2. They are expressed at a higher level of abstraction than the code. Figure 9.8 shows examples of comments that violate both properties, and Figure 9.9 shows a better example. First, if you write comments as you code, much of what your code does is surely obvious to you, since you just wrote it. (Alas, not commenting as you go is a common defect of legacy code.) But if you or someone else reads your code later, long after you\u2019ve forgotten those design ideas, comments should help you remember the non-obvious reasons you wrote the code the way you did. Examples of non-obvious things include the units for variables, code invariants, subtle problems that required a particular implementation, or unusual code that is there solely to work around some bug or account for a non-obvious boundary condition or corner case. In the case of legacy code, you are trying to add comments to document what went through another programmer\u2019s mind; once you \ufb01gure it out, be sure to write it down before you forget! Second, comments should raise the level of abstraction from the code. The programmer\u2019s goal is to write classes and other code that hides complexity; that is, to make it easier for oth- ers to use this existing code rather than re-create it themselves. Comments should therefore address concerns such as: What do I need to know to invoke this method? Are there precon- ditions, assumptions, or caveats? Among other jobs, a comment should provide enough of this information that someone who wants to call an existing class or method doesn\u2019t have to read its source code to \ufb01gure these things out. 9.5. METRICS, CODE SMELLS, AND SOFA 281 These guidelines are also generally true for commit messages, which you supply when- ever you commit a set of code changes. However, one important principle is that you shouldn\u2019t put information in a commit message that a future developer will need to know while working on the code. Historical information\u2014why a certain function was deleted or refactored, for example\u2014is appropriate for including in a commit message. But information that a developer would need to know to use the code as it exists now should be in a comment, where the developer cannot fail to see it when they go to edit the code. As with many other elements of Agile, when a process isn\u2019t working smoothly, it\u2019s trying to tell you something about your code. For example, we saw in Chapter 8 that when a test is hard to write due to the need for extensive mocking and stubbing, the test is trying to tell you that your code is not testable because it\u2019s poorly factored. Similarly here: if following the above guideline about comments vs. commits means you \ufb01nd yourself writing lots of cautionary caveats in the comments, your code is telling you that it might bene\ufb01t from a refactoring cleanup so that you wouldn\u2019t need to post so many warning signs for the next developer who comes along with the intention of modifying it. While virtually every other software engineering sermon in this book is paired with a tool that makes it easy for you to stay on the true path and for others to check if you have strayed, this is not the case for comments and commit messages. The only enforcement mechanism beyond self-discipline is inspection, which we discuss in Sections 10.4 and 10.7. Summary of comments: \u2022 Comments are best written at the same time as the code, not as an afterthought. \u2022 Comments should not repeat what is obvious from the code. They should explain why the code is written the way it is, rather than simply repeating what it does. \u2022 Comments should raise the level of abstraction from the code, describing what a logical block of code does rather than providing line-by-line details. \u2022 Commits should include historical information about why the code is the way it is, but information that developers need while using the current code belongs in comments. If this leads to too many comments, your code may need cleanup. Self-Check 9.4.1. True or False: One reason legacy code is long lasting is because it typi- cally has good comments. False. We wish it were true. Comments are often missing or inconsistent with the code, which is one reason it is called legacy code rather than beautiful code."
    ]
  },
  {
    "id": "sec_0392",
    "title": "9.5 Metrics, Code Smells, and SOFA",
    "pages": [
      293,
      294,
      295,
      296,
      297,
      298
    ],
    "text_blocks": [
      "7. Declining Quality - The quality of [software] systems will appear to be declining unless they are rigorously maintained and adapted to operational environment changes. \u2014Lehman\u2019s seventh law of software evolution A key theme of this book is that engineering software is about creating not just working code, but beautiful working code. This chapter should make clear why we believe this: beau- tiful code is easier and less expensive to maintain. Given that software can live much longer 282 CHAPTER 9. LEGACY, REFACTORING, AND AGILE Figure 9.10: The node numbers in this control \ufb02ow graph correspond to line numbers in Figure 9.6. Cyclomatic complexity is E \u2212 N + 2P where E is the number of edges, N the number of nodes, and P the number of connected components. convert scores a cyclomatic complexity of 4 as measured by saikuro and an ABC score (Assignments, Branches, Conditionals) of 23 as measured by flog. Figure 9.11 puts these scores in context. than hardware, even engineers whose aesthetic sensibilities aren\u2019t moved by the idea of beau- tiful code can appreciate the practical economic advantage of reducing lifetime maintenance costs. How can you tell when code is less than beautiful, and how do you improve it? We\u2019ve all seen examples of code that\u2019s less than beautiful, even if we can\u2019t always pin down the speci\ufb01c problems. We can identify problems in two ways: quantitatively using software metrics and qualitatively using code smells. Both are useful and tell us different things about the code, and we apply both to the ugly code in Figure 9.6. Software metrics are quantitative measurements of code complexity, which is often an estimate of the dif\ufb01culty of thoroughly testing a piece of code. Dozens of metrics exist, and opinion varies widely on their usefulness, effectiveness, and \u201cnormal range\u201d of values. Most metrics are based on the control \ufb02ow graph of the program, in which each graph node represents a basic block (a set of statements that are always executed together), and an edge from node A to node B means that there is some code path in which B\u2019s basic block is executed immediately after A\u2019s. Figure 9.10 shows the control \ufb02ow graph corresponding to Figure 9.6, which we can use to compute two widely-used indicators of method-level complexity: Plan-and-Document software projects sometimes include speci\ufb01c contractual requirements based on software metrics. Software engineer Frank McCabe Sr. invented the cyclomatic complexity metric in 1976. 1. Cyclomatic complexity measures the number of linearly-independent paths through a piece of code. 2. ABC score is a weighted sum of the number of Assignments, Branches and Conditionals in a piece of code. These analyses are usually performed on source code and were originally developed for statically-typed languages. In dynamic languages, the analyses are complicated by metapro- gramming and other mechanisms that may cause changes to the control \ufb02ow graph at run- time. Nonetheless, they are useful \ufb01rst-order metrics, and as you might expect, the Ruby community has developed tools to measure them. saikuro computes a simpli\ufb01ed version of cyclomatic complexity and flog computes a variant of the ABC score that is weighted in a way appropriate for Ruby idioms. Both of these and more are included in the metric_fu gem (part of the courseware). Running rake metrics on a Rails app computes various met- rics including these, and highlights parts of the code in which multiple metrics are outside their recommended ranges. In addition, CodeClimate8 provides many of these metrics as a service: by creating an account there and linking your GitHub repository to it, you can view a \u201creport card\u201d of your code metrics anytime, and the report is automatically updated when 9.5. METRICS, CODE SMELLS, AND SOFA 283 Metric Code-to-test ratio C0 coverage ABC score Cyclomatic Target score Tool \u2264 1 : 2 rake stats \u2265 90% SimpleCov < 20/method flog (rake metrics) saikuro (rake metrics) < 10/method Book Reference Section 8.7 Section 8.7 Section 9.5 Section 9.5 Figure 9.11: A summary of useful metrics we\u2019ve seen so far that highlight the connection between beauty and testability, including Ruby tools that compute them and suggested \u201cnormal\u201d ranges. (The recommended value for cyclomatic complexity comes from NIST, the U.S. National Institute of Standards and Technologies.) The metric_fu gem includes flog, saikuro, and additional tools for computing metrics we\u2019ll meet in Chapter 11. Name Shotgun Surgery Data Clump Inappropriate Intimacy Symptom Making a small change to a class or method results in lots of little changes rippling to other classes or methods. The same three or four data items seem to often be passed as arguments together or manipulated to- gether. One class exploits too much knowledge about the implementation (methods or attributes) of another. Repetitive Boilerplate You have bits of code that are the same or nearly the same in various different places (non-DRY). Possible refactorings Use Move Method or Move Field to bring all the data or behaviors into a single place. Use Extract Class or Preserve Whole Object to cre- ate a class that groups the data together, and pass around instances of that class. Use Move Method or Move Field if the meth- ods really need to be somewhere else, use Extract Class if there is true overlap between two classes, or introduce a Delegate to hide the implementa- tion. Use Extract Method to pull redundant code into its own method that the repetitive places can call. In Ruby, you can even use yield to extract the \u201cenclosing\u201d code and having it yield back to the non-repetitive code. Figure 9.12: Four whimsically-named code smells from Fowler\u2019s list of 22, along with the refactorings (some of which we\u2019ll meet in the next section) that might remedy the smell if applied. Refer to Fowler\u2019s book for the refactorings mentioned in the table but not introduced in this book. you push new code to GitHub. Figure 9.11 summarizes useful metrics we\u2019ve seen so far that speak to testability and therefore to code beauty. The second way to spot code problems is by looking for code smells, which are struc- tural characteristics of source code not readily captured by metrics. Like real smells, code smells call our attention to places that may be problematic. Martin Fowler\u2019s classic book on refactoring (Fowler et al. 1999) lists 22 code smells, four of which we show in Figure 9.12, and Robert C. Martin\u2019s Clean Code (Martin 2008) has one of the more comprehensive cat- alogs with an amazing 63 code smells, of which three are speci\ufb01c to Java, nine are about testing, and the remainder are more general. Four particular smells that appear in Martin\u2019s Clean Code are worth emphasizing, because they are symptoms of other problems that you can often \ufb01x by simple refactorings. These four are identi\ufb01ed by the acronym SOFA, which states that a well-written method should: \u2022 be Short, so that its main purpose is quickly grasped; \u2022 do only One thing, so testing can focus on thoroughly exercising that one thing; \u2022 take Few arguments, so that all-important combinations of argument values can be tested; Design smells (see Chapter 11) tell us when something\u2019s wrong in the way classes interact, rather than within the methods of a speci\ufb01c class. 284 CHAPTER 9. LEGACY, REFACTORING, AND AGILE What Variable or class name Method with side effects Method that returns a value Boolean variable or method Adjective phrase Guideline Noun phrase Verb phrase Noun phrase Example PopularMovie, top_movies pay_for_order, charge_credit_card! movie.producers, actor_list already_rated?, @is_oscar_winner Figure 9.13: variable-naming guidelines based on simple English, excerpted from Green and Ledgard 2011. Given that disk space is free and modern editors have auto-completion that saves you retyping the full name, your colleagues will thank you for writing @is_oscar_winner instead of OsWin. start with Year = 1980 while ( days remaining > 365) https://gist.github.com/2183dec77d51a632f93923c6c3946fe6 1 2 3 4 5 6 7 peel off 365 days and advance Year by 1 if Year is a leap year return Year else then if possible , peel off 366 days and advance Year by 1 Figure 9.14: The computation of the current year given the number of days since the beginning of a start year (1980) is much more clear when written in pseudocode. Notice that what the method does is quick to grasp, even though each step would have to be broken down into more detail when turned into code. We will refactor the Ruby code to match the clarity and conciseness of this pseudocode. \u2022 maintain a consistent level of Abstraction, so that it doesn\u2019t jump back and forth be- tween saying what to do and saying how to do it. Figure 9.6 violates at least the \ufb01rst and last of these, and exhibits other smells as well, as time_setter . rb -- 5 warnings : we can see by running reek on it: https://gist.github.com/223f7e7b28b390b650dd196f80048a2f 1 2 3 4 5 6 TimeSetter # self . convert calls ( y + 1) twice ( Duplication ) TimeSetter # self . convert has approx 6 statements ( LongMethod ) TimeSetter # self . convert has the parameter name 'd ' ( U n c o m m u n i ca t i v e N a m e ) TimeSetter # self . convert has the variable name 'd ' ( U n c o m m u n i ca t i v e N a m e ) TimeSetter # self . convert has the variable name 'y ' ( U n c o m m u n i ca t i v e N a m e ) Not DRY (line 2). Admittedly this is only a minor duplication, but as with any smell, it\u2019s worth asking ourselves why the code turned out that way. Uncommunicative names (lines 4\u20136). Variable y appears to be an integer (lines 6, 7, 10, 14) and is related to another variable d\u2014what could those be? For that matter, what does the class TimeSetter set the time to, and what is being converted to what in convert? Four decades ago, memory was precious and so variable names were kept short to allow more space for code. Today, there\u2019s no excuse for poor variable names; Figure 9.13 provides suggestions. Too long (line 3). More lines of code per method means more places for bugs to hide, more paths to test, and more mocking and stubbing during testing. However, excessive length is really a symptom that emerges from more speci\ufb01c problems\u2014in this case, failure to stick to a single level of Abstraction. As Figure 9.14 shows, convert really consists of a small number of high-level steps, each of which could be divided into sub-steps. But in the code, there is no way to tell where the boundaries of steps or sub-steps would be, making the method harder to understand. Indeed, the nested conditional in lines 6\u20138 makes it hard for a programmer to mentally \u201cwalk through\u201d the code, and complicates testing since you have to select sets of test cases that exercise each possible code path. The ancient wisdom that a method shouldn\u2019t exceed one screenful of code was based on text-only terminals with 24 lines of 80 characters. A modern 22-inch monitor shows 10 times that much, so guidelines like SOFA are more reliable today. 9.5. METRICS, CODE SMELLS, AND SOFA 285 As a result of these de\ufb01ciencies, you probably had to work hard to \ufb01gure out what this relatively simple method does. (You might blame this on a lack of comments in the code, but once the above smells are \ufb01xed, there will be hardly any need for them.) Astute readers usually note the constants 1980, 365, and 366, and infer that the method has something to do with leap years and that 1980 is special. In fact, convert calculates the current year given a starting year of 1980 and the number of days elapsed since January 1 of that year, as Figure 9.14 shows using simple pseudocode. In Section 9.5, we will make the Ruby code as transparent as the pseudocode by refactoring it\u2014applying transformations that improve its structure without changing its behavior. A few speci\ufb01c examples of doing one thing are worth calling out because they occur frequently: \u2022 Handling an exception is one thing. If method M computes something and also tries to handle various exceptions that could arise while doing so, consider splitting out a method M that just does the work, and having M do exception handling and delegate the \u201creal\u201d work to M . \u2022 Queries (computing something) and commands (doing something that causes a side effect) are distinct, so a method should either compute something that is side-effect- free or it should cause a speci\ufb01c side effect, but not both. Such violations of command\u2013 query separation also complicate testing. Summary \u2022 Software metrics provide a quantitative measure of code quality. While opinion varies on which metrics are most useful and what their \u201cnormal\u201d values should be (especially in dynamic languages such as Ruby), metrics such as cyclomatic com- plexity and ABC score can be used to guide your search toward code that is in particular need of attention, just as low C0 coverage identi\ufb01es undertested code. \u2022 Code smells provide qualitative but speci\ufb01c descriptions of problems that make code hard to read. Depending on which catalog you use, over 60 speci\ufb01c code smells have been identi\ufb01ed. \u2022 The acronym SOFA names four desirable properties of a method: it should be Short, do One thing, have Few arguments, and maintain a single level of Abstraction. Self-Check 9.5.1. Give an example of a dynamic language feature in Ruby that could distort metrics such as cyclomatic complexity or ABC score. Any metaprogramming mechanism could do this.",
      "A trivial example is s=\"if (d>=366)[. . . ]\"; eval s, since the evaluation of the string would cause a conditional to be executed even though there\u2019s no conditional in the code itself, which contains only an assignment to a variable and a call to the eval method. A subtler example is a method such as before_filter (Section 5.1), which essentially adds a new method to a list of methods to be called before a controller action. 286 CHAPTER 9. LEGACY, REFACTORING, AND AGILE Self-Check 9.5.2. Which SOFA guideline\u2014be Short, do One thing, have Few arguments, stick to a single level of Abstraction\u2014do you think is most important from a unit-testability point of view? Few arguments implies fewer ways that code paths in the method can depend on the arguments, making testing more tractable. Short methods are certainly easier to test, but this property usually follows when the other three are observed."
    ]
  },
  {
    "id": "sec_0393",
    "title": "9.6 Method-Level Refactoring: Replacing Dependencies With Seams",
    "pages": [
      298
    ],
    "text_blocks": [
      "2. Increasing Complexity - As [a software] system evolves, its complexity increases unless work is done to maintain or reduce it. \u2014Lehman\u2019s second law of software evolution With the characterization specs developed in Section 9.3, we have a solid foundation on which to base our refactoring to repair the problems identi\ufb01ed in Section 9.5. The term refactoring refers not only to a general process, but also to an instance of a speci\ufb01c code transformation. Thus, just as with code smells, we speak of a catalog of refactorings, and there are many such catalogs to choose from. We prefer Fowler\u2019s catalog, so the examples in this chapter follow Fowler\u2019s terminology and are cross-referenced to Chapters 6, 8, 9, and"
    ]
  },
  {
    "id": "sec_0394",
    "title": "10 of his book Refactoring: Ruby Edition (Fields et al. 2009). While the correspondence",
    "pages": [
      298,
      299,
      300,
      301,
      302,
      303,
      304
    ],
    "text_blocks": [
      "between code smells and refactorings is not perfect, in general each of those chapters de- scribes a group of method-level refactorings that address speci\ufb01c code smells or problems, and further chapters describe refactorings that affect multiple classes, which we\u2019ll learn about in Chapter 11. Each refactoring consists of a descriptive name and a step-by-step process for transform- ing the code via small incremental steps, testing after each step. Most refactorings will cause at least temporary test failures, since unit tests usually depend on implementation, which is exactly what refactoring changes. A key goal of the refactoring process is to minimize the amount of time that tests are failing (red); the idea is that each refactoring step is small enough that adjusting the tests to pass before moving on to the next step is not dif\ufb01cult. If you \ufb01nd that getting from red back to green is harder than expected, you must determine if your understanding of the code was incomplete, or if you have really broken something while refactoring. Getting started with refactoring can seem overwhelming: without knowing what refac- torings exist, it may be hard to decide how to improve a piece of code. Until you have some experience improving pieces of code, it may be hard to understand the explanations of the refactorings or the motivations for when to use them. Don\u2019t be discouraged by this apparent chicken-and-egg problem; like TDD and BDD, what seems overwhelming at \ufb01rst can quickly become familiar. As a start, Figure 9.15 shows four of Fowler\u2019s refactorings that we will apply to our code. In his book, each refactoring is accompanied by an example and an extremely detailed list of mechanical steps for performing the refactoring, in some cases referring to other refactorings that may be necessary in order to apply this one. For example, Figure 9.16 shows the \ufb01rst few steps for applying the Extract Method refactoring. With these examples in mind, we can refactor Figure 9.6. 9.6. METHOD-LEVEL REFACTORING AND SEAMS 287 Name (Chap- ter) Extract method (6) Decompose Conditional (9) Replace Method with Method Object (6) Replace Magic Number with Symbolic Constant (8) Problem Solution You have a code fragment that can be grouped together. You have a complicated conditional (if- then-else) statement. Turn the fragment into a method whose name explains the purpose of the method. Extract methods from the condition, \u201cthen\u201d part, and \u201celse\u201d part(s). You have a long method that uses local variables in such a way that you cannot apply Extract Method. You have a literal number with a partic- ular meaning. Turn the method into its own object so that all the local variables become instance variables on that object. You can then decompose the method into other methods on the same object. Create a constant, name it after the meaning, and re- place the number with it. Figure 9.15: Four example refactorings, with parentheses around the chapter in which each appears in Fowler\u2019s book. Each refactoring has a name, a problem that it solves, and an overview of the code transformation(s) that solve the problem. Fowler\u2019s book also includes detailed mechanics for each refactoring, as Figure 9.16 shows. 1. Create a new method, and name it after the intention of the method (name it by what it does, not by how it does it). If the code you want to extract is very simple, such as a single message or function call, you should extract it if the name of the new method reveals the intention of the code in a better way. If you can\u2019t come up with a more meaningful name, don\u2019t extract the code. 2. Copy the extracted code from the source method into the new target method. 3. Scan the extracted code for references to any variables that are local in scope to the source method. These are local variables and parameters to the method. 4. See whether any temporary variables are used only within this extracted code. If so, declare them in the target method as temporary variables. 5. Look to see whether any of these local-scope variables are modi\ufb01ed by the extracted code. If one variable is modi\ufb01ed, see whether you can treat the extracted code as a query and assign the result to the variable concerned. If this is awkward, or if there is more than one such variable, you can\u2019t extract the method as it stands. You may need to use Split Temporary Variable and try again. You can eliminate temporary variables with Replace Temp with Query (see the discussion in the examples). 6. Pass into the target method as parameters local-scope variables that are read from the extracted method. 7. . . . Figure 9.16: Fowler\u2019s detailed steps for the Extract Method refactoring. In his book, each refactoring is described as a step-by-step code transformation process that may refer to other refactorings. 288 CHAPTER 9. LEGACY, REFACTORING, AND AGILE # NOTE : line 7 fixes bug in original version class TimeSetter end def self . convert ( d ) y = 1980 while ( d > 365) do if leap_year ?( y ) if ( d >= 366) d -= 366 y += 1 https://gist.github.com/44ef9cea09c14d79a37ef43f66168cf7 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 end private def self . leap_year ?( year ) ( year % 4 == 0 && year % 100 != 0) year % 400 == 0 || end return y d -= 365 y += 1 else end end end Figure 9.17: Applying the Extract Method refactoring to lines 6\u20137 of Figure 9.6 makes the conditional\u2019s purpose immediately clear (line 6) by replacing the condition with a well-named method (lines 19\u201322), which we declare private to keep the class\u2019s implementation details well encapsulated. For even more transparency, we could apply Extract Method again to leap_year? by extracting methods every_400_years? and every_4_years_except_centuries?. Long method is the most obvious code smell in Figure 9.6, but that\u2019s just an overall symp- tom to which various speci\ufb01c problems contribute. The high ABC score (23) of convert suggests one place to start focusing our attention: the condition of the if in lines 6\u20137 is dif\ufb01cult to understand, and the conditional is nested two-deep. As Figure 9.15 suggests, a hard-to-read conditional expression can be improved by applying the very common refactor- ing Decompose Conditional, which in turn relies on Extract Method. We move some code into a new method with a descriptive name, as Figure 9.17 shows. Note that in addition to making the conditional more readable, the separate de\ufb01nition of leap_year? makes the leap year calculation separately testable and provides a seam at line 6 where we could stub the method to simplify testing of convert, similar to the example in the Elaboration at the end of Section 8.4. In general, when a method mixes code that says what to do with code that says how to do it, this may be a warning to check whether you need to use Extract Method in order to maintain a consistent level of Abstraction. The conditional is also nested two-deep, making it hard to understand and increasing convert\u2019s ABC score. The Decompose Conditional refactoring also breaks up the complex condition by replacing each arm of the conditional with an extracted method. Notice, though, that the two arms of the conditional correspond to lines 4 and 6 of the pseudocode in Fig- ure 9.14, both of which have the side effects of changing the values of d and y (hence our use of ! in the names of the extracted methods). In order for those side effects to be visible to convert, we must turn the local variables into class variables throughout TimeSetter, giving them more descriptive names @@year and @@days_remaining while we\u2019re at it. Finally, since @@year is now a class variable, we no longer need to pass it as an explicit argument to leap_year?. Figure 9.18 shows the result. As long as we\u2019re cleaning up, the code in Figure 9.18 also \ufb01xes two minor code smells. The \ufb01rst is uncommunicative variable names: convert doesn\u2019t describe very well what 9.6. METHOD-LEVEL REFACTORING AND SEAMS 289 ORIGIN_YEAR = 1980 def self . c a l c u l a t e _ c u r r e n t _ y e a r ( da ys_ sin ce_ ori gin ) end else if leap_year ? p ee l _o f f_ l ea p _y e ar ! p e e l _ o f f _ r e g u l a r _ y e a r ! end return @@year # NOTE : line 7 fixes bug in original version class TimeSetter @@year = ORIGIN_YEAR @ @d ay s_ remaining = d ays _si nc e_o rig in while ( @ @days_remaining > 365) do https://gist.github.com/35461c627212c8098f6517855331ab02 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 end private def self . p e el _ of f _l e ap _ ye a r ! end def self . p e e l _ o f f _ r e g u l a r _ y e a r ! end def self . leap_year ? @ @d ay s_ remaining -= 365 ; @@year += 1 @ @d ay s_remaining -= 366 ; @@year += 1 ( @@year % 4 == 0 && @@year % 100 != 0) if ( @@ da ys_remaining >= 366) @@year % 400 == 0 || end end end Figure 9.18: We decompose the conditional in line 7 by replacing each branch with an extracted method. Note that while the total number of lines of code has increased, convert itself has become Shorter, and its steps now correspond closely to the pseudocode in Figure 9.14, sticking to a single level of Abstraction while delegating details to the extracted helper methods. 290 CHAPTER 9. LEGACY, REFACTORING, AND AGILE this method does, and the parameter name d is not useful. The other is the use of \u201cmagic number\u201d literal constants such as 1980 in line 4; we apply Replace Magic Number with Symbolic Constant (Fowler chapter 8) to replace it with the more descriptive constant name ORIGIN_YEAR. What about the other constants such as 365 and 366? In this example, they\u2019re probably familiar enough to most programmers, but if you saw 351 rather than 365, and if line 26 (in leap_year?) used the constant 19 rather than 400, you might not recognize the constants as being related to the Hebrew calendar . Remember that refactoring only improves the code for human readers; the computer doesn\u2019t care. So in such cases use your judgment as to how much refactoring is enough. In our case, re-running flog on the refactored code in Figure 9.18 brings the ABC score for the newly-renamed calculate_current_year from 23.0 down to 6.6, which is well below the suggested NIST threshold of 10.0. Also, reek now reports only two smells. The \ufb01rst is \u201clow cohesion\u201d for the helper methods peel_off_leap_year and peel_off_- regular_year; this is a design smell, and we will discuss what it means in Chapter 11. The second smell is declaration of class variables inside a method. When we applied Decompose Conditional and Extract Method, we turned local variables into class variables @@year and @@days_remaining so that the newly-extracted methods could successfully modify those variables\u2019 values. Our solution is effective, but clumsier than Replace Method with Method Object (Fowler chapter 6). In that refactoring, the original method convert is turned into an object instance (rather than a class) whose instance variables capture the object\u2019s state; the helper methods then operate on the instance variables. Figure 9.19 shows the result of applying such a refactoring, but there is an important caveat. So far, none of our refactorings have caused our characterization specs to fail, since the specs were just calling TimeSetter.convert. But applying Replace Method With Method Object changes the calling interface to convert in a way that makes tests fail. If we were working with real legacy code, we would have to \ufb01nd every site that calls convert, change it to use the new calling interface, and change any failing tests accordingly. In a real project, we\u2019d want to avoid changes that needlessly break the calling interface, so we\u2019d need to consider carefully whether the readability gained by applying this refactoring would outweigh the risk of introducing this breaking change. Summary of refactoring: \u2022 A refactoring is a particular transformation of a piece of code, including a name, a description of when to use the refactoring and what it does, and a detailed sequence of mechanical steps to perform it. Effective refactorings improve software metrics, eliminate code smells, or both. \u2022 Although most refactorings will inevitably cause some existing tests to fail (if not, the code in question is probably undertested), a key goal of the refactoring process is to minimize the amount of time until those tests are modi\ufb01ed and once again passing green. \u2022 Sometimes applying a refactoring may result in recursively having to apply simpler refactorings \ufb01rst, as Decompose Conditional may require applying Extract Method. 9.6. METHOD-LEVEL REFACTORING AND SEAMS 291 year = TimeSetter . new (367) . c a l c u l a t e _ c u r r e n t _ y e a r year = TimeSetter . c a l c u l a t e _ c u r r e n t _ y e a r (367) else if leap_year ? p ee l _o f f_ l ea p _y e ar ! while ( @ days_remaining > 365) do end def c a l c u l a t e _ c u r r e n t _ y e a r ORIGIN_YEAR = 1980 def initialize ( day s_s inc e_o rig in ) @year = ORIGIN_YEAR @ days _re maining = d ays _s inc e_o rig in # An example call would now be : # # rather than : # class TimeSetter https://gist.github.com/e4028ce92d0109b232142a45c3d03c66 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 end private def p e e l _o f f_ l ea p _y e ar ! end def p e e l _ o f f _ r e g u l a r _ y e a r ! ( @year % 4 == 0 && @year % 100 != 0) @ days _re maining -= 365 ; @year += 1 @ da ys_ remaining -= 366 ; @year += 1 end def leap_year ? if ( @da ys_remaining >= 366) end return @year p e e l _ o f f _ r e g u l a r _ y e a r ! @year % 400 == 0 || end end end end Figure 9.19: If we use Fowler\u2019s recommended refactoring, the code is cleaner because we now use instance variables rather than class variables to track side effects, but it changes the way calculate_current_year is called because it\u2019s now an instance method. This would break existing code and tests, and so might be deferred until later in the refactoring process. 292 CHAPTER 9. LEGACY, REFACTORING, AND AGILE Elaboration: Refactoring and language choice Some refactorings compensate for programming language features that may encourage bad code. For example, one suggested refactoring for adding seams is Encapsulate Field, in which direct access to an object\u2019s instance variables is replaced by calls to getter and setter methods. This makes sense in Java, but as we\u2019ve seen, getter and setter methods provide the only access to a Ruby object\u2019s instance variables from outside the object. (The refactoring still makes sense inside the object\u2019s own methods, as the Elaboration at the end of Section 2.3 suggests.) Similarly, the Generalize Type refactoring suggests creating more general types to improve code sharing, but Ruby\u2019s mixins and duck typing make such sharing easy. As we\u2019ll see in Chapter 11, it\u2019s also the case that some design patterns are simply unnecessary in Ruby because the problem they solve doesn\u2019t arise in dynamic languages. Self-Check 9.6.1. Which is not a goal of method-level refactoring: (a) reducing code com- plexity, (b) eliminating code smells, (c) eliminating bugs, (d) improving testability? (c). While debugging is important, the goal of refactoring is to preserve the code\u2019s current behavior while changing its structure."
    ]
  },
  {
    "id": "sec_0395",
    "title": "9.7 The Plan-And-Document Perspective on Working With Legacy Code",
    "pages": [
      304,
      305,
      306
    ],
    "text_blocks": [
      "One reason for the term lifecycle from Chapter 1 is that a software product enters a mainte- nance phase after development completes. Roughly two-thirds of the costs are in maintenance versus one-third in development. One reason that companies charge roughly 10% of the price of software for annual maintenance is to pay the team that does the maintenance. Organizations following Plan-And-Document processes typically have different teams for development and maintenance, with developers being redistributed onto new projects once the project is released. Thus, we now have a maintenance manager who takes over the role of the project manager during development, and we have maintenance software engineers who make changes to the code. Sadly, maintenance engineering has an unglamorous reputation, so it is typically performed by either the newest or least accomplished managers and engineers in an organization. Many organizations use different people for Quality Assessment (to do the testing) and for user documentation. For software products developed using Plan-And-Document processes, the environment for maintenance is very different from the environment for development: \u2022 Working software\u2014A working software product is in the \ufb01eld during this whole phase, and new releases must not interfere with existing features. \u2022 Customer collaboration\u2014Rather than trying to meet a speci\ufb01cation that is part of a negotiated contract, the goal for this phase is to work with customers to improve the product for the next release. Change requests are called maintenance requests in IEEE standards. \u2022 Responding to change\u2014Based on use of the product, customers send a stream of change requests, which can be new features as well as bug \ufb01xes. One challenge of the maintenance phase is prioritizing whether to implement a change request and in which release it should appear. Regression testing plays a much bigger role in maintenance to avoid breaking old features when developing new ones. Refactoring also plays a much bigger role, as you may need to 9.7. PLAN & DOCUMENT PERSPECTIVE ON LEGACY CODE 293 refactor to implement a change request or simply to make the code more maintainable. There is less incentive for the extra time and cost of refactoring in the initial phase of Plan-And- Document processes if the company developing the software is not the one that maintains it, which is one reason refactoring plays a smaller role during development. As mentioned above, change management is based on change requests made by cus- tomers and other stakeholders to \ufb01x bugs or to improve functionality (see Section 10.7). They typically \ufb01ll out change request forms, which are tracked using a ticket tracking system so that each request is responded to and resolved. A key tool for change management is a version control system, which tracks all modi\ufb01cations to all objects, as we describe in Sections 10.3 and 10.2. The prior paragraphs should sound familiar, for we are describing Agile development; in fact, the three bullets are copied from the Agile Manifesto (see Section 1.3). Thus, mainte- nance is essentially an Agile process. Change requests are like user stories; the triaging of change requests is similar to the assignment of points and using Pivotal Tracker to decide how to prioritize stories; and new releases of the software product act as Agile iterations of the working prototype. Plan-and-document maintenance even follows the same strategy of breaking a large change request into many smaller ones to make them easier to assess and implement, just as we do with user stories assigned more than eight points (see Section 7.4). Hence, if the same team is developing and maintaining the software, nothing changes after the \ufb01rst release of the product when using the Agile lifecycle. Although one paper reports successfully using an Agile process to maintain software developed using Plan-And-Document processes (Poole and Huisman 2001), normally an or- ganization that follows Plan-And-Document for development also follows it for maintenance. As we saw in earlier chapters, this process expects a strong project manager who makes the cost estimate, develops the schedule, reduces risks to the project, and formulates a careful plan for all the pieces of the project. This plan is re\ufb02ected in many documents, which we saw in Figures 7.6 and 8.14 and will see in the next chapter in Figures 10.11, 10.12, and 10.13. Thus, the impact of change in Plan-And-Document processes is not just the cost to change the code, but also to change the documentation and testing plan. Given the many more objects of Plan-And-Document, it takes more effort to synchronize to keep them all consistent when a change is made. A change control board examines all signi\ufb01cant requests to decide if the changes should be included in the next version of the system. This group needs estimates of the cost of a change to decide whether or not to approve the change request. The maintenance manager must estimate the effort and time to implement each change, much as the project manager did for the project initially (see Section 7.9). The group also asks the QA team for the cost of testing, including running all the regression tests and developing new ones (if needed) for a change. The documentation group also estimates the cost to change the documentation. Finally, the customer support group checks whether there is a workaround to decide if the change is urgent or not. Besides cost, the group considers the increased value of the product after the change when deciding what to do. To help keep track what must be done in Plan-And-Document processes, you will not be surprised to learn that IEEE offers standards to help. Figure 9.21 shows the outline of a maintenance plan from the IEEE Maintenance Standard 1219-1998. Ideally, changes can all be scheduled to keep the code, documents, and plans all in syn- chronization with an upcoming release. Alas, some changes are so urgent that everything else is dropped to try to get the new version to the customer as fast as possible. For example: 294 CHAPTER 9. LEGACY, REFACTORING, AND AGILE Tasks In Plan-and-Document Customer change request Change request forms Change request cost/time esti- mate By Maintenance Manager Triage of change requests Change Control Board Roles Maintenance Manager Maintenance SW Engineers QA team Documentation teams Customer support group In Agile User story on 3x5 cards in Connextra format Points by Development Team Development team with customer participation N.A. Development team Figure 9.20: The relationship between the maintenance related tasks of Plan-and-Document versus Agile methodologies. Table of Contents 1. Introduction 2. References 3. De\ufb01nitions 4. Software Maintenance Overview"
    ]
  },
  {
    "id": "sec_0396",
    "title": "4.1 Organization",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0397",
    "title": "4.2 Scheduling Priorities",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0398",
    "title": "4.3 Resource Summary",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0399",
    "title": "4.4 Responsibilities",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0400",
    "title": "4.5 Tools, Techniques, and Methods",
    "pages": [
      306
    ],
    "text_blocks": [
      "5. Software Maintenance Process"
    ]
  },
  {
    "id": "sec_0401",
    "title": "5.1 Problem/modi\ufb01cation identi\ufb01cation/classi\ufb01cation, and prioritization",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0402",
    "title": "5.2 Analysis",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0403",
    "title": "5.3 Design",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0404",
    "title": "5.4 Implementation",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0405",
    "title": "5.5 System Testing",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0406",
    "title": "5.6 Acceptance Testing",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0407",
    "title": "5.7 Delivery",
    "pages": [
      306
    ],
    "text_blocks": [
      "6. Software Maintenance Reporting Requirements 7. Software Maintenance Administrative Requirements"
    ]
  },
  {
    "id": "sec_0408",
    "title": "7.1 Anomaly Resolution and Reporting",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0409",
    "title": "7.2 Deviation Policy",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0410",
    "title": "7.3 Control Procedures",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0411",
    "title": "7.4 Standards, Practices, and Conventions",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0412",
    "title": "7.5 Performance Tracking",
    "pages": [
      306
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0413",
    "title": "7.6 Quality Control of Plan",
    "pages": [
      306,
      307,
      308,
      309
    ],
    "text_blocks": [
      "8. Software Maintenance Documentation Requirements Figure 9.21: Maintenance plan outline from the IEEE 1219-1998 Standard for Maintenance in Systems and Software Engineering. Back\ufb01lling is the term maintenance engineers use to describe getting code back in synch after emergencies. 9.7. PLAN & DOCUMENT PERSPECTIVE ON LEGACY CODE 295 \u2022 The software product crashes. \u2022 A security hole has been identi\ufb01ed that makes the data collected by the product partic- ularly vulnerable. \u2022 New releases of the underlying operating system or libraries force changes to the prod- uct for it to continue to function. \u2022 A competitor brings out a product or feature that if not matched will dramatically affect the business of the customer. \u2022 New laws are passed that affect the product. While the assumption is that the team will update the documentation and plans as soon as the emergency is over, in practice emergencies can be so frequent that the maintenance team can\u2019t keep everything in synch. Such a buildup is called a technical debt. The procrastination can lead to code that is increasingly dif\ufb01cult to maintain, which in turn leads to an increasing need to refactor the code as the code\u2019s \u201cviscosity\u201d makes it more and more dif\ufb01cult to add functionality cleanly. While refactoring is a natural part of Agile, it less likely for the Change Control Committee to approve changes that require refactoring, as such changes are much more expensive. That is\u2013as the name is intended to indicate\u2013if you don\u2019t repay your technical debt, it grows: the \u201cuglier\u201d the code gets, the more error-prone and time-consuming it is to refactor! In addition to estimating the cost of each potential change for the Change Control Board, an organization\u2019s management may ask what will be the annual cost of maintenance of a project. The maintenance manager may base this estimate on software metrics, just as the project manager may use metrics to estimate the cost to develop a project (see Section 7.9). The metrics used for maintenance are different, as they are measuring the maintenance pro- cess. Examples of metrics that may indicate increased dif\ufb01culty of maintenance include the average time to analyze or implement a change request and increases in the number of change requests made or approved. At some point in the lifecycle of a software product, the question arises whether it is time for it to be replaced. An alternative that is related to refactoring is called reengineering. Like refactoring, the idea is to keep functionality the same but to make the code much easier to maintain. Examples include: \u2022 Changing the database schema. \u2022 Using a reverse engineering tool to improve documentation. \u2022 Using a structural analysis tool to identify and simplify complex control structures. \u2022 Using a language translation tool to change code from a procedure-oriented language like C or COBOL to an object-oriented language like C++ or Java. The hope is that reengineering will be much less expensive and much more likely to succeed than reimplementing the software product from scratch. 296 CHAPTER 9. LEGACY, REFACTORING, AND AGILE Summary: The insight from this section is that you can think of Agile as a maintenance process, in that change is the norm, you are in continuous contact with the customer, and that new iterations of the product are routinely deployed to the customer as new releases. Hence, regression testing and refactoring are standard in the Agile process just as they are in the maintenance phase of Plan-and-Document. In Plan-and-Document processes: \u2022 Maintenance managers play the role of project managers: they interface with the customer and upper management, make the cost and schedule estimates, document the maintenance plan, and manage the maintenance software engineers. \u2022 Customers and other stakeholders issue change requests, which a Change Control Committee triages based on the bene\ufb01t of the change and cost estimates from the maintenance manager, the documentation team, and the QA team. \u2022 Regression testing plays a bigger role in maintenance to ensure that new features do not interfere with old ones. \u2022 Refactoring plays a bigger role as well, in part because there is often less refac- toring in Plan-and-Document processes during product development than in Agile development. \u2022 An alternative to starting over when the code becomes increasingly dif\ufb01cult to main- tain is to reengineer the code to lower the cost of having a much more maintainable system. One argument for Agile development is therefore as follows: if two-thirds of the cost of product are in the maintenance phase, why not use the same maintenance-compatible software development process for the whole lifecycle? Self-Check 9.7.1. True or False: The cost of maintenance usually exceeds the cost of devel- opment. True. Self-Check 9.7.2. True or False: Refactoring and reengineering are synonyms. False: While related terms, reengineering often relies on automatic tools and occurs as software ages and maintainability becomes more dif\ufb01cult, yet refactoring is a continuous process of code improvement that happens during both development and maintenance. Self-Check 9.7.3. Match the Plan-and-Document maintenance terms on the left to the Agile terms on the right: Change request Change request cost estimate Change request triage Release Iteration Icebox, Active columns in Pivotal Tracker Points User story Change request \u21d0\u21d2 User story; Change request cost estimate \u21d0\u21d2 Points; Release \u21d0\u21d2 Iteration; and Change request triage \u21d0\u21d2 Icebox, Active columns in Pivotal Tracker. 9.8. FALLACIES AND PITFALLS 297"
    ]
  },
  {
    "id": "sec_0414",
    "title": "9.8 Fallacies and Pitfalls",
    "pages": [
      309,
      310
    ],
    "text_blocks": [
      "Pitfall: Using TDD and CRC to think only tactically and not strategically about design. The extreme version of CRC cards seems to \ufb01t well with Agile: design and build the simplest thing that could possibly work, and embrace the fact that you\u2019ll need to change it later. But it\u2019s possible to take this approach too far. One suggestion from accomplished software craftsman and engineer John Ousterhout 1 is to \u201cdesign it twice\u201d: use CRC cards to come up with a design, then put it aside and try a different design from scratch, perhaps thinking a bit adversarially about how you want to beat the team that did the original design. If you\u2019re unable to improve on the original design, you can be more con\ufb01dent that it represents a reasonable starting point. But surprisingly often, you\u2019ll \ufb01nd a simpler or more elegant design after you\u2019ve had a chance to think through the problem the \ufb01rst time. Pitfall: Conjoined Methods Ousterhout (Ousterhout 2018) warns against creating conjoined methods: two methods that collaborate tightly in accomplishing one goal, so that there is a lot of interaction between them and neither can be effectively understood without also understanding the other. This advice is consistent with the SOFA advice that a method should do One thing (Ousterhout would say that each of the conjoined methods only does part of a thing) but is an easy pitfall to experience if you\u2019re overzealous in making methods Short. One sign of this is that it\u2019s nearly impossible to isolate one method from the other in tests; this is different from a helper method, which breaks out a well-de\ufb01ned subtask that can be individually tested. Pitfall: Con\ufb02ating refactoring with enhancement. When you\u2019re refactoring or creating additional tests (such as characterization tests) in preparation to improve legacy code, there is a great temptation to \ufb01x \u201clittle things\u201d along the way: methods that look just a little messy, instance variables that look obsolete, dead code that looks like it\u2019s never reached from anywhere, \u201creally simple\u201d features that look like something you could quickly add while doing other tasks. Resist these temptations! First, the reason to establish ground-truth tests ahead of time is to bootstrap yourself into a position from which you can make changes with con\ufb01dence that you\u2019re not breaking anything. Trying to make such \u201cimprovements\u201d in the absence of good test coverage invites disaster. Second, as we\u2019ve said before and will repeat again, programmers are optimists: tasks that look trivial to \ufb01x may sidetrack you for a long time from your primary task of refactoring, or worse, may get the code base into an unstable state from which you must backtrack in order to continue refactoring. The solution is simple: when you\u2019re refactoring or laying groundwork, focus obsessively on completing those steps before trying to enhance the code. Fallacy: It\u2019ll be faster to start from a clean slate than to \ufb01x this design. Putting aside the practical consideration that management will probably wisely forbid you from doing this anyway, there are many reasons why this belief is almost always wrong. 1Inventor of the Magic VLSI design software, the scripting language Tcl , the GUI toolkit Tk, and too many other software projects to mention! 298 CHAPTER 9. LEGACY, REFACTORING, AND AGILE First, if you haven\u2019t taken the time to understand a system, you are in no position to estimate how hard it will be to redesign, and you will probably vastly underestimate the effort required, given programmers\u2019 incurable optimism. Second, however ugly it may be, the current system works; a main tenet of doing short Agile iterations is \u201calways have working code,\u201d and by starting over you are immediately throwing that away. Third, if you use Agile methods in your redesign, you\u2019ll have to develop user stories and scenarios to drive the work, which means you\u2019ll need to prioritize them and write up quite a few of them to make sure you\u2019ve captured at least the functionality of the current system. It would probably be faster to use the techniques in this chapter to write scenarios for just those parts of the system to be improved and drive new code from there, rather than doing a complete rewrite. Does this mean you should never wipe the slate clean? No. As Rob Mee of Pivotal Labs points out, a time may come when the current codebase is such a poor re\ufb02ection of the original design intent that it becomes a liability, and starting over may well be the best thing to do. (Sometimes this results from not refactoring in a timely way!) But in all but the most trivial systems, this should be regarded as the \u201cnuclear option\u201d when all other paths have been carefully considered and determined to be inferior ways to meet the customer\u2019s needs. Pitfall: Rigid adherence to metrics or \u201callergic\u201d avoidance of code smells. In Chapter 8 we warned that correctness cannot be assured by relying on a single type of test (unit, functional, integration/acceptance) or by relying exclusively on quantitative code coverage as a measure of test thoroughness. Similarly, code quality cannot be assured by any single code metric or by avoiding any speci\ufb01c code smells. Hence the metric_fu gem inspects your code for multiple metrics and smells so you can identify \u201chot spots\u201d where multiple problems with the same piece of code call for refactoring."
    ]
  },
  {
    "id": "sec_0415",
    "title": "9.9 Concluding Remarks: Continuous Refactoring",
    "pages": [
      310,
      311,
      312,
      313,
      314
    ],
    "text_blocks": [
      "A ship in port is safe, but that\u2019s not what ships are built for. \u2014Admiral Grace Murray Hopper As we said in the opening of the chapter, modifying legacy code is not a task to be undertaken lightly, and the techniques required must be honed by experience. The \ufb01rst time is always the hardest. But fundamental skills such as refactoring help with both legacy code and new code, and as we saw, there is a deep connection among legacy code, refactoring, and testability and test coverage. We took code that was neither good nor testable\u2014it scored poorly on complexity metrics and code smells, and isolating behaviors for unit testing was awkward\u2014and refactored it into code that has much better metric scores, is easier to read and understand, and is easier to test. In short, we showed that good methods are testable and testable methods are good. We used refactoring to beautify existing code, but the same techniques can be used when performing the enhancements themselves. For example, if we need to add functionality to an existing method, rather than simply adding a bunch of lines of code and risk violating one or more SOFA guidelines, we can apply Extract Method to place the functionality in a new method that we call from the existing method. As you can see, this technique has the nice bene\ufb01t that we already know how to develop new methods using TDD! This observation explains why TDD leads naturally to good and testable code\u2014it\u2019s hard for a method not to be testable if the test is written \ufb01rst\u2014and illustrates the rationale behind 9.9. CONTINUOUS REFACTORING 299 the \u201crefactor\u201d step of Red\u2013Green\u2013Refactor. If you are refactoring constantly as you code, each individual change is likely to be small and minimally intrusive on your time and con- centration, and your code will tend to be beautiful. When you extract smaller methods from larger ones, you are identifying collaborators, describing the purpose of code by choosing good names, and inserting seams that help testability. When you rename a variable more descriptively, you are documenting design intent. But if you continue to encrust your code with new functionality without refactoring as you go, when refactoring \ufb01nally does become necessary (and it will), it will be more painful and require the kind of signi\ufb01cant scaffolding described in Sections 9.2 and 9.3. In short, refactoring will suddenly change from a background activity that takes incremental extra time to a foreground activity that commands your focus and concentration at the expense of adding customer value. Since programmers are optimists, we often think \u201cThat won\u2019t happen to me; I wrote this code, so I know it well enough that refactoring won\u2019t be so painful.\u201d But in fact, your code becomes legacy code the moment it\u2019s deployed and you move on to focusing on another part of the code. Unless you have a time-travel device and can talk to your former self, you might not be able to divine what you were thinking when you wrote the original code, so the code\u2019s clarity must speak for itself. This Agile view of continuous refactoring should not surprise you: just as with develop- ment, testing, or requirements gathering, refactoring is not a one-time \u201cphase\u201d but an ongoing process. In Chapter 12 we will see that the view of continuous vs. phased also holds for de- ployment and operations. It may be a surprise that the fundamental characteristics of Agile make it an excellent match to the needs of software maintenance. In fact, we can think of Agile as not having a development phase at all, but being in maintenance mode from the very start of its lifecycle! Working with legacy code isn\u2019t exclusively about refactoring, but as we\u2019ve seen, refac- toring is a major part of the effort. The best way to get better at refactoring is to do it a lot. Initially, we recommend you browse through Fowler\u2019s refactoring book just to get an overview of the many refactorings that have been catalogued. We recommend the Ruby- speci\ufb01c version (Fields et al. 2009), since not all smells or refactorings that arise in statically- typed languages occur in Ruby; versions are available for other popular languages, including Java. We introduced only a few in this chapter; Figure 9.22 lists more. As you become more experienced, you\u2019ll recognize refactoring opportunities without consulting the catalog each time. Code smells came out of the Agile movement. Again, we introduced only a few from a more extensive catalog; Figure 9.23 lists more. Good programmers don\u2019t deliberately cre- ate code with code smells; more often, the smells creep in as the code grows and evolves over time, sometimes beyond its original design. Pytel and Saleh\u2019s Rails Antipatterns (Py- tel and Saleh 2010) and Tucker\u2019s treatment of code smells and refactoring in the context of contributing to open source software (Tucker et al. 2011) address these realistic situations. We also introduced some simple software metrics; over four decades of software engi- neering, many others have been produced to capture code quality, and many analytical and empirical studies have been done on the costs and bene\ufb01ts of software maintenance. Robert Glass (Glass 2002) has produced a pithy collection of Facts & Fallacies of Software Engi- neering, informed by both experience and the scholarly literature and focusing in particular on the perceived vs. actual costs and bene\ufb01ts of maintenance activities. Sandi Metz\u2019s Practical Object-Oriented Design in Ruby (Metz 2012) covers object- 300 REFERENCES Category Composing Methods Organizing Data Simplifying Conditionals Simplifying Method Calls Extract method Replace method with method ob- ject Remove parameter assignments self-encapsulate \ufb01eld replace array/hash with Object Decompose Conditional Replace Conditional with Poly- morphism Consolidate Duplicate Condi- tional Fragments Rename Method Replace Parameter with Explicit Methods Refactorings Replace temp with method Inline temp Introduce explaining variable Split temp variable Substitute algorithm replace data value with object Replace magic number with symbolic constant Consolidate Conditional Replace Type Code with Polymor- phism Remove Control Flag Introduce Assertion Replace Nested Conditional with Guard Clauses Introduce Null Object change value to reference Add Parameter Preserve Whole Object Separate Query from Modi\ufb01er Replace Error Code with Excep- tion Figure 9.22: Several more of Fowler\u2019s refactorings, with the ones introduced in this chapter in italics. Duplicated Code Divergent Change Temporary Field Feature Envy Large Class Primitive Obsession Data Class Lazy Class Speculative Generality Refused Bequest Too Many Comments Message Chains Case Statements Middle Man Alternative Classes with Different Interfaces Long Parameter List Metaprogramming Mad- ness Parallel Inheritance Hierar- chies Incomplete Library Class Figure 9.23: More of Fowler\u2019s and Martin\u2019s code smells. oriented design from the perspective of minimizing the cost of change, and expands on many of the themes in this chapter with practical examples. The other primary sources for this chapter are Feathers\u2019s excellent practical treatment of working with legacy code (Feathers 2004), Nierstrasz and Demeyer\u2019s book on reengineering object-oriented software (Nierstrasz et al. 2009), and of course, the Ruby edition of Fowler\u2019s classic catalog of refactorings (Fields et al. 2009). Finally, John Ousterhout\u2019s A Philosophy of Software Design (Ousterhout 2018) collects practical advice for structuring software at the class and method level, with a view towards robustness and manageability. It\u2019s aimed at more advanced developers and is an excellent source of wisdom when you\u2019re ready to go beyond the introductory material in this chapter. M. Feathers. Working Effectively with Legacy Code. 9780131177055. Prentice Hall, 2004. ISBN J. Fields, S. Harvie, M. Fowler, and K. Beck. Refactoring: Ruby Edition. Addison-Wesley Professional, 2009. ISBN 0321603508. M. Fowler, K. Beck, J. Brant, W. Opdyke, and D. Roberts. Refactoring: Improving the Design of Existing Code. Addison-Wesley Professional, 1999. ISBN 0201485672. R. L. Glass. Facts and Fallacies of Software Engineering. Addison-Wesley Professional, 2002. ISBN 0321117425. NOTES 301 R. Green and H. Ledgard. Coding guidelines: Finding the art in the science. Communica- tions of the ACM, 54(12):57\u201363, Dec 2011. B. P. Lientz, E. B. Swanson, and G. E. Tompkins. Characteristics of application software maintenance. Communications of the ACM, 21(6):466\u2013471, 1978. R. C. Martin. Clean Code: A Handbook of Agile Software Craftsmanship. Prentice Hall, 2008. ISBN 9780132350884. S. Metz. Practical Object-Oriented Design in Ruby: An Agile Primer (Addison-Wesley Professional Ruby). Addison-Wesley Professional, 2012. ISBN 0321721330. URL http: //poodr.com. O. Nierstrasz, S. Ducasse, and S. Demeyer. Object-Oriented Reengineering Patterns. Square Bracket Associates, 2009. ISBN 395233412X. J. K. Ousterhout. A Philosophy of Software Design. Yaknyam Press, 2018. C. Poole and J. W. Huisman. Using extreme programming in a maintenance environment. Software, IEEE, 18(6):42\u201350, 2001. C. Pytel and T. Saleh. Rails AntiPatterns: Best Practice Ruby on Rails Refactoring (Addison-Wesley Professional Ruby Series). Addison-Wesley Professional, 2010. ISBN 9780321604811. A. Tucker, R. Morelli, and C. de Silva. Software Development: An Open Source Approach (Chapman & Hall/CRC Innovations in Software Engineering and Software Development Series). CRC Press, 2011. ISBN 143981290X. Notes 1http://campfirenow.com 2http://basecamphq.com 3http://en.wikibooks.org/wiki/Ruby_Programming/RubyDoc 4http://api.rubyonrails.org 5http://paulschreiber.com/blog/2010/06/15/rake-task-extracting-database-contents/ 6http://c2.com/doc/oopsla89/paper.html 7https://vimeo.com/24668095 8http://codeclimate.com 10 Agile Teams There are no winners on a losing team, and no losers on a winning team. \u2014Fred Brooks, quoting North Carolina basketball coach Dean Smith, 1990 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0416",
    "title": "10.1 It Takes a Team: Two-Pizza and Scrum .",
    "pages": [
      314
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0417",
    "title": "10.2 Using Branches Effectively",
    "pages": [
      314
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0418",
    "title": "10.3 Pull Requests and Code Reviews",
    "pages": [
      314
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0419",
    "title": "10.4 Delivering the Backlog Using Continuous Integration .",
    "pages": [
      314
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0420",
    "title": "10.5 CHIPS: Agile Iterations .",
    "pages": [
      314
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0421",
    "title": "10.6 Reporting and Fixing Bugs: The Five R\u2019s .",
    "pages": [
      314
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0422",
    "title": "10.7 The Plan-And-Document Perspective on Managing Teams .",
    "pages": [
      314
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0423",
    "title": "10.8 Fallacies and Pitfalls .",
    "pages": [
      314
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0424",
    "title": "10.9 Concluding Remarks: From Solo Developer to Teams of Teams",
    "pages": [
      314
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304 . 306 . 311 . 315 . 320 . 320 . 322 . 330 . 332 Frederick P. \u201cFred\u201d Brooks, Jr. (1931\u2013) wrote the classic software engineering book The Mythical Man-Month based on his years leading OS/360, the operating system for the highly successful IBM System/360 family of computers. This family was the \ufb01rst to feature instruction set compatibility across models, making it the \ufb01rst system to which the term \u201ccomputer architecture\u201d could be meaningfully applied. Brooks received the"
    ]
  },
  {
    "id": "sec_0425",
    "title": "1999 Turing Award for",
    "pages": [
      314,
      315,
      316
    ],
    "text_blocks": [
      "landmark contributions to computer architecture, operating systems, and software engineering. 303 Prerequisites and Concepts Prerequisites: You should have a free GitHub account and be comfortable with the basic Git opera- tions and commands for solo work: creating a new repo in your development environment and pushing it to GitHub, cloning an existing repo from GitHub to your development en- vironment, adding and removing les in a repo, committing changes accompanied by descriptive log messages, and pushing your changes to GitHub. Even if your Integrated Development Environments (IDEs) provides buttons and menus for interacting with Git and GitHub, you need to be comfortable doing these operations from the command line. To learn or refresh these skills, we recommend this basic Git guide1 (developed for UC Berkeley CS61B Data Structures). Concepts: Whether Agile or Plan-and-Document, programming is now primarily a team sport. This chapter covers techniques that can help teams succeed in coordinating and delivering their work. All software teams rely on version control to manage code and conguration data, code reviews to ensure quality, release management to ship new versions, and change management while maintaining a shipped product, but the processes around these activities differ between Agile and P&D teams. The version of these concepts for Agile is: \u2022 Two-pizza teams are four to nine people in size. \u2022 Self-organizing teams follow the Scrum model, which relies on one teammate to act as the Product Owner, who represents the customer, and one to act as the Scrum Lead, who acts as a buffer between the team and external distractions. These roles rotate between the team members over time. \u2022 Code reviews occur continuously, often as the result of pull requests, which start the process of integrating new team contributions into the mainline code. For the Plan-and-Document lifecycle, you will become familiar with the same concepts from a different perspective: \u2022 The project manager writes the contract, interfaces with the customer and upper management, recruits and manages the development team, resolves conicts, and documents the plans for managing congurations and the project itself. \u2022 While group sizes are similar to Agile, large teams can be created by combining groups into a hierarchy under the project manager, with each group having its own leader. 304 CHAPTER 10. AGILE TEAMS Figure 10.1: The Agile software lifecycle and its relationship to the chapters in this book. This chapter emphasizes evaluating the productivity of the team so as to come up with schedules that are more accurate by tracking velocity."
    ]
  },
  {
    "id": "sec_0426",
    "title": "10.1 It Takes a Team: Two-Pizza and Scrum",
    "pages": [
      316,
      317,
      318
    ],
    "text_blocks": [
      "The Six Phases of a Project: (1) Enthusiasm, (2) Disillusionment, (3) Panic, (4) Search for the guilty, (5) Punishment of the innocent, (6) Praise for non-participants. \u2014Dutch Holland (Holland 2004) The days of the hero programmer are now past. Whereas once a brilliant individual could create breakthrough software, the rising bar on functionality and quality means software de- velopment is now primarily a team sport. Hence, success today means that not only do you have great design and coding skills, but that you work well with others and can help your team succeed. As the opening quote from Fred Brooks states, you cannot win if your team loses, and you cannot lose if your team wins. Hence, the \ufb01rst step of a software development project is to form and organize a team. As to its size, a \u201ctwo-pizza\u201d team\u2014a group that can be fed by two pizzas in a meeting\u2014is typical for SaaS projects. Our discussions with senior software engineers suggest the typical team size varies by company, with four to nine developers being a typical range. While there are many ways to organize a two-pizza team, a popular one today is Scrum (Schwaber and Beedle 2001). Its frequent short meetings\u201415 minutes every day at the same place and time\u2014inspire the name. During the scrum, each team member answers three ques- tions: 1. What have you done since yesterday? 2. What are you planning to do today? 3. Are there any impediments or stumbling blocks? Jeff Bezos, the CEO of Amazon who received his college degree in computer science, coined the two-pizza characterization of team size. 10.1. IT TAKES A TEAM: TWO-PIZZA AND SCRUM 305 The bene\ufb01t of these daily scrums is that by understanding what each team member is doing and has already completed, the team can identify work that would help others make faster Indeed, daily scrums are sometimes referred to as standups, implying that the progress. meeting should be kept short enough that everyone can remain standing the entire time. When combined with the weekly or biweekly iteration model of Agile to collect the feed- back from all the stakeholders, the Scrum organization makes it more likely that the rapid progress will be towards what the customers want. Rather than use the Agile term iteration, Scrum uses the term sprint. A Scrum has three main roles: A scrum is held on every minor infraction in the sport of rugby. The game stops to bring the players together for a quick \u201cmeeting\u201d in order to restart the game. 1. Team\u2014A two-pizza size team that delivers the software. 2. Scrum Lead\u2014A team member who acts as buffer between the Team and external dis- tractions, keeps the team focused on the task at hand, enforces team rules, and removes impediments that prevent the team from making progress. One example is enforcing coding standards, which are style guidelines that improve the consistency and read- ability of the code. 3. Product Owner\u2014A team member (not the Scrum Lead) who represents the voice of the customer and prioritizes user stories. Scrum relies on self-organization, and team members often rotate through different roles. For example, we recommend that each team member rotate through the Product Owner role, changing on every iteration or sprint. In any group working together, con\ufb02icts can occur around which technical direction the group should go. Depending in part on the personalities of the members of the team, they may not be able to quickly reach agreement. One approach to resolving con\ufb02icts is to start with a list of all the items on which the sides agree, as opposed to starting with the list of disagreements. This technique can make the sides see that perhaps they are closer together than they thought. Another approach is for each side to articulate the other\u2019s arguments. This technique makes sure both sides understand what the arguments are, even if they don\u2019t agree with some of them. This step can reduce confusion about terms or assumptions, which may be the real cause of the con\ufb02ict. Of course, such an approach requires great team dynamics. Everyone on the team should ideally feel psychological safety \u2014the belief that they will not be humiliated for voicing their ideas to the team, even if those ideas might turn out to be wrong. Indeed, a two-year study by Google2 found that the most effective Google teams weren\u2019t the ones with the most senior engineers or the smartest people, but the teams with high psychological safety. One way Agile teams promote psychological safety is to do a short Retrospective meeting, often shortened to \u201cretro,\u201d at the end of each iteration. A typical format for the retro focuses on Plus/Minus/Interesting (PMI): each team member writes down, perhaps anonymously at \ufb01rst, what they thought went well, went poorly, and was unusual or noteworthy (neither good nor bad) during the iteration. The PMI items are often not technical, for example, \u201cWhen I brought up my concern about some new code to Armando, I felt he was dismissive about my idea\u201d or \u201cDave really helped me with a bug I\u2019d been chasing this week without making me feel stupid.\u201d All team members then review the items (and where appropriate reveal their identities, or say \u201cI agree,\u201d or \u201cI noticed that too\u201d), noting especially if some items were raised by more than one team member. The PMI items can also be compared to the previous iteration\u2019s retro items, since one goal of Agile is continuous improvement. Postfacto is a free Web-based tool from Pivotal Labs that facilitates retros. 306 CHAPTER 10. AGILE TEAMS The rest of this chapter focuses on coordinating the work of the team, and in particular the use of version control tools to support coordination. How is the code repository managed? What happens if team members accidentally make con\ufb02icting changes to a set of \ufb01les? Which lines in a given \ufb01le were changed, when, and by whom? How does one developer work on a new feature without introducing problems into stable code? How does the team ensure the quality of the code and tests on an ongoing basis as more contributions accrete in the repository? As we will see, when software is developed by a team rather than an individual, version control can be used to address these questions using merging and branching . Both tasks involve combining changes made by many developers into a single code base, a task that sometimes requires manual resolution of con\ufb02icting changes. Summary: SaaS is a good match for two-pizza teams and Scrum, a self-organized small team that meets daily. Two team members take on the additional roles of Scrum Lead, who removes impediments and keeps the team focused, and Product Owner, who speaks for the customer. It can be helpful to follow structured strategies to resolve con\ufb02icts when they occur and to re\ufb02ect on past work in a retrospective meeting. Elaboration: Coding standards Coding standards or stylesheets are style guidelines that everyone on the team is expected to follow, usually related to indentation, variable naming, and so on. The goal is to improve the consistency and readability of the code. For example, here is one for Rails3. Some projects keep their own coding style guidelines in a document in the project\u2019s main repository; others adhere to guidelines for whichever frameworks or languages the project uses. Self-Check 10.1.1. True or False: Scrum is an appropriate methodology when it is dif\ufb01cult to plan ahead. True: Scrum relies more on real-time feedback than on the traditional management ap- proach of central planning with command and control."
    ]
  },
  {
    "id": "sec_0427",
    "title": "10.2 Using Branches Effectively",
    "pages": [
      318,
      319,
      320,
      321,
      322,
      323
    ],
    "text_blocks": [
      "Besides taking snapshots of your work and backing it up, version control also lets you manage multiple versions of a project\u2019s code base simultaneously, for example, to allow part of the team to work on an experimental new feature without disrupting working code, or to \ufb01x a bug in a previously-released version of the code that some customers are still using. Branches are designed for such situations. Rather than thinking of commits as just a sequence of snapshots, we should instead think of a directed, acyclic graph of commits. When a new repo is created, by default it contains only a single branch, usually called the main branch, on which a linear sequence of commits is made. At any point in time, a new branch can be created that \u201csplits off\u201d from any commit of an existing branch, creating a copy of the codebase as it exists at that commit. As soon as a branch is created, that branch and the one from which it was split are separate: commits to one branch don\u2019t affect the other, though depending on project needs, commits in either may be merged back into the other. Indeed, branches can even be split off from other branches, but overly complex branching structures offer few bene\ufb01ts and are dif\ufb01cult to maintain. Finally, unlike a real tree branch, a repo branch can be merged back into another branch later\u2014either the branch from which Prior to June 2020, the main branch was usually called master. 10.2. USING BRANCHES EFFECTIVELY 307 Figure 10.2: Each circle represents a commit. Amy, Bob and Dee each start branches based on the same commit (a) to work on different RottenPotatoes features. After several commits, Bob decides his feature won\u2019t work out, so he deletes his branch (b); meanwhile, Amy completes her work and merges her feature branch back into the main branch, creating the merge-commit (c). Finally, Dee completes her feature, but since the main branch has changed due to Amy\u2019s merge-commit (c), Dee has to do some manual con\ufb02ict resolution to complete her merge-commit (d). it split off, or some other branch. A branch can also be deleted, for example, if the project decides to abandon the work-in-progress that branch represents. We highlight two common branch management strategies that can be used together or separately, both of which strive to ensure that the main branch always contains a stable work- ing version of the code. Figure 10.2 shows a feature branch, which allows a developer or sub-team to make the changes necessary to implement a particular feature without affecting the main branch until the changes are complete and tested. If the feature is merged into the main branch and a decision is made later to remove it (perhaps it failed to deliver the expected customer value), the speci\ufb01c commits related to the merge of the feature branch can sometimes be undone, as long as there haven\u2019t been many changes to the main branch that depend on the new feature. Figure 10.3 shows how release branches are used to \ufb01x problems found in a speci\ufb01c release. They are widely used for delivering non-SaaS products such as libraries or gems whose releases are far enough apart that the main branch may diverge substantially from the most recent release branch. For example, the Linux kernel, for which developers check in thousands of lines of code per day, uses release branches to designate stable and long-lived releases of the kernel. Release branches often receive multiple merges from the development or main branch and contribute multiple merges to it. Release branches are less common in delivering SaaS because of the trend toward continuous integration/continuous deployment (Section 1.4): if you deploy several times per week, the deployed version won\u2019t have time to get out of sync with the main branch, so you might as well deploy directly from the main branch. We discuss continuous deployment further in Chapter 12. Figure 10.4 shows some commands for manipulating Git branches. At any given time, the current branch is whichever one you\u2019re working on in your copy of the repo. Since in general each copy of the repo contains all the branches, you can quickly switch back and forth between branches in the same repo (but see Fallacies and Pitfalls for an important caveat about doing so). Small teams working on a common set of features commonly use a shared-repository model for managing the repo: one particular copy of the repo, referred to as the origin repo, is designated as authoritative, and all developers agree to push their changes to the origin Topic branch is a generic term that may refer to feature, release, or bug \ufb01x branches. 308 CHAPTER 10. AGILE TEAMS Many earlier VCSs such as Subversion supported only the shared-repository model of development, and the \u201cone true repo\u201d was often called the master, a term that meant something quite different in Git and was abandoned in 2020 in favor of main. PaaS (Platform-as-a-Service) deployment servers such as Heroku often appear as a Git remote; pushing code to that remote deploys the pushed version of the app. git pull actually combines two separate commands: git fetch, which copies new commits from the origin, and git merge, which tries to reconcile the commits with those in the branch on the local clone. Figure 10.3: (a) A new release branch is created to \u201csnapshot\u201d version 1.3 of RottenPotatoes. A bug is found in the release and the \ufb01x is committed in the release branch (b); the app is redeployed from the release branch. The commit(s) containing the \ufb01x are merged into the main branch (c), but the code in the main branch has evolved suf\ufb01ciently from the code in the release that manual adjustments to the bug \ufb01x need to be made. Meanwhile, the dev team working on the main branch \ufb01nds a critical security \ufb02aw and \ufb01xes it with one commit (d). The speci\ufb01c commit containing the security \ufb01x can be merged into the release branch (e) using git cherry-pick, since we don\u2019t want to apply any other main branch changes to the release branch except for this \ufb01x. and periodically pull from the origin to get others\u2019 changes. Famously, Git itself doesn\u2019t care which copy of the repo is authoritative\u2014any developer can pull changes from or push changes to any other developer\u2019s copy of that repo if the repo\u2019s permissions are con\ufb01gured to allow it\u2014but for small teams, it\u2019s convenient (and conventional) for the origin repo to reside in the cloud on a service such as GitHub. Each team member can clone the origin repo onto their development computer, do their work, make their commits on their local clone, and periodically push their commits to the origin. From the point of view of each developer\u2019s local clone, the origin is one of possibly several remote copies of the repo, or simply \u201cremotes.\u201d In the shared-repository model, the origin repo is usually the only remote. Section 10.4 describes scenarios in which there may be multiple remotes. As Figure 10.4 shows, the git push and git pull commands usually specify which copy of the repository and which branch should be involved in a push or pull operation. If Amy commits changes to her clone of the repo, those changes aren\u2019t visible to her teammate Bob until she does a push and Bob does a pull. This raises the possibility of a merge con\ufb02ict scenario. Returning to Figure 10.2, suppose that Dee\u2019s feature branch results in changes to some of the same \ufb01les as Amy\u2019s feature branch. At the commit marked (c), Amy has successfully merged her changes into the main branch. When Dee tries to push her changes (d), she will initially be prevented from doing so because additional commits have occurred in the origin repo since she last pulled (probably at point (a) when creating her branch). Dee must bring her copy of the repo up-to-date with respect to the origin before she can push her changes. One way to do this is for her to switch back to her main branch, then run git pull origin main to get the latest commits on main from the origin repo; her copy of the repo now looks the same as it did to Amy right after point (c). Now Dee can try to merge her feature branch back into the main branch. If Dee\u2019s branch changes different \ufb01les than Amy\u2019s branch, or if they change different parts of the same \ufb01le that are far apart, the merge will succeed and Dee can then push her merged main branch back to the shared repo (git push origin main). But if Dee and Amy had edited parts of the same \ufb01le that were within a few lines of each other, as in Figure 10.5, Git will conclude that there is no safe way to automatically 10.2. USING BRANCHES EFFECTIVELY 309 \u2022 git branch List existing branches in repo, indicating current branch with *. If you\u2019re using sh or a bash- derived shell on a Unix-like system, placing the following in \u223c/.profile will make the shell prompt display the current Git branch when you\u2019re in a Git repo directory: https://gist.github.com/17f75e5697e5bca7a9ce2be75d012a65 1 2 export PS1 = \" [ ` git branch --no - color 2 >/ dev / null | \\ sed -e '/^[^*]/ d ' -e 's /* \\(.*\\) /\\1/ ' `]% \" \u2022 git checkout name Switch to existing branch name. \u2022 git branch name If branch name exists, switch to it; otherwise create a new branch called name without switching to it. The shortcut git checkout -b name [commit-id] creates and switches to a new branch based on commit-id, which defaults to most recent commit in the current branch. \u2022 git push [repo] [branch] Push the changes (commits) on branch to remote repository repo. (The \ufb01rst time you do this for a given branch, it creates that branch on the remote repo.) With no arguments, pushes the current local branch to the current branch\u2019s remote, or the remote called origin by default. \u2022 git pull [repo] [branch] Fetches and merges commits from branch branch on the remote repo into your local repo\u2019s cur- rent branch (even if the current branch\u2019s name doesn\u2019t match the branch name you\u2019re pulling from\u2014beware!). To fetch a remote branch foo for which you have no corresponding local branch, \ufb01rst use git checkout -b foo to create a local branch by that name and switch to it, then git pull origin foo. With no arguments, repo and branch default to the values of git config branch.currentbranch.remote and git config branch.currentbranch.merge re- spectively, which are automatically set up by certain Git commands and can be changed with git branch --track. If you setup a new repo in the usual way, repo defaults to origin and branch defaults to main. \u2022 git remote show [repo] If repo omitted, show a list of existing remote repos. If repo is the name of an existing remote repo, shows branches located at repo and which of your local branches are set up to track them. Also shows which local branches are not up-to-date with respect to repo. \u2022 git merge branch Merge all changes from branch into the current branch. \u2022 git rebase source-branch Try to rewrite history as if the current branch had originated from the latest commit on source- branch. You can also specify a speci\ufb01c commit-ID instead of the name of a source branch. Useful in pull requests since it shifts the work of con\ufb02ict resolution from the target branch\u2019s maintainer to the feature branch\u2019s maintainer. \u2022 git cherry-pick commits Rather than merging all changes (commits) from a given branch, apply only the changes intro- duced by each of the named commits to the current branch. \u2022 git checkout branch \ufb01le1 \ufb01le2. . . For each \ufb01le, merge the differences in branch\u2019s version of that \ufb01le into the current branch\u2019s version of that \ufb01le. Figure 10.4: Common Git commands for handling branches and merging. Branch management involves merging; Figure 10.6 tells how to undo merges gone awry. 310 CHAPTER 10. AGILE TEAMS https://gist.github.com/708b2be6cbc71f1f3d499e683a4474fb 1 2 3 4 5 6 7 8 Roses are red , Violets are blue . <<<<<<< HEAD : poem . txt I love GitHub , ======= ProjectLocker rocks , >>>>>>> 77976 d a 3 5 a 1 1 d b 4 5 8 0 b 8 0 a e 2 7 e 8 d 6 5 c a f 5 2 0 8 0 8 6 : poem . txt and so do you . Figure 10.5: When Bob tries to merge Amy\u2019s changes, Git inserts con\ufb02ict markers in poem.txt to show a merge con\ufb02ict. Line 3 marks the beginning of the con\ufb02icted region with <<<; everything until === (line 5) shows the contents of the \ufb01le in HEAD (the latest commit in Bob\u2019s local repo) and everything thereafter until the end-of-con\ufb02ict marker >>>(line 7) shows Amy\u2019s changes (the \ufb01le as it appears in Amy\u2019s con\ufb02icting commit, whose commit-ID is on line 7). Lines 1,2 and 8 were either unaffected or merged automatically by Git. create a version of the \ufb01le that re\ufb02ects both sets of changes, and it will leave a con\ufb02icted and uncommitted version of the \ufb01le with con\ufb02ict markers (<<< and >>>) in Dee\u2019s main branch. Dee must now manually edit that \ufb01le and add and commit the manually edited version to complete the merge, after which she can push the merged main back to the shared repo. In the next section, we will discuss an alternative process for preventing merge con\ufb02icts before they occur. If a merge goes badly awry, Figure 10.6 provides some mechanisms for partially or fully undoing the results of the merge. Figure 10.7 lists some useful Git commands to help keep track of who did what and when. Figure 10.8 shows some convenient notational alternatives to the cumbersome 40-digit Git commit-IDs. Finally, don\u2019t overlook the importance of a scratch branch, which is a branch that is never intended to be merged back into the mainline code. You can create a scratch branch to explore code changes such as exploring a spike (Section 7.4) or dry-running a radical change such as upgrading to a major new version of your app framework. Whichever branches you create, if those branches are pushed to the main repo, over time the number of branches will grow. GitHub has a user interface for viewing and pruning stale (inactive) branches, which helps keep your codebase manageable. Summary of branching: \u2022 Small teams typically use a \u201cshared-repo\u201d model, in which pushes and pulls use a single authoritative copy of the repo. In Git, the authoritative copy is often referred to as the origin repo and is stored in the cloud on GitHub or on an internal company server. \u2022 Branches allow variation in a code base. For example, feature branches support the development of new features without destabilizing working code, and release branches allow \ufb01xing bugs in previous releases whose code has diverged from the main line of development. \u2022 Merging changes from one branch into another (for example, from a feature branch back into the main branch) may result in con\ufb02icts that must be manually resolved. \u2022 With Agile and SaaS, feature branches are usually short-lived and release branches are uncommon. 10.3. PULL REQUESTS AND CODE REVIEWS 311 Self-Check 10.2.1. Describe a scenario in which merges could go in both directions\u2014 changes in a feature branch merged into the main branch, and changes in the main branch merged into a feature branch. (In Git, this is called a crisscross merge.) Diana starts a new branch to work on a feature. Before she completes the feature, an im- portant bug is \ufb01xed and the \ufb01x is merged into the main branch. Because the bug is in a part of the code that interacts with Diana\u2019s feature, she merges the \ufb01x from main into her own feature branch. Finally, when she \ufb01nishes the feature, her feature branch is merged back into main."
    ]
  },
  {
    "id": "sec_0428",
    "title": "10.3 Pull Requests and Code Reviews",
    "pages": [
      323,
      324,
      325,
      326
    ],
    "text_blocks": [
      "There is a really interesting group of people in the United States and around the world who do social coding now. The most interesting stuff is not what they do on Twitter, it\u2019s what they do on GitHub. \u2014Al Gore, former US Vice President, 2013 Section 10.7 describes the use of design reviews or code reviews to improve quality of the software product. You may be surprised to learn that most companies using Agile methods do not perform formal design or code reviews. But perhaps more surprising is that experienced Agile companies\u2019 code is better and more frequently reviewed compared to companies that do formal code reviews. For the explanation of this paradox, recall the basic idea of extreme programming: every good programming practice is taken to an extreme. Section 2.2 already described one form of \u201cextreme code review\u201d in the form of pair programming, in which the navigator continuously reviews the code being entered by the driver. In this section we describe another form of code review, in which the rest of the team has frequent opportunities to review the work of their colleagues. Our description follows the process used at GitHub, where formal code reviews are rare. When a developer (or a pair) has \ufb01nished work on a branch, rather than directly merging the topic branch into the main branch, the developer makes a pull request, or PR for short, asking that the branch\u2019s changes be merged into (usually) the main branch. All developers sharing the repo see each PR, and each has the responsibility to determine how merging those changes might affect their own code. If anyone has a concern, an online discussion coalesces around the PR. For example, GitHub\u2019s user interface allows any developer to make comments either on the PR overall or on speci\ufb01c lines of particular \ufb01les modi\ufb01ed by the PR. This discussion might result in changes to the code in question before the PR is accepted and merged; any further changes made on the PR\u2019s topic branch and pushed to GitHub will automatically be re\ufb02ected in the PR, so the PR process is really a form of code review. And since many PRs typically occur each day, these \u201cmini-reviews\u201d are occurring continuously, so there is no need for special meetings. The PR therefore serves as a way to focus a code review discussion on a particular set of changes. That said, a PR shouldn\u2019t be opened until the developer is con\ufb01dent their code is ready. Such preparation includes the following: \u2022 The PR\u2019s \u201cdescription\u201d \ufb01eld should provide a well-written explanation of what the proposed code does overall. For example, since PRs are often in support of a particular user story, the PR description could indicate which parts of the necessary functionality are covered by the proposed code. Merge request is an alternative name for pull request. 312 CHAPTER 10. AGILE TEAMS \u2022 The code to be merged should be well covered by tests, all of which should be passing. (CHIPS 10.5 describes one way to con\ufb01gure GitHub so that every push to a topic branch automatically triggers a run of the test suite.) \u2022 The commit messages should clearly indicate what was changed in each commit. (Since a PR is a request to merge one branch into another, it will often be the case that the branch being merged has had several commits.) \u2022 Documentation (design documents, the README \ufb01le, the project wiki, and so on) has been updated if necessary to explain new design decisions or changes to important con\ufb01guration \ufb01les (such as the Gemfile for Ruby projects). \u2022 Any temporary or non-essential \ufb01les that were versioned during development of the code have been removed from version control. \u2022 Steps have been taken to eliminate or minimize merge con\ufb02icts that will occur when the PR is accepted and merged. The last item above can be tricky, because as the previous section explained, it\u2019s not uncommon for a merge to encounter con\ufb02icts that must be manually resolved. Indeed, when you open a PR, GitHub checks and informs you whether the merge would require manual con\ufb02ict resolution. Such a scenario motivates the possible use of rebasing, an operation in which you tell Git to make the world look as if you had branched from a later commit. For example, if there have been 3 new commits on main since the time you branched off of it, and you now rebase your branch on top of main, Git will \ufb01rst apply those 3 new commits to the original state of your branch, and then try to apply your own commits. This latter step may cause con\ufb02icts if the 3 commits on the main branch touched some of the same \ufb01les your changes have touched. If so, Git generally requires you to resolve each con\ufb02ict as it is detected, before proceeding with the rebase, and allows you to abort the rebase entirely if things get too ugly. But once you have resolved those con\ufb02icts, merging your branch back to main is guaranteed not to cause any new con\ufb02icts (unless, of course, additional commits to main happened while you were rebasing). In other words, from the point of view of trying to merge changes into a shared main branch, rebasing before merging forces you to resolve the con\ufb02icts at rebasing time, thus saving work for whoever will merge your branch back into the main branch. There is an important caveat to rebasing. By its very nature, rebasing rewrites history, by making the world look as if your branch had been created from a different commit than it actually was, and by rewriting the commit history of the branch itself. This rewriting of history can occur in one of three scenarios: 1. You have not yet pushed to the shared repo. The history of your branch exists only in your copy of the repo, so rewriting that history does not affect the team. 2. You have pushed to the shared repo, but no one else has made additional changes based on your branch. This is the common case when using branch-per-feature, since there is normally no reason for one developer to base work on another developer\u2019s commits in a feature branch. You may need to use the --force \ufb02ag to git push when pushing the branch, to indicate your acknowledgment that you\u2019re changing the shared repo\u2019s view of history. Commit squashing is an optional rebasing step in which the branch\u2019s commits are \u201csquashed\u201d into a single commit that can be easily backed out to undo the effects of merging the PR. 10.3. PULL REQUESTS AND CODE REVIEWS 313 3. You have pushed to the shared repo, and others have based work off of your changes. Anyone who has based their work off of your branch commits will now be out of sync since their history doesn\u2019t match the shared repo\u2019s history. Case 3 is rare, but if it occurs, you should coordinate carefully with your team before forcing a push to avoid others\u2019 repos getting out of sync with the shared copy. One good practice is to construct feature branch names in some way that signals that others should not build off of those commits, for example by prepending the developer\u2019s initials to the branch name or using a standard naming convention such as feature-xxx for feature branch names. An alternative to rebasing is merging: running git pull origin main in your feature branch at any time will update your clone from the origin repo, then merge any new changes from the main branch into your feature branch. Compared with rebasing, this approach is nondestructive because it doesn\u2019t rewrite history, but it also adds a lot of extra commits (the merge commits) to your feature branch, which can make it tricky to reconstruct the history of the feature branch using git log. Atlassian has an excellent set of tutorials4 covering this and many other Git-related topics. All this having been said, if you\u2019re breaking down your user stories into tasks of man- ageable size (Section 7.4) and doing frequent deployments (Section 12.4), messy merges and rebases should rarely be necessary in Agile development. Once the PR has been opened, one or more team members should review the PR. GitHub\u2019s user interface allows commenting on the PR as a whole as well as on speci\ufb01c changed lines of code, and the \u201csplit view\u201d feature makes it easy to see which speci\ufb01c lines were changed in each \ufb01le. Each reviewer\u2014there should be more than one, or reviewers can work as a pair\u2014should If the \ufb01rst read the description to understand what the code changes are intended to do. description is unclear, the developer who opened the PR should amend it. Once the description is clearly understood, it is helpful to next review the tests, since good tests also serve as documentation of how the code is supposed to behave. Tests are assumed to be passing, or the original developer would not have opened the PR for review. Finally, the reviewers examine the new or changed code, and (politely) ask for additional explanation wherever needed to understand why the code is written as it is. Frequently, the developer who opened the PR will make additional commits to address reviewers\u2019 comments; the PR will remain open and the new commits will be added to it, and this feedback cycle can continue until the PR is either approved (merged into the main branch) or closed without merging. 314 CHAPTER 10. AGILE TEAMS \u2022 git reset --hard ORIG_HEAD Revert your repo to last committed state just before the merge. \u2022 git reset --hard HEAD Revert your repo to last committed state. \u2022 git checkout commit -- [\ufb01le] Restore a \ufb01le, or if omitted the whole repo, to its state at commit (see Figure 10.8 for ways to refer to a commit besides its 40-digit SHA-1 hash). Can be used to recover \ufb01les that were previously deleted using git rm. \u2022 git revert commit Reverts the changes introduced by commit. If that commit was the result of a merge, effectively undoes the merge, and leaves the current branch in the state it was in before the merge. Git tries to back out just the changes introduced by that commit without disturbing other changes since that commit, but if the commit happened a long time ago, manual con\ufb02ict resolution may be required. Figure 10.6: When a merge goes awry, these commands can help you recover by undoing all or part of the merge. git blame [\ufb01le] git diff [\ufb01le] git diff branch [\ufb01le] git log [ref ..ref] [\ufb01les] git log --since=\"date\" \ufb01les Annotate each line of a \ufb01le to show who changed it last and when. Show differences between current working version of \ufb01le and last committed version. Show differences between current version of \ufb01le and the way it appears in the most recent commit on branch (see Section 10.2). Show log entries affecting all \ufb01les between the two commits speci\ufb01ed by the ref s (which must be separated by exactly two dots), or if omitted, entire log history affecting those \ufb01les. Show the log entries affecting all \ufb01les since the given date (examples: \"25-Dec-2019\", \"2 weeks ago\"). Figure 10.7: Git commands to help track who changed what \ufb01le and when. Many commands accept the option --oneline to produce a compact representation of their reports. If an optional [\ufb01le] argument is omitted, default is \u201call tracked \ufb01les.\u201d Note that all these commands have many more options, which you can see with git help command. HEAD HEAD\u223c ORIG_HEAD 1dfb2c\u223c2 \"branch@{date}\" The most recently committed version on the current branch. The prior commit on the current branch (HEAD\u223cn refers to the n\u2019th previous commit). When a merge is performed, HEAD is updated to the newly-merged version, and ORIG_HEAD refers to the commit state before the merge. Useful if you want to use git diff to see how each \ufb01le changed as a result of the merge."
    ]
  },
  {
    "id": "sec_0429",
    "title": "2 commits prior to the commit whose ID has 1dfb2c as a unique pre\ufb01x.",
    "pages": [
      326,
      327
    ],
    "text_blocks": [
      "The last commit prior to date (see Figure 10.7 for date format) on branch, where HEAD refers to the current branch. Figure 10.8: Convenient ways to refer to certain commits in Git commands, rather than using a full 40-digit commit ID or a unique pre\ufb01x of one. git rev-parse expr resolves any of the above expressions into a full commit ID. 10.4. DELIVERING THE BACKLOG USING CONTINUOUS INTEGRATION 315 Summary of merge management for small teams: 1. By opening a pull request to merge a feature branch rather than performing the merge directly, the rest of the team is noti\ufb01ed of the proposed changes and has a chance to do an on-the-spot code review around the pull request before it is accepted. 2. Rebasing rewrites history by \u201crewinding\u201d a branch to originate from a different com- mit than it actually does, and then trying to apply the branch\u2019s commits, thereby forcing the branch maintainer to resolve con\ufb02icts that would result if the un-rebased branch were merged. A common use for rebasing is to allow subsequent creation of a pull request that is guaranteed to be free of merge con\ufb02icts. 3. Because it rewrites history after the fact, rebasing should only be used when you can be sure that no one else has based their additional work on that branch\u2019s commits. Elaboration: When to open a pull request Our advice above has been to open a PR when you\u2019re con\ufb01dent that the code is ready for review, but some teams instead open a PR much earlier as a \u201cdraft PR,\u201d as the code is in progress. The requester knows the PR won\u2019t be merged, but this way the rest of the team can comment on the code as it evolves, rather than waiting until it\u2019s fully ready. The PR can remain open as the code evolves in response to comments. Once the PR is judged ready for \ufb01nal review prior to merge, the \u201cdraft\u201d designation is removed. The \u201cearly draft PR\u201d approach is consistent with the XP philosophy: if code reviews are good, do them as early as possible and on \ufb01ne-grained evolution of the code. The disadvantage is that it may create additional work for other team members compared to the simpler \u201cPlease look over my code now\u201d approach, especially if the developer opening the PR is experienced and unlikely to bene\ufb01t from very-early-stage code review. Self-Check 10.3.1. True or false: If you attempt git push and it fails with a message such as \u201cNon-fast-forward (error): failed to push some refs,\u201d this means some \ufb01le contains a merge con\ufb02ict between your repo\u2019s version and the origin repo\u2019s version. Not necessarily. It just means that your copy of the repo is missing some commits that are present in the origin copy, and until you merge in those missing commits, you won\u2019t be allowed to push your own commits. Merging in these missing commits may lead to a merge con\ufb02ict, but frequently does not."
    ]
  },
  {
    "id": "sec_0430",
    "title": "10.4 Delivering the Backlog Using Continuous Integration",
    "pages": [
      327,
      328,
      329,
      330,
      331,
      332
    ],
    "text_blocks": [
      "As Section 7.4 explained, the backlog is the somewhat pessimistic term for the work remain- ing to be done during the current Agile iteration. That section described how to prioritize and estimate the dif\ufb01culty of the iteration\u2019s planned work, and brie\ufb02y introduced Pivotal Tracker as a way to track the work. While there is no single \u201ccorrect\u201d work\ufb02ow for Agile teams, in this section we describe a widely-used work\ufb02ow and suggest best practices for using it effec- tively. We assume that the stories have already been prioritized and assigned points during an Iteration Planning Meeting, as Section 7.4 described. The key idea behind delivering the backlog is continuous integration (CI), which min- imizes the time between when changes are made on a feature branch and when those changes A full CI run may include compilation (for compiled languages) and running operational tests (Chapter 12) beyond the scope of the speci\ufb01c feature being developed. 316 CHAPTER 10. AGILE TEAMS are merged into the main branch and deployed for customer review. A good CI work\ufb02ow for Agile two-pizza teams starts with a shared team repo and the use of pull requests to integrate changes from feature branches into the main branch. We introduce two new concepts here that are central to CI. The \ufb01rst is that of a service such as Travis5, whose job is to run your complete test suite, usually in the cloud, each time signi\ufb01cant changes are made during de- velopment of a new feature. The rationale is that while you\u2019re continuously testing the code for the feature you\u2019re developing, you may not be taking the time to run the full test suite, which can take minutes or even tens of minutes for large projects. Somewhat confusingly, such services are usually called CI services, even though technically CI refers not just to run- ning the test suite but to the entire work\ufb02ow by which changes are integrated into mainline code. Most CI services can be connected directly to a GitHub repository and automatically trigger a CI run every time code is pushed to any branch in that repository. The second concept is that of a staging server, which is con\ufb01gured as similarly as possible to the production server but usually much smaller in scale. The purpose of a staging server is to provide a safe place to deploy new features for customer review before they are deployed in production. The staging server may not even be a speci\ufb01c persistent server like the production server, but an ephemeral one \u201cspun up\u201d just to give the customer the opportunity to see a speci\ufb01c feature in action. A staging server has its own copy of the database containing test data (possibly extracted from real customer data), and is usually off-limits to outside users. In this work\ufb02ow, we distinguish two copies of a repo, each of whose main branches is represented by a thick horizontal line in Figure 10.9. Initially, we will describe the work\ufb02ow from the point of view of the origin repo, which is owned by some team member and shared in the cloud by the team, and some developer\u2019s local clone of the origin. (We will use \u201cdevel- oper\u201d to mean either an individual team member or a pair working on a story.) The local repo is created by running git clone with the URL of the origin repo. From the point of view of the local repo, the origin repo is one of possibly several remotes, and usually the default remote when there is more than one. The following numbered steps are keyed to the numbers in the \ufb01gure, and annotated to indicate the associated state of the story in Pivotal Tracker. 1. On the main branch of local, the developer uses git pull origin main to ensure she has the most up-to-date version of main. 2. The developer creates a new feature branch for the story (Section 10.2). At this point the story state changes from Unstarted to Started. 3. The developer writes tests and code for the feature (Chapters 7 and 8), committing frequently. Periodically pushing the feature branch\u2019s commits to the origin repo (git push origin feature-branch) keeps a copy of the feature branch on the origin repo up-to-date with the one on the local feature branch. 4. This team has their work\ufb02ow con\ufb01gured so that any push to the origin repo will auto- matically trigger an external CI run on whatever branch was pushed. 5. When the code and tests are ready, the developer marks the story Finished, and opens a pull request. Note that the PR relates the topic branch on the origin repo to the main branch also on the origin repo, that is, the developer must have pushed the most recent commits on her local topic branch to its counterpart on origin. 10.4. DELIVERING THE BACKLOG USING CONTINUOUS INTEGRATION 317 Figure 10.9: A basic work\ufb02ow for a coordinated team delivering features when the team itself \u201cowns\u201d the app being developed. The boxes along the top indicate suggested interpretation of the Pivotal Tracker story states (started, \ufb01nished, delivered, accepted) relative to events in the work\ufb02ow. 6. Other team members review and comment on the PR (Section 10.3), in this case leading to required changes by the developer, who makes the changes and reopens the PR (or opens a new one). 7. The revised PR is accepted and the changes are merged into the origin repo\u2019s main branch, triggering another CI run, since the main branch now includes not only this PR but possibly other developers\u2019 PRs that have been merged since Step 1. 8. Assuming CI passes, the origin\u2019s main branch is deployed to a staging server and the story is marked Delivered. The customer can now review and comment on the new feature. If the customer requests revisions, another round of changes, PR, and merging follows. With the above work\ufb02ow, in a team with several developers (or pairs) many stories and feature branches may be \u201cin \ufb02ight\u201d at the same time. What happens next depends on which repo is the base repo for the app, that is, the de\ufb01ni- tive repo from which the production app is released and which is stewarded by the app\u2019s owners. If the development team in question owns the app, then the team\u2019s origin repo may be the app\u2019s base repo as well. But if the app is owned by other developers, then their repo is the base repo, and this team\u2019s origin repo is just used for development. In that case, a pull request can be opened from the origin\u2019s main branch to the base repo\u2019s main branch to merge the changes, and goes through the usual process of review. Figure 10.10 shows this \u201cfork-and-pull\u201d collaboration model with the upstream or base repo shown as the top line. The subteam\u2019s origin repo, sometimes also called the head repo, is a fork of the base repo and opens PRs to merge head repo changes into the base repo. Just as feature branch developers may periodically rebase (Section 10.3) against their origin repo\u2019s main branch to get the latest changes and avoid later merge con\ufb02icts, the head repo may pull changes from the base repo for the same reason, but because of the way Git works, these changes cannot propagate directly from the base repo on GitHub to its fork. Instead, some developer must pull the changes into their own local copy of the repo, then push the changes to the appropriate branch of the origin repo. The of\ufb01cial GitHub tutorial on forking6 gives detailed steps for keeping a fork up-to-date with an upstream repo, though in your authors\u2019 opinion this alternative tutorial7 is both clearer and more concise. Fork historically meant a schism in which one team makes a copy of another team\u2019s source code and starts developing it independently, often against the wishes of the original authors. GitHub overloaded the term to mean \u201ccreating your own copy of a repo to which you want to contribute but lack push access.\u201d 318 CHAPTER 10. AGILE TEAMS Figure 10.10: Variation of Figure 10.9 when the team does not own the app being developed. The \ufb01nal steps now involve coordinating with the upstream repo\u2019s stewards to get the changes merged there, and then update the team\u2019s origin repo (via a two-step process, as the text describes) to get the latest upstream changes. These work\ufb02ows should make even more clear why Section 7.4 recommends keeping stories simple: A 1-point story is one whose implementation strategy is mostly known to the team, so it can be delivered quickly and predictably, and if mistakes are made, they can be easily undone with little time being wasted. As with all aspects of Agile, a short cycle with quick feedback is better than spending a lot of time making large changes that carry more uncertainty and risk. A small story also means a simple and short-lived branch, speeding up pull requests and often eliminating the need for rebasing. Still, no matter how careful your team is, sometimes a pull request may need to be revised before it\u2019s accepted, or the customer may partially reject a feature leading to the branch being modi\ufb01ed and the PR being reopened, as both \ufb01gures show. Such scenarios are part and parcel of Agile development, but to keep your repo clean and your team sane, we recommend mitigating such \u201cloops\u201d by following these best practices for delivering the backlog: 1. Follow your own advice. The goal of the Iteration Planning Meeting is to determine points and priorities for this iteration. Those decisions should be respected during the iteration, but if they need to be revisited, that should be a team effort rather than a unilateral decision by one developer. 2. Work on one story at a time. One developer or pair should \ufb01nish a story before starting stories that require other changes, unless they run into impediments that prevent further progress on delivering that story. 3. A sustainable pace is more important than total points. Rather than delivering 5 points all at once at the iteration\u2019s end, deliver 1 point per day for 5 days, giving the rest of the team (and the customer) the opportunity to review your contributions as they come in. Summary of pull-request-based work\ufb02ow using branch-per-feature: 1. Pick a story to implement and mark it \u201cStarted\u201d 2. Create and switch to a new feature branch for the story in your local copy of the repo 3. Develop code and tests using BDD and TDD on the branch, committing frequently 4. When the branch is ready for review and all tests are passing, open a pull request 10.4. DELIVERING THE BACKLOG USING CONTINUOUS INTEGRATION 319 5. Based on team feedback on the pull request, continue making changes on the branch until all feedback has been addressed 6. Merge the branch into the main or main branch 7. Mark the story \u201cFinished\u201d 8. The story will be marked \u201cDelivered\u201d when it is ready for the customer to try out, and \u201cAccepted\u201d when the customer signs off Summary of Delivering the Backlog via CI: \u2022 Continuous integration is about frequently integrating new code and tests into the mainline. Each integration provides an opportunity to get feedback from the team via \u201cmini code reviews\u201d during pull requests, and from the customer via frequent deployment to a staging server. \u2022 Central to CI is the continuous running of tests as code is developed, usually using a separate service such as Travis. \u2022 When a subteam is working on features, they may fork the upstream repo and do their teamwork on their development repo, issuing a \ufb01nal pull request to the up- stream repo when their own work\ufb02ow is complete. \u2022 CI relies heavily on automation. For example, work\ufb02ows can be constructed that automatically trigger a testing run optionally followed by automatic deployment to a staging server when commits are pushed to a speci\ufb01c repo or branch. Elaboration: Further Automating CI You can con\ufb01gure your work\ufb02ow so that CI not only runs automatically on every push, but if the push passes CI, it is automatically deployed to an ephemeral staging server for customer review. This way, both code reviews and customer reviews can occur before the formal merge of the PR integrates these changes into the main branch. Some companies such as Salesforce go even further: if any test fails in CI, the CI tool performs binary searches across recent commits to pinpoint which speci\ufb01c commit introduced a new bug, and automatically opens and assigns a bug report for the developer responsible for that commit (Hansma 2011). Self-Check 10.4.1. Can you think of a scenario in which it makes sense for the team to review a PR for a particular story, but it does not make sense to deploy the story to staging for the customer\u2019s feedback? Often, a customer-requested feature is broken down into many separate stories, some of which do not result in new functionality visible to the customer, such as adding a new model without yet creating any views for it. The customer\u2019s feedback will be needed as soon as there is a way to interact with the feature, even if incomplete, but not before. 320 CHAPTER 10. AGILE TEAMS"
    ]
  },
  {
    "id": "sec_0431",
    "title": "10.5 CHIPS: Agile Iterations",
    "pages": [
      332
    ],
    "text_blocks": [
      "CHIPS 10.5: Agile Iterations https://github.com/saasbook/hw-agile-iterations Perform one or two complete iterations of the Agile lifecycle by planning and tracking fea- tures for a SaaS app, adding code and tests for the features, deploying the features to staging and production, and using tools to track test coverage and code quality throughout."
    ]
  },
  {
    "id": "sec_0432",
    "title": "10.6 Reporting and Fixing Bugs: The Five R\u2019s",
    "pages": [
      332,
      333,
      334
    ],
    "text_blocks": [
      "Inevitably, bugs happen. If you\u2019re lucky, they are found before the software is in production, but production bugs happen too. Everyone on the team must agree on processes for managing the phases of the bug\u2019s lifecycle: 1. Reporting a bug 2. Reproducing the problem, or else Reclassifying it as \u201cnot a bug\u201d or \u201cwon\u2019t be \ufb01xed\u201d 3. Creating a Regression test that demonstrates the bug 4. Repairing the bug 5. Releasing the repaired code Any stakeholder may \ufb01nd and report a bug in server-side or client-side SaaS code. A member of the development or QA team must then reproduce the bug, documenting the environment and steps necessary to trigger it. This process may result in reclassifying the bug as \u201cnot a bug\u201d for various reasons: \u2022 This is not a bug but a request to make an enhancement or change a behavior that is working as designed \u2022 This bug is in a part of the code that is being undeployed or is otherwise no longer supported \u2022 This bug occurs only with an unsupported user environment, such as a very old browser lacking necessary features for this SaaS app \u2022 This bug is already \ufb01xed in the latest version (uncommon in SaaS, whose users are always using the latest version) Once the bug is con\ufb01rmed as genuine and reproducible, it\u2019s entered into a bug manage- ment system. A plethora of such systems exists, but the needs of many small to medium teams can be met by a tool you\u2019re already using: Pivotal Tracker allows marking a story as a Bug rather than a Feature, which assigns the story zero points but otherwise allows it to be tracked to completion just like a regular user story. An advantage of this tool is that Tracker manages the bug\u2019s lifecycle for you, so existing processes for delivering user stories can be readily adapted to \ufb01xing bugs. For example, \ufb01xing the bug must be prioritized relative to other work; in a waterfall process, this may mean prioritization relative to other outstanding Large projects for widely-used software may use considerably more complex bug tracking systems, such as the open-source Bugzilla8. \u201cSeverity 1\u201d bugs at Amazon.com require the responsible engineers to initiate a conference call within 15 minutes of learning of the bug\u2014a stricter responsiveness requirement than for on-call physicians! (Bod\u00edk et al. 2006) 10.6. REPORTING AND FIXING BUGS: THE FIVE R\u2019S 321 bugs while in the maintenance phase, but in an Agile process it usually means prioritization relative to developing new features from user stories. Using Tracker, the Product Manager can move the bug story above or below other stories based on the bug\u2019s severity and impact on the customer. For example, bugs that may cause data loss in production will get prioritized very high. The next step is repair, which always begins with \ufb01rst creating the simplest possible auto- mated test that fails in the presence of the bug, and then changing the code to make the test(s) pass green. This should sound familiar to you by now as a TDD practitioner, but this practice is true even in non-TDD environments: no bug can be closed out without a test. Depending on the bug, unit tests, functional tests, integration tests, or a combination of these may be required. Simplest means that the tests depend on as few preconditions as possible, tightly circumscribing the bug. For example, simplifying an RSpec unit test would mean minimiz- ing the setup preceding the test action or in the before block, and simplifying a Cucumber scenario would mean minimizing the number of Given or Background steps. These tests usually get added to the regular regression suite to ensure the bug doesn\u2019t recur undetected. A complex bug may require multiple commits to \ufb01x; a common policy in BDD+TDD projects is that commits with failing or missing tests shouldn\u2019t be merged to the main development branch until the tests pass green. Many bug tracking systems can automatically cross-reference bug reports with the commit-IDs that contain the associated \ufb01xes and regression tests. For example, using GitHub\u2019s service hooks9, a commit can be annotated with the story ID of the corresponding bug or feature in Tracker, and when that commit is pushed to GitHub, the story is automati- cally marked as Delivered. Depending on team protocol and the bug management system in use, the bug may be \u201cclosed out\u201d either immediately by noting which release will contain the \ufb01x or after the release actually occurs. As we will see in Chapter 12, in most Agile teams releases are very frequent, shortening the bug lifecycle. Summary: the 5 R\u2019s of bug \ufb01xing \u2022 A bug must be reported, reproduced, demonstrated in a regression test, and repaired, all before the bug \ufb01x can be released. \u2022 No bug can be closed out without an automated test demonstrating that we really understand the bug\u2019s cause. \u2022 Bugs that are really enhancement requests or occur only in obsolete versions of the code or in unsupported environments may be reclassi\ufb01ed to indicate they\u2019re not going to be \ufb01xed. Self-Check 10.6.1. Why do you think \u201cbug \ufb01x\u201d stories are worth zero points in Tracker even though they follow the same lifecycle as regular user stories? A team\u2019s velocity would be arti\ufb01cially in\ufb02ated by \ufb01xing bugs, since they\u2019d get points for implementing the feature in the \ufb01rst place and then more points for actually getting the implementation right. Self-Check 10.6.2. True or false: a bug that is triggered by interacting with another service (for example, authentication via Twitter) cannot be captured in a regression test because the 322 CHAPTER 10. AGILE TEAMS necessary conditions would require us to control Twitter\u2019s behavior. False: integration-level mocking and stubbing, for example using the Webmock gem10 or the techniques described in Section 8.4, can almost always be used to mimic the external conditions necessary to reproduce the bug in an automated test. Self-Check 10.6.3. True or false: a bug in which the browser renders the wrong content or layout due to JavaScript problems might be reproducible manually by a human being, but it cannot be captured in an automated regression test. False: tools such as Jasmine and Webdriver (Section 6.8) can be used to develop such tests."
    ]
  },
  {
    "id": "sec_0433",
    "title": "10.7 The Plan-And-Document Perspective on Managing Teams",
    "pages": [
      334,
      335
    ],
    "text_blocks": [
      "In Plan-And-Document processes, project management starts with the project manager. Project managers are the bosses of the projects: \u2022 They write the contract proposal to win the project from the customer. \u2022 They recruit the development team from existing employees and new hires. \u2022 They typically write team members\u2019 performance reviews, which shape salary in- creases. \u2022 From a Scrum perspective (Section 10.1), they act as Product Owner\u2014the primary customer contact\u2014and they act as Scrum Lead, as they are the interface to upper man- agement and they procure resources for the team. \u2022 As we saw in Section 7.9, project managers also estimate costs, make and maintain the schedule, and decide which risks to address and how to overcome or avoid them. \u2022 As you would expect for Plan-And-Document processes, project managers must docu- ment their project management plan. Figure 10.11 gives an outline of Project Manage- ment Plans from the corresponding IEEE standard. As a result of all these responsibilities, project managers receive much of the blame if projects have problems. Quoting a textbook author from his introduction to project manage- ment: . . . if a post mortem were to be conducted for every [problematic] project, it is very likely that a consistent theme would be encountered: project management was weak. \u2014(Pressman 2010) We cover four major tasks for project managers to increase their chances of being successful: 1. Team size, roles, space, communication 2. Managing people and con\ufb02icts 3. Inspections and metrics 4. Con\ufb01guration management 10.7. TEAMS: PLAN & DOCUMENT PERSPECTIVE 323 1. Project overview"
    ]
  },
  {
    "id": "sec_0434",
    "title": "1.1 Project summary",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0435",
    "title": "1.1.1 Purpose, scope and objectives",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0436",
    "title": "1.1.2 Assumptions and constraints",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0437",
    "title": "1.1.3 Project deliverables",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0438",
    "title": "1.1.4 Schedule and budget summary",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0439",
    "title": "1.2 Evolution of the plan",
    "pages": [
      335
    ],
    "text_blocks": [
      "2. References 3. De\ufb01nitions 4. Project context"
    ]
  },
  {
    "id": "sec_0440",
    "title": "4.1 Process model",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0441",
    "title": "4.2 Process improvement plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0442",
    "title": "4.3 Infrastructure plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0443",
    "title": "4.4 Methods, tools and techniques",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0444",
    "title": "4.5 Product acceptance plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0445",
    "title": "4.6 Project organization",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0446",
    "title": "4.6.1 External interfaces",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0447",
    "title": "4.6.2 Internal interfaces",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0448",
    "title": "4.6.3 Authorities and responsibilities",
    "pages": [
      335
    ],
    "text_blocks": [
      "5. Project planning"
    ]
  },
  {
    "id": "sec_0449",
    "title": "5.1 Project initiation",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0450",
    "title": "5.1.1 Estimation plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0451",
    "title": "5.1.2 Staf\ufb01ng plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0452",
    "title": "5.1.3 Resource acquisition plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0453",
    "title": "5.1.4 Project staff training plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0454",
    "title": "5.2 Project work plans",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0455",
    "title": "5.2.1 Work activities",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0456",
    "title": "5.2.2 Schedule allocation",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0457",
    "title": "5.2.3 Resource allocation",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0458",
    "title": "5.2.4 Budget allocation",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0459",
    "title": "5.2.5 Procurement plan",
    "pages": [
      335
    ],
    "text_blocks": [
      "6. Project assessment and control"
    ]
  },
  {
    "id": "sec_0460",
    "title": "6.1 Requirements management plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0461",
    "title": "6.2 Scope change control plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0462",
    "title": "6.3 Schedule control plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0463",
    "title": "6.4 Budget control plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0464",
    "title": "6.5 Quality assurance plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0465",
    "title": "6.6 Subcontractor management plan",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0466",
    "title": "6.7 Project closeout plan",
    "pages": [
      335
    ],
    "text_blocks": [
      "7. Product delivery 8. Supporting process plans"
    ]
  },
  {
    "id": "sec_0467",
    "title": "8.1 Project supervision and work environment",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0468",
    "title": "8.2 Decision management",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0469",
    "title": "8.3 Risk management",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0470",
    "title": "8.4 Con\ufb01guration management",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0471",
    "title": "8.5 Information management",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0472",
    "title": "8.5.1 Documentation",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0473",
    "title": "8.5.2 Communication and publicity",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0474",
    "title": "8.6 Quality assurance",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0475",
    "title": "8.7 Measurement",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0476",
    "title": "8.8 Reviews and audits",
    "pages": [
      335
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0477",
    "title": "8.9 Veri\ufb01cation and validation",
    "pages": [
      335,
      336,
      337,
      338,
      339
    ],
    "text_blocks": [
      "Figure 10.11: Format of a project management plan from the IEEE 16326-2009 ISO/IEC/IEEE Systems and Software Engineering\u2013Life Cycle Processes\u2013Project Management standard. 324 CHAPTER 10. AGILE TEAMS 1. Team size, roles, space, and communication. The Plan-and-Document processes can scale to larger sizes, where group leaders report to the project manager. However, each subgroup typically stays the size of the two-pizza teams we saw in Section 10.1. Size recommendations are three to seven people (Braude and Bernstein 2011) to no more than ten (Sommerville 2010). Fred Brooks gave us the reason in Chapter 7: adding people to the team increases parallelism, but also increases the amount of time each person must spend communicating. These team sizes are reasonable considering the fraction of time spent com- municating. Given we know the size of the team, members of a subgroup in Plan-and-Document pro- cesses can be given different roles in which they are expected to lead. For example (Pressman 2010): \u2022 Con\ufb01guration management leader \u2022 Quality assurance leader \u2022 Requirements management leader \u2022 Design leader \u2022 Implementation leader One surprising result is that the type of space for the team to work in affects project man- agement. One study found that colocating the team in open space could double productivity (Teasley et al. 2000). The reasons include that team members had easy access to each other for both coordination of their work and for learning, and they could post their work artifacts on the walls so that all could see. Another study of teams in open space concludes: One of the main drivers of success was the fact that the team members were at hand, ready to have a spontaneous meeting, advise on a problem, teach/learn something new, etc. We know from earlier work that the gains from being at hand drops off signi\ufb01cantly when people are \ufb01rst out of sight, and then most severely when they are more than 30 meters apart. \u2014(Allen and Henn 2006) Samosas are a popular stuffed deep-fried snack from India. While the team relies on email and texting for communicating and shares information in wikis and the like, there is also typically a weekly meeting to help coordinate the project. Recall that the goal is to minimize the time spent communicating unnecessarily, so it is im- portant that the meetings be effective. Below is our digest of advice from the many guidelines found on the Web on how to have ef\ufb01cient meetings. We use the acronym SAMOSAS as a memory device; surely bringing a plate of them will make for an effective meeting! \u2022 Start and stop meeting on time. \u2022 Agenda created in advance of meeting; if there is no agenda, then cancel the meeting. \u2022 Minutes must be recorded so everyone can recall results afterwards; the \ufb01rst agenda item is \ufb01nding a note taker. \u2022 One speaker at a time; no interruptions when another is speaking. \u2022 Send material in advance, since people read much faster than speakers talk. 10.7. TEAMS: PLAN & DOCUMENT PERSPECTIVE 325 \u2022 Action items at end of meeting, so people know what they should do as a result of the meeting. \u2022 Set the date and time of the next meeting. 2. Managing people and con\ufb02icts. Thousands of books have been written on how to manage people, but the two most useful ones that we have found are The One Minute Man- ager and How to Win Friends and In\ufb02uence People (Blanchard and Johnson 1982; Carnegie 1998). What we like about the \ufb01rst book is that it offers short quick advice. Be clear about the goals of what you want done and how well it should be done, but to encourage creativity, leave it up to the team member to decide how to do it. When meeting with individuals to review progress, start with positive feedback to help build their con\ufb01dence. Then, be honest with them about what is not going well, and what they need to do to \ufb01x it. Finally, conclude with positive feedback and encouragement to continue improving their work. What we like about the second book is that it helps teach the art of persuasion, to get people to do what you think should be done without ordering them to do it. These skills also help persuade people you cannot command: your customers and your management. Both books are helpful when it comes to resolving con\ufb02icts within a team. Con\ufb02icts are not necessarily bad, in that it can be better to have the con\ufb02ict than to let the project crash and burn. Intel Corporation labels this attitude constructive confrontation. If you have a strong opinion that a person is proposing the wrong thing technically, you are obligated to bring it up, even to your bosses. The Intel culture is to speak up even if you disagree with the highest ranked people in the room. If con\ufb02ict continues, given that Plan-and-Document processes have a project manager, that person can make the \ufb01nal decision. One reason the US made it to the moon in the 1960s is that a leader of NASA, Wernher von Braun, had a knack for quickly resolving con\ufb02icts on close decisions. His view was that picking an option arbitrarily but quickly was frequently better, since the choice was roughly 50-50, so that the project could move ahead rather than take the time to carefully collect all the evidence to see which choice was slightly better. However, once a decision is made, the teams needs to embrace it and move ahead. The Intel motto for this resolution is disagree and commit: \u201cI disagree, but I am going to help even if I don\u2019t agree.\u201d 3. Inspections and metrics. Inspections like design reviews and code reviews allow feedback on the system even before everything is working. The idea is that once you have a design and initial implementation plan, you are ready for feedback from developers beyond your team. Design and code reviews follow the Waterfall lifecycle in that each phase is completed in sequence before going on to the next phase, or at least for the phases of a single iteration in Spiral or RUP development. A design review is a meeting in which the authors of program present its design. The goal of the review is to improve software quality by bene\ufb01ting from the experience of the people attending the meeting. A code review is held once the design has been implemented. This peer-oriented feedback also helps with knowledge exchange within the organization and offers coaching that can help the careers of the presenters. Shalloway suggests that formal design and code reviews are often too late in the process to make a big impact on the result (Shalloway 2002). He recommends to instead have earlier, smaller meetings that he calls \u201capproach reviews.\u201d The idea is to have a few senior developers assist the team in coming up with an approach to solve the problem. The group brainstorms about different approaches to help \ufb01nd a good one. 326 CHAPTER 10. AGILE TEAMS If you plan to do a formal design review, Shalloway suggests that you \ufb01rst hold a \u201cmini- design review\u201d after the approach has been selected and the design is nearing completion. It involves the same people as before, but the purpose is to prepare for the formal review. The formal review itself should start with a high-level description of what the customers want. Then give the architecture of the software, showing the APIs of the components. It will be important to highlight the design patterns used at different levels of abstraction (see Chapter 11). You should expect to explain why you made the decisions, and whether you considered plausible alternatives. Depending on the amount of time and the interests of those at the meeting, the \ufb01nal phase would be to go through the code of the implemented methods. At all these phases, you can get more value from the review if you have a concrete list of questions or issues that you would like to hear about. One advantage of code reviews is that they encourage people outside your team to look at your comments as well as your code. As we don\u2019t have a tool that can enforce the advice from Chapter 9 about making sure the comments raise the level of abstraction, the only enforcing mechanism is the code review. In addition to reviewing the code and the comments, inspections can give feedback on every part of the project in Plan-and-Document processes: the project plan, schedule, re- quirements, testing plan, and so on. This feedback helps with veri\ufb01cation and validation of the whole project, to ensure that it is on a good course. There is even an IEEE standard on how to document the veri\ufb01cation and validation plan for the project, which Figure 10.12 shows. Like the algorithmic models for cost estimation (see Section 7.9), some researchers have advocated that software metrics could replace inspections or reviews to assess project quality and progress. The idea is to collect metrics across many projects in an organization over time, establish a baseline for new projects, and then see how the project is doing compared to baseline. This quote captures the argument for metrics: Without metrics, it is dif\ufb01cult to know how a project is executing and the quality level of the software. \u2014(Braude and Bernstein 2011) Below are sample metrics that can be automatically collected: \u2022 Code size, measured in thousands of lines of code (KLOC) or in function points (Sec- tion 7.9). \u2022 Effort, measured in person-months spent on project. \u2022 Project milestones planned versus ful\ufb01lled. \u2022 Number of test cases completed. \u2022 Defect discovery rate, measured in defects discovered (via testing) per month. \u2022 Defect repair rate, measured in defects \ufb01xed per month. Other metrics can be derived from these so as to normalize the numbers to help compare results from different projects: KLOC per person-month, defects per KLOC, and so on. The problem with this approach is that there is little evidence of correlation between these metrics that we can automatically collect and project outcomes. Ideally, the metrics would 10.7. TEAMS: PLAN & DOCUMENT PERSPECTIVE 327"
    ]
  },
  {
    "id": "sec_0478",
    "title": "5.4 Hardware V&V Processes, Activities and Tasks",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0479",
    "title": "5.4.1 Hardware Concept",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0480",
    "title": "5.4.2 Hardware Requirements",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0481",
    "title": "5.4.3 Hardware Design",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0482",
    "title": "5.4.4 Hardware Fabrication",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0483",
    "title": "5.4.5 Hardware Integration Test",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0484",
    "title": "5.4.6 Hardware Quali\ufb01cation Test",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0485",
    "title": "5.4.7 Hardware Acceptance Test",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0486",
    "title": "5.4.8 Hardware Transition",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0487",
    "title": "5.4.9 Hardware Operation",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0488",
    "title": "5.4.10 Hardware Maintenance",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0489",
    "title": "5.4.11 Hardware Disposal",
    "pages": [
      339
    ],
    "text_blocks": [
      "6. V&V reporting requirements"
    ]
  },
  {
    "id": "sec_0490",
    "title": "6.1 Task reports",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0491",
    "title": "6.2 Anomaly reports",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0492",
    "title": "6.3 V&V \ufb01nal report",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0493",
    "title": "6.4 Special studies reports (optional)",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0494",
    "title": "6.5 Other reports (optional)",
    "pages": [
      339
    ],
    "text_blocks": [
      "7. V&V administrative requirements"
    ]
  },
  {
    "id": "sec_0495",
    "title": "7.1 Anomaly resolution and reporting",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0496",
    "title": "7.2 Task iteration policy",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0497",
    "title": "7.3 Deviation policy",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0498",
    "title": "7.4 Control procedures",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0499",
    "title": "7.5 Standards, practices, and conventions",
    "pages": [
      339
    ],
    "text_blocks": [
      "8. V&V test documentation requirements 1. Purpose 2. Referenced documents 3. De\ufb01nitions 4. V&V overview"
    ]
  },
  {
    "id": "sec_0500",
    "title": "4.1 Organization",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0501",
    "title": "4.2 Top-level schedule",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0502",
    "title": "4.3 Integrity level scheme",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0503",
    "title": "4.4 Resources summary",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0504",
    "title": "4.5 Responsibilities",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0505",
    "title": "4.6 Tools, techniques, and methods",
    "pages": [
      339
    ],
    "text_blocks": [
      "5. V&V processes"
    ]
  },
  {
    "id": "sec_0506",
    "title": "5.1 Common V&V Processes, Activities and Tasks",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0507",
    "title": "5.2 System V&V Processes, Activities and Tasks",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0508",
    "title": "5.2.1 Acquisition Support",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0509",
    "title": "5.2.2 Supply Planning",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0510",
    "title": "5.2.3 Project Planning",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0511",
    "title": "5.2.4 Con\ufb01guration Management",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0512",
    "title": "5.2.5 Stakeholder Requirements De\ufb01nition",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0513",
    "title": "5.2.6 Requirements Analysis",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0514",
    "title": "5.2.7 Architectural Design",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0515",
    "title": "5.2.8 Implementation",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0516",
    "title": "5.2.9 Integration",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0517",
    "title": "5.2.10 Transition",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0518",
    "title": "5.2.11 Operation",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0519",
    "title": "5.2.12 Maintenance",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0520",
    "title": "5.2.13 Disposal",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0521",
    "title": "5.3 Software V&V Processes, Activities and Tasks",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0522",
    "title": "5.3.1 Software Concept",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0523",
    "title": "5.3.2 Software Requirements",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0524",
    "title": "5.3.3 Software Design",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0525",
    "title": "5.3.4 Software Construction",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0526",
    "title": "5.3.5 Software Integration Test",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0527",
    "title": "5.3.6 Software Quali\ufb01cation Test",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0528",
    "title": "5.3.7 Software Acceptance Test",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0529",
    "title": "5.3.8 Software Installation and Checkout (Transition)",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0530",
    "title": "5.3.9 Software Operation",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0531",
    "title": "5.3.10 Software Maintenance",
    "pages": [
      339
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0532",
    "title": "5.3.11 Software Disposal",
    "pages": [
      339,
      340,
      341
    ],
    "text_blocks": [
      "Figure 10.12: Outline of a plan for System and Software Veri\ufb01cation and Validation from the IEEE 1012-2012 Standard. 328 CHAPTER 10. AGILE TEAMS correlate and we could have much \ufb01ner-grained understanding than comes from the occa- sional and time-consuming inspections. This quote captures the argument de-emphasizing metrics: However, we are still quite a long way from this ideal situation, and there are no signs that automated quality assessment will become a reality in the foreseeable future. \u2014(Sommerville 2010) 4. Con\ufb01guration management. Con\ufb01guration management includes four varieties of changes, three of which we have seen before. The \ufb01rst is version control , sometimes also called source and con\ufb01guration management (SCM), described in Sections 10.2\u201310.4. This variety keeps track of versions of components as they are changed. The second, system building, is closely related to the \ufb01rst. Tools like make assemble the compatible versions of components into an executable program for the target system. The third variety is release management, which we cover in Chapter 12. The last is change management, which comes from change requests made by customers and other stakeholders to \ufb01x bugs or to improve functionality (see Section 9.7). As you surely expect by now, IEEE has a standard for Con\ufb01guration Management. Fig- ure 10.13 shows its table of contents. Summary: In Plan-and-Document processes: \u2022 Project managers are in charge: they write the contract, recruit the team, and inter- face with the customer and upper management. \u2022 The project manager documents the project plan and con\ufb01guration plan, along with the veri\ufb01cation and validation plan that ensures that other plans are followed! \u2022 To limit time spent communicating, groups are three to ten people. They can be composed into hierarchies to form larger teams reporting to the project manager, with each group having its own leader. \u2022 Guidelines for managing people include giving them clear goals but empowering them, and starting with the positive feedback in reviews but being honest about shortcomings and how to overcome them. \u2022 While con\ufb02icts need to be resolved, they can be helpful in \ufb01nding the best path forward for a project. \u2022 Inspections like design reviews and code reviews let outsiders give feedback on the current design and future plans. Such reviews allow the team to bene\ufb01t from the experience of others. They are also a good way to check if good practices are being followed and if the plans and documents are sensible. \u2022 Con\ufb01guration management is a broad category that includes change management while maintaining a product, version control of software components, system build- ing of a coherent working program from those components, and release management to ship the product to customers. 10.7. TEAMS: PLAN & DOCUMENT PERSPECTIVE 329 Table of Contents 1. Overview"
    ]
  },
  {
    "id": "sec_0533",
    "title": "1.1 Scope",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0534",
    "title": "1.2 Purpose",
    "pages": [
      341
    ],
    "text_blocks": [
      "2. De\ufb01nitions, acronyms, and abbreviations"
    ]
  },
  {
    "id": "sec_0535",
    "title": "2.1 De\ufb01nitions",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0536",
    "title": "2.2 Acronyms and abbreviations",
    "pages": [
      341
    ],
    "text_blocks": [
      "3. Tailoring 4. Audience 5. The con\ufb01guration management process 6. CM planning lower-level process"
    ]
  },
  {
    "id": "sec_0537",
    "title": "6.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0538",
    "title": "6.2 Activities and tasks",
    "pages": [
      341
    ],
    "text_blocks": [
      "7. CM management lower-level process"
    ]
  },
  {
    "id": "sec_0539",
    "title": "7.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0540",
    "title": "7.2 Activities and tasks",
    "pages": [
      341
    ],
    "text_blocks": [
      "8. Con\ufb01guration identi\ufb01cation lower-level process"
    ]
  },
  {
    "id": "sec_0541",
    "title": "8.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0542",
    "title": "8.2 Activities and tasks",
    "pages": [
      341
    ],
    "text_blocks": [
      "9. Con\ufb01guration change control lower-level process"
    ]
  },
  {
    "id": "sec_0543",
    "title": "9.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0544",
    "title": "9.2 Activities and Tasks",
    "pages": [
      341
    ],
    "text_blocks": [
      "10. Con\ufb01guration status accounting lower-level process"
    ]
  },
  {
    "id": "sec_0545",
    "title": "10.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0546",
    "title": "10.2 Activities and tasks",
    "pages": [
      341
    ],
    "text_blocks": [
      "11. CM con\ufb01guration auditing lower-level process"
    ]
  },
  {
    "id": "sec_0547",
    "title": "11.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0548",
    "title": "11.2 Activities and Tasks",
    "pages": [
      341
    ],
    "text_blocks": [
      "12. Interface control lower-level process"
    ]
  },
  {
    "id": "sec_0549",
    "title": "12.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0550",
    "title": "12.2 Activities and Tasks",
    "pages": [
      341
    ],
    "text_blocks": [
      "13. Supplier con\ufb01guration item control lower-level process"
    ]
  },
  {
    "id": "sec_0551",
    "title": "13.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0552",
    "title": "13.2 Activities and Tasks",
    "pages": [
      341
    ],
    "text_blocks": [
      "14. Release management lower-level process"
    ]
  },
  {
    "id": "sec_0553",
    "title": "14.1 Purpose",
    "pages": [
      341
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0554",
    "title": "14.2 Activities and tasks",
    "pages": [
      341,
      342
    ],
    "text_blocks": [
      "Figure 10.13: A table of contents for the IEEE 828-2012 Standard for Con\ufb01guration Management in Systems and Software Engineering. 330 CHAPTER 10. AGILE TEAMS Self-Check 10.7.1. Compare the size of teams in Plan-and-Document processes versus Agile processes. Plan-and-Document processes can form hierarchies of subgroups to create a much larger project, but each subgroup is basically the same size as a \u201ctwo-pizza\u201d team for Agile. Self-Check 10.7.2. True or False: Design reviews are meetings intended to improve the quality of the software product using the wisdom of the attendees, but they also result in technical information exchange and can be highly educational for junior members of the organization, whether presenters or just attendees. True."
    ]
  },
  {
    "id": "sec_0555",
    "title": "10.8 Fallacies and Pitfalls",
    "pages": [
      342,
      343,
      344
    ],
    "text_blocks": [
      "Fallacy: If a software project is falling behind schedule, you can catch up by adding more people to the project. The main theme of Fred Brooks\u2019s classic book, The Mythical Man-Month, is that not only does adding people not help, it makes it worse. The reason is twofold: it takes a while for new people to learn about the project, and as the size of the team grows, the amount of communication increases, which can reduce the time available for people to get their work done. His summary, which some call Brooks\u2019s Law, is: Adding manpower to a late software project makes it later. \u2014Fred Brooks, Jr. Pitfall: Dividing work based on the software stack rather than on features. It\u2019s less common than it used to be to divide the team into a front-end specialist, back-end specialist, customer liaison, and so forth, but it still happens. Your authors and others believe that better results come from having each team member deliver all aspects of a chosen feature or story\u2014Cucumber scenarios, RSpec tests, views, controller actions, model logic, and so on. Especially when combined with pair programming, having each developer maintain a \u201cfull stack\u201d view of the product spreads architectural knowledge around the team. Fallacy: It\u2019s \ufb01ne to make simple changes on the main branch. Programmers are optimists. When we set out to change our code, we always think it will be a one-line change. Then it turns into a \ufb01ve-line change; then we realize the change affects another \ufb01le, which has to be changed as well; then it turns out we need to add tests or change existing tests that relied on the old code; and so on. For this reason, always create a feature branch when starting new work. Branching with Git is nearly instantaneous, and if the change truly does turn out to be small, you can delete the branch after merging to avoid having it clutter your branch namespace. Pitfall: Forgetting to add \ufb01les to the repo. If you create a new \ufb01le but forget to add it to the repo, your copy of the code will still work but when others pull your changes your code won\u2019t work for them. Use git status 10.8. FALLACIES AND PITFALLS 331 regularly to see the list of Untracked Files, and use the .gitignore \ufb01le to avoid being warned about \ufb01les you never want to track, such as binary \ufb01les or temporary \ufb01les. Pitfall: Versioning \ufb01les that shouldn\u2019t be versioned. If a \ufb01le isn\u2019t required to run the code, it probably shouldn\u2019t be in the repo: temporary \ufb01les, binary \ufb01les, log \ufb01les, and so on should not be versioned. If \ufb01les of test data are versioned, they should be part of a proper test suite. Files containing sensitive information such as API keys should never be checked into GitHub in plaintext (i.e. without encryption). If the \ufb01les must be checked in, they should be encrypted. Pitfall: Accidentally stomping on changes after merging or switching branches. If you do a pull or a merge, or if you switch to a different branch, some \ufb01les may suddenly have different contents on disk. If any such \ufb01les are already loaded into your editor, the versions being edited will be out of date, and even worse, if you now save those \ufb01les, you will either overwrite merged changes or save a \ufb01le that isn\u2019t in the branch you think it is. The solution is simple: before you pull, merge or switch branches, make sure you commit all current changes; after you pull, merge or switch branches, reload any \ufb01les in your editor that may be affected\u2014or to be really safe, just quit your editor before you commit. Be careful too about the potentially destructive behavior of certain Git commands such as git reset. Pitfall: Letting your copy of the repo get too far out of sync with the origin (authoritative) copy. It\u2019s best not to let your copy of the repo diverge too far from the origin, or merges (Sec- tion 10.2) will be painful. You should update frequently from the origin repo before starting work, and if necessary, rebase incrementally so you don\u2019t drift too far away from the main branch. Fallacy: Since each subteam is working on its own branch, we don\u2019t need to communicate regularly or merge frequently. Branches are a great way for different team members to work on different features simul- taneously, but without frequent merges and clear communication of who\u2019s working on what, you risk an increased likelihood of merge con\ufb02icts and accidental loss of work when one developer \u201cresolves\u201d a merge con\ufb02ict by deleting another developer\u2019s changes. Pitfall: Making commits too large. Git makes it quick and easy to do a commit, so you should do them frequently and make each one small, so that if some commit introduces a problem, you don\u2019t have to also undo all the other changes. For example, if you modi\ufb01ed two \ufb01les to work on feature A and three other \ufb01les to work on feature B, do two separate commits in case one set of changes needs to be undone later. In fact, advanced Git users use git add with speci\ufb01c \ufb01les, rather than git add . which adds every \ufb01le in the current directory, to \u201ccherry pick\u201d a subset of changed \ufb01les to include in a commit. And don\u2019t forget that no one else will see the commit until you use git push to propagate them to the team\u2019s origin repo. 332 CHAPTER 10. AGILE TEAMS"
    ]
  },
  {
    "id": "sec_0556",
    "title": "10.9 Concluding Remarks: From Solo Developer to Teams of Teams",
    "pages": [
      344,
      345,
      346,
      347,
      348
    ],
    "text_blocks": [
      "The \ufb01rst 90% of the code accounts for the \ufb01rst 10% of the development time. The remain- ing 10% of the code accounts for the other 90% of the development time. \u2014Tom Cargill, quoted in Programming Pearls, 1985 The history of version control systems mirrors the movement towards distributed col- laboration among \u201cteams of teams,\u201d with two-pizza teams emerging as a popular unit of cohesiveness. From about 1970\u20131985, the original Unix Source Code Control System (SCCS) and its longer-lived descendant Revision Control System (RCS) required the repo and all development to stay on the same computer (which might be a multi-user system) and disallowed simultaneous editing of the same \ufb01le by different developers. The Concurrent Versions System (CVS) and Subversion introduced simultaneous editing and branches, but only a single repo. Git completed the decentralization by allowing any copy of a repo to push or pull from any other, enabling completely decentralized \u201cteams of teams,\u201d and by mak- ing branching and merging much quicker and easier than its predecessors. Today, distributed collaboration is the norm: rather than a large distributed team, fork-and-pull allows a large number of Agile two-pizza teams to make independent progress, and the use of Git to sup- port such efforts has become ubiquitous. The two-pizza team size makes it easier for a team to stay organized than the giant programming teams possible in Plan-and-Document. The decentralized approach also distributes responsibility for project planning and cost esimation more than P&D, which relies on the project manager to make the time and cost estimates, assess risks, and to run the project so that it delivers the product on time and on budget with the required functionality. We have previously seen two examples of processes in which the P&D and Agile versions comprise the same skills and steps, but sequenced differently. Test-driven development uses the same elements as conventional code writing followed by debugging, but in a different order. Agile iterations include the same elements as a waterfall project, but in a different order. Team coordination is a third example: Agile teams use the same processes as P&D teams\u2014releases, code reviews, customer reviews, cost and effort estimation, assignment of different parts of the coding task to different developers\u2014but in a different order. Agile proponents believe the techniques in this chapter can help an agile team avoid many of the pitfalls that have made software projects infamous for being late and over budget. Checking in continuously with other developers (via PRs) and customers (via frequent deployments to staging) during each iteration guides your team into spending its resources most effectively and is more likely to result in software that makes customers happy within the time and cost budget. A disciplined work\ufb02ow using version control allows developers to make progress on many fronts simultaneously without interfering with each others\u2019 work, and also allows disciplined and systematic management of the bug lifecycle. Finally, as with any experience, you should re\ufb02ect on what went well, what didn\u2019t go well, and what you would do differently. It is not a sin to make a mistake, as long as you learn from it; the sin is making the same mistake repeatedly. Many Agile teams\u2019 end-of-iteration Retrospective meeting allows this learning to happen incrementally each week and makes the team more cohesive over time, rather than waiting until the end of a long project to determine what could have gone better. For more comprehensive details on this chapter\u2019s topics, we recommend these resources: \u2022 You can \ufb01nd very detailed descriptions of Git\u2019s powerful features in Version Control REFERENCES 333 With Git (Loeliger 2009), which takes a more tutorial approach, and in the free Git Community Book11, which is also useful as a thorough reference on Git. For de- tailed help on a speci\ufb01c command, use git help command, for example, git help branch; but be aware that these explanations are for reference, not tutorial. \u2022 Atlassian has an excellent set of tutorials12 covering many Git-related topics, including rebasing. \u2022 Many medium-sized projects that don\u2019t use Pivotal Tracker, or whose bug-management needs go somewhat beyond what Tracker provides, rely on the Issues feature built into every GitHub repo. The Issues system allows each team to create appropriate \u201clabels\u201d for different bug types and priorities and create their own \u201cbug lifecycle\u201d process. T. J. Allen and G. Henn. The Organization and Architecture of Innovation: Managing the Flow of Technology. Butterworth\u2013Heinemann, 2006. K. H. Blanchard and S. Johnson. The One Minute Manager. William Morrow, Cambridge, MA, 1982. P. Bod\u00edk, A. Fox, M. I. Jordan, D. Patterson, A. Banerjee, R. Jagannathan, T. Su, S. Teng- inakai, B. Turner, and J. Ingalls. Advanced tools for operators at Amazon.com. In First Workshop on Hot Topics in Autonomic Computing (HotAC\u201906), Dublin, Ireland, June 2006. E. Braude and M. Bernstein. Software Engineering: Modern Approaches, Second Edition. John Wiley and Sons, 2011. ISBN 9780471692089. D. Carnegie. How to Win Friends and In\ufb02uence People. Pocket, 1998. S. Hansma. Go fast and don\u2019t break things: Ensuring quality in the cloud. In Workshop on High Performance Transaction Systems (HPTS 2011), Asilomar, CA, Oct 2011. Summa- rized in Conference Reports column of USENIX ;login 37(1), February 2012. D. Holland. Red Zone Management. WinHope Press, 2004. ISBN 0967140188. J. Loeliger. Version Control with Git: Powerful Tools and Techniques for Collaborative Software Development. O\u2019Reilly Media, 2009. ISBN 0596520123. R. Pressman. Software Engineering: A Practitioner\u2019s Approach, Seventh Edition. McGraw- Hill, 2010. ISBN 0073375977. K. Schwaber and M. Beedle. Agile Software Development with Scrum (Series in Agile Software Development). Prentice Hall, 2001. ISBN 0130676349. A. Shalloway. netobjectives.com/download/designreviews.pdf. Agile Design and Code Reviews. 2002. URL http://www. I. Sommerville. Software Engineering, Ninth Edition. Addison-Wesley, 2010. 0137035152. ISBN S. Teasley, L. Covi, M. S.Krishnan, and J. S. Olson. How does radical collocation help In Proceedings of the 2000 ACM conference on Computer supported a team succeed? cooperative work, pages 339\u2013346, Philadelphia, Pennsylvania, December 2000. 334 Notes NOTES 1https://sp19.datastructur.es/materials/guides/using-git.html 2https://rework.withgoogle.com/guides/understanding-team-effectiveness/steps/ introduction/ 3https://github.com/bbatsov/rails-style-guide 4https://www.atlassian.com/git/tutorials 5http://travis-ci.org 6https://help.github.com/en/github/getting-started-with-github/fork-a-repo 7https://gist.github.com/Chaser324/ce0505fbed06b947d962 8http://mozilla.org 9http://github.com/ 10https://github.com/bblimke/webmock 11http://book.git-scm.com 12https://www.atlassian.com/git/tutorials NOTES 335 11 Design Patterns for SaaS Apps William Kahan (1933\u2013) received the 1989 Turing Award for his fundamental contributions to numerical analysis. Kahan dedicated himself to \u201cmaking the world safe for numerical computations.\u201d Things are genuinely simple when you can think correctly about what\u2019s going on without having a lot of extraneous or confusing thoughts to impede you. Think of Einstein\u2019s maxim, \u201cEverything should be made as simple as possible, but no simpler.\u201d \u2014\u201cA Conversation with William Kahan,\u201d Dr. Dobbs\u2019 Journal, 1997 . . . . . . . ."
    ]
  },
  {
    "id": "sec_0557",
    "title": "11.1 Patterns, Antipatterns, and SOLID Class Architecture .",
    "pages": [
      348
    ],
    "text_blocks": [
      ". . . . . ."
    ]
  },
  {
    "id": "sec_0558",
    "title": "11.2 Just Enough UML .",
    "pages": [
      348
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0559",
    "title": "11.3 Single Responsibility Principle",
    "pages": [
      348
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0560",
    "title": "11.4 Open/Closed Principle .",
    "pages": [
      348
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0561",
    "title": "11.5 Liskov Substitution Principle .",
    "pages": [
      348
    ],
    "text_blocks": [
      ". . . ."
    ]
  },
  {
    "id": "sec_0562",
    "title": "11.6 Dependency Injection Principle .",
    "pages": [
      348
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0563",
    "title": "11.7 Demeter Principle .",
    "pages": [
      348
    ],
    "text_blocks": [
      ". . . . ."
    ]
  },
  {
    "id": "sec_0564",
    "title": "11.8 The Plan-And-Document Perspective on Design Patterns .",
    "pages": [
      348
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0565",
    "title": "11.9 6S: A Clean Code Checklist",
    "pages": [
      348,
      349,
      350
    ],
    "text_blocks": [
      ". . . 11.10Fallacies and Pitfalls . 11.11Concluding Remarks: Frameworks Capture Design Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338 . 342 . 345 . 347 . 351 . 354 . 358 . 362 . 363 . 365 . 366 337 Prerequisites and Concepts The big concept of this chapter is that design patterns can improve the quality of the classes. A design pattern captures proven solutions to problems by separating the things that change from those that don\u2019t. Concepts: Five object-oriented design principles identied by the acronym SOLID describe sound design of interactions among classes. An antipattern indicates poor class design, which a design smell can identify. Thus, using design smells to detect violations to the SOLID principles for good class design is analogous to using code smells to detect violations of the SOFA principles for good method design (Section 9.5). The ve letters of the SOLID acronym stand for: 1. Single Responsibility Principle: a class should have one and only one responsibility; that is, only one reason to change. The Lack of Cohesion Of Methods metric indicates the antipattern of too large a class. 2. Open/Closed Principle: a class should be open for extension, but closed against modication. The Case Statement design smell suggests a violation. 3. Liskov Substitution Principle: a method designed to work on an object of type T should also work on an object of any subtype of T. That is, all of T\u2019s subtypes should preserve T\u2019s contract. The refused bequest design smell often indicates a violation. 4. Dependency Injection Principle: if two classes depend on each other but their implementations may change, it would be better for them to both depend on a separate abstract interface which is injected between them. 5. Demeter Principle: a method can call other methods in its own class, and methods on the classes of its own instance variables; everything else is taboo. A design smell that indicates a violation is inappropriate intimacy. For Agile, refactoring is the vehicle for improving the design of classes and methods; In in some cases refactoring may allow you to apply an appropriate design pattern. contrast, for the Plan-and-Document lifecycles: \u2022 The early design phase makes it easier to select a good initial software architecture and class designs. \u2022 The specication is broken into problems and then into subproblems, where devel- opers try to use patterns to solve them. \u2022 As design precedes coding, design reviews can offer early feedback. \u2022 One concern is whether the design must change once coding begins. 338 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS Figure 11.1: The Agile software lifecycle and its relationship to the chapters in this book. This chapter covers design patterns, which in\ufb02uence BDD and TDD for new apps and for enhancing legacy code."
    ]
  },
  {
    "id": "sec_0566",
    "title": "11.1 Patterns, Antipatterns, and SOLID Class Architecture",
    "pages": [
      350,
      351,
      352,
      353,
      354
    ],
    "text_blocks": [
      "In Chapter 3, we introduced the idea of a design pattern: a reusable structure, behavior, strategy, or technique that captures a proven solution to a collection of similar problems by separating the things that change from those that stay the same. Patterns play a major role in helping us achieve our goal throughout this book: producing code that is not only correct (TDD) and meets a customer need (BDD), but is also concise, readable, DRY, and generally beautiful. Figure 11.1 highlights the role of design patterns in the Agile lifecycle as covered in this chapter. While we have already seen architectural patterns such as Client\u2013Server and structural patterns such as Model\u2013View\u2013Controller, this chapter examines design patterns that apply to classes and class architecture. As Figure 11.2 shows, we will follow a similar approach as we did in Chapter 9. Rather than simply listing a catalog of design patterns, we\u2019ll motivate their use by starting from some guidelines about what makes a class architecture good or bad, identifying smells and metrics that indicate possible problem spots, and showing how some of these problems can be \ufb01xed by refactoring\u2014both within classes and by moving code across classes\u2014to eliminate the problems. In some cases, we can refactor to make the code match an existing and proven design pattern. In other cases, the refactoring doesn\u2019t necessarily result in major structural changes to the class architecture. As with method-level refactoring, application of design patterns is best learned by doing, and the number of design patterns exceeds what we can cover in one chapter of one book. Indeed, there are entire books just on design patterns, including the seminal Design Patterns: Elements of Reusable Object-Oriented Software (Gamma et al. 1994), whose authors became known as the \u201cGang of Four\u201d or GoF, and their catalog known as the \u201cGoF design pat- 11.1. PATTERNS, ANTIPATTERNS, AND SOLID 339 Chapter 9 Code smells warn of problems in methods of a class Many catalogs of code smells and refactorings; we use Fowler\u2019s as de\ufb01nitive ABC, Cyclomatic Complexity metrics complement code smells with quantitative warnings Refactoring by extracting methods and moving code within a class SOFA guidelines for good methods (Short, do One thing, Few arguments, single Abstraction level) Some code smells don\u2019t apply in Ruby Chapter 11 Design smells warn of problems in relationships among classes Many catalogs of design smells and design patterns; we use Ruby-speci\ufb01c versions of the Gang of Four (GoF) design patterns as de\ufb01nitive LCOM (Lack of Cohesion of Methods) metric com- plements design smells with quantitative warnings Refactoring by extracting classes and moving code be- tween classes SOLID guidelines for good class architecture (Single responsibility, Open/Closed, Liskov substitution, de- pendency Injection, Demeter) Some design smells don\u2019t apply in Ruby or SaaS Figure 11.2: The parallels between the warning symptoms and remedies introduced for individual classes and methods in Chapter 9 and those introduced for inter-class relationships in this chapter. For reasons explained in the text, whereas most books use the I in SOLID for Interface Segregation (a smell that doesn\u2019t arise in Ruby) and D for injecting Dependencies, we instead use I for Injecting dependencies and D for the Demeter principle, which arises frequently in Ruby. terns.\u201d The 23 GoF design patterns are divided into Creational, Structural, and Behavioral design patterns, as Figure 11.3 shows. As with Fowler\u2019s original book on refactoring, the GoF design patterns book gave rise to other books with examples tailored to speci\ufb01c lan- guages including Ruby (Olsen 2007). The GoF authors cite two overarching principles of good object-oriented design that in- form most of the patterns: \u2022 Prefer Composition and Delegation over Inheritance. \u2022 Program to an Interface, not an Implementation. We will learn what these catch-phrases mean as we explore some speci\ufb01c design patterns. In an ideal world, all programmers would use design patterns tastefully, continuously refactoring their code as Chapter 9 suggests, and all code would be beautiful. Needless to say, this is not always the case. An antipattern is a piece of code that seems to want to be expressed in terms of a well-known design pattern, but isn\u2019t\u2014often because the original (good) code has evolved to \ufb01ll new needs without refactoring along the way. Design smells, similar to the code smells we saw in Chapter 9, are warning signs that your code may be headed towards an antipattern. In contrast to code smells, which typically apply to methods within a class, design smells apply to relationships between classes and how responsibilities are divided among them. Therefore, whereas refactoring a method involves moving code around within a class, refactoring a design involves moving code between classes, creating new classes or modules (perhaps by extracting commonality from existing ones), or removing classes that aren\u2019t pulling their weight. Similar to SOFA in Chapter 9, the mnemonic SOLID (credited to Robert C. Martin) stands for a set of \ufb01ve design principles that clean code should respect. As in Chapter 9, design smells and quantitative metrics can tell us when we\u2019re in danger of violating one or more SOLID guidelines; the \ufb01x is often a refactoring that eliminates the problem by bringing the code in line with one or more design patterns. Since the GoF design patterns evolved in the context of statically typed languages, some of them address problems that don\u2019t arise in Ruby. For example, patterns that eliminate type signature changes that would trigger recompilation are rarely used in Ruby, which isn\u2019t compiled and doesn\u2019t use types to enforce contracts. \u201cUncle Bob\u201d Martin, an American software engineer and consultant1 since 1970, is a founder of Agile/XP and a leading member of the Software Craftsmanship movement, which encourages programmers to see themselves as creative professionals learning a disciplined craft in an apprenticeship model. 340 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS Creational patterns Abstract Factory, Factory Method: Provide an interface for creating families of related or dependent objects without specifying their concrete classes Singleton: Ensure a class has only one instance, and provide a global point of access to it. Prototype: Specify the kinds of objects to create using a prototypical instance, and create new objects by copying this prototype. As we\u2019ve seen in Chapter 6, prototype-based inheritance is part of the JavaScript language. Builder: Separate the construction of a complex object from its representation allowing the same construction process to create various representations Structural patterns Adapter, Proxy, Fa\u00e7ade, Bridge: Convert the programming interface of a class into another (sometimes sim- pler) interface that clients expect, or decouple an abstraction\u2019s interface from its implementation, for depen- dency injection or performance Decorator: Attach additional responsibilities to an object dynamically, keeping the same interface. Helps with \u201cPrefer composition or delegation over inheritance.\u201d Composite: Provide operations that work on both an individual object and a collection of that type of object Flyweight: Use sharing to support large numbers of similar objects ef\ufb01ciently Behavioral patterns Template Method, Strategy: Uniformly encapsulate multiple varying strategies for same task Observer: One or more entities need to be noti\ufb01ed when something happens to an object Iterator, Visitor: Separate traversal of a data structure from operations performed on each element of the data structure Null Object: (Doesn\u2019t appear in GoF catalog) Provide an object with de\ufb01ned neutral behaviors that can be safely called, to take the place of conditionals guarding method calls State: Encapsulate an object whose behaviors (methods) differ depending on which of a small number of internal states the object is in Chain of Responsibility: Avoid coupling the sender of a request to its receiver by giving more than one object a chance to handle the request, passing request up the chain until someone handles it Mediator: De\ufb01ne an object that encapsulates how a set of objects interact without those objects having to refer to each other explicitly, allowing decoupling Interpreter: De\ufb01ne a representation for a language along with an interpreter that executes the representation Command: Encapsulate an operation request as an object, thereby letting you parameterize clients with differ- ent requests, queue or log requests, and support undoable operations Figure 11.3: The 23 GoF design patterns spanning three categories, with italics showing a subset we\u2019ll encounter as we illustrate and \ufb01x SOLID violations and with closely-related patterns grouped into a single entry, as with Abstract Factory and Factory Method. Whenever we introduce a design pattern, we\u2019ll explain the pattern\u2019s goal, show a Uni\ufb01ed Modeling Language representation (introduced in the next section) of the class architecture before and after refactoring to that pattern, and when possible, give an example of how the pattern is used \u201cin the wild\u201d in Rails itself or in a Ruby gem. 11.1. PATTERNS, ANTIPATTERNS, AND SOLID 341 Principle Single Responsibility Meaning A class should have one and only one reason to change Open/Closed Classes should be open for ex- tension but closed for modi\ufb01- cation Liskov Substitution Injection of Dependencies Substituting a subclass for a class should preserve correct program behavior Collaborating classes whose implementation may vary at runtime should depend on an intermediate \u201cinjected\u201d de- pendency Demeter Principle Speak only to your friends; treat your friends\u2019 friends as strangers Warning smells Large class, poor LCOM (Lack of Cohesion Of Methods) score, data clumps Conditional based dispatcher complexity, case- subclass de- Refused bequest: structively overrides an inherited method Unit tests that require ad hoc stub- bing to create seams; construc- tors that hardwire a call to another class\u2019s constructor, rather than al- lowing runtime determination of which other class to use Inappropriate envy, mock trainwrecks intimacy, feature Refactoring \ufb01x Extract class, move methods Use Strategy or Template Method, possibly combined with Abstract Factory pattern; use Decorator to avoid explo- sion of subclasses Replace inheritance with del- egation Inject a dependency on a shared interface to isolate the classes; use Adapter, Fa\u00e7ade, or Proxy patterns as needed to make the interface uniform across variants Delegate behaviors and call the delegate methods instead Figure 11.4: The SOLID design guidelines and some smells that may suggest your code violates one or more of them. We diverge a little bit from standard usage of SOLID: we use I for Injecting dependencies and D for the Demeter principle, whereas most books use I for Interface Segregation (which doesn\u2019t apply in Ruby) and D for injecting Dependencies. Figure 11.4 shows the SOLID mnemonics and what they tell us about good composition of classes. In our discussion of selected design patterns, we\u2019ll see violations of each one of these guidelines, and show how refactoring the bad code (in some cases, with the goal of applying a design pattern) can \ufb01x the violation. In general, the SOLID principles strive for a class architecture that avoids various problems that thwart productivity: 1. Viscosity: it\u2019s easier to \ufb01x a problem using a quick hack, even though you know that\u2019s not the right thing to do. 2. Immobility: it\u2019s hard to be DRY and because the functionality you want to reuse is wired into the app in a way that makes extraction dif\ufb01cult. 3. Needless repetition: possibly as a consequence of immobility, the app has similar func- tionality duplicated in multiple places. As a result, a change in one part of the app often ripples to many other parts of the app, so that a small change in functionality requires a lot of little changes to code and tests, a process sometimes called shotgun surgery. 4. Needless complexity: the app\u2019s design re\ufb02ects generality that was inserted before it was needed. As with refactoring and legacy code, seeking out design smells and addressing them by refactoring with judicious use of design patterns is a skill learned by doing. Therefore, rather than presenting \u201claundry lists\u201d of design smells, refactorings, and design patterns, we focus our discussion around the SOLID principles and give a few representative examples of the overall process of identifying design smells and assessing the alternatives for addressing 342 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS them. As you tackle your own applications, perusing the more detailed resources listed in Section 11.11 is essential. Summary of patterns, antipatterns and SOLID: \u2022 Good code should accommodate evolutionary change gracefully. Design patterns are proven solutions to common problems that thwart this goal. They work by pro- viding a clean way to separate the things that may change or evolve from those that stay the same and a clean way to accommodate those changes. \u2022 Just as with individual methods, refactoring is the process of improving the structure of a class architecture to make the code more maintainable and evolvable by moving code across classes as well as refactoring within the class. In some cases, these refactorings lead us to one of the 23 \u201cGang of Four\u201d (GoF) design patterns. \u2022 Just as with individual methods, design smells and metrics can serve as early warn- ings of an antipattern\u2014a piece of code that would be better structured if it followed a design pattern. Elaboration: Other types of patterns As we\u2019ve emphasized since the beginning of this book, judicious use of patterns pervades good software engineering. To complement class-level design patterns, others have developed catalogs of architectural patterns for enterprise applications2 (we met some in Chapter 3), parallel programming patterns, computational patterns (to support speci\ufb01c algorithm families such as graph algorithms, linear algebra, circuits, grids, and so on), Concurrency patterns, and user interface patterns3. Grady Booch (1955\u2013), internationally recognized for his work in software engineering and collaborative development environments, developed UML with Ivar Jacobson and James Rumbaugh. Self-Check 11.1.1. True or false: one measure of the quality of a piece of software is the degree to which it uses design patterns. False: while design patterns provide proven solutions to some common problems, code that doesn\u2019t exhibit such problems may not need those patterns, but that doesn\u2019t make it poor code. The GoF authors speci\ufb01cally warn against measuring code quality in terms of design pattern usage."
    ]
  },
  {
    "id": "sec_0567",
    "title": "11.2 Just Enough UML",
    "pages": [
      354,
      355,
      356,
      357
    ],
    "text_blocks": [
      "The Uni\ufb01ed Modeling Language or UML is not a textual language, but a set of graphical notation techniques that provide a \u201cstandard way to visualize the design of a [software] sys- tem.\u201d UML evolved from 1995 to the present through the uni\ufb01cation of previously-distinct modeling language standards and diagram types, which Figure 11.5 lists. While this book focuses on more lightweight Agile modeling\u2014indeed, UML-based mod- eling has been criticized as being too \u201cbloated\u201d and heavyweight\u2014some types of UML dia- grams are widely used even in Agile modeling. Figure 11.6 shows a UML class diagram, which depicts each actual class in the app, its most important class and instance variables and methods, and its relationship to other classes, such as has-many or belongs-to associations. Each end of the line connecting two associated classes is annotated with the minimum and 11.2. JUST ENOUGH UML 343 Class Component Composite structure Deployment Object Package Pro\ufb01le Communication Interaction overview Sequence Timing Activity State machine Use Case Structure diagrams Describes the structure of a system by showing the system\u2019s classes, their attributes, and the relationships among the classes. Describes how a software system is split up into components and shows the dependencies among these components. Describes the internal structure of a class and the collaborations that this structure makes possible. Describes the hardware used in system implementations and the execution environments and artifacts deployed on the hardware. Shows a complete or partial view of the structure of an example modeled system at a speci\ufb01c time. Describes how a system is split up into logical groupings by showing the dependencies among these groupings. Describes reusable domain-speci\ufb01c \u201cstereotype\u201d objects from which speci\ufb01c object types can be derived for use in a particular application. Interaction diagrams Shows the interactions between objects or parts in terms of sequenced messages. They represent a combination of information taken from Class, Sequence, and Use Case Diagrams describing both the static structure and dynamic behavior of a system. Provides an overview in which the nodes represent communication diagrams. Shows how objects communicate with each other in terms of a sequence of messages. Also indicates the lifespans of objects relative to those messages. A speci\ufb01c type of interaction diagram where the focus is on timing constraints. Behavior diagrams Describes the business and operational step-by-step work\ufb02ows of components in a system. An activity diagram shows the overall \ufb02ow of control. Describes the states and state transitions of the system. Describes the functionality provided by a system in terms of actors, their goals represented as use cases, and any dependencies among those use cases. Figure 11.5: The fourteen types of diagrams de\ufb01ned by UML 2.2 for describing a software system. These descriptions are based on the excellent Wikipedia summary of UML5, which also shows an example of each diagram type. Use case diagrams are similar to Agile user stories, but lack the level of detail that allows tools like Cucumber to bridge the gap between user stories and integration/acceptance tests. Figure 11.6: This UML class diagram shows a subset of the classes in the theater-ticketing app consistent with Figures 9.4 and 9.5. Each box represents a class with its most important methods and attributes (responsibilities). Inheritance is represented by an arrow. Classes with associations are connected by lines whose endpoints are annotated with a multiplicity and optionally a diamond\u2014open for aggregations, \ufb01lled for compositions, absent otherwise. 344 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS maximum number of instances that can participate in that \u201cside\u201d of the association, called the association\u2019s multiplicity, using the symbol * for \u201cunlimited\u201d. For example, a multiplicity 1..* means \u201cone or more\u201d, 0..* means \u201czero or more\u201d, and 1 means \u201cexactly one.\u201d UML distinguishes two kinds of \u201cowning\u201d (has-one or has-many) associations. In an aggregation, the owned objects survive destruction of the owning object. For example, Course has many Students is an aggregation because the students happily don\u2019t get destroyed when the course is over! In a composition, the owned objects are usually destroyed when the owning object is destroyed. For example, Movie has many Reviews is a composition since deleting a Movie should cause all of its reviews to be deleted. Class diagrams are popular even among software engineers who don\u2019t use the other parts of UML. With this introduction to UML in hand, we can use class diagrams to illustrate \u201cbefore and after\u201d class architecture when we improve code using the SOLID guidelines and design patterns. Summary of Uni\ufb01ed Modeling Language (UML): \u2022 UML comprises a family of diagram types to illustrate various aspects of a software design and implementation. \u2022 UML class diagrams are widely used even by engineers who don\u2019t use other UML features. They show a class\u2019s name, its most important public and private methods and attributes, and its relationship to other classes. Elaboration: When to use UML? While heavyweight, UML is useful for modeling very large applications divided into subsys- tems being worked on by widely-distributed teams. Also, since UML notation is language- neutral, it can be helpful for coordinating international teams. Because of UML\u2019s maturity, many tools support its use; the challenge is keeping the diagrams \u201cin sync\u201d with the code and the design, which is why most such tools try to go in both directions, synthesizing code skele- tons from UML and extracting UML diagrams from code. One such tool useful for learning UML is UMPLE6, a domain-speci\ufb01c language developed at the University of Ottawa for ex- pressing class relationships. The Try Umple7 web site can generate UML class diagrams from UMPLE code, generate UMPLE code from diagrams you draw yourself, or generate executable code in various programming languages corresponding to your UMPLE code or UML diagrams. It\u2019s a great tool for exploring UML and class diagrams, but we don\u2019t rec- ommend using the Ruby code it generates, which is non-DRY and somewhat non-idiomatic. Self-Check 11.2.1. In a UML class diagram depicting the relationship \u201cUniversity has many Departments,\u201d what multiplicities would be allowable on each side of the association? The University side has multiplicity 1, because a Department must belong to exactly one University. The Department side has multiplicity 1..*, because one or more Departments can belong to a University. Self-Check 11.2.2. Should the relationship \u201cUniversity has many Departments\u201d be modeled as an aggregation or a composition? It should be a composition, since departments wouldn\u2019t survive the closing of a university. 11.3. SINGLE RESPONSIBILITY PRINCIPLE 345 LCOM variant Revised Henderson-Sellers LCOM LCOM-4 Scores"
    ]
  },
  {
    "id": "sec_0568",
    "title": "0 (best) to",
    "pages": [
      357
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0569",
    "title": "1 (worst)",
    "pages": [
      357
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0570",
    "title": "1 (best) to",
    "pages": [
      357
    ],
    "text_blocks": [
      "n (worst) Interpretation"
    ]
  },
  {
    "id": "sec_0571",
    "title": "0 means all instance methods access all instance variables. 1 means any given instance",
    "pages": [
      357
    ],
    "text_blocks": [
      "variable is used by only one instance method, that is, the instance methods are fairly independent of each other. Estimates number of responsibilities n in your class as the number of connected com- ponents in a graph in which related methods\u2019 nodes are connected by an edge. n > 1 suggests that up to n \u2212 1 responsibilities could be extracted into their own classes. Figure 11.7: The \u201crecommended\u201d lack of cohesion of methods (LCOM) score depends heavily on which LCOM variant is used. The table shows two of the most widely-used variants."
    ]
  },
  {
    "id": "sec_0572",
    "title": "11.3 Single Responsibility Principle",
    "pages": [
      357,
      358,
      359
    ],
    "text_blocks": [
      "The Single Responsibility Principle (SRP) of SOLID states that a class should have one and only one responsibility\u2014that is, only one reason to change. For example, in Section 5.2, when we added single sign-on to RottenPotatoes, we created a new SessionsController to handle the sign-on interaction. An alternate strategy would be to augment MoviegoersController, since sign-on is an action associated with moviegoers. Indeed, before the single sign-on approach described in Chapter 5, this was the recommended way to implementing password-based authentication in earlier versions of Rails. But such a scheme would require changing the Moviegoer model and controller whenever we wanted to change the authentication strategy, even though the \u201cessence\u201d of a Moviegoer doesn\u2019t re- ally depend on how they sign in. In MVC, each controller should specialize in dealing with one resource; an authenticated user session is a distinct resource from the user himself, and deserves its own RESTful actions and model methods. As a rule of thumb, if you cannot describe the responsibility of a class in 25 words or less, it may have more than one respon- sibility, and the new ones should be split out into their own classes. In statically typed compiled languages, the cost of violating SRP is obvious: any change to a class requires recompilation and may also trigger recompilation or relinking of other classes that depend on it. Because we don\u2019t pay this price in interpreted dynamic languages, it\u2019s easy to let classes get too large and violate SRP. One tip-off is lack of cohesion, which is the degree to which the elements of a single logical entity, in this case a class, are related. Two methods are related if they access the same subset of instance or class variables or if one calls the other. The LCOM metric, for Lack of Cohesion Of Methods, measures cohesion for a class: in particular, it warns you if the class consists of multiple \u201cclusters\u201d in which methods within a cluster are related, but methods in one cluster aren\u2019t strongly related to methods in other clusters. Figure 11.7 shows two of the most commonly used variants of the LCOM metric. The Data Clumps design smell is one warning sign that a good class is evolving toward the \u201cmultiple responsibilities\u201d antipattern. A Data Clump is a group of variables or values that are always passed together as arguments to a method or returned together as a set of results from a method. This \u201ctraveling together\u201d is a sign that the values might really need their own class. Another symptom is that something that used to be a \u201csimple\u201d data value acquires new behaviors. For example, suppose a Moviegoer has attributes phone_number and zipcode, and you want to add the ability to check the zip code for accuracy or canon- icalize the formatting of the phone number. If you add these methods to Moviegoer, they will reduce its cohesion because they form a \u201cclique\u201d of methods that only deal with speci\ufb01c instance variables. The alternative is to use the Extract Class refactoring to put these methods In Section 9.6, after successfully refactoring convert, reek reported \u201clow cohesion\u201d in the TimeSetter class because we used class variables rather than instance variables for maintaining what was actually instance state, as that section described. 346 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS attr_accessor : name , : street , : phone_number , : zipcode validates : phone_number , # ... validates : zipcode , # ... def f o r m a t _ p h o n e _ n u mb e r ; ... ; end def check_zipcode ; ... ; end def format_address ( street , phone_number , zipcode ) # data clump # do formatting , calling f o r m a t _ p h o n e _ n u m be r and check_zipcode end class Moviegoer end # After applying Extract Class : class Moviegoer https://gist.github.com/a100b89babb3e1dfc3f0fbbe98fcd820 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 attr_accessor : name has_one : address end class Address end belongs_to : moviegoer attr_accessor : phone_number , : zipcode validates : phone_number , # ... validates : zipcode , # ... def format_address ; ... ; end # no arguments - operates on ' self ' private def f o r m a t _ p h o n e _ nu m b e r ; ... ; end def check_zipcode ; ... ; end # no need to expose these now : Figure 11.8: To perform Extract Class, we identify the group of methods that shares a responsibility distinct from that of the rest of the class, move those methods into a new class, make the \u201ctraveling together\u201d data items on which they operate into instance variables of the class, and arrange to pass an instance of the class around rather than the individual items. into a new Address class, as Figure 11.8 shows. Summary of Single Responsibility Principle: \u2022 A class should have one and only one reason to change, that is, one responsibility. \u2022 A poor LCOM (Lack of Cohesion Of Methods) score and the Data Clump design smell are both warnings of possible SRP violations. The Extract Class refactoring can help remove and encapsulate additional responsibilities in a separate class. Elaboration: Interface Segregation Principle Related to SRP is the Interface Segregation Principle (ISP, and the original I in SOLID), which states that if a class\u2019s API is used by multiple quite different types of clients, the API probably should be segregated into subsets useful to each type of client. For example, the Movie class might provide both movie metadata (MPAA rating, release date, and so on) and an interface for searching TMDb, but it\u2019s unlikely that a client using one of those two sets of services would care about the other. The problem solved by ISP arises in compiled languages in which changes to an interface require recompiling the class, thereby triggering recompilation or relinking of classes that use that interface. While documenting separate interfaces for distinct sets of functionality is good style, ISP rarely arises in Ruby since there are no compiled classes, so we won\u2019t discuss it further. Self-Check 11.3.1. Draw the UML class diagrams showing class architecture before and after the refactoring in Figure 11.8. Figure 11.9 shows the UML diagrams. 11.4. OPEN/CLOSED PRINCIPLE 347 Figure 11.9: UML class diagrams before (left) and after (right) extracting the Address class from Moviegoer. formatter = class Report def output case @format when : html https://gist.github.com/ce84aab55f40bdc7566e84a7512ede27 1 2 3 4 5 6 7 8 9 10 11 12 PdfFormatter . new ( self ) # ... etc HtmlFormatter . new ( self ) when : pdf end end end Figure 11.10: The Report class depends on a base class Formatter with subclasses HtmlFormatter and PdfFormatter. Because of the explicit dispatch on the report format, adding a new type of report output requires modifying Report#output, and probably requires changing other methods of Report that have similar logic\u2014so-called shotgun surgery ."
    ]
  },
  {
    "id": "sec_0573",
    "title": "11.4 Open/Closed Principle",
    "pages": [
      359,
      360,
      361,
      362,
      363
    ],
    "text_blocks": [
      "The Open/Closed Principle (OCP) of SOLID states that classes should be \u201copen for ex- tension, but closed against modi\ufb01cation.\u201d That is, it should be possible to extend the behavior of classes without modifying existing code on which other classes or apps depend. While adding subclasses that inherit from a base class is one way to extend existing classes, it\u2019s often not enough by itself. Figure 11.10 shows why the presence of case-based dispatching logic\u2014one variant of the Case Statement design smell\u2014suggests a possible OCP violation. Depending on the speci\ufb01c case, various design patterns can help. One problem that the smelly code in Figure 11.10 is trying to solve is that the desired subclass of Formatter isn\u2019t known until runtime, when it is stored in the @format instance variable. The abstract factory pattern provides a common interface for instantiating an object whose subclass may not be known until runtime. Ruby\u2019s duck typing and metaprogramming enable a particularly elegant implementation of this pattern, as Figure 11.11 shows. (In statically-typed languages, to \u201cwork around\u201d the type system, we have to create a factory method for each subclass and have them all implement a common interface\u2014hence the name of the pattern.) Another approach is to take advantage of the Strategy pattern or Template Method pattern. Both support the case in which there is a general approach to doing a task but many possible variants. The difference between the two is the level at which commonality is captured. With Template Method, although the implementation of each step may differ, the set of steps is the same for all variants; hence it is usually implemented using inheritance. With Strategy, the overall task is the same, but the set of steps may be different in each variant; 348 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS begin formatter_class = class Report def output https://gist.github.com/4d15a866491b82e0b6f19f1e97d5601b 1 2 3 4 5 6 7 8 9 10 11 12 @format . to_s . classify . constantize rescue NameError end end end # ... handle ' invalid formatter type ' formatter = formatter_class . send (: new , self ) # etc Figure 11.11: Ruby\u2019s metaprogramming and duck typing enable an elegant implementation of the abstract factory pattern. classify is provided by Rails to convert snake_case to UpperCamelCase. constantize is syntactic sugar provided by Rails that calls the Ruby introspection method Object#const_get on the receiver. We also handle the case of an invalid value of the formatter class, which the bad code doesn\u2019t. Figure 11.12: In Template Method (left), the extension points are header, body, and footer, since the Report#output method calls @formatter.header, @formatter.body, and so on, each of which delegates to a specialized counterpart in the appropriate subclass. (Light gray type indicates methods that just delegate to a subclass.) In Strategy (right), the extension point is the output method itself, which delegates the entire task to a subclass. Delegation is such a common ingredient of composition that some people refer to it as the delegation pattern. 11.4. OPEN/CLOSED PRINCIPLE 349 Figure 11.13: (Left) The multiplication of subclasses resulting from trying to solve the Formatter problem using inheritance shows why your class designs should \u201cprefer composition over inheritance.\u201d (Right) A more elegant solution uses the Decorator design pattern. hence it is usually implemented using composition. Figure 11.12 shows how either pattern could be applied to the report formatter. If every kind of formatter followed the same high- level steps\u2014for example, generate the header, generate the report body, and then generate the footer\u2014we could use Template Method. On the other hand, if the steps themselves were quite different, it would make more sense to use Strategy. An example of the Strategy pattern in the wild is OmniAuth (Section 5.2): many apps need third-party authentication, and the steps are quite different depending on the auth provider, but the API to all of them is the same. Indeed, OmniAuth even refers to its plug-ins as \u201cstrategies.\u201d A different kind of OCP violation arises when we want to add behaviors to an existing class and discover that we cannot do so without modifying it. For example, PDF \ufb01les can be generated with or without password protection and with or without a \u201cDraft\u201d watermark across the background. Both features amount to \u201ctacking on\u201d some extra behavior to what PdfFormatter already does. If you\u2019ve done a lot of object-oriented programming, your \ufb01rst thought might therefore be to solve the problem using inheritance, as the UML diagram in Figure 11.13 (left) shows, but there are four permutations of features so you\u2019d end up with four subclasses with duplication across them\u2014hardly DRY. Fortunately, the decorator pattern can help: we \u201cdecorate\u201d a class or method by wrapping it in an enhanced version that has the same API, allowing us to compose multiple decorations as needed. Figure 11.14 shows the code corresponding to the more elegant decorator-based design of the PDF format- ter shown in Figure 11.13 (right). In the wild, the ActiveSupport module of Rails provides method-level decoration via alias_method_chain, which is very useful in conjunction with Ruby\u2019s open classes, as Figure 11.15 shows. A more interesting example of Decorator in the wild is the Rack ap- plication server we\u2019ve been using since Chapter 3. The heart of Rack is a \u201cmiddleware\u201d module that receives an HTTP request and returns a three-element array consisting of an HTTP response code, HTTP headers, and a response body. A Rack-based application spec- i\ufb01es a \u201cstack\u201d of middleware components that all requests traverse: to add a behavior to an HTTP request (for example, to intercept certain requests as OmniAuth does to initiate an authentication \ufb02ow), we decorate the basic HTTP request behavior. Additional decorators add support for SSL (Secure Sockets Layer), measuring app performance, and some types of HTTP caching. Python\u2019s \u201cdecorators\u201d8 are, unfortunately, completely unrelated to the Decorator design pattern. 350 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS class PdfFormatter def initialize ; ... ; end def output ; ... ; end end class P d f W i t h P a s s w o r d F o r m a t t e r < PdfFormatter def initialize ( base ) ; @base = base ; end def p r o t e c t _ w i t h _ p a s s w o r d ( original_output ) ; ... ; end def output ; p r o t e c t _ w i t h _ p a s s w o r d @base . output ; end https://gist.github.com/4f46456d38c0dfb5743481ae76acb83d 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 end class P d f W i t h W a t e r m a r k F o r m a t t e r < PdfFormatter def initialize ( base ) ; @base = base ; end def add_watermark ( original_output ) ; ... ; end def output ; add_watermark @base . output ; end end end # If we just want a plain PDF formatter = PdfFormatter . new # If we want a \" draft \" watermark formatter = P d f W i t h W a t e r m a r k F o r m a t t e r . new ( PdfFormatter . new ) # Both password protection and watermark formatter = P d f W i t h W a t e r m a r k F o r m a t t e r . new ( P d f W i t h P a s s w o r d F o r m a t t e r . new ( PdfFormatter . new ) ) Figure 11.14: To apply Decorator to a class, we \u201cwrap\u201d class by creating a subclass (to follow the Liskov Substitution Principle, as we\u2019ll learn in Section 11.5). The subclass delegates to the original method or class for functionality that isn\u2019t changed, and implements the extra methods that extend the functionality. We can then easily \u201cbuild up\u201d just the version of PdfFormatter we need by \u201cstacking\u201d decorators. a li a s_ m et h od _ ch a in : send_email , : cc def s en d _e m ai l _w i th _ cc ( recipient , body ) # this is our new method # reopen Mailer class and decorate its send_email method . class Mailer https://gist.github.com/d6e8a3aeb60516338d38ee95478be708 1 2 3 4 5 6 7 8 9 10 11 12 end # now we have two methods : send_email (...) s en d _e m ai l _w i th _ cc (...) s e n d _ e m a i l _ w i t h o u t _ c c (...) # call ( renamed ) original method # calls se n d_ e ma i l_ w it h _c c # same thing s e n d _ e m a i l _ w i t h o u t _ c c ( recipient , body ) # will call original method copy_sender ( body ) end Figure 11.15: To decorate an existing method Mailer#send_email, we reopen its class and use alias_method_chain to decorate it. Without changing any classes that call send_email, all calls now use the decorated version that sends email and copies the sender. 11.5. LISKOV SUBSTITUTION PRINCIPLE 351 Summary of Open/Closed Principle: \u2022 To make a class open for extension but closed against modi\ufb01cation, we need mech- anisms that enable speci\ufb01c extension points at places we think extensions might be needed in the future. The Case Statement design smell is one symptom of a possible OCP violation. \u2022 If the extension point takes the form of a task with varying implementations for the steps, the Strategy and Template Method patterns may apply. Both are often used in conjunction with the Abstract Factory pattern, since the variant to create may not be known until runtime. \u2022 If the extension point takes the form of selecting different subsets of features that \u201cadd on\u201d to existing class behaviors, the Decorator pattern may apply. The Rack application server is designed this way. Elaboration: Closed against what? \u201cOpen for extension but closed against modi\ufb01cation\u201d presupposes that you know in advance what the useful extension points will be, so you can leave the class open for the \u201cmost likely\u201d changes and strategically close it against changes that might break its dependents. In our example, since we already had more than one way to do something (format a report), it seemed reasonable to allow additional formatters to be added later, but you don\u2019t always know in advance what extension points you\u2019ll want. Make your best guess, and deal with change as it comes. Self-Check 11.4.1. Here are two statements about delegation: 1. A subclass delegates a behavior to an ancestor class 2. A class delegates a behavior to a descendant class Looking at the examples of the Template Method, Strategy, and Decorator patterns (Fig- ures 11.12 and 11.13), which statement best describes how each pattern uses delegation? In Template Method and Strategy, the ancestor class provides the \u201cbasic game plan\u201d which is customized by delegating speci\ufb01c behaviors to different subclasses. In Decorator, each subclass provides special functionality of its own, but delegates back to the ancestor class for the \u201cbasic\u201d functionality."
    ]
  },
  {
    "id": "sec_0574",
    "title": "11.5 Liskov Substitution Principle",
    "pages": [
      363,
      364,
      365,
      366
    ],
    "text_blocks": [
      "The Liskov Substitution Principle (LSP) is named for Turing Award winner Barbara Liskov, who did seminal work on subtypes that heavily in\ufb02uenced object-oriented program- ming. Informally, LSP states that a method designed to work on an object of type T should also work on an object of any subtype of T . That is, all of T \u2019s subtypes should preserve T \u2019s \u201ccontract.\u201d This may seem like common sense, but it\u2019s subtly easy to get wrong. Consider the code in Figure 11.16, which suffers from an LSP violation. You might think a Square is just a 352 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS class Rectangle end # A square is just a special case of rectangle ... right ? class Square < Rectangle attr_accessor : width , : height , : top_left def initialize ( width , height , top_left ) ... ; end def area ... ; end def perimeter ... ; end https://gist.github.com/cca588f67ed62d38e96094\ufb00f68a5418 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 end # But is a Square really a kind of Rectangle ? class Rectangle # ooops ... a square has to have width and height equal attr_reader : width , : height , : side def width =( w ) ; @width = @height = w ; end def height =( w ) ; @width = @height = w ; end ; @width = @height = w ; end def side =( w ) self . width = 2* dim self . height = dim def m a k e _ t w i c e _ a s _ w i d e _ a s _ h i g h ( dim ) # doesn 't work ! end end Figure 11.16: Behaviorally, rectangles have some capabilities that squares don\u2019t have\u2014for example, the ability to set the lengths of their sides independently, as in Rectangle#make_twice_as_wide_as_high. special case of Rectangle and should therefore inherit from it. But behaviorally, a square is not like a rectangle when it comes to setting the length of a side! When you spot this problem, you might be tempted to override Rectangle#make_twice_as_wide_as_high within Square, perhaps raising an exception since this method doesn\u2019t make sense to call on a Square. But that would be a refused bequest\u2014a design smell that often indicates an LSP violation. The symptom is that a subclass either destructively overrides a behavior inherited from its superclass or forces changes to the superclass to avoid the problem (which itself should indicate a possible OCP violation). The problem is that inheritance is all about imple- mentation sharing, but if a subclass won\u2019t take advantage of its parent\u2019s implementations, it might not deserve to be a subclass at all. The \ufb01x, therefore, is to again use composition and delegation rather than inheritance, as Figure 11.17 shows. Happily, because of Ruby\u2019s duck typing, this use of composition and delegation still allows us to pass an instance of Square to most places where a Rectangle would be expected, even though it\u2019s no longer a subclass; a statically-typed language would have to introduce an explicit interface capturing the operations common to both Square and Rectangle. 11.5. LISKOV SUBSTITUTION PRINCIPLE 353 # LSP - compliant solution : replace inheritance with delegation # Ruby 's duck typing still lets you use a square in most places where # rectangle would be used - but no longer a subclass in LSP sense . class Square attr_accessor : rect def initialize ( side , top_left ) https://gist.github.com/8c1a10862521a34e274c3f1cfa5c24d8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ; rect . area end @rect = Rectangle . new ( side , side , top_left ) end def area ; end def perimeter ; rect . perimeter ; end # A more concise way to delegate , if using ActiveSupport ( see text ) : # def side =( s ) ; rect . width = rect . height = s ; end delegate : area , : perimeter , : to = > : rect Figure 11.17: As with some OCP violations, the problem arises from a misuse of inheritance. As Figure 11.18 shows, preferring composition and delegation to inheritance \ufb01xes the problem. Line 12 shows a concise syntax for delegation available to apps using ActiveSupport (and all Rails apps do); similar functionality for non-Rails Ruby apps is provided by the Forwardable module in Ruby\u2019s standard library. Figure 11.18: Left: The UML class diagram representing the original LSP-violating code in Figure 11.16, which destructively overrides Rectangle#make_twice_as_wide_as_high. Right: the class diagram for the refactored LSP-compliant code in Figure 11.17. 354 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS Summary of the Liskov Substitution Principle: \u2022 LSP states that a method that operates on objects of some class should also work cor- rectly on objects of any subclass of that class. When a subclass differs behaviorally from one of its parents, an LSP violation can arise. \u2022 The refused bequest design smell, in which a subclass destructively overrides a parent behavior or forces changes to the parent class so that the behavior is not inherited\u2014often signals an LSP violation. \u2022 Many LSP violations can be \ufb01xed by using composition of classes rather than inher- itance, achieving reuse through delegation rather than through subclassing. Self-Check 11.5.1. Why is Forwardable in the Ruby standard library provided as a module rather than a class? Modules allow the delegation mechanisms to be mixed in to any class that wants to use them, which would be awkward if Forwardable were a class. That is, Forwardable is itself an example of preferring composition to inheritance!"
    ]
  },
  {
    "id": "sec_0575",
    "title": "11.6 Dependency Injection Principle",
    "pages": [
      366,
      367,
      368,
      369,
      370
    ],
    "text_blocks": [
      "The dependency injection principle (DIP), sometimes also called dependency inversion, states that if two classes depend on each other but their implementations may change, it would be better for them to both depend on a separate abstract interface that is \u201cinjected\u201d between them. class EmailList attr_reader : mailer delegate : send_email , : to = > : mailer def initialize Suppose RottenPotatoes now adds email marketing\u2014interested moviegoers can receive emails with discounts on their favorite movies. RottenPotatoes integrates with the external email marketing service MailerMonkey to do this job: https://gist.github.com/c722647142f471b8bb7806055a8c4765 1 2 3 4 5 6 7 8 9 10 11 12 end # in RottenPotatoes E m a i l L i s t C on t r o l l e r : def a d v e r t i s e _ d i s c o u n t _ f o r _ m o v i e moviegoers = Moviegoer . interested_in params [: movie_id ] EmailList . new . send_email_to moviegoers @mailer = MailerMonkey . new end end Suppose the feature is so successful that you decide to extend the mechanism so that moviegoers who are on the Amiko social network can opt to have these emails forwarded to their Amiko friends as well, using the new Amiko gem that wraps Amiko\u2019s RESTful API for friend lists, posting on walls, messaging, and so on. There are two problems, however. First, EmailList#initialize has a hardcoded dependency on MailerMonkey, but now we will sometimes need to use Amiko instead. This runtime variation is the problem solved by dependency injection\u2014since we won\u2019t know until runtime which type of mailer we\u2019ll need, we modify EmailList#initialize so we can \u201cinject\u201d the correct value at runtime: 11.6. DEPENDENCY INJECTION PRINCIPLE 355 class EmailList attr_reader : mailer delegate : send_email , : to = > : mailer def initialize ( mailer_type ) @mailer = mailer_type . new https://gist.github.com/c9a3235dbf7be72738dcb4911ccb18e9 1 2 3 4 5 6 7 8 9 10 11 12 13 end # in RottenPotatoes E m a i l L i s t C o nt r o l l e r : def a d v e r t i s e _ d i s c o u n t _ f o r _ m o v i e end end moviegoers = Moviegoer . interested_in params [: movie_id ] mailer = if Config . has_amiko ? then AmikoAdapter else MailerMonkey end EmailList . new ( mailer ) . send_email_to moviegoers ActiveRecord has been criticized for con\ufb01guring the database at startup from database.yml rather than using DIP. Presumably the designers judged that the database wouldn\u2019t change while the app was running. While DIP-induced seams also help with stubbing and mocking, Chapter 8 shows that Ruby\u2019s open classes and metaprogramming let you insert test seams wherever needed. You can think of DIP as injecting an additional seam between two classes, and indeed, in statically compiled languages DIP helps with testability. This bene\ufb01t is less apparent in Ruby, since as we\u2019ve seen we can create seams almost anywhere we want at runtime using mocking or stubbing in conjunction with Ruby\u2019s dynamic language features. The second problem is that Amiko exposes a different and more complex than the simple send_email method provided by MailerMonkey (to which API EmailList#send_email delegates in line 3), yet our controller method is already set up to call send_email on the mailer object. The Adapter pattern can help us here: it\u2019s designed to convert an existing API into one that\u2019s compatible with an existing caller. In this case, we can de\ufb01ne a new class AmikoAdapter that converts the more complex Amiko API into the simpler one that our controller expects, by providing the same send_email method that MailerMonkey provides: https://gist.github.com/411c249b2ba9e9f04613df32bc8862c1 1 2 3 4 5 6 7 8 9 10 11 12 13 moviegoers = Moviegoer . interested_in params [: movie_id ] mailer = if Config . has_amiko ? then AmikoAdapter else MailerMonkey end EmailList . new ( mailer ) . send_email_to moviegoers end # Change the controller method to use the adapter : def a d v e r t i s e _ d i s c o u n t _ f o r _ m o v i e def initialize ; @mailer = Amiko . new (...) ; end def send_email @mailer . authenticate (...) @mailer . send_message (...) class AmikoAdapter end end When the Adapter pattern not only converts an existing API but also simpli\ufb01es it\u2014for example, the Amiko gem also provides many other Amiko functions unrelated to email, but AmikoAdapter only \u201cadapts\u201d the email-speci\ufb01c part of that API\u2014it is sometimes called the Fa\u00e7ade pattern. Lastly, even in cases where the email strategy is known when the app starts up, what if we want to disable email sending altogether from time to time? Figure 11.19 (top) shows a naive approach: we have moved the logic for determining which emailer to use into a new Config class, but we still have to \u201ccondition out\u201d the email-sending logic in the controller method if email is disabled. But if there are other places in the app where a similar check must be performed, the same condition logic would have to be replicated there (shotgun surgery). A better alternative is the Null Object pattern, in which we create a \u201cdummy\u201d object that has all the same behaviors as a real object but doesn\u2019t do anything when those behaviors are called. Figure 11.19 (bottom) applies the Null Object pattern to this example, avoiding the proliferation of conditionals throughout the code. Figure 11.20 shows the UML class diagrams corresponding to the various versions of our 356 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS def self . email_enabled ? ; ... ; end def self . emailer ; if has_amiko ? then Amiko else MailerMonkey end ; end moviegoers = Moviegoer . interested_in ( params [: movie_id ]) EmailList . new ( Config . emailer ) . send_email_to ( moviegoers ) class Config end def a d v e r t i s e _ d i s c o u n t _ f o r _ m o v i e https://gist.github.com/3533bdccbcc7bcd3fb36b7f18fc79862 1 2 3 4 5 6 7 8 9 10 if Config . email_enabled ? end end end end if email_disabled ? then NullMailer else class Config def self . emailer end class NullMailer https://gist.github.com/4b333ccb9cbf7f5de75c1ca9d94e7ad6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def initialize ; end def send_email_to (* args ) ; true ; end end def a d v e r t i s e _ d i s c o u n t _ f o r _ m o v i e end if has_amiko ? then Amiko else MailerMonkey end moviegoers = Moviegoer . interested_in ( params [: movie_id ]) EmailList . new ( Config . emailer ) . send_email_to ( moviegoers ) end Figure 11.19: Top: a naive way to disable a behavior is to \u201ccondition it out\u201d wherever it occurs. Bottom: the Null Object pattern eliminates the conditionals by providing \u201cdummy\u201d methods that are safe to call but don\u2019t do anything. DIP example. An interesting relative of the Adapter and Fa\u00e7ade patterns is the Proxy pattern, in which one object \u201cstands in\u201d for another that has the same API. The client talks to the proxy instead of the original object; the proxy may forward some requests directly to the original object (that is, delegate them) but may take other actions on different requests, perhaps for reasons of performance or ef\ufb01ciency. Two classic examples of this pattern are found in ActiveRecord itself. First, the object re- turned by ActiveRecord\u2019s all, where and find-based methods quacks like a collection, but it\u2019s actually a proxy object that doesn\u2019t even do the query until you force the issue by asking for one of the collection\u2019s elements. That is why you can build up complex queries with mul- tiple wheres without paying the cost of doing the query each time. The second is when you use ActiveRecord\u2019s associations (Section 5.4): the result of evaluating @movie.reviews quacks like an enumerable collection, but it\u2019s actually a proxy object that responds to all the collection methods (size, <<, and so on), without querying the database except when it has to. Another example of a use for the proxy pattern would be for sending email while disconnected from the Internet. If the real Internet-based email service is accessed via a send_email method, a proxy object could provide a send_email method that just stores an email on the local disk until the next time the computer is connected to the Internet. This proxy shields the client (email GUI) from having to change its behavior when the user isn\u2019t connected. 11.6. DEPENDENCY INJECTION PRINCIPLE 357 Figure 11.20: Left: Without dependency injection, EmailList depends directly on MailerMonkey. Center: With dependency injection, @mailer can be set at runtime to use any of MailerMonkey, NullMailer (which implements the Null Object pattern to disable email), or AmikoAdapter (which implements the Adapter/Fa\u00e7ade pattern over Amiko), all of which have the same API. Right: In statically typed languages, the abstract superclass GenericMailer formalizes the fact that all three mailers have compatible APIs, but in Ruby this superclass is often omitted if it consists entirely of abstract methods (as is the case here), since abstract methods and classes aren\u2019t part of the language. Summary of Dependency Injection: \u2022 Dependency injection inserts a seam between two classes by passing in (injecting) a dependency whose value may not be known until runtime, rather than hardwiring a dependency into the source code. \u2022 Because dependency injection is often used to vary which of a collection of imple- mentations is used at runtime, it\u2019s often seen together with the Adapter pattern, in which a class converts one API into another that a client expects to use. \u2022 Variations on Adapter include Fa\u00e7ade, in which the API is not only adapted but also simpli\ufb01ed, and Proxy, in which the API is exactly imitated but the behaviors changed to accommodate different usage conditions without the client (caller of the API) having to change its behavior. \u2022 The Null Object pattern is another mechanism for replacing unwieldy conditionals with safe \u201cneutral\u201d behaviors as a way of disabling a feature. Elaboration: Did injecting a dependency violate the Open/Closed Principle? You might wonder whether our \u201c\ufb01x\u201d to add a second type of mailer service violates OCP, because adding support for a third mailer would then require modifying advertise_- discount_for_movie. If you had reason to believe you might indeed need to add ad- ditional mailers later, you could combine this with the Abstract Factory pattern introduced in Section 11.4. This scenario is an example of making a judgment call about whether the possibility of handling additional mailers is an extension point you want to leave open, or a change you feel the app wouldn\u2019t accommodate well and should therefore be strategically closed against. Self-Check 11.6.1. Why does proper use of DIP have higher impact in statically typed lan- guages? In such languages, you cannot create a runtime seam to override a \u201chardwired\u201d behavior as you can in dynamic languages like Ruby, so the seam must be provided in advance by 358 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS # ... setup wallet attribute with correct credit balance # This example is adapted from Dan Manges 's blog , dcmanges . com class Wallet ; attr_accessor : credit_balance ; end class Moviegoer # VIOLATION OF DEMETER ( see text ) if moviegoer . wallet . credit_balance < due_amount moviegoer . wallet . credit_balance -= due_amount @c oll ect ed_ am oun t += due_amount end else raise I n s u f f i c i e n t F u n d s E r r o r end class MovieTheater def collect_money ( moviegoer , due_amount ) attr_accessor : wallet def initialize https://gist.github.com/d3ea5309672163c64674b21033c9106c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 end # Imagine testing the above code : describe MovieTheater do describe \" collecting money \" do to raise_error (...) end end end end end it \" should raise error if moviegoer can 't pay \" do # \" Mock trainwreck \" is a warning of a Demeter violation wallet = double ( ' wallet ' , : credit_balance = > 5.00) moviegoer = double ( ' moviegoer ' , : wallet = > wallet ) expect { @theater . collect_money ( moviegoer , 10.00) }. Figure 11.21: Line 12 contains a Demeter violation: while it\u2019s reasonable for MovieTheater to know about Moviegoer, it also knows about the implementation of Wallet, since it \u201creaches through\u201d the wallet attribute to manipulate the wallet\u2019s credit_balance. Also, we\u2019re handling the problem of \u201cnot enough cash\u201d in MovieTheater, even though logically it seems to belong in Wallet. injecting the dependency."
    ]
  },
  {
    "id": "sec_0576",
    "title": "11.7 Demeter Principle",
    "pages": [
      370,
      371,
      372,
      373,
      374
    ],
    "text_blocks": [
      "The name comes from the Demeter Project on adaptive and aspect-oriented programming, which in turn is named for the Greek goddess of agriculture to signify a \u201cfrom the ground up\u201d approach to programming. The Demeter Principle or Law of Demeter states informally: \u201cTalk to your friends\u2014don\u2019t get intimate with strangers.\u201d Speci\ufb01cally, a method can call other methods in its own class, and methods on the classes of its own instance variables; everything else is taboo. Demeter isn\u2019t originally part of the SOLID guidelines, as Figure 11.4 explains, but we include it here since it is highly applicable to Ruby and SaaS, and we opportunistically hijack the D in SOLID to represent it. The Demeter Principle is easily illustrated by example. Suppose RottenPotatoes has made deals with movie theaters so that moviegoers can buy movie tickets directly via RottenPota- toes by maintaining a credit balance (for example, by receiving movie theater gift cards). Figure 11.21 shows an implementation of this behavior that contains a Demeter Principle violation. A problem arises if we ever change the implementation of Wallet\u2014for exam- ple, if we change credit_balance to cash_balance, or add points_balance to allow moviegoers to accumulate PotatoPoints by becoming top reviewers. All of a sudden, the MovieTheater class, which is \u201ctwice removed\u201d from Wallet, would have to change. Two design smells can tip us off to possible Demeter violations. One is inappropri- 11.7. DEMETER PRINCIPLE 359 # Better : delegate credit_balance so MovieTheater only accesses Moviegoer class Moviegoer end # delegation def credit_balance self . wallet . credit_balance end class MovieTheater https://gist.github.com/6a636b98e53b84c9628eba411d3d4086 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 if moviegoer . credit_balance >= due_amount moviegoer . credit_balance -= due_amount @ c o ll e ct ed _am oun t += due_amount def collect_money ( moviegoer , due_amount ) raise I n s u f f i c i e n t F u n d s E r r o r else end end end attr_reader : credit_balance # no longer attr_accessor ! def withdraw ( amount ) raise I n s u f f i c i e n t F u n d s E r r o r if amount > @credit_balance @ cr edi t_balance -= amount amount end class Wallet end class Moviegoer https://gist.github.com/8a6859cdd248ab77673f3eb5373e9a67 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # behavior delegation def pay ( amount ) end class MovieTheater def collect_money ( moviegoer , amount ) wallet . withdraw ( amount ) end end end @ c o ll ec t ed_ am oun t += moviegoer . pay ( amount ) Figure 11.22: (Top) If Moviegoer delegates credit_balance to its wallet, MovieTheater no longer has to know about the implementation of Wallet. However, it may still be undesirable that the payment behavior (subtract payment from credit balance) is exposed to MovieTheater when it should really be the responsibility of Moviegoer or Wallet only. (Bottom) Delegating the behavior of payment, rather than the attributes through which it\u2019s accomplished, solves the problem and eliminates the Demeter violation. ate intimacy : the collect_money method manipulates the credit_balance attribute of Wallet directly, even though managing that attribute is the Wallet class\u2019s responsibil- ity. (When the same kind of inappropriate intimacy occurs repeatedly throughout a class, it\u2019s sometimes called feature envy , because Moviegoer \u201cwishes it had access to\u201d the features managed by Wallet.) Another smell that arises in tests is the mock trainwreck, which occurs in lines 25\u201327 of Figure 11.21: to test code that violates Demeter, we \ufb01nd ourselves setting up a \u201cchain\u201d of mocks that will be used when we call the method under test. Once again, delegation comes to the rescue. A simple improvement comes from dele- gating the credit_balance attribute, as Figure 11.22 (top) shows. But the best delegation is that in Figure 11.22 (bottom), since now the behavior of payment is entirely encapsulated within Wallet, as is the decision of when to raise an error for failed payments. Inappropriate intimacy and Demeter violations can arise in any situation where you feel you are \u201creaching through\u201d an interface to get some task done, thereby exposing yourself to dependency on implementation details of a class that should really be none of your business. Three design patterns address common scenarios that could otherwise lead to Demeter vio- 360 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS moviegoers = review . moviegoers # from has_many : through , remember ? self . email ( moviegoers , \" A new review for #{ review . movie } is up . \" ) class EmailList observe Review def after_create ( review ) https://gist.github.com/7d58ab75f108b42105b6c198040f831b 1 2 3 4 5 6 7 8 9 10 11 12 end observe Moviegoer def after_create ( moviegoer ) end def self . email ; ... ; end end self . email ([ moviegoer ] , \" Welcome , #{ moviegoer . name }! \" ) Observer was \ufb01rst implemented in the MVC framework of Smalltalk, from which Ruby inherits its object model. Figure 11.23: An email list subsystem observes other models so it can generate email in response to certain events. The Observer pattern is an ideal \ufb01t since it collects all the concerns about when to send email in one place. lations. One is the Visitor pattern, in which a data structure is traversed and you provide a callback method to execute for each member of the data structure, allowing you to \u201cvisit\u201d each element while remaining ignorant of the way the data structure is organized. Indeed, the \u201cdata structure\u201d could even be materialized lazily as you visit the different nodes, rather than existing statically all at once. An example of this pattern in the wild is the Nokogiri9 gem, which supports traversal of HTML and XML documents organized as a tree: in addition to searching for a speci\ufb01c element in a document, you can have Nokogiri traverse the document and call a visitor method you provide at each document node. A simple special case of Visitor is the Iterator pattern, which is so pervasive in Ruby (you use it anytime you use each) that many Rubyists hardly think of it as a pattern. It- erator separates the implementation of traversing a collection from the behavior you want to apply to each collection element. Without iterators, the behavior would have to \u201creach into\u201d the collection, thereby knowing inappropriately intimate details of how the collection is organized. The last design pattern that can help with some cases of Demeter violations is the Ob- server pattern, which is used when one class (the observer) wants to be kept aware of what another class is doing (the subject) without knowing the details of the subject\u2019s implemen- tation. The Observer design pattern provides a canonical way for the subject to maintain a list of its observers and notify them automatically of any state changes in which they have indicated interest, using a narrow interface to separate the concept of observation from the speci\ufb01cs of what each observer does with the information. While the Ruby standard library includes a mixin10 called Observable, Rails\u2019 Ac- tiveSupport provides a more concise Observer that lets you observe any model\u2019s ActiveRe- cord lifecycle hooks (after_save and so on), introduced in Section 5.1. Figure 11.23 shows how easy it is to add an EmailList class to RottenPotatoes that \u201csubscribes\u201d to two kinds of state changes: 1. When a new review is added, it emails all moviegoers who have already reviewed that same movie. 2. When a new moviegoer signs up, it sends her a \u201cWelcome\u201d email. In addition to ActiveRecord lifecycle hooks, Rails caching, which we will encounter in Chapter 12, is another example of the Observer pattern in the wild: the cache for each type of ActiveRecord model observes the model instance in order to know when model instances 11.7. DEMETER PRINCIPLE 361 become stale and should be removed from the cache. The observer doesn\u2019t have to know the implementation details of the observed class\u2014it just gets called at the right time, like Iterator and Visitor. To close out this section, it\u2019s worth pointing out an example that looks like it violates Demeter, but really doesn\u2019t. It\u2019s common in Rails views (say, for a Review) to see code such as: https://gist.github.com/c5ddf39643f6763c5b7ec377a8cdd5e7 <%= @review . movie . title % > 1 2 <p > Review of : </p > <p > Written by : <%= @review . moviegoer . name % > </p > Aren\u2019t these Demeter violations? It\u2019s a judgment call: strictly speaking, a review shouldn\u2019t know the implementation details of movie, but it\u2019s hard to argue that creating delegate methods Review#movie_title and Review#moviegoer_name would enhance readability in this case. The general opinion in the Rails community is that it\u2019s acceptable for views whose purpose is to display object relationships to also expose those relationships in the view code, so examples like this are usually allowed to stand. Summary of Demeter Principle: \u2022 The Demeter Principle states that a class shouldn\u2019t be aware of the details of collab- orator classes from which it is further away than \u201conce removed.\u201d That is, you can access instance methods in your own class and in the classes corresponding to your nearest collaborators, but not on their collaborators. \u2022 The Inappropriate Intimacy design smell, which sometimes manifests as a Mock Trainwreck in unit tests, may signal a Demeter violation. If a class shows many instances of Inappropriate Intimacy with another class, it is sometimes said to have Feature Envy with respect to the other class. \u2022 Delegation is the key mechanism for resolving these violations. \u2022 Design patterns cover some common manipulations of classes without violating Demeter, including Iterator and Visitor (separating traversal of an aggregate from behavior) and Observer (separating noti\ufb01cation of \u201cinteresting\u201d events from the de- tails of the class being observed). Elaboration: Observers, Visitors, Iterators, and Mixins Because of duck typing and mixins, Ruby can express many design patterns with far less code than statically-typed languages, as the Wikipedia entries for Observer , Iterator and Visitor clearly demonstrate by using Java-based examples. In contrast to Ruby\u2019s internal iterators based on each, statically-typed languages usually provide external iterators and visitors in which you set up the iterator over a collection and ask the iterator explicitly whether the collection has any more elements, sometimes requiring various contortions to work around the type system. Similarly, Observer usually requires modifying the subject class(es) so that they can implement an Observable interface, but Ruby\u2019s open classes allow us to skip that step, as Figure 11.23 showed: from the programmer\u2019s point of view, all of the logic is in the observing class, not the subjects. Self-Check 11.7.1. Ben Bitdiddle is a purist about Demeter violations, and he objects to the 362 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS expression @movie.reviews.average_rating in the movie details view, which shows a movie\u2019s average review score. How would you placate Ben and \ufb01x this Demeter violation? self . reviews . average_rating # delegate to Review # average_rating # naive way : class Movie has_many : reviews def average_rating https://gist.github.com/77f741c6c441b81be9c3220bf01a05ee 1 2 3 4 5 6 7 8 9 10 11 12 has_many : reviews delegate : average_rating , : to = > : review end # Rails shortcut : class Movie end end",
      "Self-Check 11.7.2. Notwithstanding that \u201cdelegation is the key mechanism\u201d for resolving Demeter violations, why should you be concerned if you \ufb01nd yourself delegating many meth- ods from class A to class B just to resolve Demeter violations present in class C? You might ask yourself whether there should be a direct relationship between class C and class B, or whether class A has \u201cfeature envy\u201d for class B, indicating that the division of responsibilities between A and B might need to be reengineered."
    ]
  },
  {
    "id": "sec_0577",
    "title": "11.8 The Plan-And-Document Perspective on Design Patterns",
    "pages": [
      374,
      375
    ],
    "text_blocks": [
      "A strength of Plan-and-Document is that careful upfront planning can result in a product with a good software architecture that uses design patterns well. This preplanning is re\ufb02ected in the alternative catch phrase for these processes of Big Design Up Front, as Chapter 1 mentions. A Plan-and-Document development team starts with the Software Requirements Speci\ufb01cation (SRS) (see Section 7.9), which the team breaks into a series of problems. For each one, the team looks for one or more architecture patterns that might solve the prob- lem. The team then goes down to the next level of subproblems, and looks for design patterns that match them. The philosophy is to learn from the experience of others captured as pat- terns so as to avoid repeating the mistakes of your predecessors. Another way to get feedback from more experienced engineers is to hold a design review (see Section 10.7). Note that design reviews can be done before any code is written in Plan-and-Document processes. Thus, compared to Agile, there is considerably more effort in starting with a good design in Plan-and-Document. As Martin Fowler points out in his article Is Design Dead?11, a frequent critique of Agile is that it encourages developers to jump in and start coding without any design, and rely too much on refactoring to \ufb01x things later. As the critics sometimes say, you can build a doghouse by slapping stuff together and planning as you go, but you can\u2019t build a skyscraper that way. Agile supporters counter that Plan-and-Document methods are just as bad: by disallowing any code until the design is complete, it\u2019s impossible to be con\ufb01dent that the design will be implementable or that it really captures the customer\u2019s needs. This critique especially holds when the architects/designers will not be writing the code or may be out of touch with current coding practices and tools. As a result, say Agile proponents, when coding starts, the design will have to change anyway. 11.9. 6S: A CLEAN CODE CHECKLIST 363 Both sides have a point, but the critique can be phrased in a more nuanced way as \u201cHow much design makes sense up front?\u201d For example, Agile developers plan for persistent stor- age as part of their SaaS apps, even though the \ufb01rst BDD and TDD tests they write will not touch the database. A more subtle example is horizontal scaling. As we alluded to in Chapter 3, and will discuss more fully in Chapter 12, designers of successful SaaS must think about horizontal scalability early on. Even though it may be months before scalability mat- ters, design decisions early in the project can cripple scalability, and it may be dif\ufb01cult to change them without major rewriting and refactoring. A possible solution to the conundrum is captured by a rule of thumb in Fowler\u2019s article. If you have previously done a project that has some design constraint or element, it\u2019s OK to plan for it in a new project that is similar, because your previous experience will likely lead to reasonable design decisions this time. Summary: Plan-and-Document processes have an explicit design phase that is a natural \ufb01t to the use of design patterns in the software development process. One potential draw- back is uncertainty as to whether the initial architecture and design patterns will need to change as the code is written and as the system evolves. In contrast, the Agile process relies on refactoring to incorporate design patterns as the code evolves, although experi- enced developers may lay plans for software architectures and design patterns that they expect to need based on previous, similar projects. Self-Check 11.8.1. True or False: Agile design is an oxymoron. False. Although there is no separate design phase in Agile development, the refactoring that is the norm in Agile can incorporate design patterns."
    ]
  },
  {
    "id": "sec_0578",
    "title": "11.9 6S: A Clean Code Checklist",
    "pages": [
      375,
      376,
      377
    ],
    "text_blocks": [
      "A key message of this book is that when you write code, you\u2019re writing for other devel- opers who will maintain it after you\u2019ve moved on. The many tools and techniques we introduced\u2014software architectures such as model-view-controller and client-server, class- level and method-level design patterns, and tools for measuring and improving code quality through refactoring\u2014are all there to help enhance code beauty and therefore maintainability. While there is no \ufb01xed recipe for creating beautiful code (other than lots of practice), the information in this book on refactoring (Chapter 9) and design patterns (this chapter) can go a long way towards helping you produce beautiful code, and the frequent code reviews that are part of the pull request process (Chapter 10) can serve as a further cross-check. You have also learned in multiple contexts that while automated code quality tools are useful, they are no substitute for engineering judgment, a solid understanding of the codebase, and a team whose members trust and rely on each other for constructive criticism. To help pull all of this advice together, in this section we present a \u201cchecklist\u201d you and your team can use to evaluate your code. Since Agile is all about iterative re\ufb01nement in the pursuit of higher code quality, we will call it the \u201c6S List,\u201d which we hope you will remember because it almost sounds like \u201csuccess list.\u201d Here is our proposed 6S list, ordered from highest to lowest level of abstraction, to use as a checklist before opening a pull request: Site, SOLID, SOFA, Smells, Style, and Sign-off. The name is also a nod to Six Sigma, a technique for manufacturing-process improvement that uses statistical methods to \ufb01nd and remediate process problems that harm output quality. 364 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS Site. If you\u2019re adding new code, is it in the right place architecturally? Does it properly belong directly in a model, view, controller, or helper? Or, at least as often, should it be separately modularized as a service object, form object, or other type of code (Section 5.8), with clear and explicit dependencies on other existing classes? Is the new code connected in the proper way to the rest of the app? For example, JavaScript code must be appropriately loaded by the asset pipeline, and may require DOM bindings (Section 6.4) on particular app pages. SOLID. If you\u2019re adding new classes or adding new code to existing classes, really scr- utizing your code against each of the SOLID principles (Sections 11.3\u201311.7) can reveal risk areas in which you are introducing unnecessary technical debt\u2014changes that will make the code harder to understand, maintain, or modify later. This is the moment to identify possible refactorings, even simple ones such as extracting a class (Section 11.3). Automated tools such as CodeClimate can help identify trouble spots. Once technical debt is incurred and gets into the mainline codebase, it is extremely resistant to being paid back, since new features or other work always seem to take priority. SOFA. Just as with SOLID, make an effort to critically apply each of the four SOFA criteria (Section 9.5) to any new or refactored methods within each class. Is each method Short, because it does only One thing requiring Few arguments while maintaining a single level of Abstraction? Just as one of the most frequent violations of SOLID is violating the Single Responsibility Principle, one of the most frequent violations of SOFA is violating \u201cMethods should be Short.\u201d Both violations are usually symptomatic of other violations likely lurking in the code. Smells. Is the code relatively free of code and design smells (Chapters 9 and 11)? Tools like CodeClimate can \ufb01nd both language-independent smells (high cyclomatic complexity, deeply nested conditionals, meaningless variable names, arguments that travel around as a group) and language-speci\ufb01c or framework-speci\ufb01c problems (overly long controller actions, use of potentially confusing language idioms). Again, use automated tools in tandem with good engineering judgment, not as a substitute for it. Style. Most languages and frameworks have low-level best practices regarding variable and function naming (Section 2.3), spacing and indentation, punctuation, and so on. Where such practices are unambiguous, your code should follow them; where there is \ufb02exibility in the practices, your code should follow the existing conventions of the codebase. All modern editors allow customizing the rules for automatic indentation and spacing, use of spaces rather than tabs, and so on; con\ufb01gure your editor to match the codebase\u2019s conventions. Sign-off. When you\u2019ve checked all of the above, the last step is to open a pull request and invite team feedback until the code passes your team\u2019s review with \u201cLGTM\u201d (\u201clooks good to me\u201d) or similar. Automated tools are wonderful, but the eyes and brains of your team can produce codebase-speci\ufb01c suggestions beyond what automated tools are able to do. 11.10. FALLACIES AND PITFALLS 365 Summary: \u2022 The six S\u2019s\u2014site, SOLID, SOFA, smells, style, sign-off\u2014can help you check your own work as you get more pro\ufb01cient at creating beautiful code. \u2022 Automated tools can help with some of the S\u2019s, but in the end, there\u2019s no substi- tute for an informed team who trust and hold each other responsible for providing constructive feedback. Keeping the codebase clean is everyone\u2019s job! Elaboration: Guidelines or Rules? In a 2013 presentation12 at the Barcelona Ruby Conference, Rubyist Sandi Metz, the author of one of the books we recommend on object-oriented design (Metz 2012), proposes a set of rules based on a seventh S, size. Her proposed rules are: \u2022 Classes must be no longer than 100 lines \u2022 Methods must be no longer than 5 lines, and take no more than 4 arguments \u2022 Controller actions may name at most 2 other classes, and may set at most 1 instance variable to be consumed by the view The rules may only be broken if you can convince your pair programming partner that it makes sense to do so in a given situation. Metz notes that while these thresholds are arbitrary, at least they force developers to think about why they might need to break the rules or whether they should refactor. We largely agree with her rules (even if the thresholds are a bit tight), and we hope the 6S approach will help identify why the rules are about to be broken and provide guidance for how to improve. Self-Check 11.9.1."
    ]
  },
  {
    "id": "sec_0579",
    "title": "11.10 Fallacies and Pitfalls",
    "pages": [
      377,
      378
    ],
    "text_blocks": [
      "Pitfall: Over-reliance or under-reliance on patterns. As with every tool and methodology we\u2019ve seen, slavishly following design patterns is a pitfall: they can help point the way when your problem could take advantage of a proven solution, but they cannot by themselves ensure beautiful code. In fact, the GoF authors speci\ufb01cally warn against trying to evaluate the soundness of a design based on the number of patterns it uses. In addition, if you apply design patterns too early in your design cycle, you may try to implement a pattern in its full generality even though you may not need that generality for solving the current problem. That will complicate your design because most design patterns call for more classes, methods, and levels of indirection than the same code would require without this level of generality. In contrast, if you apply design patterns too late, you risk falling into antipatterns and extensive refactoring. What to do? Develop taste and judgment through learning by doing. You will make some mistakes as you go, but your judgment on how to deliver working and maintainable code will quickly improve. 366 CHAPTER 11. DESIGN PATTERNS FOR SAAS APPS Pitfall: Over-reliance on UML or other diagrams. A diagram\u2019s purpose is communication of intent. Reading UML diagrams is not neces- sarily easier than reading user stories or well-factored TDD tests. Create a diagram when it helps to clarify a class architecture; don\u2019t rely on them as a crutch. Fallacy: SOLID principles aren\u2019t needed in dynamic languages. As we saw in this chapter, some of the problems addressed by SOLID don\u2019t really arise in dynamically-typed languages like Ruby. Nonetheless, the SOLID guidelines still represent good design; in static languages, there is simply a much more tangible up-front cost to ig- noring them. In dynamic languages, while the opportunity exists to use dynamic features to make your code more elegant and DRY without the extra machinery required by some of the SOLID guidelines, the corresponding risk is that it\u2019s easier to fall into sloth and end up with ugly antipattern code. Pitfall: Lots of private methods in a class. You may have already discovered that methods declared private are hard to test, because by de\ufb01nition they can only be called from within an instance method of that class\u2014meaning they cannot be called directly from an RSpec test. Although you can use a hack to temporarily make the method public (MyClass.send(:public,:some_private_method)), complex enough to need their own tests should be considered a smell: the methods themselves may be too long, violating the Short guideline of SOFA, and the class containing these methods may be violating the Single Responsibility Principle. In this case, consider extracting a collaborator class whose methods are public (and therefore easy to test and easy to shorten by refactoring) but are only called from the original class, thereby improving maintainability and testability. private methods Pitfall: Using initialize to implement factory patterns. In Section 11.4, we showed an example of Abstract Factory pattern in which the correct subclass constructor is called directly. Another common scenario is one in which you have a class A with subclasses A1 and A2, and you want calls to A\u2019s constructor to return a new object of the correct subclass. You usually cannot put the factory logic into the initialize method of A, because that method must by de\ufb01nition return an instance of class A. Instead, give the factory method a different name such as create, make it a class method, and call it from A\u2019s constructor: https://gist.github.com/f6cd62078436064577a5773617fcccd4 1 2 3 4 5 def self . create ( subclass , * args ) # subclass must be either ' A1 ' or ' A2 ' return Object . const_get ( subclass ) . send (: new , * args ) class A end end"
    ]
  },
  {
    "id": "sec_0580",
    "title": "11.11 Concluding Remarks: Frameworks Capture Design Patterns",
    "pages": [
      378,
      379,
      380,
      381,
      382
    ],
    "text_blocks": [
      "The process of preparing programs for a digital computer is especially attractive, not only because it can be economically and scienti\ufb01cally rewarding, but also because it can be REFERENCES 367 an aesthetic experience much like composing poetry or music. \u2014Donald Knuth The idea of design patterns is inspired by Christopher Alexander\u2019s 1977 book A Pattern Language: Towns, Buildings, Construction describing design patterns for civil architecture. Erich Gamma, Richard Helm, Ralph Johnson and John Vlissides (the \u201cGang Of Four\u201d or GOF) published the seminal book Design Patterns: Elements of Reusable Object-Oriented Software in 1995 (Gamma et al. 1994). It described what are now called the 23 GoF Design Patterns focusing on class-level structures and behaviors. The original 23 design patterns from the Gang of Four have been expanded dramatically since their book appeared. There are numerous repositories of design patterns (Cunningham 2013; Noble and Johnson 2013), with some tailored to speci\ufb01c problem areas such as user interfaces (Grif\ufb01ths 2013; Toxboe 2013). Despite design patterns\u2019 popularity as a tool, they have been the subject of some critique; for example, Peter Norvig, currently Google\u2019s Director of Research, has argued that some design patterns just compensate for de\ufb01ciencies in statically-typed programming languages such as C++ and Java, and that the need for them disappears in dynamic languages such as Lisp or Ruby. Notwithstanding some controversy, patterns of many kinds remain a valuable way for software engineers to identify structure in their work and bring proven solutions to bear on recurring problems. A problem for novice developers is that even if you read the Gang of Four book or study If you don\u2019t have previous these repositories, it is hard to know which pattern to apply. experience with a given design pattern, and you try to design for it in an anticipatory manner, you\u2019re more likely to get it wrong, so you should instead wait to add it later when and if it\u2019s really needed. The good news is that frameworks like Rails encapsulate others\u2019 design experience to pro- vide abstractions and design constraints that have been proven through reuse. For example, it may not occur to you to design your app\u2019s actions around REST, but it turns out that doing so results in a design that is more consistent with the scalability success stories of the Web. While the Gang of Four went out of their way to differentiate design patterns from frame- works to try to make it clear what design patterns are\u2014more abstract, narrower in focus, and not targeted to a problem domain\u2014today frameworks are a great way for a novice to get started with design patterns. By examining the patterns in a framework that are instantiated as code, you can gain experience on how to create your own code based on design patterns. Design Patterns (Gamma et al. 1994) is the classic Gang of Four text on design patterns. While canonical, it\u2019s a bit slower reading than some other sources, and the examples are heavily oriented to C++. Design Patterns in Ruby (Olsen 2007) treats a subset of the GoF patterns in detail showing Ruby examples. It also discusses patterns made unnecessary by Ruby language features. Clean Code (Martin 2008) has a more thorough exposition of both the SOFA and SOLID guidelines that motivate the use of design patterns. Rather than presenting a \u201claundry list\u201d of patterns, we tried to motivate a subset of patterns by showing the design smells they \ufb01x. Rails Antipatterns (Pytel and Saleh 2010) gives great examples of how real-life code that starts with a good design can become cluttered over time, and how to beautify and streamline it by refactoring, often using one or more of the appropriate design patterns. Figure 11.24 shows a few examples of those refactorings, largely drawn from Martin Fowler\u2019s online catalog of refactorings13 and comprehensive book (Fields et al. 2009). 368 REFERENCES Smell Comment deodorant, inappropriate name Description Obfuscated variable or method names make lots of comments necessary Lazy class, data class Duplicated code, combinatorial explosion Parallel inheritance hierarchy A class does too little, for example, providing nothing but getters and setters for some object but no other logic Nearly the same code repeated with subtle changes in multiple methods, in same class Nearly the same code repeated with subtle changes in different classes that inherit from dif- ferent ancestors; for example, numerous pieces of code using slightly different combinations of data or behavior Fix Reduce need for comments through descriptive names and (as necessary) by addressing other smells within the offending code Merge methods that encapsulate the data object into another class Extract common parts using DRY mechanisms like blocks and yield (Section 2.3), extracting helper methods (Section 9.6), using Template or Strategy design pattern (Section 11.4) Extract commonality into its own class and del- egate to that class (Section 11.7). If classes with different ancestors need the functionality, try ex- tracting it into a module that can be mixed in Figure 11.24: Some smells are relatively easily \ufb01xed by a local modi\ufb01cation. These are excerpted from Fowler\u2019s Refactoring, Ruby Edition (Fields et al. 2009). W. Cunningham. Portland pattern repository, 2013. URL http://c2.com/ppr/. J. Fields, S. Harvie, M. Fowler, and K. Beck. Refactoring: Ruby Edition. Addison-Wesley Professional, 2009. ISBN 0321603508. E. Gamma, R. Helm, R. Johnson, and J. M. Vlissides. Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley Professional, 1994. ISBN 0201633612. R. Grif\ufb01ths. HCI design patterns, 2013. URL http://www.hcipatterns.org/ patterns. R. C. Martin. Clean Code: A Handbook of Agile Software Craftsmanship. Prentice Hall, 2008. ISBN 9780132350884. S. Metz. Practical Object-Oriented Design in Ruby: An Agile Primer (Addison-Wesley Professional Ruby). Addison-Wesley Professional, 2012. ISBN 0321721330. URL http: //poodr.com. J. Noble and R. Johnson. Design patterns library, 2013. URL http://hillside.net/ patterns. R. Olsen. Design Patterns in Ruby. Addison-Wesley Professional, 2007. 9780321490452. ISBN C. Pytel and T. Saleh. Rails AntiPatterns: Best Practice Ruby on Rails Refactoring (Addison-Wesley Professional Ruby Series). Addison-Wesley Professional, 2010. ISBN 9780321604811. A. Toxboe. UI patterns, 2013. URL http://ui-patterns.com/. NOTES Notes 369 1http://cleancoder.com 2http://martinfowler.com/eaaCatalog 3http://ui-patterns.com 4http://en.wikipedia.org/wiki/Unified_Modeling_Language 5http://en.wikipedia.org/wiki/Unified_Modeling_Language 6http://cruise.site.uottawa.ca/umple/ 7http://try.umple.org 8http://en.wikipedia.org/wiki/Python_syntax_and_semantics#Decorators 9http://nokogiri.org 10http://www.ruby-doc.org/stdlib-1.9.3/libdoc/observer/rdoc/Observable.html 11http://www.martinfowler.com/articles/designDead.html 12https://youtu.be/npOGOmkxuio 13http://martinfowler.com/refactoring/catalog 12 Dev/Ops: Deployment, Performance, Reliability, and Practical Security Ronald Rivest (1947\u2013), Adi Shamir (1952\u2013), and Leonard Adleman (1945\u2013) received the 2002 Turing Award for making public-key cryptography useful in practice. In the eponymous RSA algorithm, the security properties of keypairs are based on the dif\ufb01culty of factoring large integers and performing modular exponentiation, that is, determining m such that C = mE mod N . My response was \u201cCongratulations, Ron, that should work.\u201d \u2014Len Adleman, reacting to Ron Rivest\u2019s encryption proposal, 1977 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
    ]
  },
  {
    "id": "sec_0581",
    "title": "12.1 From Development to Deployment",
    "pages": [
      382
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0582",
    "title": "12.2 Three-Tier Architecture .",
    "pages": [
      382
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0583",
    "title": "12.3 Responsiveness, Service Level Objectives, and Apdex .",
    "pages": [
      382
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0584",
    "title": "12.4 Releases and Feature Flags",
    "pages": [
      382
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0585",
    "title": "12.5 Monitoring and Finding Bottlenecks",
    "pages": [
      382
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0586",
    "title": "12.6 Improving Rendering and Database Performance With Caching .",
    "pages": [
      382
    ],
    "text_blocks": [
      ". . ."
    ]
  },
  {
    "id": "sec_0587",
    "title": "12.7 Avoiding Abusive Database Queries .",
    "pages": [
      382
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0588",
    "title": "12.8 CHIPS: Exploiting Caching and Indices",
    "pages": [
      382
    ],
    "text_blocks": [
      ". ."
    ]
  },
  {
    "id": "sec_0589",
    "title": "12.9 Security: Defending Customer Data in Your App .",
    "pages": [
      382,
      383,
      384,
      385
    ],
    "text_blocks": [
      ". 12.10The Plan-And-Document Perspective on Operations . . . . 12.11Fallacies and Pitfalls . . . 12.12Concluding Remarks: Beyond PaaS Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373 . 375 . 378 . 382 . 385 . 387 . 391 . 394 . 394 . 400 . 402 . 406 371 Prerequisites and Concepts The big concept of this chapter is how to avoid the following headaches when your app is deployed: crashes, becoming unresponsive if it experiences a surge in popularity, or compromising customer data. Such non-functional characteristics can be more important than functional features since such headaches can drive users away. While deploying on a Platform-as-a-Service (PaaS) simplies addressing these challenges, the techniques you must use to make your app take best advantage of PaaS are essentially the same ones you will need if you abandon PaaS. Concepts: For SaaS using an Agile lifecycle: \u2022 Most SaaS servers follow the three-tier architecture pattern, which separates the responsibilities of different SaaS server components (Web server tier, applica- tion server tier, and database or storage tier) and enables horizontal scaling to accommodate millions of users. \u2022 Deployment and maintenance headaches are greatly simplied by deploying your app on a Platform as a Service (PaaS), which manages much of the administration and scaling for you, including some aspects of horizontal scaling. \u2022 Because the database cannot benet from horizontal scaling in a 3-tier architecture as readily as the Web server or app server, database capacity is often the reason an app has to abandon the PaaS solution. But you can maximize your benet from a PaaS-hosted database by using techniques that ease the load on the database, such as caching , creating indices, and avoiding unnecessary and expensive database queries. \u2022 Even with PaaS and horizontal scaling, the difcult performance challenge for 3-tier apps is latency , which can be helped by overprovisioning in limited cases. The Apdex metric is a standard measure to see if an app is meeting its Service Level Objective (SLO). \u2022 Releases are more challenging in SaaS since you normally need to deploy new versions without rst taking down old ones. Feature ags make it easier to quickly deploy and remove new features should the need arise. \u2022 Security can be enhanced by following the principles of least privilege and fail- safe defaults, which limit access to assets on a need-to-know basis, and the principle of psychological acceptability, which states that the user interface must not be more difcult with protection features than without them. \u2022 Defensive programming anticipates aws before they appear and can lead to systems that are both more reliable and more secure. For Plan-and-Document lifecycles: \u2022 Performance is just a possible non-functional requirement. 372 CHAPTER 12. DEV/OPS \u2022 Releases are less frequent, larger events than in Agile. \u2022 The Mean Time Between Failures (MTBF) is a holistic measure of uptime, in- cluding errors by the hardware, the software, and the operators. Reducing Mean Time to Repair (MTTR) can be just as effective in improving uptime as trying to increase MTBF, and MTTR is easier to measure than MTBF. \u2022 Security can be enhanced by making the system robust against software aws that leave it open to attacks, such as bu\ufb00er over\ufb02ows, arithmetic over\ufb02ows, and data races. 12.1. FROM DEVELOPMENT TO DEPLOYMENT 373 Figure 12.1: The Agile software lifecycle and its relationship to the chapters in this book. This chapter covers deploying the app into the cloud so that the customer can evaluate this Agile iteration."
    ]
  },
  {
    "id": "sec_0590",
    "title": "12.1 From Development to Deployment",
    "pages": [
      385,
      386,
      387
    ],
    "text_blocks": [
      "Users are a terrible thing. Systems would be in\ufb01nitely more stable without them. \u2014Michael Nygard, Release It! (Nygard 2007) The moment a SaaS app is deployed, its behavior changes because it has actual users. If it is a public-facing app, it is open to malicious attacks as well as unexpected success, but even private apps such as internal billing systems must be designed for deployability and monitorability in order to ensure smooth deployment and operations. In addition, there are necessarily differences between the environment in which you develop and test your app and the environment in which it is deployed, and these differences can sometimes result in unexpected (and usually undesirable) changes in app behavior between development and deployment that your tests didn\u2019t catch. Fortunately, as Figure 12.1 reminds us, deployment is part of every iteration in the Agile lifecycle\u2014indeed, many Agile SaaS companies deploy several times per day\u2014so you will quickly become practiced in \u201croutine\u201d deployments. SaaS deployment is much easier than it used to be. Just a few years ago, SaaS devel- opers had to learn quite a bit about system administration in order to manage their own production servers. For small sites they were typically hosted on shared Internet Service Providers (\u201cmanaged-hosting ISP\u201d), on virtual machines running on shared hardware (Vir- tual Private Server or VPS), or on one or more dedicated computers physically located at the ISP\u2019s datacenter (\u201chosting service\u201d). Today, the horizontal scaling enabled by cloud comput- ing (Section 12.2) has given rise to companies like Heroku that provide a Platform as a Service (PaaS): a curated software stack ready for you to deploy your app, with much of the administration and scaling responsibility managed for you, making deployment much more developer-friendly. PaaS providers may either run their own datacenters or, increasingly, rely 374 CHAPTER 12. DEV/OPS on lower-level Infrastructure as a Service (IaaS) providers such as the Amazon public cloud, as Heroku does. For early-stage and many mature SaaS apps, PaaS is now the preferred way to deploy: basic scaling issues and performance tuning are handled for you by professional SaaS ad- ministrators who are more experienced at operations than most developers. Of course, when a site becomes large enough or popular enough, its technical needs may outgrow what PaaS can provide, or economics may suggest bringing operations \u201cin-house\u201d, which as we will see is a major undertaking. Therefore one goal of this chapter is to help your app stay within the PaaS-friendly usage tier for as long as possible. Indeed, if your app is internally-facing, so that its maximum user base is bounded and it runs in a more protected and less hostile environment than public-facing apps, you may have the good fortune to stay in that tier in- de\ufb01nitely. In general, though, performance, reliability, and security are systemwide concerns that must be constantly reviewed, rather than problems to be solved once and then set aside. While PaaS helps address some of these concerns, others must be confronted directly by the app developers, or PaaS cannot help you. For example, as we will see, a key to managing the growth of your app is controlling the demands placed on the database, which is harder to scale horizontally. One insight of this chapter is that the performance and security problems you face are the same for both small- and large-scale SaaS apps, but the solutions differ because PaaS providers can be very helpful in solving some of the problems, saving you the work of a custom-built solution. Notwithstanding the title of this chapter, the terms performance and security are often overused and ill-de\ufb01ned. Here is a more focused list of key operational criteria we will address. \u2022 Responsiveness: how long do most users wait before the app delivers a useful re- sponse? (Section 12.3) \u2022 Release management: how can you deploy or upgrade your app \u201cin place\u201d without reducing availability and responsiveness? (Section 12.4) \u2022 Availability: what percentage of the time is your app correctly serving requests? (Sec- tion 12.3) \u2022 Scalability: as the number of users increases, either gradually and permanently or as a one-time surge of popularity, can your app maintain its steady-state availability and responsiveness without increasing the operational cost per user? As Section 12.2 ex- plains, three-tier SaaS apps on cloud computing have excellent potential horizontal scalability, but good design alone doesn\u2019t guarantee that your app will scale (though poor design guarantees that it won\u2019t). Caching (Section 12.6) and avoiding abuse of the database (Section 12.7) can help. \u2022 Privacy: is important customer data accessible only to authorized parties, such as the data\u2019s owner and perhaps the app\u2019s administrators? \u2022 Authentication: can the app ensure that a given user is who they claim to be, by verify- ing a password or using third-party authentication such as Facebook Login or OpenID in such a way that an impostor cannot successfully impersonate another user without having obtained the user\u2019s credentials? 12.2. THREE-TIER ARCHITECTURE 375 \u2022 Data integrity: can the app prevent customer data from being tampered with, or at least detect that tampering has occurred or that data may have been compromised? The \ufb01rst three items in the above list might be collectively referred to as performance stability, while the last three collectively address security, which Section 12.9 discusses. Lastly, the opening of this section warned about unexpected problems due to differences between development and production environments, or a lack of so-called development\u2013 production parity. Because it is impossible to foresee and test every such possibility be- fore deployment, the alternative is to make deployment itself as agile as possible by relying heavily on automation. If deployment of a new version of the software causes unexpected problems, how easily can you \u201croll back\u201d to the previous version? If a schema migration or data migration causes unexpected problems, can you easily restore a database snapshot taken immediately before the migration was run? A good rule of thumb for managing your production environment is to assume that any task you need to do in that environment will fail the \ufb01rst time and will have to be repeated from scratch. If the task was automated, you just type one line to rerun the script. If the task consisted of manual steps, you must repeat the steps, which takes longer and is particularly error-prone when you\u2019re operating under the psychological pressure caused by having broken the production server. More so than with any other aspect of SaaS, when it comes to deployment, automate everything. Summary \u2022 High availability and responsiveness, release management without downtime, and scalability without increasing per-user costs are three key performance stability con- cerns of SaaS apps, and defending your customers\u2019 data is the app\u2019s key security concern. \u2022 Good PaaS providers can provide infrastructure mechanisms to automatically han- dle some of the details of maintaining performance stability and security, but as a developer you must also address these concerns in various aspects of your app\u2019s design and implementation, using mechanisms we will discuss in this chapter. \u2022 Compared to shrink-wrapped software, SaaS developer-operators are typically much more involved with deploying, releasing, and upgrading their apps and monitoring them for problems with performance or security. Self-Check 12.1.1. Which aspects of application scalability are not automatically handled for you in a PaaS environment? If your app \u201coutgrows\u201d the capacity of the largest database offered by the PaaS provider, you will need to manually build a solution to split it into multiple distinct databases. This task is highly app-speci\ufb01c so PaaS providers cannot provide a generic mechanism to do it."
    ]
  },
  {
    "id": "sec_0591",
    "title": "12.2 Three-Tier Architecture",
    "pages": [
      387,
      388,
      389,
      390
    ],
    "text_blocks": [
      "So far we have treated the overall SaaS server as a \u201cblack box\u201d: whereas Chapter 3 considered the software architecture of SaaS and SOA generally, and Chapter 4 examined the software rake is the Rails tool designed to automate deployment tasks that require access to the app\u2019s classes, schema, and so on. 376 CHAPTER 12. DEV/OPS architecture of SaaS applications using patterns such as Model\u2013View\u2013Controller, we have been oblivious to how the other parts of the server are organized. For example, SaaS apps use HTTP to communicate, yet you haven\u2019t had to write any of the code that handles the details of such communication. We also have largely ignored how SaaS software components are deployed on actual hardware in production. While PaaS hides much of the hardware details from you, a high-level understanding of the hardware architecture is key to making good de- cisions about scalability in your software architecture. To that end, this section explains how SaaS servers typically follow a three-tier architecture, how the logical boundaries sepa- rating those tiers are in place whether you run a development server on your own computer or deploy on a public cloud facility such as Heroku, how the components in the three-tier architecture typically map onto the cloud hardware, and what the resulting implications are for scaling up a SaaS app, that is, allowing it to serve more and more users. Figure 12.2 shows the canonical three-tier architecture. The presentation tier usually con- sists of an HTTP server (or simply \u201cWeb server \u201d), which accepts HTTP requests from the outside world (i.e. users) and handles the serving of static assets such as images, stylesheets, \ufb01les of JavaScript code, and so on. The web server forwards requests for dynamic content to the logic tier , where your actual application runs. The application is typically supported by an application server whose job is to hide the low-level mechanics of these HTTP interactions from the app writer. We\u2019ve been using the Rack application server, which ships with the Rails framework. If you were writing in PHP, Python, or Java, you would use an application server that handles code written in frameworks that use those languages, such as Django for Python or Node.js for JavaScript. Finally, since HTTP is stateless (Chapter 3), application data that must remain stored across HTTP requests, such as users\u2019 login and pro\ufb01le information, is stored in the persis- tence tier . Popular choices for the persistence tier have traditionally been databases such as the open-source MySQL or PostgreSQL, although prior to their proliferation, commercial databases such as Oracle or IBM DB2 were also popular choices. The \u201ctiers\u201d in the three-tier model are logical tiers. On a site with little content and low traf\ufb01c, the software in all three tiers might run on a single physical computer: when you run rails server to do local development, the simple single-user WEBrick Web server ful\ufb01lls the role of the presentation tier, and a single-user database called SQLite, which stores its information directly in \ufb01les on your local computer, serves for persistence. In production, it\u2019s more common for each tier to span one or more physical computers and to use highly specialized software. As Figure 12.2 shows, in a typical site, incoming HTTP requests are directed to one of several Web servers, possibly Apache1 or Microsoft Internet Information Server2, either of which can be deployed on hundreds of computers ef\ufb01ciently serving many copies of the same site to millions of users. When a Web server receives a request for you app, it selects one of several available application servers to handle dynamic-content generation, allowing computers to be added or removed from each tier as needed to handle demand. However, as the Fallacies and Pitfalls section explains, making the persistence tier \u201cshared-nothing\u201d is much more complicated. Figure 12.2 shows one approach: a prima- ry/replica or primary/secondary con\ufb01guration, used when the database is read much more frequently than it is written. In this approach, any replica can perform reads, only the primary can perform writes, and the primary updates the replicas with the results of writes as quickly as possible. However, in the end, this and other techniques only postpone the scaling problem LAMP. Early SaaS sites were created using the Perl or PHP scripting languages, whose availability coincided with the early success of Linux, an open-source operating system, and MySQL, an open-source database. Thousands of sites are still powered by the LAMP Stack\u2014Linux, Apache, MySQL, and PHP or Perl. Cowboy, Heroku\u2019s custom-built web server, is written in Erlang , a language optimized for \u201cevent driven\u201d apps such as serving Web content. Separate tiers mean that each tier\u2019s software can use the best tool for the job. 12.2. THREE-TIER ARCHITECTURE 377 Figure 12.2: The 3-tier shared-nothing architecture, so called because entities within a tier generally do not communicate with each other, allows adding computers to each tier independently to match demand. Load balancers, which distribute workload evenly, can be either hardware appliances or specially-con\ufb01gured Web servers. The statelessness of HTTP makes shared-nothing possible: since all requests are independent, any server in the presentation or logic tier can be assigned to any request. However, scaling the persistence tier is much more challenging, as the text explains. rather than solving it. As one of Heroku\u2019s3 founders wrote: A question I\u2019m often asked about Heroku is: \u201cHow do you scale the SQL database?\u201d There\u2019s a lot of things I can say about using caching, sharding, and other techniques to take load off the database. But the actual answer is: we don\u2019t. SQL databases are fundamentally non-scalable, and there is no magical pixie dust that we, or anyone, can sprinkle on them to suddenly make them scale. \u2014Adam Wiggins, Heroku, in 2009 Summary \u2022 The three-tier architecture includes a presentation tier, which renders views and in- teracts with the user; a logic tier, which runs SaaS app code; and a persistence tier, which stores app data. \u2022 HTTP\u2019s statelessness allows the presentation and logic tiers to be shared-nothing , so cloud computing can be used to add more computers to each tier as demand requires. However, the persistence tier is harder to scale. \u2022 Depending on the scale (size) of the deployment, more than 1 tier may be hosted on a single computer, or a single tier may require many computers. 378 CHAPTER 12. DEV/OPS Elaboration: Why Databases? While the earliest Web apps sometimes manipulated \ufb01les directly for storing data, there are two reasons why databases overwhelmingly took over this role very early. First, databases have historically provided high durability for stored information\u2014the guarantee that once something has been stored, unexpected events such as system crashes or transient data cor- ruption won\u2019t cause data loss. For a Web app storing millions of users\u2019 data, this guarantee is critical. Second, databases store information in a structured format\u2014in the case of relational databases, by far the most popular type, each kind of object is stored in a table whose rows represent object instances and whose columns represent object properties. This organization is a good \ufb01t for the structured data that many Web apps manipulate. Interestingly, today\u2019s largest Web apps, such as Facebook, have grown so far beyond the scale for which relational databases were designed that they are being forced to look at alternatives to the long-reigning relational database. Self-Check 12.2.1. Explain why cloud computing might have had a lesser impact on SaaS if most SaaS apps didn\u2019t follow the shared-nothing architecture. Cloud computing allows easily adding and removing computers while paying only for what you use. The shared-nothing architecture takes advantage of this ability to rapidly \u201cabsorb\u201d new computers into a running app and \u201crelease\u201d them when no longer needed. Self-Check 12.2.2. Which tier(s) of three-tier SaaS apps can be scaled just by adding more computers and why? The presentation and logic tiers. Because neither HTTP (Web) servers nor app servers maintain any of the state associated with user sessions, any computer in those tiers can in principle satisfy any user\u2019s request."
    ]
  },
  {
    "id": "sec_0592",
    "title": "12.3 Responsiveness, Service Level Objectives, and Apdex",
    "pages": [
      390,
      391
    ],
    "text_blocks": [
      "Speed is a feature. Performance is a feature. \u2014Adam De Boor, Gmail software engineer, Google \u2014Jeff Atwood, co-founder of StackOver\ufb02ow The best performance improvement is the transition from the nonworking state to the working state. \u2014John Ousterhout, designer of magic and Tcl/Tk As we learned in Section 1.7, availability refers to the fraction of time your site is avail- able and working correctly. For example, Gmail guarantees4 an availability of \u201cthree nines\u201d or 99.9% during any given month for its enterprise customers. (Nygard wryly notes (Nygard 2007) that less-disciplined sites provide closer to \u201ctwo eights\u201d or 88.0%.) Why might your app be unavailable? For one thing, it may have crashed because of an unexpected error. While most PaaS services automatically restart a crashed app, restarting can induce delays and harm availability. One way to improve the reliability of software is to make it more robust. Defensive programming is a philosophy that tries to anticipate potential software \ufb02aws and write code to handle them. Here are three examples: 12.3. RESPONSIVENESS, SERVICE LEVEL OBJECTIVES, AND APDEX 379 \u2022 Check input values. A common cause of problems is for the user to input values that the developer doesn\u2019t expect. Checking that the input is in a reasonable range for individual values, that it is not too big for a series of data, and that the collection of inputs are logically consistent can reduce the chances of outages. \u2022 Check input data type. Another mistake users can make is to enter an unexpected type of data in response to a query. Making sure the user enters a valid type of data increases the chances of success for the app. \u2022 Catch exceptions. Modern programming languages offer the ability to execute code when exceptions occur, such as arithmetic over\ufb02ow. Offering code that can catch any exception increases the chances of the app continuing to run well even when unex- pected events occur. Another availability challenge is a bug that leads to outages but only appears after a long time or under heavy load. A classic example is a resource leak: a long-running process eventually runs out of a resource, such as memory, because it cannot reclaim 100% of the unused resource due to either an application bug or the inherent design of a language or framework. Software rejuvenation is a long-established way to alleviate a resource leak: the Apache web server runs a number of identical worker processes, and when a given worker process has \u201caged\u201d enough, that process stops accepting requests and dies, to be replaced by a fresh worker. Since only one worker (1/n of total capacity) is \u201crejuvenated\u201d at a time, this process is sometimes called rolling reboot, and most PaaS platforms employ some variant of it. Overprovisioning is often used in anticipation of crash recovery and rolling reboot. The idea is to provide more servers in a tier at any given time than you think you\u2019ll need. For example, by deploying n + 1 servers in a tier, temporarily losing one server degrades per- formance by only 1/n. Good values for n can sometimes be determined empirically by monitoring, as the rest of this chapter describes. However, at large scale, systematic overpro- visioning is both economically unattractive and may be insuf\ufb01cient by itself. For example, in an app whose database queries are poorly constructed, the database will quickly become the bottleneck, and as Section 12.2 reminds us, databases are generally not amenable to shared- nothing horizontal scaling. In such a situation, overprovisioning the other tiers won\u2019t help. The lesson is that in the end, there\u2019s no substitute for a design that is free of gratuitous bot- tlenecks to scalability. Later in this chapter we identify some common bottlenecks and how to avoid them. Of course, it\u2019s not much good if your app is technically \u201cavailable\u201d but so sluggish that users don\u2019t want to use it. Responsiveness is the perceived delay between when a user takes an action such as clicking on a link and when the user perceives a response, such as new content appearing on the page. Technically, responsiveness has two components: latency , the initial delay to start receiving new content, and throughput, the time it takes for all the content to be delivered. As recently as the mid-1990s, many home users connected to the Internet using telephone modems that took 100 ms (milliseconds) to deliver the \ufb01rst packet of information and show part of the Web page. Telephone modems could sustain at most"
    ]
  },
  {
    "id": "sec_0593",
    "title": "56 Kbps (56 \u00d7 103 bits per second), so loading a complete Web page or image 50 KBytes",
    "pages": [
      391,
      392
    ],
    "text_blocks": [
      "(400 KBits) in size could take more than eight seconds. Since today\u2019s home customers in- creasingly use broadband connections whose throughput is 1\u201350 Mbps, responsiveness for Web pages is dominated by latency rather than throughput. SLA vs. SLO: A service level agreement (SLA) is a contract between a service provider and its customers that provides for customer consideration if the SLO is not met. Google believes6 that because many aspects of time-to-glass are independent of the speci\ufb01c service, it is even more important for the service to be responsive, so that getting a response from any Google service is no slower than contacting the service to begin with. 380 CHAPTER 12. DEV/OPS Since responsiveness has such a large effect on user behavior, SaaS operators carefully monitor the responsiveness of their sites. Of course, in practice, not every user interaction with the site takes the same amount of time, so evaluating performance requires appropriately characterizing a distribution of response times. Consider a site on which 8 out of 10 requests complete in 100 ms, 1 out of 10 completes in 250 ms, and the remaining 1 out of 10 completes in 850 ms. If the user satisfaction threshold T for the latency of this site is 200 ms, it is true that the average response time of (8(100) + 1(250) + 1(850))/10 = 190 ms is below the satisfaction threshold. But on the other hand, 20% of requests (and therefore, up to 20% of users) are receiving unsatisfactory service. Two de\ufb01nitions are used to measure latency in a way that makes it impossible to ignore the bad experience of even a small number of users: \u2022 A service level objective (SLO) usually takes the form of a quantitative statement about the quantiles of the latency distribution over a time window of a given width. For example, \u201c95% of requests within any 5-minute window should have a latency below"
    ]
  },
  {
    "id": "sec_0594",
    "title": "100 ms.\u201d In statistical terms, the 95th quantile of the latency distribution must not",
    "pages": [
      392,
      393,
      394
    ],
    "text_blocks": [
      "exceed 100 ms. \u2022 The Apdex score (Application Performance Index) is an open standard5 that computes a simpli\ufb01ed SLO as a number between 0 and 1 inclusive representing the fraction of satis\ufb01ed users. Given a user satisfaction threshold latency T selected by the application operator, a request is satisfactory if it completes within time T , tolerable if it takes longer than T but less than 4T , and unsatisfactory otherwise. The Apdex score is then (Satisfactory +0.5(Tolerable)) / (Number of samples). In the example above, the Apdex score would be (8 + 0.5(1))/10 = 0.85. Of course, the total response time perceived by the users includes many factors beyond your SaaS app\u2019s control. It includes DNS lookup, time to set up the TCP connection and send the HTTP request to the server, and Internet-induced latency in receiving a response containing enough content that the browser can start to draw something (so-called \u201ctime to glass,\u201d a term that will soon seem as quaint as \u201ccounterclockwise\u201d). Especially when using curated PaaS, SaaS developer/operators have the most control over the code paths in their own apps: routing and dispatch, controller actions, model methods, and database access. We will therefore focus on measuring and improving responsiveness in those components. For small sites, a perfectly reasonable way to mitigate latency is to overprovision (provide excess resources relative to steady-state) at one or more tiers, as Section 12.2 describes for the presentation and logic tiers. A few years ago, overprovisioning meant purchasing additional hardware that might sit idle, but pay-as-you-go cloud computing lets you \u201crent\u201d the extra servers for pennies per hour only when needed. Indeed, technologies like RightScale7 offer just this service on top of Amazon EC2. As we will see, a key insight that helps us is that the same problems that push us out of the \u201cPaaS-friendly\u201d tier are the ones that will hinder scalability of our post-PaaS solutions, so understanding what kinds of problems they are and how to solve them will serve you well in either situation. What are the thresholds for user satisfaction on responsiveness? A classic 1968 study from the human-computer interaction literature (Miller 1968) found three interesting thresh- olds: if a computer system responds to a user action within 100 ms, it\u2019s perceived as instan- taneous; within 1 second, the user will still perceive a cause-and-effect connection between their action and the response, but will perceive the system as sluggish; and after about 8 sec- onds, the user\u2019s attention drifts away from the task while waiting for a response. Surprisingly, 12.3. RESPONSIVENESS, SERVICE LEVEL OBJECTIVES, AND APDEX 381 more than thirty years later, a scholarly study in 2000 (Bhatti et al. 2000) and another by in- dependent \ufb01rm Zona Research in 2001 af\ufb01rmed the \u201ceight second rule.\u201d While many believe that a faster Internet and faster computers have raised users\u2019 expectations, the eight-second rule is still used as a general guideline. New Relic, whose monitoring service we introduce later, reported in March 2012 that the average page load for all pages they monitor worldwide is 5.3 seconds and the average Apdex score is 0.86. Summary \u2022 Availability measures the percentage of time over a speci\ufb01ed window that your app is correctly responding to user requests. Availability is usually measured in \u201cnines\u201d with the gold standard of 99.999% (\u201c\ufb01ve nines\u201d, corresponding to \ufb01ve minutes of downtime per year) set by the US telephone network and rarely matched by SaaS apps. \u2022 While PaaS services usually restart crashed SaaS apps, the time required to do so can harm availability. App developers can mitigate this harm using defensive pro- gramming , which adds code to handle common classes of potential \ufb02aws before they cause the app to crash. PaaS providers can mitigate it using software reju- venation, which proactively restarts members of a set of identical processes on a rotating schedule to neutralize resource leaks. \u2022 Responsiveness measures how \u201csnappy\u201d an interactive app feels to users. Given today\u2019s high-speed Internet connections and fast computers, responsiveness is dom- inated by latency. Service Level Objectives (SLOs) quantify responsiveness goals with statements such as \u201c99% of requests within any 5-minute window should have a latency below 100 ms.\u201d \u2022 Overprovisioning helps improve latency by making more computers available to handle requests in a given tier and helps with availability by dealing gracefully with server crashes. However, at large scale, systematic overprovisioning is both eco- nomically unattractive and insuf\ufb01cient by itself. \u2022 The Apdex score is a simple SLO measure between 0.0 and 1.0 in which a site gets \u201cfull credit\u201d for requests that complete within a site-speci\ufb01c latency threshold T , \u201chalf credit\u201d for requests that complete within 4T , and no credit for requests taking longer than that. \u2022 The problems that threaten availability and responsiveness are the same whether we use PaaS or not, but it\u2019s worth trying to stay within the PaaS tier because it provides machinery to help mitigate those problems. Part of \u201cscaling gracefully\u201d is avoiding problems that lead to intrinsic scalability bottlenecks, some of which we discuss in the rest of this chapter. Self-Check 12.3.1. For a SaaS app to scale to large numbers of users, it must maintain its ____ and ____ as the number of users increases, without increasing the ____. Availability; responsiveness; cost per user Self-Check 12.3.2. True or False: From the perspective of responsiveness, faster is always 382 CHAPTER 12. DEV/OPS better. False. Faster than 100 ms is not perceptible to people, and people abandon sites only when responsiveness slows to 8 seconds or worse."
    ]
  },
  {
    "id": "sec_0595",
    "title": "12.4 Releases and Feature Flags",
    "pages": [
      394,
      395,
      396,
      397
    ],
    "text_blocks": [
      "As we discussed way back in Section 1.2, prior to SaaS, software releases were major and infrequent milestones after which product maintenance responsibility passed largely to the In contrast, Many Agile companies Quality Assurance or Customer Service department. deploy new versions frequently (sometimes several times per day) and the developers stay close to operations and to customer needs. In Agile development, making deployment a non-event requires complete automation, so that typing one command triggers all the actions to deploy a new version of the software, including cleanly aborting the deploy without modifying the released version if anything goes wrong. As with iteration-based TDD and BDD, by deploying frequently you become good at it, and by automating deployment you ensure that it\u2019s done consistently every time. Although deployment is a non-event, there is still a role for release milestones: they re- assure the customer that new work is being deployed. For example, a customer-requested feature may require multiple commits to implement, each of which may include a deploy- ment, but the overall feature remains \u201chidden\u201d in the user interface until all changes are completed. \u201cTurning on\u201d the feature would be a useful release milestone. For this reason, many continuous-deployment work\ufb02ows assign distinct and often whimsical labels to spe- ci\ufb01c release points (such as \u201cBamboo\u201d and \u201cCedar\u201d for Heroku\u2019s software stacks), but just use the Git commit-id to identify deployments that don\u2019t include customer-visible changes. Of course, deployment can only be successful if the app is well tested and stable in devel- opment. Although we\u2019ve already focused heavily on testing in this book, making deployment a true non-event requires meeting two additional challenges: deployment testing and incre- mental feature rollout. Beyond traditional CI, deployment testing must account for differences between the de- velopment and production environments, such as the type of database used or the need for JavaScript-intensive apps to work correctly on a variety of browser versions. Deployment testing should also test the app in ways it was never meant to be used\u2014users submitting non- sensical input, browsers disabling cookies or JavaScript, miscreants trying to turn your site into a distributor of malware (as we describe further in Section 12.9)\u2014and ensuring that it survives those conditions without compromising customer data or responsiveness. The second challenge is the rollout of complex features that may require several code pushes, especially features that require database schema changes. In particular, a challenge arises when the new code does not work with the old schema and vice-versa. To make the example concrete, suppose RottenPotatoes currently has a moviegoers table with a name column, but we want to change the schema to have separate first_name and last_name columns instead. If we change the schema before changing the code, the app will break because methods that expect to \ufb01nd the name column will fail. If we change the code before changing the schema, the app will break because the new methods will look for first_name and last_name columns that don\u2019t exist yet. We could try to solve this problem by deploying the code and migration atomically : take the service of\ufb02ine, apply the migration to perform the schema change and copy the data from the existing name column into the two new columns, and bring the service back online. This 12.4. RELEASES AND FEATURE FLAGS 383 /* in code paths for functionality that searches the database : */ if ( featureflag is on ) results = union ( query using old schema , query using new schema ) end else /* featureflag is off */ results = ( query using old schema ) https://gist.github.com/0131ef743244fae7b9ac5fa466a7e582 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 end ( update data according to new schema ) ( update data according to old schema ) else end /* in code paths that write to the database */ if ( featureflag is on ) if ( data to be written is still using old schema ) ( convert existing record from old to new schema ) ( mark record as converted ) Figure 12.3: Pseudocode for using a feature \ufb02ag to help migrate data from an older to a newer schema incrementally. After an initial migration creates any necessary new schema elements, each function that reads or updates the affected data implements two code paths, corresponding to the older and newer schema respectively. If the feature \ufb02ag is off, only the old code path is ever used; but when the feature \ufb02ag is on, the new code path contributes results to searches and causes old data to be incrementally migrated to the new schema. Once all data has been migrated, a subsequent migration and code push can remove unused columns or tables from the old schema and remove the alternate code paths protected by the feature \ufb02ag. is the simplest solution, but may cause unacceptable unavailability: a complex migration on a database of hundreds of thousands of rows can take tens of minutes or even hours to run. The second option is to split the change across multiple deployments using a feature \ufb02ag\u2014a con\ufb01guration variable whose value can be changed while the app is running to con- trol which code paths in the app are executed. Notice that each step in Figure 12.3 is nonde- structive: as we did with refactoring in Chapter 9, if something goes wrong at a given step, the app is still left in a working intermediate state. Figure 12.3 illustrates schematically how to do this: 1. Create a migration that makes only those changes to the schema that add new tables or columns, including a column indicating whether the current record has been migrated to the new schema or not. 2. Create version n+1 of the app in which every code path affected by the schema change is split into two code paths, of which one or the other is executed based on the value of a feature \ufb02ag. Critical to this step is that correct code will be executed regardless of the feature \ufb02ag\u2019s value at any time, so the feature \ufb02ag\u2019s value can be changed without stopping and restarting the app; typically this is done by storing the feature \ufb02ag in a special database table. 3. Deploy version n+1, which may require pushing the code to multiple servers, a process that can take several minutes. 4. Once deployment is complete (all servers have been updated to version n + 1 of the code), while the app is running set the feature \ufb02ag\u2019s value to True. Essentially, each record will be migrated to the new schema the next time it\u2019s modi\ufb01ed for any reason. If you wanted to speed things up, you could also run a low-traf\ufb01c background job that opportunistically migrates a few records at a time to minimize the additional load on the app, or migrates many records at a time during hours when the app is lightly 384 CHAPTER 12. DEV/OPS loaded, if any. If something goes wrong at this step, turn off the feature \ufb02ag; the code will revert to the behavior of version n, since the new schema is a proper superset of the old schema and the before_save callback is nondestructive (that is, it correctly updates the user\u2019s name in both the old and new schemata). 5. If all goes well, once all records have been migrated, deploy code version n + 2, in which the feature \ufb02ag is removed and only the code path associated with the new schema remains. 6. Finally, apply a new migration that removes the old name column and the temporary migrated column (and therefore the index on that column). What about a schema change that modi\ufb01es a column\u2019s name or format rather than adding or removing columns? The strategy is the same: add a new column, remove the old column, and if necessary rename the new column, using feature \ufb02ags during each transition so that every deployed version of the code works with both versions of the schema. Besides handling destructive migrations, feature \ufb02ags have other uses as well: \u2022 Pre\ufb02ight checking: roll out a feature to a small percentage of users only, in order to make sure the feature doesn\u2019t break anything or have a negative effect on overall site performance. \u2022 A/B testing: roll out two different versions of a feature to two different sets of users to see which version most improves user retention, purchases, and so on. \u2022 Complex feature: sometimes the complete functionality associated with a feature may require multiple incremental deployment cycles such as the one described above. In this case, a separate feature \ufb02ag can be used to keep the feature hidden from the user interface until 100% of the new feature code has been deployed. Summary \u2022 In general, SaaS deployment should be so automated and straightforward that it can be done frequently, up to several times a day, while remaining a non-event. \u2022 One way to ensure a smooth deployment is to include additional deployment tests that must run before a deploy is attempted, to test differences between the develop- ment and production environments and to stress the app by deliberately simulating user misbehaviors. \u2022 To perform a complex upgrade that changes both the app code and the schema, use a feature \ufb02ag whose value can be changed while the app is running. The feature \ufb02ag\u2019s value selectively enables certain code paths at runtime, and can be immedi- ately turned off if a bug is observed after deployment. Otherwise, once all data has been incrementally migrated as a result of changing the feature \ufb02ag\u2019s value, you can deploy a new migration and code push that eliminate the old code paths and schema elements. The rollout8 gem supports the use of feature \ufb02ags for all these cases. 12.5. MONITORING AND FINDING BOTTLENECKS 385 Elaboration: Continuous Deployment The extreme version of making deployment a non-event is continuous deployment, in which every successful CI run (continuous integration, discussed in Section 10.4) automatically triggers a deployment to staging or production. CD can result in multiple deployments per day, many of which include changes not visible to the customer that \u201cbuild towards\u201d a feature that will be unveiled at a release milestone. Self-Check 12.4.1. Which of the following are appropriate places to store the value of a simple Boolean feature \ufb02ag and why: (a) a YAML \ufb01le in the app\u2019s config directory, (b) a column in an existing database table, (c) a separate database table? The point of a feature \ufb02ag is to allow its value to be changed at runtime without modifying the app. Therefore (a) is a poor choice because a YAML \ufb01le cannot be changed without touching the production servers while the app is running."
    ]
  },
  {
    "id": "sec_0596",
    "title": "12.5 Monitoring and Finding Bottlenecks",
    "pages": [
      397,
      398,
      399
    ],
    "text_blocks": [
      "If you\u2019re not monitoring it, it\u2019s probably broken. \u2014variously attributed Given the importance of responsiveness and availability, how can we measure them, and if they\u2019re unsatisfactory, how can we identify what parts of our app need attention? Monitoring consists of collecting app performance data for analysis and visualization. In the case of SaaS, application performance monitoring (APM) refers to monitoring the Key Performance Indicators (KPIs) that directly impact business value. KPIs are by nature app-speci\ufb01c\u2014for example, an e-tailer\u2019s KPIs might include responsiveness of adding an item to a shopping cart and percentage of user searches in which the user selects an item that is in the top 5 search results. There are various techniques for monitoring SaaS apps, and we can characterize them in terms of three axes: 1. Is the monitoring active or passive? In active monitoring, an external stimulus is delib- erately applied to the app (even if the app would be otherwise idle) in order to ensure it\u2019s working. In passive monitoring, no monitoring data is collected until some external user asks the app to do something. 2. Is the monitoring external or internal? External monitoring can only report on the behavior of an app as seen from the outside\u2014for example, reporting that some types of requests take longer than other types. Internal monitoring can \u201chook\u201d into the code of the app server or the app itself, so it can provide better attribution\u2014how long did a request spend in each tier of the SaaS stack and in different parts of your app (for example, the controllers, the models, the database, or the view rendering)? 3. Is the monitoring focused on app performance or user behavior? For example, you might want to know what fraction of users who added an item to their shopping cart ended up purchasing the item, and what actions were taken instead by the users who didn\u2019t end up completing the purchase. Such questions can be critical for a business even though they have little to do with performance. (Of course, performance monitor- ing might reveal the reasons some users don\u2019t complete the purchase \ufb02ow!) 386 CHAPTER 12. DEV/OPS Regardless of which combination of the above axes is provided by a particular monitoring solution, we must also address the issue of how the collected monitoring data is stored and how it is presented or reported to the app\u2019s dev/ops team. Before cloud computing and the prominence of SaaS and highly-productive frameworks, internal monitoring required installing programs that collected metrics periodically, manually inserting extra code into your app, or both. Today, the combination of hosted PaaS, Ruby\u2019s dynamic language features, and well-factored frameworks such as Rails allows internal mon- itoring without modifying your app\u2019s source code or installing software. For example, New Relic9 unobtrusively collects instrumentation about your app\u2019s controller actions, database queries, and so on, making use of metaprogramming in Rails to do this without requiring changes to your app\u2019s code. Because the data is sent back to New Relic\u2019s SaaS site where you can view and analyze it, this architecture is sometimes called RPM for Remote Perfor- mance Monitoring. New Relic provides both internal passive monitoring and external active monitoring, in which you can set up HTTP \u201cprobe\u201d requests with \ufb01xed URIs and test for the presence of particular strings in the apps\u2019 responses. Internal monitoring can also occur during development, when it is often called pro\ufb01ling . New Relic and other monitoring solutions can be installed in development mode as well. How much pro\ufb01ling should you do? If you\u2019ve followed best practices in writing and testing your app, it may be most productive to just deploy and see how the app behaves under load, especially given the unavoidable differences between the development and production envi- ronments, such as the lack of real user activity and the use of a development-only database such as SQLite rather than a highly tuned production database such as PostgreSQL. After all, with agile development, it\u2019s easy to deploy incremental \ufb01xes such as implementing basic caching (Section 12.6) and \ufb01xing abuses of the database (Sections 12.7). In external monitoring (sometimes called probing or active monitoring), a separate site makes live requests to your app to check availability and response time. Why would you need external monitoring given the detailed information available from internal monitoring that has access to your code? Internal monitoring may be unable to reveal that your app is sluggish or unavailable if the problem is due to factors other than your app\u2019s code\u2014for example, performance problems in the presentation tier or other parts of the software stack beyond your app\u2019s boundaries. External monitoring, like an integration test, is a true end- to-end test of a limited subset of your app\u2019s code paths as seen by actual users \u201cfrom the outside.\u201d Once a monitoring tool has identi\ufb01ed the slowest or most expensive requests, stress test- ing or longevity testing on a staging server can quantify the level of demand at which those requests become bottlenecks. The free and widely-used command line tool httperf , main- tained by Hewlett-Packard Laboratories10, can simulate a speci\ufb01ed number of users request- ing simple sequences of URIs from an app and while recording metrics about the response times. Whereas tools like Cucumber let you write expressive scenarios and check arbitrarily complex conditions, httperf can only follow simple sequences of URIs and only checks whether a successful HTTP response was received from the server. In a typical stress test, the test engineer will set up several computers running httperf against the staging site and gradually increase the number of simulated users until some resource becomes the bottleneck. Finally, monitoring can also help you understand your customers\u2019 behavior: \u2022 Clickstreams: what are the most popular sequences of pages your users visit? \u2022 Think times/dwell times: how long does a typical user stay on a given page? 12.6. IMPROVING RENDERING AND DATABASE PERFORMANCE WITH CACHING387 \u2022 Abandonment: if your site contains a \ufb02ow that has a well-de\ufb01ned termination, such as making a sale, what percentage of users \u201cabandon\u201d the \ufb02ow rather than completing it and how far do they get? layout Google Analytics provides free basic analytics-as-a-service: you embed a small piece of JavaScript in every page on your site (for example, by embedding it on the de- fault template) that sends Google Analytics information each time a page is loaded. To help you use this information, Google\u2019s \u201cSpeed is a Feature\u201d11 site links the different ways to a breathtakingly comprehensive collection of articles about all you can speed up your SaaS apps, including many optimizations to reduce the overall size of your pages and improve the speed at which Web browsers can render them. Summary \u2022 As with testing, no single type of monitoring will alert you of all performance prob- lems: use a combination of internal and external (end-to-end) monitoring. \u2022 Hosted monitoring such as Pingdom and PaaS-integrated monitoring such as New Relic greatly simplify monitoring compared to the early days of SaaS. \u2022 Stress testing and longevity testing can reveal the bottlenecks in your SaaS app and frequently expose bugs that would otherwise remain hidden. \u2022 User-centric analytics can provide information about the behavior of users as they navigate your site, which can be extremely valuable business data even though un- related to performance per se. Elaboration: Request tracing A \ufb01ner-grained approach to internal monitoring is request tracing, which is used in conjunc- tion with metric aggregation to pinpoint and diagnose slow requests. Request tracing follows a request through every software component in every tier and timestamping it along the way, often at every function call entry. Google has used request tracing to identify obstacles to keeping their massively-parallel systems highly responsive (Barroso and Dean 2012). Self-Check 12.5.1. Which of the following key performance indicators (KPIs) would be rel- evant for Application Performance Monitoring: CPU utilization of a particular computer; completion time of slow database queries; view rendering time of 5 slowest views. Query completion times and view rendering times are relevant because they have a direct impact on responsiveness, which is generally a Key Performance Indicator tied to business value delivered to the customer. CPU utilization, while useful to know, does not directly tell us about the customer experience."
    ]
  },
  {
    "id": "sec_0597",
    "title": "12.6 Improving Rendering and Database Performance With Caching",
    "pages": [
      399,
      400,
      401,
      402,
      403
    ],
    "text_blocks": [
      "There are only two hard things in computer science: cache invalidation and naming things. \u2014Phil Karlton 388 CHAPTER 12. DEV/OPS Figure 12.4: The goal of multiple levels of caching is to satisfy each HTTP request as close to the user as possible. (a) A Web browser that has previously visited a page can reuse the copy in its local cache after verifying with the server that the page hasn\u2019t changed. (b) Otherwise, the Web server may be able to serve it from the page cache, bypassing Rails altogether. (c) Otherwise, if the page is generated by an action protected by a before-\ufb01lter, Rails may be able to serve it from the action cache without querying the database or rendering any templates. (d) Otherwise, some of the fragments comprised by the view templates may be in the fragment cache. (e) As a last resort, the database\u2019s query cache serves the results of recent queries whose results haven\u2019t changed, such as Movie.all. The idea behind caching is simple: information that hasn\u2019t changed since the last time it was requested can simply be regurgitated rather than recomputed. In SaaS, caching can help two kinds of computation. First, if information needed from the database to complete an action hasn\u2019t changed, we can avoid querying the database at all. Second, if the information underlying a particular view or view fragment hasn\u2019t changed, we can avoid re-rendering the view (recall that rendering is the process of transforming Erb with embedded Ruby code and variables into HTML). In any caching scenario, we must address two issues: 1. Naming: how do we specify that the result of some computation should be cached for later reuse, and name it in a way that ensures it will be used only when that exact same computation is called for? 2. Expiration: how do we detect when the cached version is out of date (stale) because the information on which it depends has changed, and how do we remove it from the cache? The variant of this problem that arises in microprocessor design is often referred to as cache invalidation. Figure 12.4 shows how caching can be used at each tier in the 3-tier SaaS architecture and what Rails entities are cached at each level. The simplest thing we could do is cache the entire HTML page resulting from rendering a particular controller action. For example, the MoviesController#show action and its corresponding view depend only on the attributes of the particular movie being displayed (the @movie variable in the controller method and view template). Figure 12.5 shows how to cache the entire HTML page for a movie, so that future requests to that page neither access the database nor re-render the HTML, as in Figure 12.4(b). Of course, this is unsuitable for controller actions protected by before-\ufb01lters, such as pages that require the user to be logged in and therefore require executing the controller \ufb01lter. In such cases, changing caches_page to caches_action will still execute any \ufb01lters but allow Rails to deliver a cached page without consulting the database or re-rendering views, as in Figure 12.4(c). Figure 12.7 shows the bene\ufb01ts of page and action caching for this simple 12.6. CACHING FOR DATABASES & RENDERING 389 https://gist.github.com/178cb5d9f527c2d6e5b045edd418550b 1 2 3 4 # In Gemfile , include gems for page and action caching gem ' actionpack - page_caching ' gem ' actionpack - action_caching ' gem ' rails - observers ' class M ovi e sController < A p p l i c a t i o n C o n t r o l l e r https://gist.github.com/c14b8bbe5c710a570401d3c520bd093d 1 2 3 4 5 6 7 caches_page : show cache_sweeper : movie_sweeper def show @movie = Movie . find ( params [: id ]) end end and rendered partials become invalid class MovieSweeper < ActionController :: Caching :: Sweeper observe Movie # if a movie is created or deleted , movie list becomes invalid # def after_save ( movie ) ; invalidate ; end def after_destroy ( movie ) ; invalidate ; end private def invalidate https://gist.github.com/436e15467dbc9b41d9a36d87d47c2481 1 2 3 4 5 6 7 8 9 10 11 12 expire_action : action = > [ ' index ' , ' show '] e xpir e_f ragment ' movie ' end end Figure 12.5: (Top) As of Rails 4, caching and observers are provided by separate gems, which must be included in the Gemfile. (Middle) Line 2 speci\ufb01es that Rails should cache the result of the show action. Action caching is implemented as a before-\ufb01lter that checks whether a cached version should be used and an around-\ufb01lter that captures and caches the rendered output, making it an example of the Decorator design pattern (Section 11.4). (Bottom) This \u201csweeper,\u201d referenced by line 3 of the controller, uses the Observer design pattern (Section 11.7) to add ActiveRecord lifecycle hooks (Section 5.1) to expire any objects that might become stale as a result of updating a particular movie. example. Note that in Rails page caching, the name of the cached object ignores embedded parameters in URIs such as /movies?ratings=PG+G, so parameters that affect how the page would be displayed should instead be part of the RESTful route, as in /movies/ratings/ PG+G. the layout does. An in-between case involves action caching in which the main page content doesn\u2019t change, but For example, your app/views/layouts/ application.html.erb may include a message such as \u201cWelcome, Alice\u201d contain- ing the name of the logged-in user. To allow action caching to work properly in this case, passing :layout=>false to caches_action will result in the layout getting fully re-rendered but the action (content part of the page) taking advantage of the action cache. Keep in mind that since the controller action won\u2019t be run, any such dynamic content appearing in the layout must be set up in a before-\ufb01lter. Page-level caching isn\u2019t useful for pages whose content changes dynamically. For exam- ple, the list of movies page (MoviesController#index action) changes when new movies are added or when the user \ufb01lters the list by MPAA rating. But we can still bene\ufb01t from caching by observing that the index page consists largely of a collection of table rows, each of which depends only on the attributes of one speci\ufb01c movie. Indeed, that observation al- lowed us to factor out the code for one row into a partial, as Figure 5.1 (Section 5.1) showed. Figure 12.6 shows how a trivial change to that partial caches the rendered HTML fragment corresponding to each movie. 390 CHAPTER 12. DEV/OPS <% cache ( movie ) do % > < div class = \" row \" > https://gist.github.com/f7e6de0cc4bb0fa21e34da8432bd413e 1 2 3 4 5 6 7 </ div > <% end % > < div class = \" col -8 \" > <%= link_to movie . title , movie_path ( movie ) % > </ div > < div class = \" col -2 \" > <%= movie . rating % > </ div > < div class = \" col -2 \" > <%= movie . release_date . strftime ( '% F ') % > </ div > Figure 12.6: Compared to Figure 5.1 in Section 5.1, only two lines have been added, to \u201cwrap\u201d the rendered content with a call to cache. Rails will generate a name for the cached fragment based on the pluralized resource name and primary key, for example, movies/23. A convenient shortcut provided by Rails is that if the argument to cache is an ActiveRe- cord object whose table includes an updated_at or updated_on column, the cache will auto-expire a fragment if its table row has been updated since the fragment was \ufb01rst cached. Nonetheless, for clarity, line 10 of the sweeper in Figure 12.5 shows how to explicitly expire a fragment whose name matches the argument of cache whenever the underlying movie object is saved or destroyed. Unlike action caching, which avoids running the controller action at all, checking the fragment cache occurs after the controller action has run. Given this fact, you may already be wondering how fragment caching helps reduce the load on the database. For example, suppose we add a partial to the list of movies page to display the @top_5 movies based on average review scores, and we add a line to the index controller action to set up the variable: https://gist.github.com/3727b1cf67ba36339f999c4be9623034 1 2 3 4 5 6 7 8 <! - - a cacheable partial for top movies --> <% - cache ( ' top_moviegoers ') do % > <% - @top_5 . each do | movie | <li > <%= movie . name % > <% end % > < ul id = \" topmovies \" > </ ul > <% end % > </ li > % > def index class MoviesController < A p p l i c a t i o n C o n t r o l l e r https://gist.github.com/090b252fc85756ad441e38d5106a5906 1 2 3 4 5 6 7 order ( \" AVG ( potatoes ) DESC \" ) . limit (5) @movies = Movie . all @top_5 = Movie . joins (: reviews ) . group ( ' movie_id ') . end end Action caching is now less useful, because the index view may change when a new movie is added or when a review is added (which might change what the top 5 reviewed movies are). If the controller action is run before the fragment cache is checked, aren\u2019t we negating the bene\ufb01t of caching, since setting @top_5 in lines 4\u20135 of the controller method causes a database query? Surprisingly, no. In fact, lines 4\u20135 don\u2019t cause a query to happen: they construct an object that can do the query if it\u2019s ever asked for the result! This is called lazy evaluation, an enor- mously powerful programming-language technique that comes from the lambda calculus underlying functional programming. Lazy evaluation is used in Rails\u2019 ActiveRelation (ARel) subsystem, which is used by ActiveRecord. The actual database query doesn\u2019t happen until each is called in line 4 of the partial, because that\u2019s the \ufb01rst time the ActiveRelation object is asked to produce a value. But since that line is inside the cache block starting on line 2, if 12.7. AVOIDING ABUSIVE DATABASE QUERIES 391 No cache Action cache"
    ]
  },
  {
    "id": "sec_0598",
    "title": "449 ms",
    "pages": [
      403
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0599",
    "title": "57 ms",
    "pages": [
      403
    ],
    "text_blocks": [
      "Speedup no cache 8x vs. Page cache 21ms vs. Speedup no cache 21x vs. Speedup action cache 3x Figure 12.7: For a PostgreSQL shared database on Heroku containing 1K movies and over 100 reviews per movie, the table shows the time in milliseconds to retrieve a list of the \ufb01rst 100 reviews sorted by creation date, with and without page and action caching. The numbers are from the log \ufb01les visible with heroku logs. Earlier versions of Rails lacked lazy query evaluation, so controller actions had to explicitly check the fragment cache to avoid needless queries\u2014 very non-DRY. the fragment cache hits, the line will never be executed and therefore the database will never be queried. Of course, you must still include logic in your cache sweeper to correctly expire the top-5-movies fragment when a new review is added. In summary, both page- and fragment-level caching reward our ability to separate things that change (non-cacheable units) from those that stay the same (cacheable units). In page or action caching, split controller actions protected by before-\ufb01lters into an \u201cunprotected\u201d action that can use page caching and a \ufb01ltered action that can use action caching. (In an extreme case, you can even enlist a content delivery network (CDN) such as Amazon CloudFront to replicate the page at hundreds of servers around the world.) In fragment caching, use partials to isolate each cacheable entity, such as a single model instance, into its own partial that can be fragment-cached. Summary: To maximize the bene\ufb01ts of caching, separate cacheable from non-cacheable units: con- troller actions can be split into cacheable and non-cacheable versions depending on whether a before-\ufb01lter must be run, and partials can be used to break up views into cacheable fragments. Elaboration: Where are cached objects stored? In development, cached objects are generally stored in the local \ufb01le system. Heroku offers add-ons such as Memcachier that store cached content in the in-memory database memcached (pronounced mem-cash-dee; the suf\ufb01x -d re\ufb02ects the Unix convention for naming daemon processes that run constantly in the background). Rails cache stores must implement a com- mon API so that different stores can be used in different environments\u2014a great example of Dependency Injection, which we encountered in Section 11.6. Self-Check 12.6.1. We mentioned that passing :layout=>false to caches_action pro- vides most of the bene\ufb01t of action caching even when the page layout contains dynamic ele- ments such as the logged-in user\u2019s name. Why doesn\u2019t the caches_page method also allow this option? Since page caching is handled by the presentation tier, not the logic tier, a hit in the page cache means that Rails is bypassed entirely. The presentation tier has a copy of the whole page, but only the logic tier knows what part of the page came from the layout and what part came from rendering the action."
    ]
  },
  {
    "id": "sec_0600",
    "title": "12.7 Avoiding Abusive Database Queries",
    "pages": [
      403,
      404,
      405,
      406
    ],
    "text_blocks": [
      "As we saw in Section 12.2, the database will ultimately limit horizontal scaling\u2014not because you run out of space to store tables, but more likely because a single computer can no longer 392 CHAPTER 12. DEV/OPS # assumes class Moviegoer with has_many : movies , : through = > : reviews # in controller method : @fans = Moviegoer . where ( \" zip = ? \" , code ) # table scan if no index ! - fan . movies . each do | movie | # in view : - @fans . each do | fan | https://gist.github.com/c1527e55d6197620bc9bcc56168e4299 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // BAD : each time thru this loop causes a new database query ! % p = movie . title # better : eager loading of the association in controller . # Rails automatically traverses the through - association between # Moviegoers and Movies through Reviews @fans = Moviegoer . where ( \" zip = ? \" , code ) . includes (: movies ) # GOOD : preloading movies reviewed by fans avoids N queries in view . # BAD : preload association but don 't use it in view : - @fans . each do | fan | % p = @fan . name // BAD : we never used the : movies that were preloaded ! Figure 12.8: The query in the controller action (line 4) accesses the database once to retrieve rows of @fans, but each pass through the loop in lines 8\u201310 causes another separate database access, resulting in n + 1 accesses for a fan who has reviewed n movies. Line 15, in contrast, performs a single eager load query that also retrieves all the movies, which is nearly as fast as line 4 since most of the overhead of small queries is in performing the database access. sustain the necessary number of queries per second while remaining responsive. When that happens, you will need to turn to techniques such as sharding and replication, which are beyond the scope of this book (but see To Learn More for some suggestions). Even on a single computer, database performance tuning is enormously complicated. The widely-used open source database MySQL has dozens of con\ufb01guration parameters, and most database administrators (DBAs) will tell you that at least half a dozen of these are \u201ccritical\u201d to getting good performance. Therefore, we focus on how to keep your database usage within the limit that will allow it to be hosted by a PaaS provider: Heroku, Amazon Web Services, Microsoft Azure, and others all offer hosted relational databases managed by professional DBAs responsible for baseline tuning. Many useful SaaS apps can be built at this scale\u2014for example, all of Pivotal Tracker12 \ufb01ts in a database on a single computer. One way to relieve pressure on your database is to avoid needlessly expensive queries. Two common mistakes for less-experienced SaaS authors arise in the presence of associa- tions: 1. The n+1 queries problem occurs when traversing an association performs more queries than necessary. 2. The full table scan problem occurs when your tables lack the proper indices to speed up certain queries. (This problem can occur even in the absence of associations, but is extremely common when associations are used.) Lines 1\u201317 of Figure 12.8 illustrate the so-called n+1 queries problem when traversing as- sociations, and also show why the problem is more likely to arise when code creeps into your views: there would be no way for the view to know the damage it was causing. Of course, just as bad is eager loading of information you won\u2019t use, as in lines 18\u201321 of Figure 12.8. The bullet13 gem helps detect both problems. 12.7. AVOIDING ABUSIVE DATABASE QUERIES 393 class A d d E m a i l I n d e x T o M o v i e g o e r s < ActiveRecord :: Migration def change https://gist.github.com/02eafcc5a821c1dacc355f4df7300ac0 1 2 3 4 5 6 7 add_index ' moviegoers ' , ' email ' , : unique = > true # : unique is optional - see text for important warning ! add_index ' moviegoers ' , ' zip ' end end Figure 12.9: Adding an index on a column speeds up queries that match on that column. The index is even faster if you specify :unique, which is a promise you make that no two rows will have the same value for the indexed attribute; to avoid errors in case of a duplicate value, use this in conjunction with a uniqueness validation as described in Section 5.1. # of reviews: Read 100, no indices Read 100, FK indices Performance 20,000 2000 1.33 0.94 0.63 0.57 166% 212% 200,000 5.28 0.65 808% Create 1K, no indices Create 1K, all indices Performance 200,000 9.69 11.30 \u201317% Figure 12.10: For a PostgreSQL shared database on Heroku containing 1K movies, 1K moviegoers, and 2K to 200K reviews, this table shows the bene\ufb01ts and penalties of indexing. The \ufb01rst part compares the time in seconds to read 100 reviews with no indices vs. with foreign key (FK) indices on movie_id and moviegoer_id in the reviews table. The second part compares the time to create 1,000 reviews in the absence of indices and in the presence of indices over every possible pair of reviews columns, showing that even in this pathological case, the penalty for using indices is slight. Another database abuse to avoid is queries that result in a full table scan. Consider line 4 of Figure 12.8: in the worst case, the database would have to examine every row of the moviegoers table to \ufb01nd a match on the zip column, so the query will run more and more slowly as the table grows, taking time O(n) for a table with n rows. The solution is to add a database index on the moviegoers.zip column, as Figure 12.9 shows. An index is a separate data structure maintained by the database that uses hashing techniques over the column values to allow constant-time access to any row when that column is used as the constraint. You can have more than one index on a given table and even have indices based on the values of multiple columns. Besides obvious attributes named explicitly in where queries, foreign keys (the subject of the association) should usually be indexed. For example, in Figure 12.8, the moviegoer_id \ufb01eld in the reviews table would need an index in order to speed up the query implied by fan.movies. Of course, indices aren\u2019t free: each index takes up space proportional to the number of table rows, and since every index on a table must be updated when table rows are added or modi\ufb01ed, updates to heavily-indexed tables may be slowed down. However, because of the read-mostly behavior of typical SaaS apps and their relatively simple queries compared to other database-backed systems such as Online Transaction Processing (OLTP), your app will likely run into many other bottlenecks before indices begin to limit its performance. Fig- ure 12.10 shows an example of the dramatic performance improvement provided by indices. 394 Summary: CHAPTER 12. DEV/OPS \u2022 The n + 1 queries problem, in which traversing a 1-to-n association results in n + 1 short queries rather than a single large query, can be avoided by judicious use of eager loading. \u2022 Full-table scans in queries can be avoided by judicious use of database indices, but each index takes up space and slows down update performance. A good starting point is to create indices for all foreign key columns and all columns referenced in the where clause of frequent queries. Elaboration: SQL EXPLAIN Many SQL databases, including MySQL and PostgreSQL (but not SQLite), support an EXPLAIN command that describes the query plan: which tables will be accessed to perform a query and which of those tables have indices that will speed up the query. Unfortunately, the output format of EXPLAIN is database-speci\ufb01c. Starting with Rails 3.2, EXPLAIN is automatically run14 on queries that take longer than a developer-speci\ufb01ed threshold in devel- opment mode, and the query plan is written to development.log. The query_reviewer15 gem, which currently works only with MySQL, runs EXPLAIN on all queries generated by ActiveRecord and inserts the results into a div at the top of every page view in development mode. Self-Check 12.7.1. An index on a database table usually speeds up ____ at the expense of ____ and ____. Query performance at the expense of space and table-update performance"
    ]
  },
  {
    "id": "sec_0601",
    "title": "12.8 CHIPS: Exploiting Caching and Indices",
    "pages": [
      406
    ],
    "text_blocks": [
      "CHIPS 12.8: The bene\ufb01ts of caching in SaaS https://github.com/saasbook/hw-indices-performance Enhance RottenPotatoes\u2019 performance by adding caching and database indices as appropriate, and measure the performance improvement from each enhancement."
    ]
  },
  {
    "id": "sec_0602",
    "title": "12.9 Security: Defending Customer Data in Your App",
    "pages": [
      406,
      407,
      408,
      409,
      410,
      411,
      412
    ],
    "text_blocks": [
      "As security is its own \ufb01eld in computing, there is no shortage of material to review or topics to study. Perhaps as a result, security experts have boiled down their advice into principles that developers can follow. Here are three: \u2022 The principle of least privilege states that a user or software component should be given no more privilege\u2014that is, no further access information and resources\u2014than what is necessary to perform its assigned task. This is analogous to the \u201cneed-to-know\u201d principle for classi\ufb01ed information. One example of this principle in the Rails world is that the Unix processes corresponding to your Rails app, your database, and the Web 12.9. SECURITY: DEFENDING CUSTOMER DATA IN YOUR APP 395 server (presentation tier) should run with low privilege and in an environment where they cannot even create new \ufb01les in the \ufb01le system. Good PaaS providers, including Heroku, offer a deployment environment con\ufb01gured in just this way. \u2022 The principle of fail-safe defaults states that unless a user or software component is given explicit access to an object, it should be denied access to the object. That is, the default should be denial of access. Proper use of strong parameters as described in Section 5.2 follows this principle. \u2022 The principle of psychological acceptability states that the protection mechanism should not make the app harder to use than if there were no protection. That is, the user interface needs to be easy to use so that the security mechanisms are routinely followed. The rest of this section covers six speci\ufb01c security vulnerabilities that are particularly relevant for SaaS applications: protecting data using encryption, cross-site request forgery, SQL injection and cross-site scripting, clickjacking, prohibiting calls to private controller methods, and self-denial-of-service. Protecting Data Using Encryption. Since competent PaaS providers make it their busi- ness to stay abreast of security-related issues in the infrastructure itself, developers who use PaaS can focus primarily on attacks that can be thwarted by good coding practices. Data- related attacks on SaaS attempt to compromise one or more of the three basic elements of security: privacy, authenticity, and data integrity. The goal of Transport Layer Secu- rity (TLS) and its predecessor Secure Sockets Layer (SSL) is to encrypt all HTTP traf\ufb01c by transforming it using cryptographic techniques driven by a secret (such as a password) known only to the two communicating parties. Running HTTP over such a secure connection is called HTTPS. Establishing a shared secret with a site you\u2019ve never visited before is a challenging prob- lem whose practical solution, public key cryptography , is credited to Ron Rivest, Adi Shamir and Len Adleman (hence RSA). A principal or communicating entity generates a keypair consisting of two matched parts, one of which is made public (accessible to everyone in the world) and the other of which is kept secret. A keypair has two important properties: 1. A message encrypted using the private key can only be decrypted using the public key, and vice-versa. 2. The private key cannot be deduced from the public key, and vice-versa. Property 1 provides the foundation of public-key encryption: if you receive a message that is decryptable with Bob\u2019s public key, only someone possessing Bob\u2019s private key could have created it. A variation is the digital signature: to attest to a message, Bob generates a one-way digest of the message (a short \u201c\ufb01ngerprint\u201d that would change if the message were altered) and encrypts the digest using his private key as a way of attesting \u201cI, Bob, vouch for the information in the message represented by this digest.\u201d To offer secure access to his site rottenpotatoes.com, Bob generates a keypair con- sisting of a public part KU and a private part KP. He proves his identity using conventional means such as government-issued IDs to a certi\ufb01cate authority (CA) such as VeriSign. The CA then uses its own private key CP to sign a public key certi\ufb01cate that states, in effect, \u201crottenpotatoes.com has public key KU.\u201d Bob installs the certi\ufb01cate on his server and Alice and Bob are the archetypal principals who appear in security scenarios, along with eavesdropper Eve, malicious Mallory, and other colorful characters. force_ssl is implemented as a top-level before-action that causes an immediate redirect from http://site/route to https://site/route. 396 CHAPTER 12. DEV/OPS enables his SaaS stack to accept secure connections\u2014usually trivial in a PaaS environment. Finally, he enables secure connections in his Rails app by adding config.force_ssl=true to his config/environments/production.rb, which turns on secure connections in pro- duction but not for development or testing. The CA\u2019s public key CU is built into most Web browsers, so when Alice\u2019s browser \ufb01rst connects to https://rottenpotatoes.com and requests the certi\ufb01cate, it can ver- ify the CA\u2019s signature and obtain Bob\u2019s public key KU from the certi\ufb01cate. Alice\u2019s browser then chooses a random string as the secret, encrypts it using KU, and sends it to rottenpotatoes.com, which alone can decrypt it using KP. This shared secret is then used to encrypt HTTP traf\ufb01c using much faster symmetric-key cryptography for the duration of the session. At this point, any content sent via HTTPS is reasonably secure from eaves- droppers, and Alice\u2019s browser believes the server it\u2019s talking to is the genuine RottenPotatoes server, since only a server possessing KP could have completed the key exchange step. It\u2019s important to recognize that this is the limit of what a secure HTTP connection can do. In particular, the server knows nothing about Alice\u2019s identity, and no guarantees can be made about Alice\u2019s data other than its privacy during transmission to RottenPotatoes. Cross-site request forgery. A CSRF attack (sometimes pronounced \u201csea-surf\u201d) involves tricking the user\u2019s browser into visiting a different web site for which the user has a valid cookie, and performing an illicit action on that site as the user. For example, suppose Alice has recently logged into her MyBank.com account, so her browser now has a valid cookie for MyBank.com showing that she is logged in. Now Alice visits a chat forum where malicious Mallory has posted a message with the following embedded \u201cimage\u201d: https://gist.github.com/4c84e87311f79ce0187b23f915f05e8e 1 2 3 < img src =\" http :// mybank . com / transfer / mallory /5000\" > <p > Here 's a risque picture of me : </p > When Alice views the chat message, or if she receives an email with the \u201cimage\u201d link em- bedded in it, her browser will try to fetch the image from this RESTful URI, which happens to transfer $5000 into Mallory\u2019s account. Alice will see a \u201cbroken image\u201d icon without real- izing the damage. CSRF is often combined with Cross-site Scripting (see below) to perform more sophisticated attacks. There are two steps to thwarting such attacks. The \ufb01rst is to ensure that RESTful actions performed using the GET HTTP method have no side effects. An action such as bank with- drawal or completing a purchase should be handled by a POST. This makes it harder for the attacker to deliver the \u201cpayload\u201d using embedded asset tags like IMG, which browsers always handle using GET. The second step is to insert a randomly-generated string based on the cur- rent session into every page view and arrange to include its value as a hidden form \ufb01eld on every form. This string will look different for Alice than it will for Bob, since their sessions are distinct. When a form is submitted without the correct random string, the submission is rejected. Rails automates this defense: all you need to do is render csrf_meta_tags in every such view and add protect_from_forgery to any controller that might handle a form submission. Indeed, when you use rails new to generate a new app, these defenses are included in app/views/layouts/application.html.erb and app/controllers/ application_controller.rb respectively. SQL injection and cross-site scripting. Both of these attacks exploit SaaS apps that handle attacker-provided content unsafely. Defending against both can be summarized by the same advice: sanitize any content coming from the user. In SQL injection, Mallory enters form data that she hopes will be interpolated directly into a SQL query statement executed 12.9. SECURITY: DEFENDING CUSTOMER DATA IN YOUR APP 397 def search class M ovi e sController https://gist.github.com/9181ed068de114441d4bc1a1c8c2aa74 1 2 3 4 5 6 end end movies = Movie . where ( \" name = '#{ params [: title ]} ' \" ) # UNSAFE ! # movies = Movie . where (\" name = ?\" , params [: title ]) # safe Figure 12.11: Code that is vulnerable to a SQL injection attack. Uncommenting line 4 and deleting line 3 would thwart the attack using a prepared statement, which lets ActiveRecord \u201csanitize\u201d malicious input before inserting it in the query. params[:title] Aladdin \u2019); DROP TABLE \"movies\"; -- SQL statement SELECT \"movies\".* FROM \"movies\" WHERE (title=\u2019Aladdin\u2019) SELECT \"movies\".* FROM \"movies\" WHERE (title=\u201d); DROP TABLE \"movies\"; -- Figure 12.12: If Mallory enters the text in the second row of the table as a movie title, line 3 of Figure 12.11 becomes a dangerous SQL statement that deletes the whole table. (The \ufb01nal --, the SQL comment character, avoids executing any SQL code that might have come after DROP TABLE.) SQL injection was often successful against early frameworks such as PHP, in which queries were hand-coded by programmers. by the app. Figure 12.11 shows an example and its defense: using prepared statements, in which \u201cdangerous\u201d characters in parts of the SQL statement are properly escaped. In cross-site scripting (XSS), Mallory prepares a fragment of JavaScript code that performs a harmful action. Her goal is to get RottenPotatoes to render that fragment as part of a displayed HTML page, triggering execution of the script. Figure 12.13 shows how Mallory might try to do this, by creating a movie whose title attribute is a simple piece of JavaScript that will display an alert; real examples often include JavaScript code that steals Alice\u2019s valid cookie and transmits it to Mallory, who can now \u201chijack\u201d Alice\u2019s session by passing Alice\u2019s cookie as her own. Worse, even if the XSS attack only succeeds in reading the page content from another site and not the cookie, the page content might contain the CSRF-prevention token generated by csrf_meta_tags corresponding to Alice\u2019s session, so XSS is often used to enable CSRF. Fortunately, the Rails Erb renderer always escapes \u201cdangerous\u201d HTML characters by default, as the \ufb01gure shows; to prevent Erb from escaping a string s, you must render raw(s), and if you do so, you\u2019d better have a good reason for believing it is safe, such as having separately sanitized s when it was \ufb01rst received from Mallory. https://gist.github.com/729b807f39577bb830a15c0a4192e0cd 1 2 <h2 > <%= movie . title % > </ h2 > <p > Released on <%= movie . release_date % >. Rated <%= movie . rating % >. </ p > https://gist.github.com/eca0ede43a6bf8123440c5eadf8bc311 1 2 <h2 > < script > alert ( \" Danger ! \" ) ; </ script > </ h2 > <p > Released on 1992 -11 -25 00:00:00 UTC . Rated G . </p > https://gist.github.com/7542d15d9c33b025050327a1af802b11 1 2 <h2 >& lt ; script & gt ; alert ( \" Danger ! \" ) ;& lt ;/ script & gt ; </ h2 > <p > Released on 1992 -11 -25 00:00:00 UTC . Rated G . </p > Figure 12.13: Top: a fragment of a view template that Mallory hopes to exploit. Middle: Mallory creates a new movie whose \u201ctitle\u201d is the string <script>alert(\"Danger!\");</script>, hoping that RottenPotatoes will send an HTML page that causes the JavaScript code to be executed. Bottom: What RottenPotatoes actually sends; the Erb renderer automatically sanitizes any strings interpolated into HTML, thwarting Mallory\u2019s attack. Amazon is well protected against clickbait attacks; we use it only as an example. 398 CHAPTER 12. DEV/OPS Clickjacking or UI redress attacks are aimed at getting the user to take a UI action they normally wouldn\u2019t take, by obfuscating that action in the UI. Like XSS, they rely on deceiving the user regarding which site is actually displaying what they\u2019re seeing. For example, suppose you want to get many people to buy your widget on Amazon. First, create an unrelated page that has a \u201cbait button\u201d on it, such as \u201cClick here for a free gift card.\u201d Craft that page so that it loads the Amazon product page for your widget into an HTTP iframe, and uses CSS to make the framed Amazon page transparent (invisible) but layered logically on top of the bait page, so that the \u201cinvisible\u201d page is actually the one whose UI elements receive click events. Then position the framed page (more CSS) such that the Amazon \u201cBuy Now With 1-Click\u201d button is positioned directly over the bait button. The user thinks they\u2019re clicking the bait button, but in fact it\u2019s the Amazon button that receives the event and is activated. Of course, the user must be signed into Amazon for this to work, but there are many sites on which users have selected \u201cremember me\u201d so they don\u2019t have to login every time. Clickjacking was famously used in 2010 to garner many illegitimate Likes16 for a particular Facebook page. The most effective defense against clickjacking is to ensure your site\u2019s pages cannot be framed on another site. All modern browsers observe the X-Frame-Options HTTP header; if the value is SAMEORIGIN, framing of a page is only allowed by other pages from the same site. Rails 4 and later set this header by default, but in earlier versions, the secure_headers gem was necessary to set it explicitly. Prohibiting calls to private controller methods. It\u2019s not unusual for controllers to in- clude \u201csensitive\u201d helper methods that aren\u2019t intended to be called by end-user actions, but only from inside an action. Use protected for any controller method that isn\u2019t the target of a user-initiated action and check rake routes to make sure no routes include wildcards that could match a nonpublic controller action. Self-denial-of-service. A malicious denial-of-service attack seeks to keep a server busy doing useless work, preventing access by legitimate users. You can inadvertently leave your- self open to these attacks if you allow arbitrary users to perform actions that result in a lot of work for the server, such as allowing the upload of a large \ufb01le or generating an expensive report. For this reason, \u201cexpensive\u201d actions are usually handled by a separate background process. For example, with Heroku, your app can queue the action using a simple queue system such as Redis, and a Heroku background worker17 can be triggered to pull jobs off the queue and run them while the main app server remains available to respond to interactive requests. Uploading \ufb01les also carries other risks, so you should \u201coutsource\u201d that responsi- bility to other services; for example, many PaaS providers provide plugins for SaaS apps in popular languages facilitate the safe upload of \ufb01les to external cloud-based storage such as Amazon Simple Storage Service (S3). A \ufb01nal warning about security is in order. The \u201carms race\u201d between SaaS developers and evildoers is ongoing, so even a carefully maintained site isn\u2019t 100% safe. In addition to defending against attacks on customer data, you should also be careful about handling sensitive data. Don\u2019t store passwords in cleartext; store them encrypted, or better yet, rely on third-party authentication as described in Section 5.2, to avoid embarrassing incidents18 of19 password20 theft.21 Don\u2019t even think of storing credit card numbers, even encrypted. The Payment Card Industry association imposes an audit burden costing tens of thousands of dollars per year to any site that does this (to prevent credit22 card23 fraud24), and the burden is only slightly less severe if your code ever manipulates a credit card number even if you don\u2019t store it. Instead, of\ufb02oad this responsibility to sites like PayPal25 or Stripe26 that specialize in meeting these heavy burdens. 12.9. SECURITY: DEFENDING CUSTOMER DATA IN YOUR APP 399 Attack Eavesdropping Cross-site request forgery (CSRF) Cross-site scripting (XSS) SQL injection Executing protected actions Self-denial-of-service, slow clients pathologically protect_from_forgery csrf_meta_tags by example, all in (for includ- in main layout) and spec- in Rails Defenses Install SSL certi\ufb01cate and con\ufb01gure SaaS app to redirect all insecure HTTP connections to HTTPS Render views ing it ify ApplicationController Sanitize HTML during rendering (many modern view-rendering systems do this automatically) Use prepared queries with placeholders, rather than interpolating strings directly into queries Use before-\ufb01lters to guard sensitive pub- lic methods in controllers Use separate background workers to perform long-running tasks, rather than tying up the app server Figure 12.14: Some common attacks against SaaS apps and the Rails mechanisms that defend against them. Summary of defending customer data: \u2022 Following the principles of least privilege, fail-safe defaults, and psychological acceptability can lead to more secure systems. \u2022 Secure HTTP connections using TLS (formerly SSL) keep data private as it travels between the browser and server, and assure the browser of the server\u2019s identity, but provide no other guarantees. If the Certi\ufb01cate Authority that originally issued the certi\ufb01cate for the server\u2019s identity has been compromised, all bets are off, since it becomes possible to create counterfeit certi\ufb01cates that allow a rogue server to impersonate the legitimate server. \u2022 Developers who deploy on a well-curated PaaS should focus primarily on attacks that can be thwarted by good coding practices. Figure 12.14 summarizes some com- mon attacks on SaaS apps and the Rails mechanisms that thwart them. \u2022 In addition to deploying app-level defenses, particularly sensitive customer data should either be stored in encrypted form or not at all, by outsourcing its handling to specialized services. 400 CHAPTER 12. DEV/OPS Elaboration: Keeping secrets: Encryption at rest If your SaaS app\u2019s data is particularly sensitive, some PaaS providers offer encryption at rest, which encrypts the database \ufb01le itself in a way that is transparent to any legitimate connection to the database. For truly end-to-end encryption, you can also encrypt speci\ufb01c data by using a strong symmetric encryption algorithm with a large key size, such as AES-"
    ]
  },
  {
    "id": "sec_0603",
    "title": "128 , and make the encryption key available only as an environment variable. (Each PaaS",
    "pages": [
      412
    ],
    "text_blocks": [
      "provider has a way to set environment variables whose values are available to a running app, so that the key value appears nowhere in the program text.) While end-to-end encryption for conventional databases prevents search queries from working, recent research such as the work of Dr. Raluca Ada Popa at UC Berkeley27 has made great strides in computing on encrypted data, especially in encrypted-at-rest databases. Self-Check 12.9.1. True or false: If a site has a valid public key certi\ufb01cate, Cross-Site Re- quest Forgery (CSRF) and SQL Injection attacks are harder to mount against it. False. The security of the HTTP channel is irrelevant to both attacks. CSRF relies only on a site erroneously accepting a request that has a valid cookie but originated elsewhere. SQL injection relies only on the SaaS server code unsafely interpolating user-entered strings into a SQL query. Self-Check 12.9.2. Why can\u2019t CSRF attacks be thwarted by checking the Referer: header of an HTTP request? The header can be trivially forged."
    ]
  },
  {
    "id": "sec_0604",
    "title": "12.10 The Plan-And-Document Perspective on Operations",
    "pages": [
      412,
      413,
      414
    ],
    "text_blocks": [
      "Non-functional requirements can be more important than adding new features, as violations can cause loss of millions of dollars, millions of users, or both. For example, sales for Ama- zon.com in the fourth quarter of 2012 was $23.3B, so the loss of income due to Amazon being down just one hour would average $10M. That same year a break-in of the Nebraska Student Information System28 revealed social security numbers of anyone who applied to the University of Nebraska since 1985, estimated as 650,000 people. If customers can\u2019t trust a SaaS app, they will stop using it no matter what the set of features. Performance. Performance is not a topic of focus in conventional software engineering, in part because it has been the excuse for bad practices and in part because it is well covered elsewhere. Performance can be part of the non-functional requirements and then later in acceptance-level testing to ensure the performance requirement is met. Release Management. Plan-and-Document processes often produce software products that have major releases and minor releases. Using the Rails as an example, the last number of version 3.2.12 is a minor release, the middle number is a major release, and the \ufb01rst number is such a large change that it breaks APIs so that apps need to be ported again to this version. A release includes everything: code, con\ufb01guration \ufb01les, any data, and documentation. Release management includes picking dates for the release, information on how it will be distributed, and documenting everything so that you know what exactly is in the release and how to make it again so that it is easy to change when you have to make the next release. Release man- agement is considered a case of con\ufb01guration management in Plan-and-Document processes, which we review in Section 10.7. 12.10. OPERATIONS: PLAN & DOCUMENT PERSPECTIVE 401 Reliability. The main tool in our bag to make a system dependable is redundancy. By having more hardware than the absolute minimum needed to run the app and store the data, the system has the potential to continue even if a component fails. As all physical hardware has a non-zero failure rate, one redundancy guideline is to make sure there is no single point of failure, as it can be the Achilles\u2019 Heel of a system. Generally, the more redundancy the lower the chance of failure. As highly redundant systems can be expensive, it is important to have an adult conversation with the customer to see how dependable the app must be. Dependability is holistic, involving the software and the operators as well as the hard- ware. No matter how dependable the hardware is, errors in the software and mistakes by the operators can lead to outages that reduce the mean time between failures (MTBF). As dependency is a function of the weakest link in the chain, it may be more effective to train operators how to run the app or to reduce the \ufb02aws in the software than to buy more redun- dant hardware to run the app. Since \u201cto err is human,\u201d systems should include safeguards to tolerate and prevent operator errors as well as hardware failures. A foundational assumption of Plan-and-Document processes is that an organization can make the production of software predictable and repeatable by honing its process of software development, which should also lead to more reliable software. Hence, organizations com- monly record everything they can from projects to learn what they can do to improve their process. For example, the ISO 9001 standard is granted if companies have processes in place, a method to see if the process is being followed, and record the results for each project so as to make improvements in their process. Surprisingly, standardization approval is not about the quality of the resulting code, it is just about the development process. Finally, like performance, reliability can be measured. We can improve availability either taking longer between failures (MTBF) or by making the app reboot faster\u2014the mean time to repair (MTTR)\u2014as this equation shows: unavailability \u2248 MTTR MTBF (12.1) While it is hard to measure improvements in MTBF, as it can take a long time to record failures, we can easily measure MTTR. We just crash a computer and see how long it takes the app to reboot. And what we can measure, we can improve. Hence, it may be much more cost-effective to try to improve MTTR than to improve MTBF since it is easier to measure progress. However, they are not mutually exclusive, so developers can try to increase dependability by following both paths. Security. While reliability can depend on probability to calculate availability\u2014it is un- likely that several disks will fail simultaneously if the storage system is designed without hidden dependencies\u2014this is not the case for security. Here there is a human adversary who is probing the corner cases of your design for weaknesses and then taking advantage of them to break into your system. The Common Vulnerabilities and Exposures database29 lists common attacks to help developers understand the dif\ufb01culty of security challenges. Fortunately, defensive programming to make your system more robust against failures can also help make your system more secure. For example, in a bu\ufb00er over\ufb02ow attack, the adversary sends too much data to a buffer to overwrite nearby memory with their own code hidden inside the data. Checking the inputs to ensure that the user is not sending too much data can prevent such attacks. Similarly, the basis of arithmetic over\ufb02ow attack might be to supply such an unexpectedly large number that when added to another number it will look small due to the wraparound nature of over\ufb02ow with 32-bit arithmetic. Checking input 402 CHAPTER 12. DEV/OPS values or catching exceptions might prevent this attack. As computers today normally have multiple processors (\u201cmulticore\u201d), an increasingly common attack is a data race attack where the program has non-deterministic behavior depending on the input. These concurrent programming \ufb02aws are much harder to detect and correct. Testing security is much more challenging, but one approach is to use a tiger team as the adversaries who perform penetration tests. The team reports back to the developers the uncovered vulnerabilities. Summary Given the importance of keeping users\u2019 trust, non-functional features can be more impor- tant than functional features, especially for SaaS apps. \u2022 The Plan-and-Document processes speak little about performance, except as a po- tential piece of the Software Requirements Speci\ufb01cation that is later validated as part of the Top-Level Test Plan. \u2022 Releases, considered part of Con\ufb01guration Management, are signi\ufb01cant events in Plan-and-Document processes. A release wraps up everything about the project at that time, including documentation about how the release was made as well as the code, con\ufb01guration \ufb01les, data, and product documentation. \u2022 Redundancy is the key to dependable systems, with highly available systems aiming to have no single point of failure. The Mean Time Between Failures (MTBF) is a function of the whole system, including hardware and operators along with the software. Another way to improve availability that is easier to measure than MTBF is to concentrate on reducing Mean Time to Repair (MTTR). \u2022 Unlike the probabilistic basis for failures in dependability analysis, security is based on an intelligent adversary who is purposely exploiting unexpected events, such as buffer over\ufb02ows. Self-Check 12.10.1. Besides buffer over\ufb02ows, arithmetic over\ufb02ows, and data races, list an- other potential bug that can lead to security problems by violating one of the three security principles listed above. One example is improper initialization, which could violate the principle of fail-safe de- faults."
    ]
  },
  {
    "id": "sec_0605",
    "title": "12.11 Fallacies and Pitfalls",
    "pages": [
      414,
      415
    ],
    "text_blocks": [
      "Fallacy: All the extra effort for testing very rare conditions in Continuous Integration tests is more trouble than it\u2019s worth. At 1 million hits per day, a \u201crare\u201d one-in-a-million event is statistically likely every day. 1 million hits per day was Slashdot\u2019s volume in 2010. At 8 billion (8 \u00d7 109) hits per day, which was Facebook\u2019s volume in 201030, 8,000 \u201cone-in-a-million\u201d events can be expected per day. This is why code reviews at companies such as Google often focus on corner cases: at large scale, astronomically-unlikely events happen all the time (Brewer 2012). The extra resilience 12.11. FALLACIES AND PITFALLS 403 Activity Amazon.com page view Yahoo.com page view Google.com search results Bing.com search results Added latency Measured effect 1% drop in sales"
    ]
  },
  {
    "id": "sec_0606",
    "title": "100 ms",
    "pages": [
      415
    ],
    "text_blocks": [
      "5\u20139% drop in full-page traf\ufb01c"
    ]
  },
  {
    "id": "sec_0607",
    "title": "400 ms",
    "pages": [
      415
    ],
    "text_blocks": [
      "20% fewer searches performed"
    ]
  },
  {
    "id": "sec_0608",
    "title": "500 ms",
    "pages": [
      415
    ],
    "text_blocks": [
      "4.3% lower revenue per user"
    ]
  },
  {
    "id": "sec_0609",
    "title": "2000 ms",
    "pages": [
      415,
      416,
      417,
      418
    ],
    "text_blocks": [
      "Figure 12.15: The measured effects of added latency on users\u2019 interaction with various large SaaS apps, from Yahoo performance engineer Nicole Sullivan\u2019s \u201cDesign Fast Websites\u201d presentation33 and a joint presentation at the Velocity 2009 conference34 by Jake Brutlag of Google and Eric Schurman of Amazon. provided by error-handling code will help you sleep better at night. Pitfall: Hidden assumptions that differ between development and production environments. Section 2.6 explained how Bundler and the Gem\ufb01le automate the management of your app\u2019s dependencies on external libraries, and Section 4.2 explained how migrations auto- mate making changes to your database. Heroku relies on these mechanisms for successful deployment of your app. If you manually install gems rather than listing them in your Gem- \ufb01le, those gems will be missing or have the wrong version on Heroku. If you change your database manually rather than using migrations, Heroku won\u2019t be able to make the produc- tion database match your development database. Other dependencies of your app include the type of database (Heroku uses PostgreSQL), the versions of Ruby and Rails, the speci\ufb01c Web server used as the presentation tier, and more. While frameworks like Rails and deployment platforms like Heroku go to great lengths to shield your app from variation in these areas, using automation tools like migrations and Bundler, rather than making manual changes to your development environment, maximizes the likelihood that you\u2019ve documented your de- pendencies so you can keep your development and production environments in sync. If it can be automated and recorded in a \ufb01le, it should be! Fallacy: We don\u2019t have to worry about performance because 3-tier SaaS apps can scale horizontally and cloud computing is cheap. If you\u2019re using well-curated PaaS, and following the advice in this chapter for being kind to your database and leveraging caching, there is some truth to this statement up to a point. However, if your app \u201coutgrows\u201d PaaS, the fundamental problems of scalability and load balancing are now passed on to you. In other words, with PaaS you are not spared having to understand and avoid such problems, but you are temporarily spared from rolling your own solutions to them. When you start to set up your own system from scratch, it doesn\u2019t take long to appreciate the value of PaaS. In Chapter 1 we argued for trading today\u2019s extra compute power for more productive tools and languages. However, it\u2019s easy to take this argument too far. In 2008, performance engineer Nicole Sullivan reported on experiments conducted by various large SaaS operators about how additional latency affected their sites. Figure 12.15 clearly shows that when extra processor time becomes extra latency (and therefore reduced responsiveness) for the end user, processor cycles aren\u2019t free at all. Fallacy: The app is still in development, so we can ignore performance. Knuth has said that premature optimization is the root of all evil \u201c. . . about 97% of the 404 CHAPTER 12. DEV/OPS time.\u201d But the quote continues: \u201cYet we should not pass up our opportunities in that critical 3%.\u201d Blindly ignoring design issues such as lack of indices or needless repeated queries at design time is just as bad as focusing myopically on performance at design time. Being alert for, and avoiding, truly egregious performance mistakes will enable you to steer a happy path between two extremes. Pitfall: Optimizing without measuring. Some customers are surprised that Heroku doesn\u2019t automatically add Web server capacity when a customer app is slow (van Hardenberg 2012). The reason is that without instrument- ing and measuring your app, you don\u2019t know why it\u2019s slow, and the risk is that adding Web servers will make the problem worse. For example, if your app suffers from a database prob- lem such as lack of indices or n + 1 queries, or if it relies on a separate service like Google Maps that is temporarily slow, adding servers to accept requests from more users will only make things worse. Without measuring, you won\u2019t know what to \ufb01x. Pitfall: Abusing continuous deployment, leading to cruft accumulation. As we have already seen, evolving apps may grow to a point where a design change or architectural change would be the cleanest way to support new functionality. Since contin- uous deployment focuses on small incremental steps and tells us to avoid worrying about any functionality we don\u2019t need immediately, the app has the potential to accumulate a lot of cruft as more code is bolted onto an obsolete design. The increasing presence of code smells (Chapter 9) is often an early symptom of this pitfall, which can be avoided by periodic design and architecture reviews when smells start to creep in. Pitfall: Bugs in naming or expiration logic, leading to silently-wrong caching behavior. As we noted, the two problems you must tackle with any kind of caching are naming and expiration. If you inadvertently reuse the same name for different objects\u2014for example, a non-RESTful action that delivers different content depending on the logged-in user, but is always named using the same URI\u2014then a cached object will be erroneously served when it shouldn\u2019t be. If your sweepers don\u2019t capture all the conditions under which a set of cached objects could become invalid, users could see stale data that doesn\u2019t re\ufb02ect the results of recent changes, such as a movie list that doesn\u2019t contain the most recently added movies. Unit tests should cover such cases (\u201cCaching system when new movie is added should immediately re\ufb02ect new movie on the home page list\u201d). Follow the steps in the Rails Caching Guide35 to turn on caching in the testing and development environments, where it\u2019s off by default to simplify debugging. Pitfall: Slow external servers in an SOA that can adversely affect your own app\u2019s performance. If your app communicates with external servers in an SOA, you should be prepared for the possibility that those external servers are slow or unresponsive. The easy case is handling an unresponsive server, since a refused HTTP connection will result in a Ruby exception that you can catch. The hard case is a server that is functioning but very slow: by default, the call to the server will block (wait until the operation is complete or the TCP \u201cslow timeout\u201d expires, which can take up to three minutes), making your app slow down as well. Even if you are using a multi-threaded Rails app server such as unicorn, if each of N Web servers 12.11. FALLACIES AND PITFALLS 405 require ' timeout ' # call external service , but abort if no answer in 3 seconds : Timeout :: timeout (3.0) do https://gist.github.com/6f8966c1f952ae9615df8170d1bb4663 1 2 3 4 5 6 7 8 9 # potentially slow operation here # what to do if timeout occurs rescue Timeout :: Error begin end end Figure 12.16: Using timeouts around calls to an external service protects your app from becoming slow if the external service is slow. (\u201cdynos\u201d in Heroku\u2019s terminology) is feeding requests to an app server with T threads, it takes only N \u00d7 T simultaneous requests to hang your application completely. The solution is to use Ruby\u2019s timeout library to \u201cprotect\u201d the call, as the code in Figure 12.16 shows. Most modern app servers have some version of this mechanism built in, and allow it to be con\ufb01gured as part of the app server setup. Fallacy: My app is secure because it runs on a secure platform and uses \ufb01re- walls and HTTPS. There\u2019s no such thing as a \u201csecure platform.\u201d There are certainly insecure platforms, but no platform by itself can assure the security of your app. Security is a systemwide and ongoing concern: Every system has a weakest link, and as new exploits and software bugs are found, the weakest link may move from one part of the system to the other. The \u201carms race\u201d between evildoers and legitimate developers makes it increasingly compelling to use professionally-curated PaaS infrastructure, so you can focus on securing your app code. Fallacy: My app isn\u2019t a target for attackers because it serves a niche audience, experiences low volume, and doesn\u2019t store valuable information. Malicious attackers aren\u2019t necessarily after your app; they may be seeking to compromise it as a vehicle to a further end. For example, if your app accepts blog-style comments, it will become the target of blog spam, in which automated agents (bots) post spammy comments containing links the spammer hopes users will follow, either to buy something or cause mal- ware to be installed. If your app is open to SQL injection attacks, one motive for such an attack might be to in\ufb02uence the code that is displayed by your views so as to incorporate a cross-site scripting attack, for example to cause malware to be downloaded onto an unsus- pecting user\u2019s machine. Even without malicious attackers, if any aspect of your app goes \u201cviral\u201d and becomes suddenly popular, you\u2019ll be suddenly inundated with traf\ufb01c. The lesson is: If your app is publicly deployed, it is a target. Fallacy: Rails doesn\u2019t scale (or Django, or PHP, or other frameworks). With the shared-nothing 3-tier architecture depicted in Figure 12.2, the Web server and app server tiers (where Rails apps would run) can be scaled almost arbitrarily far by adding computers in each tier using cloud computing. The challenge lies in scaling the database, as the next Pitfall explains. Pitfall: Putting all model data in an RDBMS on a single server computer, thereby limiting scalability. 406 CHAPTER 12. DEV/OPS The power of RDBMSs is a double-edged sword. It\u2019s easy to create database structures prone to scalability problems that might not emerge until a service grows to hundreds of thousands of users. Some developers feel that Rails compounds this problem because its Model abstractions are so productive that it is tempting to use them without thinking of the scalability consequences. Unfortunately, unlike with the presentation and logic tiers, we cannot \u201cscale our way out\u201d of this problem by simply deploying many copies of the database, because this might result in different values for different copies of the same item (the data consistency problem). Although techniques such as primary/replica and database sharding help make the database tier more like the shared-nothing presentation and logic tiers, extreme database scalability remains an area of both research and engineering effort. Pitfall: Prematurely focusing on per-computer performance of your SaaS app. Although the shared-nothing architecture makes horizontal scaling easy, we still need physical computers to do it. Adding a computer used to be expensive (buy the computer), time-consuming (con\ufb01gure and install the computer), and permanent (if demand subsides later, you\u2019ll be paying for an idle computer). With cloud computing, all three problems are alleviated, since we can add computers instantly for pennies per hour and release them when we don\u2019t need them anymore. Hence, until a SaaS app becomes large enough to require hundreds of computers, SaaS developers should focus on horizontal scalability rather than per-computer performance."
    ]
  },
  {
    "id": "sec_0610",
    "title": "12.12 Concluding Remarks: Beyond PaaS Basics",
    "pages": [
      418,
      419,
      420,
      421,
      422
    ],
    "text_blocks": [
      "The database abuses described in Section 12.7 reveal that object-relational mapping layers such as ActiveRecord, like most abstractions, are leaky: they try to hide implementation details for the sake of productivity, but concerns about security and performance sometimes require the developer to have some understanding of how the abstractions are implemented. For example, the n + 1 queries problem is not obvious from looking at ActiveRecord queries, nor are queries that would be speeded up by eager loading of associations. In Chapter 4 we emphasized the importance of keeping your development and production environments as similar as possible. This is still good advice, but obviously if your production environment involves multiple servers and a huge database, it may be impractical to replicate in your development environment. So should you keep track of database performance in development if your production environment will be different? Absolutely. Heroku and other PaaS sites do a great job at tuning the baseline performance of their databases and software stack, but no amount of tuning can compensate for an app that forces the database to do inef\ufb01cient queries or fails to use caching to ease the load on the database. Given limited space, we focused on aspects of operations that every SaaS developer should know, even given the availability of PaaS. An excellent and more detailed book that focuses on challenges speci\ufb01c to SaaS and is laced with real customer stories is Michael Nygard\u2019s Release It! (Nygard 2007), which focuses more on the problems of \u201cunexpected success\u201d (sudden traf\ufb01c surges, stability issues, and so on) than on repelling malicious at- tacks. Understanding what happens during deployment and operations (especially automated deployment) is a prerequisite to debugging more complex performance problems. The vast majority of SaaS apps today, including those hosted on Windows servers, run in an environ- REFERENCES 407 ment based on the original Unix model of processes and input/output, so an understanding of this environment is crucial for debugging any nontrivial performance problems. The Unix Programming Environment (Kernighan and Pike 1984), coauthored by one of Unix\u2019s cre- ators, offers a high-bandwidth, learn-by-doing tour (using C!) of the Unix architecture and philosophy. Sharding and replication are powerful techniques for scaling a database that require a great deal of design thinking up front. While most frameworks have libraries to help with both, these techniques usually also require database-level con\ufb01guration changes, which many PaaS providers do not support. Sharding and replication have become particularly important with the emergence of \u201cNoSQL\u201d databases, which trade the expressiveness and data format independence of SQL for better scalability. The NoSQL Ecosystem, a chapter contributed by Adam Marcus to The Architecture of Open Source Applications (Marcus 2012), has a good treatment of these topics. Security is an extremely broad topic; our goal has been to help you avoid basic mistakes by using built-in mechanisms to thwart common attacks against your app and your customers\u2019 data. Of course, an attacker who can\u2019t compromise your app\u2019s internal data can still cause harm by attacking the infrastructure on which your app relies. Distributed denial of service (DDoS) \ufb02oods a site with so much traf\ufb01c that it becomes unresponsive for its intended users. A malicious client can leave your app server or Web server \u201changing on the line\u201d as it con- sumes output pathologically slowly, unless your Web server (presentation tier) has built-in timeouts. DNS spoo\ufb01ng tries to steer you to an impostor site by supplying an incorrect IP address when a browser looks up a host name, and is often combined with a person-in-the- middle attack (formerly \u201cman-in-the-middle\u201d) that falsi\ufb01es the certi\ufb01cate attesting to the server\u2019s identity. The impostor site then looks and behaves like the real site, and can \u201cprove\u201d its falsi\ufb01ed identity to your browser, but can now collect sensitive information from users. Nonetheless, despite occasional vulnerabilities, curated PaaS sites are more likely to employ experienced professional system administrators who stay abreast of the latest techniques for avoiding such vulnerabilities, making them the best \ufb01rst line of defense for your SaaS apps. Today\u2019s best practices in SaaS security call for thinking in terms of DevSecOps, in which security is a consideration throughout the entire process of development rather than a \u201csafety fence\u201d around an existing app. Indeed, DevSecOps is the approach we advocate in this book; its key recommendations include encapsulation of microservices, automated tests for security-related features (input validation, login/authentication, and so on) in your test suite, and automated patching of security vulnerabilities arising from libraries or other app depen- dencies. This last service is provided by the free GitHub Dependabot36, which scans your code for dependency vulnerabilities on each push and can even open pull requests automati- cally to update the vulnerable dependencies to a patched version. Finally, at some point the unthinkable will happen: your production system will enter a state where some or all users receive no service. Whether the app has crashed or is \u201chung\u201d (unable to make forward progress), from a business perspective the two conditions look the same, because the app is not generating revenue. In this scenario, the top priority is to restore service, which may require rebooting servers or doing other operations that destroy the post- mortem state you want to examine to determine what caused the problem in the \ufb01rst place. Generous logging can help, as the logs provide a semi-permanent record you can examine closely after service is restored. L. Barroso and J. Dean. The tail at scale: Tolerating variability in large-scale online services. Communications of the ACM, 2012. 408 NOTES N. Bhatti, A. Bouch, and A. Kuchinsky. Integrating user-perceived quality into web server design. In 9th International World Wide Web Conference (WWW\u20139), pages 1\u201316, 2000. E. Brewer. Personal communication, May 2012. B. W. Kernighan and R. Pike. Unix Programming Environment (Prentice-Hall Software Series). Prentice Hall Ptr, 1984. ISBN 013937681X. A. Marcus. The NoSQL ecosystem. In A. Brown, editor, The Architecture of Open Source Applications. lulu.com, 2012. ISBN 1257638017. URL http://www.aosabook.org/en/ nosql.html. R. B. Miller. Response time in man-computer conversational transactions. In Proceedings of the December 9-11, 1968, fall joint computer conference, part I, AFIPS \u201968 (Fall, part I), pages 267\u2013277, New York, NY, USA, 1968. ACM. doi: 10.1145/1476589.1476628. URL http://doi.acm.org/10.1145/1476589.1476628. M. T. Nygard. Release It!: Design and Deploy Production-Ready Software (Pragmatic Programmers). Pragmatic Bookshelf, 2007. ISBN 0978739213. P. van Hardenberg. Personal communication, April 2012. Notes 1https://projects.apache.org/project.html?httpd-http_server 2http://www.iis.net 3http://heroku.com 4https://workspace.google.com/terms/partner_sla.html 5http://www.apdex.org 6https://developers.google.com/speed 7https://www.flexera.com/products/cloud-management-platform.html 8https://github.com/jamesgolick/rollout 9http://newrelic.com 10http://www.hpl.hp.com/research/linux/httperf 11https://www.thinkwithgoogle.com/future-of-marketing/digital-transformation/the- google-gospel-of-speed-urs-hoelzle 12http://pivotaltracker.com 13https://github.com/flyerhzm/bullet 14http://weblog.rubyonrails.org/2011/12/6/what-s-new-in-edge-rails-explain 15http://github.com/nesquena/query_reviewer 16https://nakedsecurity.sophos.com/2010/05/31/viral-clickjacking-like-worm-hits- facebook-users/ 17https://devcenter.heroku.com/articles/background-jobs-queueing 18http://www.huffingtonpost.co.uk/2012/06/08/lastfm-hit-by-password-leak_n_1580012. html?ref=uk 19http://www.zdnet.com/blog/btl/26000-email-addresses-and-passwords-leaked-check- this-list-to-see-if-youre-included/50424 20http://www.neowin.net/news/main/09/10/05/thousands-of-hotmail-passwords-leaked- online 21http://hothardware.com/News/55000-Twitter-Accounts-Hacked-You-Should-Probably- Change-Your-Password/ 22http://www.businessweek.com/technology/content/jul2009/tc2009076_891369.htm 23http://www.msnbc.msn.com/id/17853440/#.T9JsqxztEmY 24http://redtape.msnbc.msn.com/_news/2012/03/30/10940640-global-payments-under-15- million-account-numbers-hacked?lite 25http://paypal.com NOTES 409 26http://stripe.com 27https://people.eecs.berkeley.edu/~raluca/ 28https://newsroom.unl.edu/announce/todayatunl/1336/7831 29http://cvedetails.com/ 30http://pingdom.com/blog/facebook-twitter-myspace-page-views 31http://www.slideshare.net/stubbornella/designing-fast-websites-presentation 32http://radar.oreilly.com/2009/06/bing-and-google-agree-slow-pag.html 33http://www.slideshare.net/stubbornella/designing-fast-websites-presentation 34http://radar.oreilly.com/2009/06/bing-and-google-agree-slow-pag.html 35http://guides.rubyonrails.org/caching_with_rails.html 36https://github.com/dependabot 13"
    ]
  },
  {
    "id": "sec_0611",
    "title": "Afterword",
    "pages": [
      422
    ],
    "text_blocks": [
      "The best way to predict the future is to invent it. \u2014Alan Kay"
    ]
  },
  {
    "id": "sec_0612",
    "title": "13.1 Looking Backwards",
    "pages": [
      422
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0613",
    "title": "13.2 Looking Forwards .",
    "pages": [
      422
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0614",
    "title": "13.3 Essential Readings .",
    "pages": [
      422
    ],
    "text_blocks": [
      "."
    ]
  },
  {
    "id": "sec_0615",
    "title": "13.4 Last Words .",
    "pages": [
      422,
      423,
      424
    ],
    "text_blocks": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 412 . 413 . 415 . 416 Alan Kay (1940\u2013) received the 2003 Turing Award for pioneering many of the ideas at the root of contemporary object- oriented programming languages. He led the team that developed the Smalltalk language, from which Ruby inherits its approach to object orientation. He also invented the \u201cDynabook\u201d concept, the precursor of today\u2019s laptops and tablet computers, which he conceived as an educational platform for teaching programming. Prerequisites and Concepts Concepts: 411 \u2022 Agile is not the right t for every project, nor is SaaS the right architecture for every project. But because of the virtuous triangle of SaaS, Agile, and Cloud Computing, this particular combination of ingredients has beneted all three areas, revolutionizing the future of software and making software development easier to learn. \u2022 In this book you\u2019ve used a successful distributed architecture (SaaS) and frameworks (Rails and jQuery). As an advanced software engineer, you\u2019ll likely need to create such frameworks or extend existing ones. Paying careful attention to principles that made these frameworks successful, and the lessons from the past that informed their design, can help. \u2022 Some of these lessons can be found in the wisdom captured in books about the software world. As George Santayana said, Those who do not know history are condemned to repeat it. We provide some suggestions of classics in the eld that we believe all software engineers would benet from reading. 412 CHAPTER 13. AFTERWORD Figure 13.1: The Virtuous Triangle of Engineering SaaS is formed from the three software engineering crown jewels of (1) SaaS on Cloud Computing, (2) Highly Productive Framework and Tools, and (3) Agile Development."
    ]
  },
  {
    "id": "sec_0616",
    "title": "13.1 Looking Backwards",
    "pages": [
      424,
      425
    ],
    "text_blocks": [
      "Figure 13.1, \ufb01rst seen in Chapter 1, shows the three \u201ccrown jewels\u201d on which the material in this book is based. Each pair of \u201cjewels\u201d forms synergistic bonds that support each other, as Figure 13.1 shows. In particular, the tools and related services of Rails makes it much easier to follow the Agile lifecycle. Figure 13.2 shows our oft-repeated Agile iteration, but this time it is decorated with the tools and services that we use in this book. These 14 tools and services support both following the Agile lifecycle and developing SaaS apps. Similarly, Figure 13.3 summarizes the relationship between phases of Plan-and-Document lifecycles and their Agile equivalents, showing how the techniques described in detail in this book play similar roles to those in earlier software process models. Rails is very powerful but has evolved tremendously since version 1.0, which was orig- inally extracted from a speci\ufb01c application. Indeed, the Web itself evolved from speci\ufb01c details to more general architectural patterns: \u2022 From static documents in 1990 to dynamic content by 1995; \u2022 From opaque URIs in the early 1990s to REST by the early 2000s; \u2022 From session \u201chacks\u201d (fat URIs, hidden \ufb01elds, and so on) in the early 1990s to cookies and real sessions by the mid 1990s; and 13.2. LOOKING FORWARDS 413 Figure 13.2: An iteration of the Agile software lifecycle and its relationship to the chapters in this book, with the supporting tools and services (red/bold letters) identi\ufb01ed with each step. Waterfall/Spiral Requirements gathering and analysis Periodic code reviews Periodic design reviews Test entire design after building Post-implementation Integration Testing Infrequent major releases Agile BDD with short iterations so customer participates in design Pair programming (pairs constantly re- viewing each others\u2019 code) Pull requests drive discussions about de- sign changes TDD to test continuously as you design Continuous integration testing Continuous deployment Chapter 7 10 10 8 12 12 Figure 13.3: While Agile methods aren\u2019t appropriate for all projects, the Agile lifecycle does embrace the same process steps as traditional models such as Waterfall and Spiral, but reduces each step in scope to a single iteration so that they can be done repeatedly and frequently, constantly re\ufb01ning a working version of the product. \u2022 From setting up and administering your own ad hoc servers in 1990 to deployment on \u201ccurated\u201d cloud platforms in the 2000s. The programming languages Java and Ruby offer another demonstration that good in- cremental ideas can be embraced quickly but great radical ideas take time before they are accepted. Java and Ruby are the same age, both appearing in 1995. Within a few years Java became one of the most popular programming languages, while Ruby remained primarily of interest to the programming languages literati. Ruby\u2019s popularity came a decade later with the release of Rails. Ruby and Rails demonstrate that big ideas in programming languages really can deliver productivity through extensive software reuse. Comparing Java and its frameworks to Ruby and Rails, (Stella et al. 2008) and (Ji and Sedano 2011) found factors of"
    ]
  },
  {
    "id": "sec_0617",
    "title": "3 to 5 reductions in number of lines of code, which is one indication of productivity.",
    "pages": [
      425
    ],
    "text_blocks": []
  },
  {
    "id": "sec_0618",
    "title": "13.2 Looking Forwards",
    "pages": [
      425,
      426,
      427
    ],
    "text_blocks": [
      "I\u2019ve always been more interested in the future than in the past. 414 CHAPTER 13. AFTERWORD \u2014Grace Murray Hopper Given this history of rapidly-evolving tools, patterns, and development methodologies, what might software engineers look forward to in the next few years? One software engineering technique that we expect to become popular in the next few years is delta debugging (Zeller 2002). It uses divide-and-conquer to automatically \ufb01nd the smallest input change that will cause a bug to appear. Debuggers usually use program anal- ysis to detect \ufb02aws in the code itself. In contrast, delta debugging identi\ufb01es changes to the program state that lead to the bug. It requires two runs, one with the \ufb02aw and one without, and it looks at the differences between the sets of states. By repeatedly changing the inputs and rerunning the program using a binary search strategy and automated testing, delta debug- ging methodically narrows the differences between the two runs. Delta debugging discovers dependencies that form a cause-effect chain, which it expands until it identi\ufb01es the smallest set of changes to input variables that causes the bug to appear. Although it requires many runs of the program, this analysis is done at full program speed and without the intervention of the programmer, so it saves development time. Program synthesis may be ready for a breakthrough. The state of the art today is that given incomplete segments of programs, program synthesis tools can often supply the missing code. One of the most interesting uses of this technology is in Microsoft Of\ufb01ce Excel 2013, called the Flash Fill feature, which does programming by example (Gulwani et al. 2012). You give examples of what you want to do to rows or columns of code, and Excel will attempt to repeat and generalize what you do. Moreover, you can correct its attempts to steer it to what you want (Gantenbein 2012). This split between Plan-and-Document and Agile development may become more pro- nounced with the advances in practicality of formal methods. The size of programs that can be formally veri\ufb01ed is growing over time, with improvements in tools, faster computers, and wider understanding of how to write formal speci\ufb01cations. If the work of careful speci\ufb01ca- tion in advance of coding could be rewarded by not needing to test and yet have thoroughly veri\ufb01ed programs, then the trade-offs would be crisp around change. For formal methods to work, clearly change needs to be rare. When change is commonplace, Agile is the answer, for change is the essence of Agile. While Agile works better than other software methodologies for some types of apps today, it is surely not the \ufb01nal answer in software development. If a new methodology could simplify including a good software architecture and good design patterns while maintaining Agile\u2019s ease of change, it could become more popular. Historically, a new methodology comes along every decade or two, so it may soon be time for a new one. This book itself was developed during the dawn of the Massive Open Online Course (MOOC) movement, which is another trend that we predict will become more signi\ufb01cant in the next few years. Like many other advances in this modern world, we wouldn\u2019t have MOOCs without SaaS and cloud computing. The enabling components were: \u2022 Scalable video distribution via services like YouTube. \u2022 Sophisticated autograders running on cloud computing that evaluate assignments im- mediately yet can scale to tens of thousands of students. \u2022 Discussion forums as a scalable solution to asking questions and getting answers from both other students and the staff. 13.3. ESSENTIAL READINGS 415 These components combine to form a wonderful, low-cost vehicle for students around the world. For example, it will surely improve continuing education of professionals in our fast changing \ufb01eld, enable gifted pre-college students to go beyond what their schools can teach, and let dedicated students around the world who do not have access to great universities still get a good education. MOOCs may even have the side effect of raising the quality bar for traditional courses by providing viable alternatives to ineffective lecturers. If MOOCs deliver on only half of these opportunities, they will still be a potent force in higher education."
    ]
  },
  {
    "id": "sec_0619",
    "title": "13.3 Essential Readings",
    "pages": [
      427,
      428
    ],
    "text_blocks": [
      "Software tools change rapidly: languages and frameworks go in and out of vogue every few years. Software engineering methodologies change over time as well: Agile wasn\u2019t the \ufb01rst methodology and won\u2019t be the last, and variations of Agile continue to evolve. It may therefore seem perilous to recommend a list of readings that all aspiring software engineers should read, much less a list of online sources. Nonetheless, some of the \ufb01eld\u2019s bedrock ideas and acquired wisdom has stood the test of time, and we believe all software engineers would bene\ufb01t by reading them. With some trepidation, we offer suggestions here, reminding the reader that we have no formal or \ufb01nancial connection to any of these works, although we do have professional or academic relationships with some of the authors. Software design and architecture. We have mentioned Unix numerous times in this book; it is arguably the most in\ufb02uential production operating system ever created. While many of our readers were probably \ufb01rst exposed to it as Linux, that is only the latest and most widely adopted implementation of the original kernel or \u201ccore\u201d of Unix, which chose and re\ufb01ned some of the best ideas from pioneering experimental systems such as Multics while greatly simplifying and streamlining some of its other aspects. Multics was an acronym for Multiplexed Information and Computing Service, with Multiplexed indicating that it was designed to serve multiple users simultaneously; the designers of Unix joked that their much smaller operating system might only be suitable for a single user at a time, so they named it Unics, later shortened to Unix. The structure of Unix, and its approach to program design and to the management of processes and machine resources, are pervasive. We can suggest no better book than the one written by two of its designers: The Unix Programming Environment by Brian Kernighan and Rob Pike. Even many non-Unix operating systems borrow heavily from Unix\u2019s models of process and resource management, and from a practical perspective, strong Unix toolsmithing skills are vital when you need to quickly produce some shell scripts to automate an otherwise tedious task. Software project management. When Turing Award winner Frederick P. Brooks Jr. wrote The Mythical Man-Month (Brooks 1995), there was no such thing as \u201cthe software industry.\u201d Software was generally written by programmers working for the companies that made the hardware, but the processes for estimating effort, coordinating the work of multi- ple team members, and performing quality control were far less evolved than they were for hardware design, which had a multiple-decade head start. Brooks\u2019s account of managing the OS/360 project\u2014the operating system for the groundbreaking IBM System/360, and far and away the most complex piece of commercial software ever written up to that time\u2014still holds valuable lessons for software project management, even if the economics of the industry have changed. If OS/360 was the face of software development in the 1960s, then collaboratively- 416 CHAPTER 13. AFTERWORD authored open-source development, exempli\ufb01ed by projects such as Linux, can be said to be at least part of the face of software development today. Developer Eric S. Raymond\u2019s The Cathedral and the Bazaar1 (Raymond 2001), while controversial, is a good starting point for understanding how collaborative open-source development came about and how it com- pares to traditional in-house closed-source (proprietary) development. As of this writing, both models are vital to the software industry, with some companies embracing both. For example, Facebook and Twitter do not generally release the source code to their products, but they have released open-source tools such as React and Bootstrap originally developed for internal use. The history of software. The evolution from proprietary early software to shrink- wrapped consumer software to SaaS is beautifully described in Martin Campbell-Kelly\u2019s From Airline Reservations to Sonic the Hedgehog: A History of the Software Industry (Campbell-Kelly 2003). For those interested in the corresponding history of hardware and the computing \ufb01eld generally, Paul Ceruzzi\u2019s A History of Modern Computing (Ceruzzi 2003) provides an outstanding overview; for the impatient, we recommend the much shorter and less detailed Computing: A Concise History by the same author (Ceruzzi 2012). The modern business of software. Today, software is a business, and as Chapter 10 emphasized, most often a team effort. Building and running a successful software enterprise requires balancing technical expertise with great strategies for recruiting, hiring, team build- ing, and retention. Joel Spolsky, creator of the project management tool Trello and co-creator of StackOver\ufb02ow, for several years wrote a blog called Joel On Software2, virtually every article of which is worth reading. You can read them online for free, or purchase the two books that collect and organize many of the posts by topic, Joel On Software and More Joel On Software (Spolsky 2004a,b). And if you\u2019re going to be managing software engineers (or anyone else for that matter), the actionable advice in The One Minute Manager (Blanchard and Johnson 1982) is hard to beat for clarity and conciseness. Software as craftsmanship. Throughout the book we\u2019ve af\ufb01rmed the value of beautiful, well-tested code. Code that is hard to understand or poorly covered by tests is resistant to en- hancement, and so is likely to be short-lived. Steve McConnell\u2019s Code Complete (McConnell 1993) justi\ufb01ably remains a classic on practical software construction techniques. Robert C. \u201cUncle Bob\u201d Martin\u2019s Clean Code: A Handbook of Agile Software Craftsmanship (Martin 2008) is an excellent and more recent companion to Code Complete that emphasizes taking a craftsperson\u2019s pride in beauty and elegance in the code you write. Both should be on every developer\u2019s bookshelf. Reading and rereading these books periodically will help keep their suggestions at top of mind when you\u2019re actually at work. Finally, to recommend a particular book is not to devalue any other particular book; no list of suggested readings can be de\ufb01nitive, complete, or fully objective. Nonetheless, we believe that these suggested \u201cclassics of the genre,\u201d which combine historical perspective with modern best practices, form a great starting point for software engineers wishing to really polish their skills while being fully aware of the work of those on whose shoulders they stand."
    ]
  },
  {
    "id": "sec_0620",
    "title": "13.4 Last Words",
    "pages": [
      428,
      429,
      430
    ],
    "text_blocks": [
      "Ultimately, it comes down to taste. It comes down to exposing yourself to the best things that humans have done, and then try to bring those things into what you\u2019re doing. \u2014Steve Jobs REFERENCES 417 Software helped put humans on the moon, led to the invention of lifesaving CAT scans, and enables eyewitness citizen journalism. By working as a software developer, you become part of a community that has the power to change the world. But with great power comes great responsibility. Faulty software caused the loss of the Ariane V rocket3 and Mars Observer4 as well as the deaths of several patients due to radiation overdoses from the Therac-25 machine5. While the early stories of computers and software are dominated by \u201cfrontier narratives\u201d of lone geniuses working in garages or at startups, software today is too important to be left to any one individual, however talented. As we said in Chapter 10, software development is now a team sport. We believe the concepts in this book increase the chances of you being both a responsible software developer and a part of a winning team. There\u2019s no textbook for getting there; just keep writing, learning, and refactoring to apply your lessons as you go. And as we said in the \ufb01rst chapter, we look forward to becoming passionate fans of the beautiful and long-lasting code that you and your team create! K. H. Blanchard and S. Johnson. The One Minute Manager. William Morrow, Cambridge, MA, 1982. F. P. Brooks. The Mythical Man-Month. Addison-Wesley, Reading, MA, Anniversary edi- tion, 1995. ISBN 0201835959. M. Campbell-Kelly. From Airline Reservations to Sonic the Hedgehog: A History of the Software Industry. MIT Press, Cambridge, MA, 2003. P. Ceruzzi. A History of Modern Computing. MIT Press, Cambridge, MA, 2003. P. Ceruzzi. Computing: A Concise History. MIT Press, Cambridge, MA, 2012. D. Gantenbein. Flash \ufb01ll gives Excel a smart charge, Feb 2012. URL http://research. microsoft.com/en-us/news/features/flashfill-020613.aspx. S. Gulwani, W. R. Harris, and R. Singh. Spreadsheet data manipulation using examples. Communications of the ACM, 55(8):97\u2013105, 2012. F. Ji and T. Sedano. Comparing extreme programming and waterfall project results. Con- ference on Software Engineering Education and Training, pages 482\u2013486, 2011. R. C. Martin. Clean Code: A Handbook of Agile Software Craftsmanship. Prentice Hall, 2008. ISBN 9780132350884. S. McConnell. Code Complete (Microsoft Programming Series). Microsoft Press, 1993. ISBN 1556154844. E. S. Raymond. The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revoluationary. O\u2019Reilly Media, Inc., 2001. J. Spolsky. Joel On Software. Apress, 2004a. J. Spolsky. More Joel On Software. Apress, 2004b. 418 NOTES L. Stella, S. Jarzabek, and B. Wadhwa. A comparative study of maintainability of web applications on J2EE, .NET and Ruby on Rails. 10th International Symposium on Web Site Evolution, pages 93\u201399, October 2008. Isolating cause-effect chains from computer programs. In Proceedings of the A. Zeller. 10th ACM SIGSOFT symposium on Foundations of software engineering, pages 1\u201310, New York, NY, USA, Nov 2002. ACM. doi: 10.1145/587051.587053. URL http://www.st. cs.uni-saarland.de/papers/fse2002/p201-zeller.pdf. Notes 1http://www.catb.org/~esr/writings/cathedral-bazaar 2https://joelonsoftware.com 3http://en.wikipedia.org/wiki/Ariane_5_Flight_501 4http://en.wikipedia.org/wiki/Mars_Observer 5http://en.wikipedia.org/wiki/Therac-25"
    ]
  }
]